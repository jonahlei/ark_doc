# 免费推理额度
Source: https://www.volcengine.com/docs/82379/1399514
方舟为新用户提供免费推理试用额度，便于新用户 0 成本学习以及尝试将模型推理能力与业务相结合。您只需要注册火山引擎，即可获得一定额度的免费调用模型推理服务的次数。
<span id="54eb3225"></span>
## 使用限制

* 免费额度仅适用于抵扣**按 token 后付费产生的在线推理费用**，不能抵扣使用各类插件、知识库等产生的费用。
* 免费额度无法抵扣[批量推理](https://www.volcengine.com/docs/82379/1305505)调用产生的 token。
* 免费额度可以抵扣使用上下文缓存命中缓存的token、未命中缓存的token、输出产生的token，但是无法抵扣缓存上下文产生的存储费用。
> * 上下文缓存介绍请参见[上下文缓存（Context API）概述](https://www.volcengine.com/docs/82379/1398933)。
> * 上下文缓存计费请参见[上下文缓存计费](https://www.volcengine.com/docs/82379/1099320#191d02ec)。
* 免费推理额度，不同模型分别计算，主账号下共享。
   举例说明：
   主账号如果有 A、B 2 个子账号调用模型推理服务，分别使用模型 1、模型 2 推理额度（k token）为 300、100，300、200 。模型 1、模型 2 的免费推理额度均为 500。则主账号下的免费额度剩余：

```Plain Text
模型1： 500 - 300 - 300 = -100 (k token)
模型2： 500 - 100 - 200 =  200 (k token）
```


   模型额度剩余如下：
   模型 1 ：0，且产生 100 k token 使用量。
   模型 2：200 k token 。
* 免费推理额度，基础模型和精调后模型共享。
   举例说明：
   假设模型 1 的免费推理额度为 500，则模型 1 和基于模型 1 精调后的模型，共享 500 的额度。

<span id="8b905b46"></span>
## 获取资格
[注册并认证](https://console.volcengine.com/auth/signup)火山引擎用户。
<span id="3fda7eda"></span>
## 查询额度
您可以通过下面渠道查询到各个模型的免费额度。

* [模型列表](https://www.volcengine.com/docs/82379/1330310)：无需登陆，可以查询各个模型的免费额度。
* [开通管理](https://www.volcengine.com/docs/82379/1159200)：登陆主账号，可以在控制台实时查询账号下免费额度抵扣情况。

<span id="1c6ad848"></span>
## 消耗额度
免费额度耗尽，调用将会失败，需要继续使用，需要手动开通对应的模型推理服务，开通方式请见[开通管理](https://www.volcengine.com/docs/82379/1159200)。
<span id="132a1082"></span>
## 抵扣规则
如果您参与了[协作奖励计划](https://www.volcengine.com/docs/82379/1391869)，可能会获得「协作奖励计划资源包」。本节为您介绍抵扣顺序的优先级：

* 不同类型的资源包：
   * 「免费在线推理资源包（即免费推理额度）」抵扣优先级高于「协作奖励计划资源包」。
* 同一类型的资源包：
   如果用户名下同时存在多个可抵扣的同类型资源包，则系统会按照如下优先级进行抵扣：失效时间>生效时间
   * 优先使用失效时间早的资源包；针对周期型资源包，失效时间指的是当前重置周期结束时间。
   * 若资源包失效时间都相同，则优先使用生效时间早的的资源包进行抵扣；针对周期型资源包，生效时间指的是当前重置周期开始时间。

<span id="71a90a45"></span>
## 安心体验模式
安心体验模式是针对**未开通过模型服务的新用户**更方便体验免费额度设计的，可以保障您免费体验模型推理服务，又不产生费用。在安心体验模式下，您调用推理 API 时仅消耗平台赠送的 50w token 免费额度，接近免费额度后服务将暂停，避免产生额外费用。详情请参见 [安心体验模式细则说明](https://www.volcengine.com/docs/82379/1465347)。



# 模型服务价格
Source: https://www.volcengine.com/docs/82379/1544106
不同模型服务支持的能力及单价各不相同，本文为您介绍各模型的计费公式及单价，方便您进行模型价格查阅和比较。

:::tip
* 如需了解模型服务各功能模块支持的计费方式及详细计费逻辑，请参见 [模型服务计费说明](https://www.volcengine.com/docs/82379/1544681)。
* 支持通过 [价格计算器](https://www.volcengine.com/pricing?product=ark_bd&tab=2) **预估** 满足业务需求所需的费用。
* 本文价格和 [定价详情页](https://www.volcengine.com/pricing?product=ark_bd&tab=1) 仅作为商品规格和价格的参考，具体可购买的商品规格及费用请以实际下单结果为准。
:::
<span id="76de5911"></span>
# 深度思考模型
<span id="aa1874cf"></span>
## 在线推理
> 按 token 后付费价格 

**计费公式**
在线推理费用 = 输入单价 × 输入token + 输出单价 × 输出token，其中输出 token 包括模型输出`content`内容和思维链
`reasoning_content`内容。

若开启 [上下文缓存](https://www.volcengine.com/docs/82379/1396489)（部分模型支持），
在线推理费用 = 输入单价 × (输入token - 缓存命中token) + 缓存命中单价 × 缓存命中token + 缓存存储单价 × 缓存存储token × 时长 + 输出单价 × 输出token

> * doubao-seed-1.6- 系列支持按照每次请求的输入长度（及输出长度），划分模型单价，如下表所示。
> * 举例，调用 doubao-seed-1.6 模型，当1个请求的输入长度为 200k，输出长度为 14k 时，满足 **输入长度 (128, 256]** 条件，模型产生的所有 token 按照：输入2.4 元/百万 token，输出 24 元/百万 token 单价计费。
> * 查看往期调用的输入输出长度分布，请查看常见问题 [如何查看历史调用的输入输出长度的区间分布？](https://www.volcengine.com/docs/82379/1359411#fba666f2)

**计费单价**

| | | | | | | \
|模型名称 |条件 |\
| |千 token |输入 |\
| | |元/百万 token |缓存存储 |\
| | | |元/百万 token /小时 |缓存命中 |\
| | | | |元/百万 token |输出 |\
| | | | | |元/百万 token |
|---|---|---|---|---|---|
| | | | | | | \
|doubao-seed-1.6 |输入长度 [0, 32] |\
| |且输出长度 [0, 0.2] |0.80 |0.017 |0.16 |2.00 |
|^^| | | | | | \
| |输入长度 [0, 32] |\
| |且输出长度  (0.2,+∞) |0.80 |0.017 |0.16 |8.00 |
|^^| | | | | | \
| |输入长度 (32, 128] |1.20 |0.017 |0.16 |16.00 |
|^^| | | | | | \
| |输入长度 (128, 256] |2.40 |0.017 |0.16 |24.00 |
| | | | | | | \
|doubao-seed-1.6-thinking |输入长度 [0, 32] |0.80 |0.017 |0.16 |8.00 |
|^^| | | | | | \
| |输入长度 (32, 128] |1.20 |0.017 |0.16 |16.00 |
|^^| | | | | | \
| |输入长度 (128, 256] |2.40 |0.017 |0.16 |24.00 |
| | | | | | | \
|doubao-seed-1.6-flash |输入长度 [0, 32] |0.15 |0.017 |0.03 |1.50 |
|^^| | | | | | \
| |输入长度 (32, 128] |0.30 |0.017 |0.03 |3.00 |
|^^| | | | | | \
| |输入长度 (128, 256] |0.60 |0.017 |0.03 |6.00 |
| | | | | | | \
|doubao-1.5-thinking-pro |\
|> 含`m-250415`、`m-250428`版本 |\- |4.00 |不支持 |不支持 |16.00 |
| | | | | | | \
|doubao-1.5-thinking-vision-pro |\- |3.00 |不支持 |不支持 |9.00 |
| | | | | | | \
|deepseek-r1  |\- |4.00 |0.017 |0.80 |16.00 |
| | | | | | | \
|deepseek-r1-distill-qwen-32b |\- |1.50 |0.017 |0.30 |6.00 |
| | | | | | | \
|deepseek-r1-distill-qwen-7b |\- |0.60 |不支持 |不支持 |2.40 |

<span id="3b4c540a"></span>
## 批量推理
> 按 token 后付费价格 
> 部分模型的批量推理价格是在线推理价格的50%，实际请以下面表格中的价格为准。

**计费公式**
批量推理费用 = 输入单价 × 输入token + 输出单价 × 输出token, 其中输出token包括模型输出`content`内容和思维链`reasoning_content`内容。

若开启缓存功能（部分模型于2025年4月14日21:00开始支持透明前缀缓存能力，无需任何配置，命中缓存后可享受更低的单价），
批量推理费用 = 输入单价 × (输入token 不支持 缓存命中token) + 缓存命中单价 × 缓存命中token + 输出单价 × 输出token

> * doubao-seed-1.6-** 系列支持按照每次请求的输入长度（及输出长度），划分模型单价，如下表所示。
> * 举例，调用 doubao-seed-1.6 模型，当1个请求的输入长度为 200k，输出长度为 14k 时，满足 **输入长度 (128, 256]** 条件，模型产生的所有 token 按照：输入1.2 元/百万 token，缓存命中输入0.16 元/百万 token，输出 12 元/百万 token 单价计费。
> * 查看往期调用的输入输出长度分布，请查看常见问题 [如何查看历史调用的输入输出长度的区间分布？](https://www.volcengine.com/docs/82379/1359411#fba666f2)


**计费单价**

| | | | | | \
|模型名称 |条件 |\
| |千 token |输入 |\
| | |元/百万token |缓存命中 |\
| | | |元/百万token |输出 |\
| | | | |元/百万token |
|---|---|---|---|---|
| | | | | | \
|doubao-seed-1.6 |输入长度 [0, 32] |\
| |且输出长度 [0, 0.2] |0.40 |0.16 |1.00 |
|^^| | | | | \
| |输入长度 [0, 32] |\
| |且输出长度 (0.2,+∞) |0.40 |0.16 |4.00 |
|^^| | | | | \
| |输入长度 [32, 128] |0.60 |0.16 |8.00 |
|^^| | | | | \
| |输入长度 (128, 256] |1.20 |0.16 |12.00 |
| | | | | | \
|doubao-seed-1.6-thinking |输入长度 [0, 32] |0.40 |0.16 |4.00 |
|^^| | | | | \
| |输入长度 [32, 128] |0.60 |0.16 |8.00 |
|^^| | | | | \
| |输入长度 (128, 256] |1.20 |0.16 |12.00 |
| | | | | | \
|doubao-seed-1.6-flash |输入长度 [0, 32] |0.075 |0.03 |0.75 |
|^^| | | | | \
| |输入长度 [32, 128] |0.150 |0.03 |1.50 |
|^^| | | | | \
| |输入长度 (128, 256] |0.300 |0.03 |3.00 |
| | | | | | \
|doubao-1.5-thinking-pro |\
|> 含`m-250425`版本 |\- |2.00 |不支持 |8.00 |
| | | | | | \
|doubao-1.5-thinking-vision-pro |\- |1.50 |不支持 |4.50 |
| | | | | | \
|deepseek-r1  |\- |2.00 |0.80 |8.00 |
| | | | | | \
|deepseek-r1-distill-qwen-32b  |\- |0.75 |不支持 |3.00 |
| | | | | | \
|deepseek-r1-distill-qwen-7b  |\- |0.30 |不支持 |1.20 |

<span id="1ed6d674"></span>
# 大语言模型
<span id="f026a2f1"></span>
## 在线推理
> 按 token 后付费价格 

**计费公式**
在线推理费用 = 输入单价 × 输入token + 输出单价 × 输出token

若开启 [上下文缓存](https://www.volcengine.com/docs/82379/1396489)（部分模型支持），
在线推理费用 = 输入单价 × (输入token - 缓存命中token) + 缓存命中单价 × 缓存命中token + 缓存存储单价 × 缓存存储token × 时长 + 输出单价 × 输出token

**计费单价**

| | | | | | \
|模型名称 |输入 |\
| |元/百万token |缓存存储 |\
| | |元/百万token/小时 |缓存命中 |\
| | | |元/百万token |输出 |\
| | | | |元/百万token |
|---|---|---|---|---|
| | | | | | \
|doubao-1.5-pro-32k |0.80 |0.017 |0.16 |2.00 |
| | | | | | \
|doubao-1.5-pro-256k |5.00 |不支持 |不支持 |9.00 |
| | | | | | \
|doubao-1.5-lite-32k |0.30 |0.017 |0.06 |0.60 |
| | | | | | \
|doubao-pro-32k |0.80 |0.017 |0.16 |2.00 |
| | | | | | \
|doubao-pro-256k |5.00 |不支持 |不支持 |9.00 |
| | | | | | \
|doubao-lite-4k |\
|包括分支版本 `character` |0.30 |不支持 |不支持 |0.60 |
| | | | | | \
|doubao-lite-32k |0.30 |0.017 |0.06 |0.60 |
| | | | | | \
|doubao-lite-128k |0.80 |不支持 |不支持 |1.00 |
| | | | | | \
|deepseek-v3 |2.00 |0.017 |0.40 |8.00 |

<span id="95d5626c"></span>
## 批量推理
> 按 token 后付费价格 
> 部分模型的批量推理价格是在线推理价格的50%，实际请以下面表格中的价格为准。

**计费公式**
批量推理费用 = 输入单价 × 输入token + 输出单价 × 输出token

若开启缓存功能（部分模型于2025年4月14日21:00开始支持透明前缀缓存能力，无需任何配置，命中缓存后可享受更低的单价），
批量推理费用 = 输入单价 × (输入token - 缓存命中token) + 缓存命中单价 × 缓存命中token + 输出单价 × 输出token

**计费单价**

| | | | | \
|模型名称 |输入 |\
| |元/百万token |缓存命中 |\
| | |元/百万token |输出 |\
| | | |元/百万token |
|---|---|---|---|
| | | | | \
|doubao-1.5-pro-32k  |0.40 |0.16 |1.00 |
| | | | | \
|doubao-1.5-pro-256k  |5.00 |不支持 |9.00 |
| | | | | \
|doubao-1.5-lite-32k   |0.15 |0.06 |0.30 |
| | | | | \
|doubao-pro-32k  |0.80 |0.16 |2.00 |
| | | | | \
|doubao-lite-32k  |0.30 |0.06 |0.60 |
| | | | | \
|deepseek-v3  |1.00 |0.40 |4.00 |

<span id="d52e5943"></span>
# 视觉理解模型
> 将输入信息（包括图片）转化为 token 计费

**计费公式**
推理费用 = 输入单价 × 输入token + 输出单价 × 输出token
图片token用量 = min(图片宽 × 图片高 ÷ 784, 单图 token 限制)，具体用量统计逻辑请参见 [token 用量说明](https://www.volcengine.com/docs/82379/1362931#f9ea084e)。
<span id="d260a1f6"></span>
## 在线推理
> 按 token 后付费价格 


| | | | \
|模型 |输入 |\
| |元/百万token |输出 |\
| | |元/百万token |
|---|---|---|
| | | | \
|doubao-1.5-vision-pro |3.00 |9.00 |
| | | | \
|doubao-1.5-vision-lite |1.50 |4.50 |
| | | | \
|doubao-1.5-ui-tars |3.50 |12.00 |
| | | | \
|doubao-1.5-vision-pro-32k |3.00 |9.00 |
| | | | \
|doubao-vision-pro-32k |3.00 |9.00 |
| | | | \
|doubao-vision-lite-32k |1.50 |4.50 |


<span id="b9130a37"></span>
## 批量推理
> 按 token 后付费价格 
> 部分模型的批量推理价格是在线推理价格的50%，实际请以下面表格中的价格为准。


| | | | \
|模型 |输入 |\
| |元/百万token |输出 |\
| | |元/百万token |
|---|---|---|
| | | | \
|doubao-1.5-vision-pro-32k  |1.50 |4.50 |


<span id="02affcb8"></span>
# 视频生成模型
> 异步推理，将输出视频转化为 token 计费
> 按 token 后付费价格 

**计费公式**
推理费用 = 按token付费单价 × 视频token用量
视频token用量≈ (宽 × 高 × 帧率 × 时长)/1024，准确的 token 用量以调用 API 后返回信息中的`usage`字段为准。

**单价**

| | | | \
|模型 |\
|<div style="width:200px"></div> |文生视频 |\
| |元/百万token |\
| |<div style="width:200px"></div> |图生视频 |\
| | |元/百万token |\
| | |<div style="width:200px"></div> |
|---|---|---|
| | | | \
|doubao-seedance-1-0-pro |15.00 |15.00 |
| | | | \
|doubao-seedance-1-0-lite |10.00 |10.00 |
| | | | \
|doubao-seaweed |30.00 |30.00 |
| | | | \
|wan2.1-14b |50.00 |50.00 |

**计费示例**

| | | | | | | | | \
|模型 |画面比例 |分辨率 |宽×高 |\
| | | |(像素) |帧率 |\
| | | | |（帧/秒） |视频时长 |\
| | | | | |(秒) |用量 |\
| | | | | | |（token） |价格 |\
| | | | | | | |(元/个) |
|---|---|---|---|---|---|---|---|
| | | | | | | | | \
|doubao-seedance-1-0-pro |16:9 |480p |864×480 |24 |5 |48600 |0.73 |
|^^| |^^| | | | | | \
| |16:9 | |864×480 |24 |10 |97000 |1.46 |
|^^| |^^| | | | | | \
| |4:3 | |736×544 |24 |5 |46920 |0.70 |
|^^| |^^| | | | | | \
| |4:3 | |736×544 |24 |10 |93840 |1.41 |
|^^| |^^| | | | | | \
| |1:1 | |640×640 |24 |5 |48000 |0.72 |
|^^| |^^| | | | | | \
| |1:1 | |640×640 |24 |10 |96000 |1.44 |
|^^| |^^| | | | | | \
| |21:9 | |960×416 |24 |5 |46800 |0.70 |
|^^| |^^| | | | | | \
| |21:9 | |960×416 |24 |10 |93600 |1.40 |
|^^| | | | | | | | \
| |16:9 |720p |1248×704 |24 |5 |102960 |1.54 |
|^^| |^^| | | | | | \
| |16:9 | |1248×704 |24 |10 |205920 |3.09 |
|^^| |^^| | | | | | \
| |4:3 | |1120×832 |24 |5 |109200 |1.64 |
|^^| |^^| | | | | | \
| |4:3 | |1120×832 |24 |10 |218400 |3.28 |
|^^| |^^| | | | | | \
| |1:1 | |960×960 |24 |5 |108000 |1.62 |
|^^| |^^| | | | | | \
| |1:1 | |960×960 |24 |10 |216000 |3.24 |
|^^| |^^| | | | | | \
| |21:9 | |1504×640 |24 |5 |112800 |1.69 |
|^^| |^^| | | | | | \
| |21:9 | |1504×640 |24 |10 |225600 |3.38 |
|^^| | | | | | | | \
| |16:9 |1080p |1920×1088 |24 |5 |244800 |3.67 |
|^^| |^^| | | | | | \
| |16:9 | |1920×1088 |24 |10 |489600 |7.34 |
|^^| |^^| | | | | | \
| |4:3 | |1664×1248 |24 |5 |243360 |3.65 |
|^^| |^^| | | | | | \
| |4:3 | |1664×1248 |24 |10 |486720 |7.30 |
|^^| |^^| | | | | | \
| |1:1 | |1440×1440 |24 |5 |243000 |3.65 |
|^^| |^^| | | | | | \
| |1:1 | |1440×1440 |24 |10 |486000 |7.29 |
|^^| |^^| | | | | | \
| |21:9 | |2176×928 |24 |5 |236640 |3.55 |
|^^| |^^| | | | | | \
| |21:9 | |2176×928 |24 |10 |473280 |7.10 |
| | | | | | | | | \
|doubao-seedance-1-0-lite |16:9 |480p |\
| | | |864×480 |24 |5 |48600 |0.49 |
|^^| |^^| | | | | | \
| |16:9 | |864×480 |24 |10 |97000 |0.97 |
|^^| |^^| | | | | | \
| |4:3 | |736×544 |24 |5 |46920 |0.47 |
|^^| |^^| | | | | | \
| |4:3 | |736×544 |24 |10 |93840 |0.94 |
|^^| |^^| | | | | | \
| |1:1 | |640×640 |24 |5 |48000 |0.48 |
|^^| |^^| | | | | | \
| |1:1 | |640×640 |24 |10 |96000 |0.96 |
|^^| |^^| | | | | | \
| |21:9 | |960×416 |24 |5 |46800 |0.47 |
|^^| |^^| | | | | | \
| |21:9 | |960×416 |24 |10 |93600 |0.94 |
|^^| | | | | | | | \
| |16:9 |720p |1248×704 |24 |5 |102960 |1.03 |
|^^| |^^| | | | | | \
| |16:9 | |1248×704 |24 |10 |205920 |2.06 |
|^^| |^^| | | | | | \
| |4:3 | |1120×832 |24 |5 |109200 |1.09 |
|^^| |^^| | | | | | \
| |4:3 | |1120×832 |24 |10 |218400 |2.18 |
|^^| |^^| | | | | | \
| |1:1 | |960×960 |24 |5 |108000 |1.08 |
|^^| |^^| | | | | | \
| |1:1 | |960×960 |24 |10 |216000 |2.16 |
|^^| |^^| | | | | | \
| |21:9 | |1504×640 |24 |5 |112800 |1.13 |
|^^| |^^| | | | | | \
| |21:9 | |1504×640 |24 |10 |225600 |2.26 |
|^^| | | | | | | | \
| |16:9 |1080p |1920×1088 |24 |5 |244800 |2.45 |
|^^| |^^| | | | | | \
| |16:9 | |1920×1088 |24 |10 |489600 |4.90 |
|^^| |^^| | | | | | \
| |4:3 | |1664×1248 |24 |5 |243360 |2.43 |
|^^| |^^| | | | | | \
| |4:3 | |1664×1248 |24 |10 |486720 |4.87 |
|^^| |^^| | | | | | \
| |1:1 | |1440×1440 |24 |5 |243000 |2.43 |
|^^| |^^| | | | | | \
| |1:1 | |1440×1440 |24 |10 |486000 |4.86 |
|^^| |^^| | | | | | \
| |21:9 | |2176×928 |24 |5 |236640 |2.37 |
|^^| |^^| | | | | | \
| |21:9 | |2176×928 |24 |10 |473280 |4.73 |
| | | | | | | | | \
|doubao-seaweed |\
| |1:1 |480p |480×480  |24 |5 |27,000 |0.81 |
|^^| |^^| | | | | | \
| |4:3 | |640×480 |24 |5 |36,000 |1.08 |
|^^| |^^| | | | | | \
| |16:9 | |848×480  |24 |5 |47,700 |1.43 |
|^^| |^^| | | | | | \
| |1:1 | |480×480  |24 |10 |54,000 |1.62 |
|^^| |^^| | | | | | \
| |4:3 | |640×480 |24 |10 |72,000 |2.16 |
|^^| |^^| | | | | | \
| |16:9 | |848×480  |24 |10 |95,400 |2.86 |
|^^| | | | | | | | \
| |1:1 |720p |\
| | | |720×720 |24 |5 |60,750 |1.82 |
|^^| |^^| | | | | | \
| |4:3 | |960×720 |24 |5 |81,000 |2.43 |
|^^| |^^| | | | | | \
| |16:9 | |1280×720  |24 |5 |108,000 |3.24 |
|^^| |^^| | | | | | \
| |1:1 | |720×720 |24 |10 |121,500 |3.65 |
|^^| |^^| | | | | | \
| |4:3 | |960×720 |24 |10 |162,000 |4.86 |
|^^| |^^| | | | | | \
| |16:9 | |1280×720  |24 |10 |216,000 |6.48 |
| | | | | | | | | \
|wan2.1-14b |16:9 |480p |832×480  |16 |5 |31,200 |1.56 |
|^^| | | | | | | | \
| |16:9 |720p |1280×720  |16 |5 |72,000 |3.60 |



   # 图片生成模型    <span id="5e813e2f"></span>
   > 按使用张数后付费价格，单位：元/张
   
   | | || | \
   |模型 |定价 |\
   | |元/张 | |生成质量 |
   |---|---|---|---|
   | | || | \
   |doubao-Seedream-3.0-t2i |0.259 | |高 |


<span id="f7e78cb1"></span>
# 同声传译模型
> 按 token 后付费价格 


| | | | | | | \
|**模型名称** |**主账号下同时在线连接数** |**单连接最大连接时长** |\
| | |**（小时）** |**单连接静默持续时长**  |\
| | | |**（小时）** |**免费额度** |\
| | | | |**(token)** |**计费** |\
| | | | | |（元/千 token） |
|---|---|---|---|---|---|
| | | | | | | \
|doubao-同声传译 |100 |2 |0.5 |500k |语音输入：0.03 |\
| | | | | |文本输出：0.03 |\
| | | | | |> 源语言文本和目标语言文本 |



<span id="e68ea83c"></span>
# 文本向量模型
> 将输入信息转化为 token 计费
> 按 token 后付费价格 


| | | \
|模型 |输入 |\
| |元/百万token |
|---|---|
| | | \
|doubao-embedding |0.50 |
| | | \
|doubao-embedding-large |0.70 |

<span id="59503f99"></span>
# 图文向量模型
> 将输入信息（包括图片）转化为 token 计费
> 按 token 后付费价格 

**计费公式**
推理费用 = 文本输入单价 × 文本token + 图片输入单价 × 图片输入token
图片tokens = (width px × height px)/784，超大图封顶 1312 token。

**计费单价**

| | | | \
|模型 |文本输入 |\
| |元/百万token |图片输入 |\
| | |元/百万token |
|---|---|---|
| | | | \
|doubao-embedding-vision |0.70 |1.80 |

语音模型
> 按输入字数后付费价格，单位：元/万字


| | | \
|模型 |定价 |\
| |元/百万token |
|---|---|
| | | \
|doubao-语音合成 |5 |
| | | \
|doubao-声音复刻 |8 |


<span id="95750410"></span>
# TPM 保障包
> 对于部分模型，支持购买 TPM（Tokens Per Minute）保障包。对成功购买的保障包内，保障 token 并发。相比单纯的按token计费，可获得更高的并发，更低的延迟，更强的稳定性。
> 「小时后付费」和「包天预付费」两种方式支持叠加购买，您可依据业务流量灵活采购。

<span id="b1cac8e9"></span>
## 深度思考模型

| | | | | \
|模型 |计费方式 |输入 |输出 |
|---|---|---|---|
| | | | | \
|doubao-1.5-thinking-pro |小时后付费 |9.60 元/每10K TPM |3.84 元/每1K TPM |
|^^| | | | \
| |包天预付费 |115.20 元/每10K TPM |46.08 元/每1K TPM |
| | | | | \
|deepseek-r1 |小时后付费 |9.60 元/每10K TPM |3.84 元/每1K TPM |
|^^| | | | \
| |包天预付费 |115.20 元/每10K TPM |46.08 元/每1K TPM |

<span id="c01e6c23"></span>
## 大语言模型

| | | | | \
|模型 |计费方式 |输入 |输出 |
|---|---|---|---|
| | | | | \
|doubao-1.5-pro-32k |小时后付费 |1.920 元/每10K TPM |0.480 元/每1K TPM |
|^^| | | | \
| |包天预付费 |23.040 元/每10K TPM |5.760 元/每1K TPM |
| | | | | \
|doubao-1.5-lite-32k |小时后付费 |0.72 元/每10K TPM |0.144 元/每1K TPM |
|^^| | | | \
| |包天预付费 |8.64 元/每10K TPM |1.728 元/每1K TPM |
| | | | | \
|doubao-pro-32k |小时后付费 |1.920 元/每10K TPM |0.480 元/每1K TPM |
|^^| | | | \
| |包天预付费 |23.040 元/每10K TPM |5.760 元/每1K TPM |
| | | | | \
|deepseek-v3 |小时后付费 |4.80 元/每10K TPM |1.92 元/每1K TPM |
|^^| | | | \
| |包天预付费 |57.60 元/每10K TPM |23.04 元/每1K TPM |


<span id="b3a42676"></span>
# 模型精调
<span id="7e451788"></span>
## 精调训练
> 按 token 后付费价格

**计费公式**
训练费用 = 训练tokens量  x 精调单价 = （数据集总 tokens  x 迭代轮次）x 精调单价
若 token 数小于 1000，将会上取整为 1000 tokens 计算。

**计费单价**

| | | | \
|基础模型 |LoRA精调 |\
| |元/百万token |全量精调 |\
| | |元/百万token |
|---|---|---|
| | | | \
|doubao-1.5-pro-32k |50 |100 |
| | | | \
|doubao-1.5-lite-32k |30 |60 |
| | | | \
|doubao-pro-32k |50 |\- |
| | | | \
|doubao-lite-32k |30 |\- |

<span id="85598ccd"></span>
## 精调后在线推理
> 按 token 后付费价格

:::tip
* 仅部分 doubao 模型精调后在线推理支持按 token 付费，以创建在线推理接入点页面可选的付费方式为准。
* doubao 1.5 及后续模型的精调后推理服务在延迟和性能方面较旧版模型有比较明显的提升，在大流量场景的稳定性也有提升。
:::

| | | | \
|精调模型对应的基础模型 |输入 |\
| |元/百万token |输出 |\
| | |元/百万token |
|---|---|---|
| | | | \
|doubao-1.5-pro-32k |2.00 |5.00 |
| | | | \
|doubao-1.5-lite-32k |0.75 |1.50 |
| | | | \
|doubao-pro-32k |0.80 |2.00 |
| | | | \
|doubao-lite-32k |0.30 |0.60 |

<span id="6ad242c5"></span>
## 精调后批量推理
> 按 token 后付费价格


| | | | | \
|精调模型对应的基础模型 |输入 |\
| |元/百万token |缓存命中 |\
| | |元/百万token |输出 |\
| | | |元/百万token |
|---|---|---|---|
| | | | | \
|doubao-1.5-pro-32k |0.40 |0.16 |1.00 |
| | | | | \
|doubao-1.5-lite-32k |0.15 |0.06 |0.30 |
| | | | | \
|doubao-pro-32k |0.80 |0.16 |2.00 |
| | | | | \
|doubao-lite-32k |0.30 |0.06 |0.60 |


<span id="649485eb"></span>
# 模型单元
> 对于部分大语言模型，支持按模型单元付费。模型单元提供专属算力，对精调后模型表现更优。
> 「按小时后付费」和「包月预付费」两种方式支持叠加购买，您可依据业务流量灵活采购。

:::tip
此为邀测能力，如需使用，提交[测试申请工单](https://console.volcengine.com/auth/login?redirectURI=%2Fworkorder%2Fcreate%3Fstep%3D2%26SubProductID%3DP00001166)。
:::



| | | | | \
|模型 |计费方式 |\
| | |性能预估 TPS |\
| | |（Tokens Per Second） |定价 |\
| | | |元/个 |
|---|---|---|---|
| | | | | \
|doubao-lite-4k |按小时后付费 |3000 |60 |
|^^| | | | \
| |包月预付费 |3000 |28000 |
| | | | | \
|doubao-lite-32k |按小时后付费 |3000 |60 |
|^^| | | | \
| |包月预付费 |3000 |28000 |
| | | | | \
|doubao-lite-128k |按小时后付费 |4500 |240 |
|^^| | | | \
| |包月预付费 |4500 |112000 |
| | | | | \
|doubao-pro-32k |按小时后付费 |3200 |160 |
|^^| | | | \
| |包月预付费 |3200 |80000 |




# 模型服务计费说明
Source: https://www.volcengine.com/docs/82379/1544681
本文为您介绍火山方舟平台模型服务不同功能的计费方式、计费逻辑、计费项等内容。如需查询各模型的计费公式及单价请参考 [模型服务价格](https://www.volcengine.com/docs/82379/1544106)。
<span id="da01297e"></span>
# 在线推理计费
在线推理功能支持以下 3 种计费方式，下表为您详细对比 3 种计费方式适用的场景、功能、模型、优势等内容，供您进行选型。
<span id="1c30a865"></span>
## 计费方式选择

| | | | | \
|**对比项** |[按 token 后付费](https://www.volcengine.com/docs/82379/1544681#9be44658) |\
| |<div style="width:250px"><div> |[TPM 保障包](https://www.volcengine.com/docs/82379/1510762) |\
| | |<div style="width:250px"><div> |[模型单元（邀测）](https://www.volcengine.com/docs/82379/1513690) |\
| | | |<div style="width:250px"><div> |
|---|---|---|---|
| | | | | \
|**简介** |根据模型推理时消耗的 token 数量进行后付费。 |\
| | |TPM 保障包是针对某个特定模型以及版本保障请求并发达到一定 TPM（ Tokens Per Minute）的计费模式。 |模型单元提供专属算力，对精调后模型表现更优。 |
| | | | | \
|**适用场景** |:::tip |\
| |SLA（Service Level Agreement，服务等级协议）和延迟要求相对低 |\
| |::: |\
| | |\
| |* 新用户开始使用方舟。 |\
| |* 可接受偶发资源紧张报错的业务，或无法预估准确流量的业务。 |\
| |* 业务并发度低于平台提供的默认限流值。 |\
| | |\
| | |\
| | |\
| | |:::tip |\
| | |SLA 要求高，延迟低，并发大 |\
| | |::: |\
| | | |\
| | |* 适合生产级别、流量大小可预估的在线业务。对算力资源确定性要求高，无法接受偶发的资源紧张报错。 |\
| | |* 业务并发量高，超过平台提供的最大限流额度。 |\
| | |* 希望获得比常规按 token 计费更低的延迟。 |\
| | | |\
| | | |\
| | | |:::tip |\
| | | |精调后模型的高保障方案 |\
| | | |::: |\
| | | | |\
| | | |* 适合生产级别业务，对算力资源确定性要求非常高。 |\
| | | |* Lora 精调后的模型，期望在推理时获得更低延迟。 |\
| | | |* 使用全量精调后的模型推理。 |\
| | | |* 有特殊的延时、并发需求。 |
| | | | | \
|**适用功能** |基础模型在线推理 |\
| |Lora精调后模型在线推理 |基础模型在线推理 |基础模型在线推理 |\
| | | |全量/Lora精调后模型在线推理 |
| | | | | \
|**主要优势** |购买非常灵活，按 token 消耗量后付费。 |\
| | |* 并发能力确定性强，平台预留资源，不必担心平台整体水位对自身业务的影响。 |\
| | |* 可叠加按 token 计费使用，既保障可预估的流量，又对临时流量有一定缓冲能力。 |\
| | |* 购买相对灵活，支持按天预付费，按小时后付费购买 |* 独占算力，算力资源确定性强 |\
| | | |* 灵活度高，可支持更多复杂场景，满足更多特殊延迟、并发需求。 |\
| | | |* 购买方式一般灵活：支持按月预付费，按小时后付费。 |
| | | | | \
|**支持模型** |* 方舟平台所有模型 |\
| |* 基于豆包系列模型 Lora 精调后的模型 |* 豆包、Deepseek 系列模型 |\
| | | |\
| | | |* 部分豆包模型 |\
| | | |* 基于部分豆包模型精调后的模型 |
| | | | | \
|**价格比较** |低 |中 |高 |
| | | | | \
|**服务承诺** |不对并发能力（TPM）进行承诺 |对成功购买的保障包内，保障 token 并发（TPM） |平台提供的算力，可以保障平台预置数据集在相同配置下压测得出低于一定延时的并发 |
| | | | | \
|**计费特点** |计算token使用量 |\
| |按量后付费：不调用不计费 |购买“TPM 额度” |\
| | | |\
| | |* 按天预付费 |\
| | |* 按小时后付费：**根据购买时长计费，不调用也会收费。** |\
| | | |\
| | | |购买 “个”模型单元 |\
| | | | |\
| | | |* 按月预付费 |\
| | | |* 按小时后付费：**根据购买时长计费，不调用也会收费。** |\
| | | | |\
| | | | |
| | | | | \
|**起购时长** |\- |预付费 1 天起购 |预付费 1 个月起购 |

<span id="9be44658"></span>
## 按 token 后付费
按 token 后付费，统计模型进行实时推理服务时消耗的 token 数量，按量后付费。
:::tip
在线推理支持多种计费方式。本篇主要介绍按 token 后付费的计费方式，其他计费方式请移步 [TPM 保障包](https://www.volcengine.com/docs/82379/1510762)  [模型单元（邀测）](https://www.volcengine.com/docs/82379/1513690)
:::
<span id="f6ecf310"></span>
## 计费项
不同模型服务的计费项不同，具体请参考 [模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

* **推理输入**：将推理输入的内容（包括但不限于文字、图片）转化为 token 数进行计费，对应`prompt_token`**。**
* **推理输出**：将推理输出的内容（包括但不限于文字、图片）转化为 token 数进行计费，对应`completion_token`**。**


> 开启上下文缓存功能后，会增加以下计费项。更多信息请参见 [上下文缓存](https://www.volcengine.com/docs/82379/1396489)。


* **缓存命中**：若您的请求被系统判断命中了 Cache，被命中的 token 会按照 cached_token 来计费，价格低于`prompt_token`单价；未被命中的 token 仍按照`prompt_token`计费。
* **缓存存储**：缓存上下文信息产生的存储费用。存储按小时计费，基于每个自然小时内存储的最大 token 数。

<span id="fa27df3f"></span>
## 计费说明

* **免费额度**：用于抵扣按 token 后付费场景下，在线推理服务消耗的 token。在免费额度内，实时调用不收费。可在 [开通管理页](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement) 查看每个模型的剩余额度。
* **计费单价**：[查看价格](https://www.volcengine.com/docs/82379/1544106)
* **如何付费**：出具账单后实时结算扣款 [充值入口](https://console.volcengine.com/finance/fund/recharge)

<span id="65c1d1a2"></span>
## **出账周期**
按小时结算，账单出账时间通常在当前计费周期结束后1-2小时左右，具体以系统实际出账时间为准。例如：16:00-17:00 的账单约在 18:00-19:00 出账。
<span id="629aa744"></span>
# 批量推理计费
<span id="3383c0de"></span>
## 计费方式
按 token 后付费，统计模型进行批量推理服务时消耗的 token 数量，按量后付费。
<span id="a69f1a78"></span>
## 计费项
不同模型服务的计费项不同，具体请参考 [模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

* **推理输入**：将推理输入的内容（包括但不限于文字、图片）转化为 token 数进行计费，对应`prompt_token`。
* **推理输出**：将推理输出的内容（包括但不限于文字、图片）转化为 token 数进行计费，对应`completion_token`。


> 部分模型在2025年4月14日21:00开始支持透明前缀缓存能力，您无需任何配置，即可享受前缀缓存技术应用带来的费用降低。


* **缓存命中**：若您的请求被系统判断命中了 Cache，被命中的 token 会按照 cached_token 来计费，价格是`prompt_token`单价的 4 折；未被命中的 token 仍按照`prompt_token`计费。

<span id="f2a00ae6"></span>
## 计费说明

* **免费额度**：批量推理功能不支持免费额度抵扣。
* **计费单价**：[查看价格](https://www.volcengine.com/docs/82379/1544106)
* **如何付费**：出具账单后实时结算扣款

<span id="0baced2d"></span>
## **出账周期**
按小时结算，账单出账时间通常在当前计费周期结束后1-2小时左右，具体以系统实际出账时间为准。例如：16:00-17:00 的账单约在 18:00-19:00 出账。
<span id="9e85bab6"></span>
# 精调计费
<span id="33ff56f8"></span>
## 计费方式
按 token 后付费，统计模型进行训练时消耗的 token 数量，按量后付费。
<span id="2bb63456"></span>
## 计费项

* **精调服务**：统计模型进行训练时消耗的 token 数量。

<span id="512a675d"></span>
## 计费说明

* **免费额度**：精调功能不支持免费额度抵扣。
* **计费单价**：[查看价格](https://www.volcengine.com/docs/82379/1544106)
* **如何付费**：出具账单后实时结算扣款 [充值入口](https://console.volcengine.com/finance/fund/recharge)

<span id="58397491"></span>
## **出账周期**
按小时结算，账单出账时间通常在**训练任务结束后**的1-2小时左右，具体以系统实际出账时间为准。例如：16:00-17:00 的账单约在 18:00-19:00 出账。
<span id="66abf1da"></span>
# 欠费说明（新）
:::warning
火山方舟将于 2025年7月16日00:00:00 启用新的模型服务欠费规则[欠费说明（新）](https://www.volcengine.com/docs/82379/1544681#66abf1da)，由 **出具账单后欠费2小时以上关停** 变更为 **欠费1分钟即关停**。如需保障稳定的线上服务，可开启 [延期免停权益](https://www.volcengine.com/docs/6269/202201)。
:::

后付费账单按小时结算，出具账单后实时结算扣款。如果您账户中的可用额度（含账户余额和代金券）小于待结算的账单，会被认为欠费。

| | | \
|欠费时长 |说明 |
|---|---|
| | | \
|欠费时长 ≤ 1 分钟 |您可以正常使用火山方舟模型服务，火山方舟按照您的具体使用量出具账单。 |\
| |:::tip |\
| |如需延长免停时长，可参考 [延期免停权益说明](https://www.volcengine.com/docs/6269/202201)。 |\
| |如果希望严格控制费用预期，避免推账、关停延迟带来的额外花销，可为模型设置推理限额。当调用量达到推理限额后，平台会为您自动关停对应的模型服务。详情可参考 [推理限额设置](https://www.volcengine.com/docs/82379/1159200#405e7d60)。 |\
| |::: |
| | | \
|欠费时长 > 1 分钟 |平台会给您发送相关通知，并 **关停服务**。账号下的所有火山方舟相关模型服务将无法正常使用。 |

:::danger
* 对于**按小时后付费**的模型单元和TPM保障包，欠费关停阶段，资源会继续保留，依然会产生费用。欠费24小时后，将回收资源停止计费。如果确定不再使用服务，希望立刻停止计费，请在接入点详情页进行 [退订](https://www.volcengine.com/docs/82379/1513690#%E8%B0%83%E6%95%B4%E6%95%B0%E9%87%8F-%E7%BB%AD%E8%B4%B9-%E9%80%80%E8%AE%A2)。
* 请及时补缴所有欠费账单以避免服务中断带来的影响。请前往 [火山引擎费用中心](https://console.volcengine.com/finance/fund/recharge) 进行充值，详细操作参见 [充值操作指引](https://www.volcengine.com/docs/6269/100434)。
:::
<span id="48703695"></span>
# 
<span id="5d4791ba"></span>
# 欠费说明
后付费账单按小时结算，出具账单后实时结算扣款。如果您账户中的可用额度（含账户余额和代金券）小于待结算的账单，会被认为欠费。

| | | \
|欠费时长 |说明 |
|---|---|
| | | \
|欠费时长 ≤ 2 小时 |您可以正常使用火山方舟模型服务，火山方舟按照您的具体使用量出具账单。 |\
| |:::tip |\
| |为保证企业客户线上服务的稳定，欠费后有2小时的关停延时时长。如需更长免停时长，可参考 [延期免停权益说明](https://www.volcengine.com/docs/6269/202201)。 |\
| |如果希望严格控制费用预期，避免推账、关停延迟带来的额外花销，可为模型设置推理限额。当调用量达到推理限额后，平台会为您自动关停对应的模型服务。详情可参考 [推理限额设置](https://www.volcengine.com/docs/82379/1159200#405e7d60)。 |\
| |::: |
| | | \
|欠费时长 > 2 小时 |平台会给您发送相关通知，并 **关停服务**。账号下的所有火山方舟相关模型服务将无法正常使用。 |

:::danger
* 对于**按小时后付费**的模型单元和TPM保障包，欠费关停阶段，资源会继续保留，依然会产生费用。欠费24小时后，将回收资源停止计费。如果确定不再使用服务，希望立刻停止计费，请在接入点详情页进行 [退订](https://www.volcengine.com/docs/82379/1513690#%E8%B0%83%E6%95%B4%E6%95%B0%E9%87%8F-%E7%BB%AD%E8%B4%B9-%E9%80%80%E8%AE%A2)。
* 请及时补缴所有欠费账单以避免服务中断带来的影响。请前往 [火山引擎费用中心](https://console.volcengine.com/finance/fund/recharge) 进行充值，详细操作参见 [充值操作指引](https://www.volcengine.com/docs/6269/100434)。
:::
<span id="70eedb80"></span>
# 常见问题
[什么是 token？如何计算 token 数量?](https://www.volcengine.com/docs/82379/1359411#8f169720)
[模型推理请求报错或者中断会计费么？](https://www.volcengine.com/docs/82379/1359411#9ed23b1e)
[精调任务失败会计费吗？](https://www.volcengine.com/docs/82379/1359411#b740f18a)
[手动停止精调任务会计费吗?](https://www.volcengine.com/docs/82379/1359411#0c9ce562)
[账户欠费后如何充值？](https://www.volcengine.com/docs/82379/1359411#1b44d554)
[为什么我的账户欠费后仍在持续出账？](https://www.volcengine.com/docs/82379/1359411#08bd1d88)
[如何按 Endpoint ID 或精调任务 ID 分账？](https://www.volcengine.com/docs/82379/1359411#d53174f8)
<span id="647665e8"></span>
# 



# TPM保障包
Source: https://www.volcengine.com/docs/82379/1510762
<span id="dec1388f"></span>
## 什么是 TPM 保障包
**TPM 保障包** 是针对某个特定模型以及版本保障请求并发达到一定 TPM（ Tokens per Minute）的计费模式。

* 更低的延迟：相比按Token计费，TPM 保障包的延迟更低，通常比直接按Token计费低 1/3 - 1/2，如 Doubao-1.5-pro 模型的TPM保障包，TPOT（Time per Output Token）可低至 20 ms。
* 更高的并发：支持超过默认限流额度的并发。
* 更强稳定性：提供高资源确定性保障，提供资源的刚性保障，在保障范畴内不会命中异常流量熔断、限速策略，持续保障业务服务可用性。

除此之外， TPM保障包还具备以下特性：

* 超过保障包部分流量默认 **按Token付费** ，**超过部分流量计算在默认限流额度中**。
* 保障包支持按小时和按天付费，您可以在业务高峰时叠加按小时计费的保障包和按天的保障包，贴合流量波峰波谷，避免资源浪费。

<span id="ef2b6fc0"></span>
### 典型场景

* 对高流量业务提供资源保障，适合大流量、可预估流量大小，生产级高 SLA 要求的场景。
* 希望请求延时更低的线上业务。

<span id="a35db237"></span>
### 支持模型
> 具体支持的模型以控制台显示为准。
> 未来会支持视觉理解模型，更多模型版本，如明确需求，可提交[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)申请。

当前支持模型如下：

* Doubao-1.5-thinking-pro
* Doubao-1.5-pro-32k
* Doubao-1.5-lite-32k
* Doubao-pro-32k
* DeepSeek-R1
* DeepSeek-V3

<span id="afca3ccb"></span>
## 计费说明
TPM 保障包支持按小时后付费和按天预付费，两种方式可叠加购买，单价请参见 [TPM 保障包](https://www.volcengine.com/docs/82379/1544106#95750410)。
<span id="ecb9aaf2"></span>
### 后付费（按小时）

* **计费特点**：按照实际购买时长收费，计费粒度精确到秒。购买后持续计费，如需停止计费可在接入点详情页进行退订。
   > 举例：假设您在16:00下单成功，在18:20:31退订成功。则计费时长为 2 小时 2 分钟 31 秒，计费单价会换算成每秒钟单价进行计算。
* **计费粒度**：秒。不足一秒按一秒计算。
* **出账周期：**按小时结算，账单出账时间通常在当前计费周期结束后1-2小时左右，具体以系统实际出账时间为准。例如：16:00-17:00 的账单约在 18:00-19:00 出账。
* **欠费说明**：欠费后，资源会继续保留，依然会产生费用。欠费24小时后，将回收资源停止计费。请及时续费或销毁资源。

<span id="d2f5e45a"></span>
### 预付费（按天）

* **生效时间**：实时生效
* **到期时间**：第 N 天的 23:59 到期。其中，N 为您购买的 TPM 保障包的天数，购买当天为第 1 天。
   以购买了 1 天期限的 TPM 保障包举例：如果早上 9:00下单，则当天晚上 23:59 到期；如果晚上 21:00 下单，仍旧是当天晚上 23:59 到期。
* **提前退订**：退订退款金额=实付金额-已使用金额×惩罚系数。其中，已使用金额和使用时长相关，使用时长按自然日首尾取整（用了一分钟、还剩一分钟都算一天）。
* **续费说明**：建议开启自动续费能力，您可以在官网费用中心查看当前自动续费起始时间。

<span id="325336f4"></span>
## 购买服务
TPM保障包支持叠加购买。您可以在创建推理接入点时购买；也可以在接入点详情页进行购买、续费、退订等操作。
> 如果业务对于延时有需求，请通过[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)提需求。

<span id="d2b9b53f"></span>
### 创建推理接入点时购买

1. 访问[方舟控制台-在线推理](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint?config=%7B%7D)，切换到“**自定义推理接入点**”页签，单击 **创建推理接入点** 按钮。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/92b231e014ec4703aeb88a110b2e940e~tplv-goo7wpa0wc-image.image =1024x)

2. 在打开的页面中填写接入点名称，选择模型类型，并选择购买方式为”按Token付费“。
3. 开启 TPM保障包功能。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/021ab822ef7f44ce9b055460de50e8e0~tplv-goo7wpa0wc-image.image =853x)

4. 选择计费类型，您可以选择”后付费“或”预付费“。相关配置参数可以查看[配置参数说明](https://www.volcengine.com/docs/82379/1510762#ea03124a)。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7cec86088e52472eb5d973a828769683~tplv-goo7wpa0wc-image.image =758x)

5. 选择所需的购买额度。当前保障包可以为输入、输出分别购买 TPM 保障包，业务需求总量除以最小TPM保障包，即您需要购买的数量。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ec57d41b28394a46a8f5a747ff639929~tplv-goo7wpa0wc-image.image =631x)
<span id="6318fdcc"></span>
### 在推理接入点详情页购买

1. 访问[方舟控制台-在线推理](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint?config=%7B%7D)，切换到“**自定义推理接入点**”页签，单击 **接入点名称** 进入详情页。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/07e5c188653f4c2387ac723e65c1d02b~tplv-goo7wpa0wc-image.image =1019x)

2. 在打开的页面中，根据不同的付费类型，选择购买 TPM保障包。

> 详细配置参数请参见[配置参数说明](https://www.volcengine.com/docs/82379/1510762#ea03124a)

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/6dae0a1eaa684dd5abb119cf6c1c3bed~tplv-goo7wpa0wc-image.image =1258x)
<span id="ea03124a"></span>
### **配置参数说明**

| | | \
|配置名称 |配置说明 |
|---|---|
| | | \
|计费类型 |条件必填，当启用了 TPM保障包时，需要选择。TPM保障包的计费方式，包括 **后付费**，**预付费**： |\
| | |\
| |* **后付费**：按量计费，使用灵活，适合短期或者服务请求波动较大的场景。 |\
| |* **预付费**：提前购买，价格较为优惠，适合长期或者服务请求相对稳定的场景。 |
| | | \
|购买额度 |条件必填，当启用了 TPM保障包时，需要选择。TPM保障包的额度，请根据界面提示进行选择。 |
| | | \
|购买时长 |条件必填，当启用了 TPM保障包时，需要选择。TPM保障包的购买时长。 |
| | | \
|自动续费 |可选，推荐您进行选择，保障服务持续可用。 |
| | | \
|单次自动续费时长 |条件必填，当启用了 TPM保障包自动续费时，需要填写。触发自动续费时，为您自动购买的TPM保障包时长。 |
| | | \
|自动续费次数 |条件必选，当启用了 TPM保障包自动续费时，需要选择。默认为永久生效，您可以根据业务填写自定义次数。 |


<span id="e49d179b"></span>
## 订阅通知
您可以使用火山引擎消息通知服务（后简称 SNS） 来感知TPM保障包信息通知。
<span id="6b50833e"></span>
### 订阅流程

1. 申请 “SNS开白” ，使用请提交[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P90000689)申请，并同步申请对应的消息事件：
   * ModelTPMNewFailed：TPM保障包新购失败告警
   * ModelTPMScaleUpFailed：TPM保障包扩容失败告警
2. 在 **主题** 页面创建主题。
   * 发布者选项指定账号：`2100444922`
   * 服务选择：`ark`

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/437917a96bb84c02b1a5fafe5a3f2bd1~tplv-goo7wpa0wc-image.image =3792x)

3. 在 **云服务事件订阅** 页面创建事件订阅。Topic TRN选择刚刚创建的主题，事件选择`ModelTPMNewFailed`、`ModelTPMScaleUpFailed`。
4. 在**订阅**页面，订阅前面创建的主题，并配置可接收端地址

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/76693dd573b34176b8ca85cce0c23e30~tplv-goo7wpa0wc-image.image =1889x)

* 配置完订阅后，SNS 会向接收端发送对应的确认链接，需确认该链接来完成订阅，确认链接demo如下。需要回调下文中SubscribeURL

```JSON
{
  "Type": "SubscriptionConfirmation",
  "MessageId": "f11b9a8f-****",
  "TopicTrn": "trn:sns:cn-beijing:2100000825:topic/test",
  "Message": "You have chosen to subscribe to the topic trn:sns:cn-beijing:2100000825:topic/wyy_test. To confirm the subscription, visit the SubscribeURL included in this message.",
  "Timestamp": "2025-01-14T07:18:59Z",
  "SignatureVersion": "1",
  "Signature": "MEUCIB3NsKw***=",
  "SigningCertURL": "https://sns-public-cn-beijing.tos-cn-beijing.volces.com/certificates/cn-beijing-a31d91fc-0683-****.pem",
  "SubscribeToken": "eyJhbGciOiJIUzI1Ni****",
  "SubscribeURL": "https://sns.cn-beijing.volcengineapi.com?Action=ConfirmSubscription&Version=2023-01-01&Token=eyJhbGc***"
}
```


* 回调成功后可在 **订阅** 页面看到对应的订阅状态为：已确认，表示订阅已完成。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/301d7375496f4ac6863e38b360cdb1e0~tplv-goo7wpa0wc-image.image =486x)
<span id="47140ec8"></span>
### 订阅信息内容格式
TPM保障包订阅失败时通知的内容。
<span id="1e1707dc"></span>
##### ModelTPMNewFailed

* TPM保障包新购失败告警

```JSON
{
        "EventID": "tpmro-202502111****-****",
        "EventName": "ModelTPMNewFailed",
        "EventTime": "2025-02-11T19:41:36+08:00",
        "AccountID": 2100000825,
        "ModelTPMInfo": {
                "EndpointID": "ep-2025021******-cn***",
                "FoundationModelName": "doubao-lite-4k"
        }
}
```

<span id="fde41250"></span>
##### ModelTPMScaleUpFailed

* TPM保障包扩容失败告警

```JSON
{
        "EventID": "tpmro-202502111****-****",
        "EventName": "ModelTPMScaleUpFailed",
        "EventTime": "2025-02-11T19:41:36+08:00",
        "AccountID": 2100000825,
        "ModelTPMInfo": {
                "EndpointID": "ep-20250******-cn***",
                "FoundationModelName": "doubao-lite-4k"
        }
}
```

<span id="08c00845"></span>
## 常见问题

* [保障包是否可以与上下文缓存 Context Cache 一起使用？](https://www.volcengine.com/docs/82379/1359411#68fbdc33)
* [如何判断某个请求在保障包的保障范畴？ ](https://www.volcengine.com/docs/82379/1359411#e73b6ef5)
* [怎么保障分小时的保障包能购买成功？](https://www.volcengine.com/docs/82379/1359411#09a60616)





# 模型单元
Source: https://www.volcengine.com/docs/82379/1513690
模型单元提供隔离性更强的独占资源，适合对精调模型有一定延迟要求的场景，也适合生产级高SLA要求的场景。选择购买模型单元，通常可以获得更大的模型服务调用的并发量，使用量的计算单位也会从 token 使用量，变为模型单元的使用时长。本文为您介绍模型单元的适用场景、支持模型、购买说明等内容。
<span id="建议购买模型单元场景"></span>
## 适用场景
集中典型的应用场景如下：

* 线上生产业务，对资源确定性要求高，希望在流量峰值必须保障资源。
* 模型经过 LoRA 精调后，在推理时获得更低延迟。
* 模型经过全量精调后，在推理时获得更低延迟。
* 实际业务并发高，TPM、RPM（Request per Minute，单位时间请求量）超过方舟平台默认的限定值。

<span id="支持模型单元的模型"></span>
## 支持模型
> 具体支持模型情况，以控制台显示为准


* doubao-lite-4k
* doubao-lite-32k
* doubao-lite-128k
* doubao-pro-4k
* doubao-pro-32k
* doubao-pro-128k

<span id="79b43c4d"></span>
## 使用说明

* 模型单元为您选择的模型提供了一定量的算力，您可以联系平台获取相应算力可承载的并发能力，更建议您通过实际业务流量压测，准确判断需要的模型单元数量。
* 模型单元预计可承载性能（Tokens Per Second，TPS）是按照输入：输出 = 10:1 的数据压测得到。实际用户的输入输出比例对性能的影响较大，建议您通过实际业务流量压测，准确判断需要的模型单元数量。
* Lora精调后的模型推理性能相较平台预置模型的推理会有一定程度的降低。

<span id="36f36ae6"></span>
## 计费说明
模型单元按使用时长计费，支持按小时后付费和包月预付费，两种方式可叠加购买，单价请参见 [模型单元(邀测)](https://www.volcengine.com/docs/82379/1544106#649485eb)。
<span id="a6405ed1"></span>
### **后付费（按小时）**
> 按照实际购买时长付费，精确到秒，适合短期、弹性需求，避免浪费


* **计费特点**：按照实际购买时长收费，计费粒度精确到秒。购买后持续计费，如需停止计费可在接入点详情页进行退订。
   > 举例：假设您在16:00下单成功，在18:20:31退订成功。则计费时长为 2 小时 2 分钟 31 秒，计费单价会换算成每秒钟单价进行计算。
* **计费粒度**：秒。不足一秒按一秒计算。
* **出账周期**：按小时结算，账单出账时间通常在当前计费周期结束后1-2小时左右，具体以系统实际出账时间为准。例如：16:00-17:00 的账单约在 18:00-19:00 出账。
* **欠费说明**：欠费后，资源会继续保留，依然会产生费用。欠费24小时后，将回收资源停止计费。请及时续费或销毁资源。

<span id="afd7996e"></span>
### **预付费（按月）**
> 按月预留资源，享受更优惠价格，适合中长期稳定需求


* **生效时间**：购买后，按照自然日立即生效。
* **到期时间**：从购买日算起，到期时间为到期自然日+1 天的中午 12 点。7 天内到期的模型单元会出现到期提醒。如您在 5 月 13 日上午 9 点购买一个月的模型单元，相当于您购买了到期时间为 6 月 13 日 24 点的资源，实际到期时间为 6 月 14 日中午 12 点整。
* **到期回收**：资源到期后将被回收，您可以在资源被回收前在方舟产品控制台或[订单管理页面](https://console.volcengine.com/finance/order)进行续费，回收时间为到期时间＋ 48 小时。即如您在 5 月 13 日上午 9 点购买一个月的模型单元，相当于您购买了到期时间为 6 月 13 日 24 点的资源，在 6 月 15 日 24 点之前都可以进行续费。在回收期结束后，模型单元无法续费，您需要重新创建一个模型推理接入点来满足继续使用的需求。
* **续费说明**：强烈推荐您为资源配置自动续费，以避免由于未配置自动续费导致的业务中断。

<span id="使用说明"></span>
## **购买说明**
:::tip
此为邀测能力，如需使用，提交[测试申请工单](https://console.volcengine.com/auth/login?redirectURI=%2Fworkorder%2Fcreate%3Fstep%3D2%26SubProductID%3DP00001166)。
:::


购买模型单元，可以配置购买模型单元的数量、时长、是否自动续费等，详细请参见[配置参数说明](https://www.volcengine.com/docs/82379/1513690#1f576f06)。
> 如果业务对于延时有需求，请通过[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)提需求。


1. 访问[方舟控制台-在线推理](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint?config=%7B%7D)，切换到**自定义推理接入点**页签，单击 **创建推理接入点**。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/92b231e014ec4703aeb88a110b2e940e~tplv-goo7wpa0wc-image.image =1024x)

2. 在打开的页面中填写接入点名称，选择模型类型，并选择购买方式为”按单元付费“。

> 如果您无法购买，请按照控制台上的提示提交工单申请。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0ba2740d403c426081e5cd05062c0542~tplv-goo7wpa0wc-image.image =840x)

3. 选择需要购买的单元数量，并选择计费方式为”后付费“或”预付费“。其他相关配置参数可以查看[配置参数说明](https://www.volcengine.com/docs/82379/1513690#1f576f06)。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e29cb9ae2c544d6fb6dc02d7e6f357ff~tplv-goo7wpa0wc-image.image =860x)
<span id="1f576f06"></span>
### **配置参数说明**

| | | \
|配置名称 |配置说明 |
|---|---|
| | | \
|计费类型 |必填，当选择了 **按模型单元付费** ，需要选择计费类型。 |\
| | |\
| |* **后付费**：按照模型单元运行时长付费，适合模型推理服务波动较大或者无法预测的场景，使用更加灵活。 |\
| | |\
| |:::tip |\
| |购买后付费模型单元的前提是账号中的余额大于 100 元，否则无法成功下单。 |\
| |::: |\
| | |\
| |* **预付费**：按月预留资源，提供更优惠价格，适合模型推理服务波动较小，可预测的场景。 |\
| |* **组合使用**：预付费模型单元和后付费模型单元支持叠加使用。创建推理接入点时只能选择 1 种计费类型，操作叠加购买多种模型单元，需要创建完成推理接入点后，在推理接入点详情页进行配置。 |\
| | |\
| |:::tip |\
| |如下图所示，日常有基础访问次数以及在某时间段有高峰期的时段，可以考虑通过预付费方式购买基础访问次数匹配的模型单元以获得优惠价格；再通过购买灵活变动的后付费模型单元，来应对高峰期的超出基础次数的模型服务请求。 |\
| |::: |\
| | |\
| | |\
| | |
| | | \
|购买时长 |必填。选择模型单元购买时长，即模型单元包月的时长。 |
| | | \
|自动续费 |选填，费用到期后，是否自动续费。 |\
| |:::tip |\
| |推荐您开通**自动续费**，可避免续费不及时导致业务中断。 |\
| |::: |
| | | \
|* 单次续费时长 |必填，当开启了**自动续费**，需要配置单次续费时长，单位：月。 |
| | | \
|* 自动续费次数 |必填，当开启了**自动续费**，需要配置自动续费执行的次数。支持**永久生效**和**自定义次数**。 |

<span id="b3374a0e"></span>
## 调整数量/续费/退订

1. 访问[方舟控制台-在线推理](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint?config=%7B%7D)，切换到“**自定义推理接入点**”页签。
2. 单击目标接入点名称，进入接入点概览页。在算力保障区域，根据需要对模型单元进行调整数量、续费或退订。

:::warning
* 模型单元是按实例组购买的，点击**接入点名称详情**中复制的模型单元 ID 是实例组 ID，实例组存在强绑定关系，因此续费、退订须同步发起。
* 请注意，未到期的模型单元退订会产生惩罚系数，无法 100%退费。
:::

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a74661587efa48579a1a497acc3855da~tplv-goo7wpa0wc-image.image =2106x)




# 知识库计费
Source: https://www.volcengine.com/docs/82379/1263336
<span id="计费说明"></span>
## 计费说明
本文介绍知识库产品的计费说明，包括计费方式、计费周期、计费项。
<span id="dd0f6faa"></span>
## 计费方式
:::warning
以下两种计费方式只能选择其中一种计费方式使用
:::
知识库支持两种计费方式，分别是：

* 按量计费（后付费），即先使用再付费，费用计入账单内，您可以在账单出账后结算费用；
* 预付费，即先付费后使用，按订单结算；下单时扣费，不会再出账单。

<span id="09724e75"></span>
## 计费周期
<span id="04180889"></span>
### 预付费

| | | | | \
|类型 |计费项 |周期 |是否必买 |
|---|---|---|---|
| | | | | \
|知识库 |\
| |计算&离线存储 |按月 |必买 |
|^^| | | | \
| |文本向量模型资源包 |按年 |必买 |
|^^| | | | \
| |Rerank 模型资源包 |按年 |非必买 |
|^^| | | | \
| |大语言模型资源包 |按年 |非必买 |

<span id="f1d226d2"></span>
### 后付费
知识库以 <小时> 为周期统计所有计费项的使用量，并结算生成账单。
:::warning
创建知识库后，上传文档会触发知识库计算资源的分配和预留，并开始计费，文档删除不影响计算资源占用，若无需使用请主动删除知识库。
:::

<span id="2f23e9fb"></span>
## 计费项
<span id="02cb8e20"></span>
### 预付费
:::warning
当资源包用完后，为保障线上业务正常运行，将自动切换为后付费方式
:::

| | | | \
|类型 |**计费项** |**单价** |
|---|---|---|
| | | | \
|知识库 |\
| |计算资源 |259元/CU/月 |
|^^| | | \
| |离线存储资源 |1.08/GB/月 |
|^^| | | \
| |文本向量模型资源包 |2000元/ 5B tokens /年 |
|^^| | | \
| |Rerank 模型资源包 |50元/ 0.1B tokens /年 |
|^^| | | \
| |大语言模型资源包 |100元/ 1B /年 |

<span id="55f5a2bc"></span>
### 后付费
目前知识库为满足个人开发者和企业客户不同容量的业务需要，在后付费模式下提供了**标准版**和**旗舰版**两种知识库规格，详细对比如下：
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/00d63663287f4b56912078966b525d56~tplv-goo7wpa0wc-image.image =1278x)

| | | | | \
|**计费项** |**定义** |**如何计量** |**单价** |
|---|---|---|---|
| | | | | \
|计算资源-知识库 |使用知识库，构建索引、自动优化分析、线上检索依赖的计算资源。旗舰版知识库下计算资源采用独占模式。 |\
| | |按 CU（Compute Unit）计量，1 CU 包含的计算资源为 8 GB 内存和 1 CPU Core。 |\
| | |计算公式为 CU = MAX（CPU, MEM / 8），当使用的内存大于8倍的 1 CPU Core 时，CU 用量为消耗内存量除以 8。 |\
| | |例如，32 CU 所包含的计算资源为 256 GB 内存 和 32 CPU Core，若运行 5 小时，则计算费用 = 5 × 32 × 0.45 = 72 元。 |0.45 元/CU/小时 |
| | | | | \
|标准计算资源-知识库 |使用知识库，构建索引、自动优化分析、线上检索依赖的计算资源。标准版知识库下计算资源采用共享模式。 |按知识库数量计量。 |0.0416 元/知识库/小时 |
| | | | | \
|离线存储资源-知识库 |向量和向量相关的数据属性所需的存储资源。 |按占用的 GB 计量。 |0.0015 元/GB/小时 |
| | | | | \
|文本向量模型-知识库 |使用知识库，提供文本向量服务，帮助开发者将文本数据快速转换为向量数据。 |按输入的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0005 元/千tokens |
| | | | | \
|文本向量模型（多功能版）-知识库 |使用知识库，提供文本向量服务，帮助开发者将文本数据快速转换为向量数据。支持多语言和长文本，可同时进行稀疏和稠密索引构建和检索。 |按输入的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0005 元/千tokens |
| | | | | \
|文本向量模型（Doubao-embedding）-知识库 |使用知识库，提供文本向量服务，帮助开发者将文本数据快速转换为向量数据。字节跳动自研向量化模型，支持中英双语和高精度纯语义检索，支持4k Token的较长输入窗口。 |按输入的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0005元 / 千 tokens |
| | | | | \
|文本向量模型（Doubao- embedding-large）-知识库 |使用知识库,提供文本向量服务,帮助开发 |\
| |者将文本数据快速转换为向量数据。字节跳动自研向量化模型,支持中英双语和高精度纯语义检索。 |按输入的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0007元 / 千Tokens |
| | | | | \
|重排模型-知识库 |使用知识库，基于大语言模型对召回结果进行重排序。 |按输入 + 输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0005 元/千tokens |
| | | | | \
|大语言模型输入（Doubao-pro-4k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输入的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0008 元/千tokens |
| | | | | \
|大语言模型输出（Doubao-pro-4k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0020 元/千tokens |
| | | | | \
|大语言模型输入（Doubao-pro-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输入的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0008 元/千tokens |
| | | | | \
|大语言模型输出（Doubao-pro-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0020 元/千tokens |
| | | | | \
|大语言模型输入（Doubao-pro-128k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输入的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0050 元/千tokens |
| | | | | \
|大语言模型输出（Doubao-pro-128k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0090 元/千tokens |
| | | | | \
|大语言模型输入（Doubao-lite-4k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输入的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0003 元/千tokens |
| | | | | \
|大语言模型输出（Doubao-lite-4k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0006 元/千tokens |
| | | | | \
|大语言模型输入（Doubao-lite-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输入的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0003 元/千tokens |
| | | | | \
|大语言模型输出（Doubao-lite-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0006 元/千tokens |
| | | | | \
|大语言模型输入（Doubao-lite-128k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输入的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0008 元/千tokens |
| | | | | \
|大语言模型输出（Doubao-lite-128k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0010 元/千tokens |
| | | | | \
|大语言模型输入（Doubao-pro-256k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输入的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0050 元/千tokens |
| | | | | \
|大语言模型输出（Doubao-pro-256k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0090 元/千tokens |
| | | | | \
|大语言模型输入（Doubao-1.5-lite-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0003元/千tokens |
| | | | | \
|大语言模型输出（Doubao-1.5-lite-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0006/千tokens |
| | | | | \
|大语言模型输入（Doubao-1.5-pro-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.0008/千tokens |
| | | | | \
|大语言模型输出（Doubao-1.5-pro-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.002/千tokens |
| | | | | \
|大语言模型输入（Doubao-1.5-pro-256k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.005/千tokens |
| | | | | \
|大语言模型输出（Doubao-1.5-pro-256k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.009/千tokens |
| | | | | \
|大语言模型输入（Doubao-vision-pro-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.003/千tokens |
| | | | | \
|大语言模型输出（Doubao-vision-pro-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.009/千tokens |
| | | | | \
|大语言模型输入（Doubao-1.5-vision-pro-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.003/千tokens |
| | | | | \
|大语言模型输出（Doubao-1.5-vision-pro-32k）-知识库 |使用知识库，调用 Doubao 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.009/千tokens |
| | | | | \
|大语言模型输入（DeepSeek-V3-64k）-知识库 |使用知识库，调用 DeepSeek 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.002/千tokens |
| | | | | \
|大语言模型输出（DeepSeek-V3-64k）-知识库 |使用知识库，调用 DeepSeek 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.008/千tokens |
| | | | | \
|大语言模型输入（DeepSeek-R1-64k）-知识库 |使用知识库，调用 DeepSeek 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.004/千tokens |
| | | | | \
|大语言模型输出（DeepSeek-R1-64k）-知识库 |使用知识库，调用 DeepSeek 大语言模型服务，根据检索召回的结果生成智能回复。 |按输出的 tokens 计量。通常 1 个汉字、1 个英文字母、1 个数字或 1 个符号计为 1 个 token。 |0.016/千tokens |

<span id="874c3dc4"></span>
# 欠费说明
如果您账户中的可用额度（含账户余额和代金券）小于待结算的账单，会被认为欠费，您将会收到余额不足的短信或邮件提醒。本文介绍欠费之后您的资源情况及可执行操作。
请您在欠费 **24** 小时内充值并结清欠费账单，否则您将不能正常使用向量数据库及知识库服务。
向量数据库及知识库产生欠费后服务状态变化如下：

* 欠费 **24** 小时以内，系统将保持正常运行，持续计费。
* 欠费超过 **24** 小时不足 **168** 小时，火山引擎会暂停本服务使用，但仍保留您的数据及相关资源，欠费会继续累积。
* 当欠费超过 **168** 小时，视为您主动放弃向量数据库及知识库后付费服务，相关资源、数据将被释放，释放的资源及数据无法恢复。
* 如您在欠费 **168** 小时内补缴所有欠费账单后，服务将恢复正常。

<span id="fb5e90c2"></span>
# 税费及发票
除非另有说明，否则火山引擎平台上产品或服务定价均为包含增值税的金额。在服务提供过程中或产品使用期内，如遇国家税收政策调整，导致增值税税率发生变化的，增值税适用税率应按照国家税收政策相应调整，不含税价格保持不变。
我们支持您根据您在火山引擎账户已成功订购的订单和/或已出具的账单金额向您开具等额增值税发票，您可以通过火山引擎控制台-费用中心-发票管理申请增值税发票，我们将在收到您的发票申请后及时向您开具增值税发票。如您使用的服务对应的服务规则与本条约定不一致或双方另有约定的，应适用该等特定服务规则或双方另行约定的条款和条件。针对周期结算服务及具体使用量，公司亦保留要求用户提供资信证明、预付款、保证金或其他公司认为必要的开通和订购条件。
我们将根据您购买的具体产品或服务类型，按照如下发票内容向您开具增值税发票：

| | | | | \
|**产品或服务交付方式** |**服务期或授权期** |**发票内容** |**税率** |
|---|---|---|---|
| | | | | \
|知识库-公有云版本 |以客户实际使用服务期为准 |*信息技术服务*技术服务费 |6% |





# 联网内容插件产品计费
Source: https://www.volcengine.com/docs/82379/1338550
以下为您介绍联网内容插件的计费方式、计费组成及各插件具体计费项：

<span id="计费方式"></span>
## **计费方式**
联网内容插件当前支持按量计费后付费的计费方式，按照实际使用量付费。

<span id="计费组成"></span>
## **计费组成**

* 内容资源使用次数：联网内容插件一次接口返回中，内容资源按照资源类型去重后出现的次数。即一次请求返回结果包含某个内容源资源，该类型资源计费一次。
* 模型tokens消耗费用：使用插件可能会产生模型额外tokens消耗费用。如您在零代码中使用该插件，联网链路将包含意图识别、问题改写、总结环节。您可在“零代码-联网高级配置”中控制开启或跳过对应环节，若开启后，各环节将产生一定的模型tokens消耗，并按照真实的输入输出按量计费。

> 举例，您的应用调用了插件，返回了5个搜索结果，其中2个来源抖音资源，3个来源头条资源，即从2个内容源获取了返回结果，将计为2次搜索。

<span id="计费项"></span>
## **计费项**

| | | | | | \
|服务项 |服务说明 |计费方式 |价格 |付费方式 |
|---|---|---|---|---|
| | | | | | \
|联网资源 |支持实时搜索互联网公开域内容 |按加和量日结 |每月免费额度是2万次。超过2万次的部分是4元/千次 |按量计费后付费 |
| | | | | | \
|头条资源 |支持实时搜索今日头条图文内容，并提供内容详情信息供展示交互卡片 |按加和量日结 |6元/千次 |按量计费后付费 |
| | | | | | \
|抖音资源 |支持实时搜索抖音百科内容，并提供内容详情信息供展示交互卡片 |按加和量日结 |6元/千次 |按量计费后付费 |
| | | | | | \
|墨迹天气 |支持实时搜索墨迹天气内容资源 |按加和量日结 |6元/千次 |按量计费后付费 |


<span id="费用了解"></span>
## 费用了解

* 每次插件调用产生的内容资源使用次数，可通过调用时输出的source_type字段计算得到。
* 账号下插件调用产生的费用，可通过 [火山引擎控制台-费用中心-账单详情](https://console.volcengine.com/finance/bill/detail/) 了解，本系列插件对应产品为内容定制-联网内容插件。


<span id="税费及发票"></span>
## 税费及发票

1. 除非另有说明，否则火山引擎平台上产品或服务定价均为包含增值税的费用。在服务提供过程中或产品使用期内，如遇国家税收政策调整，导致增值税税率发生变化的，增值税适用税率应按照国家税收政策相应调整，不含税价格保持不变。
2. 我们支持您根据您在火山引擎账户已成功订购的订单和/或已出具的账单金额向您开具等额增值税发票，未消耗的预充值金额不支持开票。您可以通过火山引擎控制台-费用中心-发票管理或火山引擎不时指定并及时通知的其他渠道申请增值税发票，我们将在收到您的发票申请后及时向您开具增值税发票。如您使用的服务对应的服务规则与本条约定不一致或双方另有约定的，应适用该等特定服务规则或双方另行约定的条款和条件。
3. 我们将根据您购买的具体产品或服务类型，按照如下发票内容向您开具增值税发票：


| | | | | \
|产品或服务名称 |服务期或授权期 |发票内容 |税率 |
|---|---|---|---|
| | | | | \
|联网内容插件 |以订购页面展示的服务期为准 |*信息技术服务*技术服务费 |6% |


4. 如涉及退款且退款金额已开票，您应按照我们的要求准备退票相关的资料，通过火山引擎控制台-费用中心-发票管理或其他火山引擎支持的方式提交退票申请，并在提交退订申请时将退票相关的资料提供给我们，我们审核确认无误后进行款项的退还，详细信息请参见[退换发票](https://www.volcengine.com/docs/6269/1224228)。




# 税率与发票
Source: https://www.volcengine.com/docs/82379/1446839
1. 除非另有说明，否则火山引擎平台上产品或服务定价均为包含增值税的费用。在服务提供过程中或产品使用期内，如遇国家税收政策调整，导致增值税税率发生变化的，增值税适用税率应按照国家税收政策相应调整，不含税价格保持不变。
2. 我们支持您根据您在火山引擎账户已成功订购的订单和/或已出具的账单金额向您开具等额增值税发票，未消耗的预充值金额不支持开票。您可以通过火山引擎控制台-费用中心-发票管理或火山引擎不时指定并及时通知的其他渠道申请增值税发票，我们将在收到您的发票申请后及时向您开具增值税发票。如您使用的服务对应的服务规则与本条约定不一致或双方另有约定的，应适用该等特定服务规则或双方另行约定的条款和条件。
3. 我们将根据您购买的具体产品或服务类型，按照如下发票内容向您开具增值税发票：
   
   | | | | | \
   |产品或服务名称 |服务期或授权期 |发票内容 |税率 |
   |---|---|---|---|
   | | | | | \
   |字节跳动大模型服务（豆包大模型） |以订购页面展示的服务期为准 |*信息技术服务*技术服务费 |6% |

4. 如涉及退款且退款金额已开票，您应按照我们的要求准备退票相关的资料，通过火山引擎控制台-费用中心-发票管理或其他火山引擎支持的方式提交退票申请，并在提交退订申请时将退票相关的资料提供给我们，我们审核确认无误后进行款项的退还，详细信息请参见[退还发票](https://www.volcengine.com/docs/6269/1224228)。


# 产品更新公告
Source: https://www.volcengine.com/docs/82379/1159177
本文介绍了火山方舟大模型服务平台的新版本产品功能特性，欢迎体验。
> 模型更新信息请见：[模型发布公告](https://www.volcengine.com/docs/82379/1159178)

<span id="95501303"></span>
# Release Note - 20250611

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型广场 |* 模型广场 & 模型详情页优化 |[模型广场](https://www.volcengine.com/docs/82379/1099503) |
| | | | \
|体验中心 |* 支持视觉理解模型开启联网功能 |\
| |* 支持体验 Doubao-Seedance-1.0-pro模型 |\
| |* 支持体验 Doubao-Seedance-1.0-lite-i2v & Wan2.1-14B 首尾帧功能 |\
| |* Seedance1.0 lite 新增支持1080P分辨率 |\
| |* 支持向量模型 |\
| |* 支持知识问答 |\
| |* 支持端到端实时语音模型 |[体验中心](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|应用实验室 |* DeepSearch优化 |\
| |* 高代码应用支持通用MCP |[应用实验室](https://www.volcengine.com/docs/82379/1262002) |
| | | | \
|在线推理 |* 监控指标优化 |[在线推理](https://www.volcengine.com/docs/82379/1182403) |
| | | | \
|批量推理 |* 视觉理解模型支持base64格式或可下载链接的图片 |[批量推理](https://www.volcengine.com/docs/82379/1305505) |
| | | | \
|API |* 视频生成API： |\
| |   * 支持Seedance1.0 lite 首尾帧 |\
| |   * 支持Doubao-Seedance-1.0-pro模型调用 |\
| |   * Seedance1.0 lite 新增支持1080P分辨率 | |\
| | |[视频生成](https://www.volcengine.com/docs/82379/1520757) |
| | | | \
|模型计费 |* 模型计费升级 |[模型计费](https://www.volcengine.com/docs/82379/1544106) |


<span id="fcec8d2f"></span>
# Release Note - 20250522

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|概览页 |* 优化 2 分钟快速创建应用链路 | |
| | | | \
|模型推理 |* 配置接入点告警时支持从方舟控制台配置通知策略 |[查看并管理推理接入点](https://www.volcengine.com/docs/82379/1182403) |
| | | | \
|应用实验室 |* 自定义推理接入点的 thinking 模型支持开启联网内容插件 |[零代码应用操作指南](https://www.volcengine.com/docs/82379/1267885) |
| | | | \
|API |* 对话（Chat）API 接口支持 JSON Schema |[结构化输出](https://www.volcengine.com/docs/82379/1568221) |
| | | | \
|开通管理 |* 推理限额及安心体验模式支持文本 embedding 模型 |[开通管理](https://www.volcengine.com/docs/82379/1159200) |


<span id="906f8edb"></span>
# Release Note - 20250430

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|体验中心 |* 语音模型-语音合成-支持混音mix功能 |[体验中心](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|应用实验室 |* [火山引擎大模型生态广场](https://www.volcengine.com/mcp-marketplace) 已正式发布：目前已上线 100个 MCP Server，集成了丰富的火山引擎官方云服务及优质三方生态工具。支持用户快速跳转至火山方舟及其他支持 MCP 协议的平台（如 Trae、Cursor等），结合火山方舟大模型服务，快速进行端到端应用开发 |\
| |* 零代码应用创建中，知识库引用切片数量支持最大500条 |[高代码应用 创建部署指南](https://www.volcengine.com/docs/82379/1333715) |
| | | | \
|模型推理 |* 可在推理接入点详情页监控一键配置接入点告警 |\
| |* 支持删除预置推理接入点 |[查看并管理推理接入点](https://www.volcengine.com/docs/82379/1182403) |


<span id="6cb5afaa"></span>
# Release Note - 20250401


| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|体验中心 |* 支持一键开通所有模型、自动开通后续新增模型，实现 2 分钟快速接入的便捷式体验 |[体验中心](https://www.volcengine.com/docs/82379/1217589) |
| | | | \
|模型精调 |* 新增save_model_per_epoch参数，支持自定义精调产物保存间隔 |[模型精调](https://www.volcengine.com/docs/82379/1099460) |
| | | | \
|视频生成模型 |* 新增 seed 参数，用于控制生成内容的随机性。对于相同的请求，若使用相同的随机种子，将产生类似的视频生成结果 |\
| |* ratio 参数新增可选项 9:21 |[视频生成模型](https://www.volcengine.com/docs/82379/1366799) |
| | | | \
|模型推理 |* 接入点列表支持按照购买方式过滤 |\
| |* 接入点列表新增所属项目字段 |\
| |* doubao1.5-vision-pro-32k 模型支持 function call |[模型推理](https://www.volcengine.com/docs/82379/1182403#%E5%91%8A%E8%AD%A6%E9%80%9A%E7%9F%A5) |
| | | | \
|应用实验室 |* 零代码 DeepSeek-R1、DeepSeek-V3 支持网页解析插件 |\
| |* 高代码/零代码控制台体验时支持设置非流式输出 |\
| |* 创建应用时推理接入点参数新增预置推理接入点，支持用模型名称接入 |\
| |* 高代码智能体 Trace 追踪，并可进行可交互可视化的定位 |\
| |   * 日志服务TLS为火山方舟高代码应用用户提供**3个月专属免费额度**。详细说明：截止**2025年6月30日**，高代码应用日志服务-Trace分析处于推广阶段，推广期间每个火山引擎主账号下**享受每天10GiB的免费存储**权益，预估可存储**数万条请求分析。** |\
| | |\
| | |[应用实验室](https://www.volcengine.com/docs/82379/1333715) |


<span id="9126d310"></span>
# Release Note - 20250317

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|概览页 |* 极简首次接入模型流程，清晰了解各个功能菜单 |\
| |* 自助式运维，覆盖服务监控、用量统计、安全监控、用户 top 关注问题指引 | |
| | | | \
|体验中心 |* 支持上传文档、网页链接解析体验 |[体验中心](https://www.volcengine.com/docs/82379/1217589) |\
| | | |
| | | | \
|用量统计 |* 支持查看汇总后的插件用量 |\
| |* 支持查看体验中心、预置推理接入点用量 |[用量统计](https://www.volcengine.com/docs/82379/1159199) |\
| | | |
| | | | \
|模型推理 |* 批量推理支持 doubao1.5-pro-vision |\
| |* DeepSeek-R1、DeepSeek-V3 支持 Function Call |\
| |*  temperature 参数范围扩展至[0, 2] |\
| |* Chat API 流式输出支持返回每个 chunk 的 usage |[模型推理](https://www.volcengine.com/docs/82379/1182403#%E5%91%8A%E8%AD%A6%E9%80%9A%E7%9F%A5) |\
| | | |
| | | | \
|应用实验室 |* 增加用FC实现全链路+非平台插件的demo |\
| |   * 车载专用品网店-智能导购 |[应用实验室](https://www.volcengine.com/docs/82379/1267885) |\
| | | |


<span id="6e51a00e"></span>
# Release Note - 20250304


| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|体验中心  |* 可视化代码编辑模式，方便用户理解API调用，支持一键复制及跳转API key |[体验中心](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|用量观测  |* token计算器上新，计算逻辑适配不同模型，同时支持部分模型关于图片token的计算需求 | |
| | | | \
|模型推理 |* 支持模型单元在下单、扩缩容失败时通过火山引擎消息通知服务接收告警信息 |[模型推理](https://www.volcengine.com/docs/82379/1182403#%E5%91%8A%E8%AD%A6%E9%80%9A%E7%9F%A5) |
| | | | \
|模型精调 |* 精调效果指标支持下载 |[模型精调](https://www.volcengine.com/docs/82379/1099460) |
| | | | \
|应用广场 |* AI手机助手上线 |\
| |   * 基于豆包-图像理解模型的同屏交互系统，专为移动端即时需求设计的创作中枢，用户在任意界面唤醒AI手机助手，支持AI帮写（可支持DeepSeek回答）、物体识别、实时翻译、日程添加、体检报告解读等。可扫码下载，目前仅支持安卓5.0及以上系统 |[应用实验室](https://www.volcengine.com/docs/82379/1267885) |
| | | | \
|视觉理解模型 |* API中system_prompt支持传图：VLM的system_prompt支持list结构，可传text和image_url |\
| |* 单次请求传入图片数量只受模型上下文长度的限制，可根据图片转换的token数判断 |[视觉理解模型](https://www.volcengine.com/docs/82379/1362931) |\
| | | |
| | | | \
|视频生成模型 |* 视频生成模型API支持更多图片格式：JPEG（JPG）、PNG、webp、bmp、tiff |[视频生成模型](https://www.volcengine.com/docs/82379/1366799) |\
| | | |

<span id="b6f9af42"></span>
# Release Note - 20250214

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|体验中心 |* 新增DeepSeek模型 |[体验中心](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|应用实验室 |* 零代码应用可使用deepseek模型且**支持联网能力** |\
| |* 高代码智能体创建流程优化 |\
| |   * 创建应用 |\
| |      * 支持关联已有函数创建新的高代码应用 |\
| |   * 创建新应用函数 |\
| |      * 新增编排配置，提供示例工程可一键下载在vs code打开 |\
| |      * 新增推理接入点配置，可直接选择接入点 |\
| |      * 新增开通模型和插件扩展的快捷入口 |\
| |      * 支持一键跳转查看所关联云服务的计费说明 |\
| |      * 支持更换API访问密钥 |[高代码应用 创建部署指南](https://www.volcengine.com/docs/82379/1333715) |
| | | | \
|模型推理 |\
| |* 新增概念介绍 |\
| |   * 基于推理的不同场景新增定价与计费介绍 |\
| |   * 新增批量推理任务和批量推理接入点介绍 |[批量推理](https://www.volcengine.com/docs/82379/1305505) |\
| | | |
| | | | \
|模型精调 |* 基于模型生命周期对模型精调进行管控和提示 |\
| |   * 上线阶段，支持创建精调任务并推理 |\
| |   * 即将下线阶段，允许存量用户创建精调任务并推理 |\
| |   * 下线阶段，允许精调但仅支持按照单元计费方式使用 |[模型精调](https://www.volcengine.com/docs/82379/1099350) |\
| | | |
| | | | \
|开通管理 |* 定价展示支持K tokens（元/千tokens）和 M tokens（元/百万tokens）切换 |[开通管理](https://www.volcengine.com/docs/82379/1159200) |\
| | | |
| | | | \
|安全 |\
| |* 安全审计页面优化 |\
| |   * 部分KMS访问日志支持查看requestid |\
| |   * 会话数据安全视图增加加密情况信息 |\
| |   * 应用层会话加密看板中增加统计时间和延迟的提示 |[安全审计](https://www.volcengine.com/docs/82379/1400040) |\
| | | |


<span id="54bc4b24"></span>
# Release Note - 20250117

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|体验中心 |* VLM模型扩充上传图片格式，现支持JPEG，PNG，GIF，WEBP，BMP，DIB |[体验中心](https://www.volcengine.com/docs/82379/1099504) |\
| | | |
| | | | \
|模型精调 |* FunctionCall精调数据格式支持parallel_tool_calls 字段 |[模型精调](https://www.volcengine.com/docs/82379/1099350) |\
| | | |
| | | | \
|模型推理 |* 批量推理任务结束之后通过SNS平台发送通知 |[在线推理](https://www.volcengine.com/docs/82379/1182403) |\
| | | |
| | | | \
|模型仓库 |* 模型仓库自定义模型增加「支持部署方式」字段，标记模型支持「独立部署」或「共享部署」 |[模型仓库](https://www.volcengine.com/docs/82379/1217587) |\
| | | |
| | | | \
|用量统计 |* 新增“批量推理”维度查看用量 |[用量统计](https://www.volcengine.com/docs/82379/1159199) |\
| | | |
| | | | \
|数据集 |* 数据集支持dpo精调数据格式 |[数据集](https://www.volcengine.com/docs/82379/1356562) |\
| | | |


<span id="02f33a2f"></span>
# Release Note - 20250113

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|体验中心 |* 语音模型-声音复刻在“生成试听”过程中支持切换音色 |\
| |* 语音模型-语音合成音色标签导航栏进行重构 |\
| |* 语音模型-语音识别不同使用状态的交互提醒优化 |[体验中心](https://www.volcengine.com/docs/82379/1099504) |\
| | | |
| | | | \
|模型推理 |\
| |* 批量推理允许超限 TPD 以低优继续运行 |\
| |* 批量推理接入点接口调用支持python和java sdk |[在线推理](https://www.volcengine.com/docs/82379/1182403) |\
| | | |
| | | | \
|模型精调 |* 因为 unknown error 失败的精调任务允许 3次重试 |[模型精调](https://www.volcengine.com/docs/82379/1099459) |\
| | | |
| | | | \
|安全 |* 在用量统计页面中增加异常日志汇总、异常日志趋势、安全能力配置状态等三个模块 |/ |
|^^| | | \
| |* 可在VLM的接入点创建页面选择内容安全护栏方案，如果选择基础版，VLM API中可以返回风险分类原因 |[视觉理解模型](https://www.volcengine.com/docs/82379/1362913) |\
| | | |


<span id="0013f93d"></span>
# Release Note - 20241231

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型广场 |* 优化选择模型弹框在交互和时延上的体验 |[模型广场](https://www.volcengine.com/docs/82379/1099503) |\
| | | |
| | | | \
|体验中心 |* 视频生成体验迭代优化： |\
| |   * 任务在发送后的等待生成过程中支持撤回终止，支持展示任务ID |\
| |* 文本模型体验迭代优化： |\
| |   * prompt优化基座模型更新为doubao-pro-32k-240828 |[体验中心](https://www.volcengine.com/docs/82379/1099504) |\
| | | |
| | | | \
|模型推理 |\
| |* 模型接入点功能升级，包括： |\
| |   * 无法在即将退役的模型版本上继续创建接入点 |\
| |* 可监控性增强，包括： |\
| |   * 支持项目维度的 TPM/RPM 实际使用率统计 |[在线推理](https://www.volcengine.com/docs/82379/1182403) |\
| | | |
| | | | \
|模型精调 |* 需要模型单元推理的精调任务增加资源配额提示 |\
| |* FunctionCall分支模型支持使用含FunctionCall样本训练集进行SFT精调 |\
| |* 提供精调效果指标 OpenAPI |[模型精调](https://www.volcengine.com/docs/82379/1099459) |\
| | | |
| | | | \
|Prompt优解 |* 新增Prompt优解模块，包括Prompt生成、调优及管理功能，为用户提供辅助Prompt优化的自动化一站式解决方案 |[Prompt优解](https://www.volcengine.com/docs/82379/1399495) |\
| | | |
| | | | \
|智能体 |* 新增互动双语视频生成器原型应用，[体验](https://console.volcengine.com/ark/region:ark+cn-beijing/assistant/detail?id=bot-20241211162948-5l2kk-procode-preset&projectName=default)  |[智能体中心](https://www.volcengine.com/docs/82379/1267885) |\
| | | |
| | | | \
|数据集 |* 支持预览数据集内容和下载数据集文件，提供更强的数据管理能力 |\
| |* 支持上传含FunctionCall 样本的SFT精调格式数据文件 |[数据集](https://www.volcengine.com/docs/82379/1356562) |
| | | | \
|安全 |* 在用量统计页面中，增加存在安全风险的接入点的汇总展示 |\
| |* 在推理安全审计页面中，重构接入点登录日志，展示登录IP及对应登录次数，帮助用户判断是否有非预期IP登录自己的接入点 |[推理安全审计](https://www.volcengine.com/docs/82379/1400038) |
|^^| | | \
| |* 会话端到端加密Python SDK支持API-Key鉴权方式 |[推理会话数据应用层加密方案](https://www.volcengine.com/docs/82379/1389905) |


<span id="3320d5e2"></span>
# Release Note - 20241213

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|体验中心 |* 图片内容理解模型体验优化迭代，包括： |\
| |   * 展示tokens数量，包括输入框中显示总tokens值，和在每轮对话中提示消耗tokens值 |\
| |   * 支持用户根据使用场景选择vlm模型的高细节理解或低细节理解模式 |\
| |   * 在上传图片方式中增加“URL上传”，用户可直接复制图片URL后导入输入框 |[体验中心](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|模型推理 |* 批量推理任务支持重启 |\
| |* 批量推理支持Doubao-lite-32k｜240828 |\
| |* 支持通过创建接入点进行批量推理(需[填写工单](https://www.volcengine.com/docs/82379/1159177)申请使用）[oncall](https://www.volcengine.com/docs/82379/1159177) |\
| |   * 提供一种相比在线访问几乎无改造量的批量推理接入方式 |\
| |   * 用户无需处理数据，通过平台提供的SDK直接调用模型接口实现批量推理 |[在线推理](https://www.volcengine.com/docs/82379/1182403) |
| | | | \
|用量统计 |* 用量统计通过OpenAPI形式支持，客户可以通过GetUsage发起调试查看用量数据 |[用量统计](https://www.volcengine.com/docs/82379/1159199) |
| | | | \
|安全与信任 |* 会话数据应用层端到端加密支持VLM模型 |[推理会话数据应用层加密方案](https://www.volcengine.com/docs/82379/1389905) |
|^^| | | \
| |* 在接入点安全审计页面中，展示会话数据加密/未加密状态 |\
| |* 在数据协作计划产品界面和用户协议中透出安全方案 |\
| |* 优化推理和精调安全审计界面的监控看板 |[审计日志API文档](https://www.volcengine.com/docs/82379/1289652) |

<span id="c6d6f0b3"></span>
# Release Note - 20241126

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|体验中心 |* 文本模型界面功能升级，包括： |\
| |   * 支持AI自动总结标题 |\
| |   * 支持返回“体验中心首token延迟时间”，直观对比各模型推理延迟 |\
| |   * 优化长文本场景下体验（输入框和页面新增滑动条，输出侧新增“一键回底部”按钮） |\
| |* 图片内容理解模型（该模型需[填写工单](https://www.volcengine.com/docs/82379/1159177)申请试用）体验优化迭代，包括： |\
| |   * 支持至多50张图片的上传体验（实际上限以图片所占用的上下文窗口为准） |\
| |   * 支持将图片直接复制粘贴至输入框 |\
| |   * 页面提供丰富场景示例，支持一键发送体验 |\
| |* 视觉模型界面功能升级，AI视频生成结果支持视图切换及筛选 |[体验中心](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|在线推理 |* 支持 Doubao-lite 系列模型购买并开通 TPM 保障包，该保障包为高流量业务提供资源保障，适用于大流量、流量大小可预估且对生产级高 SLA 有要求的场景 |[在线推理](https://www.volcengine.com/docs/82379/1182403) |
| | | | \
|智能体 |* 旧版联网插件（基础版、plus版、pro版）支持一键升级为新版联网内容插件。原联网基础版、联网plus版、联网pro版插件将于**2024年12月24日18:00**下线 |\
| |* 零代码智能体功能迭代与体验优化，包括： |\
| |   * 零代码智能体的rerank重排默认链路调整 |\
| |   * 支持用户在零代码智能体中使用图片内容理解模型上传图片或图片链接进行问答 |\
| |   * 零代码群聊智能体支持以API参数的方式动态进行角色和场景配置 |\
| | |\
| |优化智能体 API 调用示例，展示了多种语言版本，支持智能体的快速调用 |[智能体中心](https://www.volcengine.com/docs/82379/1267885) |
|^^| | | \
| |* 新版联网内容插件进行了全方位升级，丰富内容源并实现链路优化，与最新豆包大模型配合使用效果提升。原联网基础版、联网plus版、联网pro版插件将于2024年12月24日18:00起停止服务，不再支持调用。更多信息详见 [升级说明文档](https://www.volcengine.com/docs/82379/1359519)，如有任何问题，请随时联系我们。 |\
| |* 网页解析插件升级，支持word、excel等更多格式 |[服务组件库](https://www.volcengine.com/docs/82379/1261475) |
| | | | \
|数据集 |* 新增 文本向量化-SFT精调 数据格式 |\
| |* 优化数据格式组织方式，更清晰地展示各数据格式的用途 |[数据集](https://www.volcengine.com/docs/82379/1356562) |
| | | | \
|安全与信任 |* 在线推理和模型精调的安全审计页面和审计日志API更新： |\
| |   * 沙箱连接日志区分连接状态 |\
| |   * 增加通过主机堡垒机登录沙箱的日志 |\
| |   * 沙箱登录日志，新增字段透出沙箱的登录方式，帮助用户定位是否是违规登录 |[审计日志API文档](https://www.volcengine.com/docs/82379/1289652) |

<span id="725ef305"></span>
# Release Note - 20241029

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型推理 |* 优化推理接入点监控面板，展示推理接入点的全局运行情况，新增TPM、RPM及成功率等指标 |\
| |* 推理接入点详情页可展示关联智能体的信息，并支持通过该页面快速创建智能体 |[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522) |
| | | | \
|智能体 |零代码智能体发布后，支持查看其调用统计数据，包括智能体调用量、智能体调用tokens数以及插件调用量指标 |[应用实验室](https://www.volcengine.com/docs/82379/1262002) |
| | | | \
|安全与信任 |在精调或创建数据集过程中：当用户选择上传数据集时，平台为该数据集自动开启SSE-TOS加密，保证数据在TOS密文存储，更安全；当用户选择从TOS导入时，引导用户为该数据集自行开启SSE-TOS加密 |- |
| | | | \
|数据集 |* 数据集模块对全量用户开放可见 |\
| |   * 支持模型精调使用数据集 |\
| |   * 支持数据集版本管理功能 |\
| |   * 支持数据集共享能力 |[共享数据集](https://www.volcengine.com/docs/82379/1284854) |

<span id="b186ea85"></span>
# Release Note - 20241015

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型广场 |在Doubao-pro聚合页新增256k模型 |[模型广场](https://www.volcengine.com/docs/82379/1099503) |
| | | | \
|体验中心 |长输入文本情况下交互体验优化，默认定位到输出内容 |[文本模型](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|智能体 |上线 ASR+LLM+TTS 官方智能体demo，如需获取最佳实践可 [联系我们](https://www.volcengine.com/docs/82379/1159177) |[应用实验室](https://www.volcengine.com/docs/82379/1262002) |
| | | | \
|服务组件库 |插件新增抖音百科内容源 |[联网系列功能说明](https://www.volcengine.com/docs/82379/664afae83c82fe026aad1bc7) |
| | | | \
|模型推理 |支持批量推理输入文件大小配额提升，可以[提交工单](https://www.volcengine.com/docs/82379/1159177)申请更大的文件大小上限（最大 8 GiB） |[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522) |
| | | | \
|安全与信任 |审计日志 API 支持精调相关日志 |[安全审计日志](https://www.volcengine.com/docs/82379/1151431) |
|^^| | | \
| |* 精调流程安全可视化： |\
| |   * 精调任务详情页面中增加安全审计 tab 页，展示精调数据流程图和精调安全日志，增加安全可信度 |\
| |   * 精调任务列表页面增加安全沙箱标识，点击后可查看精调安全技术演示动画，帮助用户理解精调数据流转路径中的安全概念 |- |

<span id="ba03c4ae"></span>
# Release Note - 20240924

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|体验中心 |* 体验中心「语音模型」新增语音识别（支持方言）体验能力，可上传音频文件或实时录音识别语音 |\
| |* 体验中心「语音模型」新增同声传译体验，支持中文与英文的同声传译，其中译文音色为复刻声音 |\
| |* 体验中心「视觉模型」新增AI视频体验，支持图片生成视频与文本生成视频 |\
| |* 体验中心「视觉模型」新增文生图的模型体验，支持文本生成图片 |[文本模型](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|智能体 |* 上线长期记忆官方智能体demo |[应用实验室](https://www.volcengine.com/docs/82379/1262002) |
| | | | \
|模型推理 |* 支持同一个推理接入点上平滑切换模型版本 |[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522) |

<span id="7872fe34"></span>
# Release Note - 20240914

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|新用户引导 |在模型精调、模型仓库、模型评测、在线推理、批量推理等页面上方，新增模块介绍和引导 |- |
| | | | \
|模型广场 |模型详情页优化，更清晰展示版本特性、价格、快捷操作入口等，并新增同类模型的聚合页 |[模型广场](https://www.volcengine.com/docs/82379/1099503) |
| | | | \
|体验中心 |同一模型的多个对话体验，可各自设置独立的参数配置 |[文本模型](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|智能体 |新增零代码智能体system prompt优化功能，支持用户一键快速优化并降低编写门槛 |\
| |智能体提示词system prompt最大长度限制升级扩展到10000字 |\
| |联网系列插件三合一升级为联网内容插件，新用户可在零代码智能体中使用。支持联网和内容源按需选择且支持与知识库混合使用。插件开通后，即可赠送每月2万次联网资源的免费额度，头条、天气等内容源资源按使用量后付费。 |[应用实验室](https://www.volcengine.com/docs/82379/1262002) |
| | | | \
|模型评测 |自动评测增加裁判员模型评测 |\
| |支持xls、xlsx格式评测集上传以及结果批量导出 |[模型评测体系介绍](https://www.volcengine.com/docs/82379/1150779) |
| | | | \
|在线推理 |模型单元改为实例型独占资源模式，支持按小时付费 |[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522) |
| | | | \
|安全与信任 |安全审计日志API新增功能：支持按时间筛选日志，新增返回风险等级和日志细节等信息 |\
| |ChatCompletions接口的审核支持 n 参数：当模型的 n 路 response 同时送审时，只针对被拦截的 response 进行拒答文案替换，其余 response 正常放行 |[安全审计日志](https://www.volcengine.com/docs/82379/1151431) |

<span id="03e48d98"></span>
# Release Note - 20240903

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型广场 |新增模型广场厂商视图，更清晰地展示同一厂商的模型家族全貌及各模型的结构化信息 |[模型广场](https://www.volcengine.com/docs/82379/1099503) |
| | | | \
|智能体 |* 新增零代码智能体自助Debug功能，支持对单轮执行完成的会话进行调试 |\
| |* 零代码智能体功能迭代与体验优化，包括： |\
| |   * 智能体中心新增“AI生成智能体”功能，支持用户一键创建并体验智能体效果 |\
| |   * 对话体验支持本地PDF文件上传 |[应用实验室](https://www.volcengine.com/docs/82379/1262002) |

<span id="release-note-20240611"></span>
# Release Note - 20240820

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|体验中心 |* 新增豆包语音合成模型的体验 |\
| |* 支持一键副本当前话题为新话题，并保留已选模型及相关参数配置 |[体验中心](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|智能体 |* 插件并发超限时将触发兜底策略 |\
| |   * 当插件并发超限时，系统会提示出错，并将对应插件的参考资料设置为空，但保留原配置 |\
| |   * 可通过自定义prompt，来调整是否需要回答参考资料为空时的问题 |\
| |* 联网+知识库同时使用参考资料增加资料来源标签 |\
| |   * 可分别指定对不同资料的处理办法 |\
| |* 联网/知识库-自定义回答方式增加使用示例与样式优化 |[智能体](https://www.volcengine.com/docs/82379/1267885) |
| | | | \
|用量统计 |* 用量统计看板拆分展示调用总tokens数、输入总tokens数、输出总tokens数 |\
| |* 支持查看所选服务下具体接入点的相关调用量 |[用量统计](https://www.volcengine.com/docs/82379/1159199) |
| | | | \
|安全与信任 |* 接入点详情页面中增加安全审计标签页： |\
| |   * 该标签页中有安全总览指标、推理流程图、审计日志，帮助用户了解推理是否安全 |/ |
|^^| | | \
| |* 增加审计日志API可审计的事件 |\
| |   * 增加了沙箱容器逃逸日志、vArmor防护日志等 | |

<span id="release-note-20240806"></span>
# Release Note - 20240806

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|体验中心 |新增豆包**声音复刻**大模型体验 |[体验中心](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|模型推理 |* 支持**批量推理**。适用于无需实时响应的推理场景，可以一次性离线处理大量数据。 |\
| |* Chat API v3 更新：支持 presence_penalty/frequency_penalty |\
| |* 增加安全沙箱标识，点击可弹出推理安全方案演示动画 |[批量推理](https://www.volcengine.com/docs/82379/1305505) |\
| | |[大模型调用ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | \
|智能体中心 |* 优化联网改写/总结prompt模版 |\
| |* 智能体SearchSummary action透出联网reference |\
| |* 高代码智能体assistant api支持方舟apikey鉴权 |[智能体中心](https://www.volcengine.com/docs/82379/1262002) |

<span id="release-note-20240723"></span>
# Release Note - 20240723

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型广场 |* 新增豆包语音合成模型 |\
| |* 模型详情页版本列表按分组展示 |\
| |* Doubao Embedding 模型的模型卡片与相应示例代码更新至 API V3 |[模型广场](https://www.volcengine.com/docs/82379/1099503) |
| | | | \
|体验中心 |- 增加智能体体验，用户可在“体验插件和模型应用”标签下选择体验示例智能体模版 |[体验中心](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|评测任务 |- 系统评测集和个人评测集会过审核机制，审核策略与用户自定义配置保持一致 |[模型评测](https://www.volcengine.com/docs/82379/1150782) |
| | | | \
|模型精调 |- 优化了精调列表页的视觉交互体验，展示状态等重点信息 |[创建精调任务](https://www.volcengine.com/docs/82379/1099459) |
| | | | \
|模型推理 |- 原「模型推理」模块更名为「在线推理」，优化模型接入点限频说明 |[创建推理接入点](https://www.volcengine.com/docs/82379/1099522) |
| | | | \
|智能体中心 |* 知识库新增命中测试功能并支持用户调整大模型问答测试有关参数 |\
| |* 智能体群聊功能上线，支持用户通过 GUI 选择多个智能体进行角色扮演 |\
| |* 优化智能体对话界面的报错交互与文案 |\
| |* 高代码智能体部署与开通流程简化 |\
| |   * 支持一键开通基础依赖服务 |\
| |   * 提供一键开通和一键加白的 API 接口，以及基于 API 接口的一键开通按钮 |[智能体中心](https://www.volcengine.com/docs/82379/1262002) |
| | | | \
|开通管理 |* 增加豆包语音合成模型开通项 |\
| |* 用户可通过开通管理页面产品入口授权提升免费额度，免费额度内的数据会被收集用于模型训练 |[开通管理](https://www.volcengine.com/docs/82379/1159200) |
| | | | \
|安全与信任 |- 支持通过OpenAPI查看安全沙箱登录和连接记录的审计日志 |[获取安全审计日志](https://www.volcengine.com/docs/82379/1289652) |
| | | | \
|其他 |- 精调、评测、模型仓库等模块，数据集和模型文件上传到 TOS 时，按项目进行管理 | |

<span id="release-note-20240611"></span>
# Release Note - 20240708

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型推理 |* 支持智谱 GLM3 / GLM4 模型的 function call 协议适配 |\
| |* 模型推理 API V3 已修复部分细节问题（如报错处理、参数范围和默认值调整等） |[API调用指南](https://www.volcengine.com/docs/82379/1262901) |
| | | | \
|体验中心 |* 体验中心界面交互优化如下： |\
| |   * 体验中心-历史对话的话题区分项目，便于用户管理使用 |\
| |   * 支持选择已创建的模型推理接入点（ Endpoint ）进行体验 |[体验中心](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|模型精调 |* 增加精调任务资源预占功能：为排队第一且排队时间远大于平台均值的任务自动开启资源预占 |\
| |* 模型仓库新增「增量训练」操作按钮，支持用户一键增量训练 |\
| |* 优化模型精调报错交互，增加显著的提示入口及明确的失败原因，提升用户体验 |[模型精调](https://www.volcengine.com/docs/82379/1099459) |
| | | | \
|智能体 |* 新增支持[网页解析插件](https://www.volcengine.com/docs/82379/1284852)： |\
| |   * 使用前需在服务组件库进行开通，限时免费 |\
| |   * 当前不支持与其他插件同时开启使用 |\
| |* 联网插件链路部分升级，其中包括： |\
| |   * 支持多风格 Prompt 模板选择及自定义，可通过零代码创建的“联网插件-高级配置-回答配置”进行选择 |\
| |   * 联网Plus版引用条数上限从5增加至10 |\
| |   * 优化联网插件的意图识别环节链路 |\
| |   * 透传userinfo(用户当前的时间和地点) 以提升模型回复正确率与效果 |\
| |* 知识库插件链路部分升级： |\
| |   * 支持多风格Prompt模板选择及自定义，可通过零代码创建的“知识库插件-高级配置-回答配置”进行选择 |\
| |* BotApi V3 [API文档](https://www.volcengine.com/docs/82379/1285207) / [SDK调用指南](https://www.volcengine.com/docs/82379/1302007) 已上线 |\
| |* Chatapi V3 已支持 Function calling 能力，支持用户将外部工具或 API 接入大模型，[使用说明](https://www.volcengine.com/docs/82379/1262342)详见文档 |[智能体中心](https://www.volcengine.com/docs/82379/1262002) |

<span id="release-note-20240611"></span>
# Release Note - 20240625

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型广场 |新增“Doubao-声音复刻”，“Doubao-语音合成”，“豆包-文生图模型-智能绘图”模型，支持模型接入 |[模型广场](https://www.volcengine.com/docs/82379/1099503) |
| | | | \
|智能体 |* 新增计算器插件（beta版本，如需使用请提交工单联系我们） |\
| |   * 当用户点击选择更多插件时支持添加计算器插件 |\
| |   * 组件可多选，请注意：计算器插件和联网/知识库不可同时开启 |\
| |   * 计算器插件限时免费，无需额外开通 |\
| |* 智能体中心支持插件限流调整：支持以账户纬度的插件限流调整 |[智能体中心](https://www.volcengine.com/docs/82379/1262002) |

<span id="release-note-20240605"></span>
# Release Note - 20240605

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型推理 |* 模型调用SDK版本升级，SDK V3新增支持Java、Golang语言。 |\
| |* 模型推理 API/SDK V3支持功能升级，新支持embedding和function call功能，包含Python、Java、Golang 三种语言。 |\
| |* 优化模型推理API调用说明，为所有推理接入点提供详细的获取授权方式说明，以及不同代码语言和不同场景切换的API调用示例。 |\
| |* API key的鉴权方式升级，平台支持长效API key的创建和管理，减少因API key失效而频繁更换的麻烦。其中包括： |\
| |   * API key的创建：用户可通过界面化形式为不同项目创建API key，`all`权限默认给予项目下所有资源访问权限。API key当前生效于推理服务（endpoint）、智能体（bot)、智能体组件（action)。 |\
| |   * API key的调用：调用方式与OpenAI SDK完全对齐。用户只需将API key替换为方舟的API key，即可调用方舟上的模型。 |\
| |   * 短效API key仍然可用，适用于对安全有更严格管理要求的用户。 |[模型调用API](https://www.volcengine.com/docs/82379/1262901) |
| | | | \
|智能体 |* 智能体广场新发布联网、联网+内容、知识库三种插件的示例智能体及prompt优化大师示例智能体。 |\
| |* 智能体体验和开发升级，其中包括： |\
| |   * 智能体体验模块增加水印。 |\
| |   * 智能体体验时前端会带入当前ip的城市区域信息。 |\
| |   * 智能体的提示词放大到3000字。 |\
| |   * 高代码智能体开发指南进一步为用户补充操作信息，包括：更清晰的代码示例、vefaas部署引导。 |\
| |   * 0代码智能体创建将面向个人开发者开放，并在流程上进一步丰富提示信息，包括：零代码操作指南及说明文案，模型接入点创建说明，其他提示文案等。 |\
| |* 联网及内容插件升级，用户可自定义联网触发条件和强制联网开启，调用方式默认为自动调用。 |[智能体中心](https://www.volcengine.com/docs/82379/1262002) |

<span id="release-note-20240515"></span>
# Release Note - 20240515

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型广场 |* 基础模型版本管理升级，让每个模型版本的可调参数和配置都以更清晰的方式展示，以便帮助您快速地选择适合您需求的基础模型； |\
| |* 引入全新的精选模型卡片，包括字节豆包APP应用的同系列豆包大模型等，为您提供更多选择，以满足各种业务场景的需求； |[模型广场介绍](https://www.volcengine.com/docs/82379/1099503) |
| | | | \
|体验中心 |* 在体验中心可以添加“模型仓库”的模型，通过直接与精调模型问答，以更直观的方式感受精调效果； |\
| |* 多模型对比模式开启后，可以同时同步对比“精调模型”与“基础模型”的差异，以及来自不同模型提供方、不同特性的模型在相同问答场景下的回复； |\
| |* 新增prompt优化选项，让大模型配合您提供更准确、更具情境感的指导词，使大模型在角色塑造和任务场景中提供更优质的回复； |\
| |* 支持图片上传，结合豆包大模型对图片理解的能力，以实现更贴切、更精准的回复，为您带来更优的体验； |[模型体验介绍](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|模型仓库 |* 新发布模型仓库，现在您可以通过模型仓库更好地管理精调模型； |\
| |* 同时，以模型为中心，您可以发起增量训练、发起效果评测、创建推理服务等，以满足您持续迭代和持续运维的需求； |[模型仓库介绍](https://www.volcengine.com/docs/82379/1159177) |
| | | | \
|模型精调 |* 精调任务中新增了“模型产出”列表，使您可以更轻松地追溯和管理同一精调任务在不同训练阶段的多个模型产出； |\
| |* 成功完成的训练任务会自动将最终模型产出录入至模型仓库，而失败的训练任务则允许您从中断位置继续训练，确保您能够充分利用资源，提高训练效率； |[模型精调介绍](https://www.volcengine.com/docs/82379/1099459) |
| | | | \
|模型推理 |* 算力保障现提供两种选项：公共资源池和模型单元。您可以从实际业务和场景出发，选择一种或灵活组合多个不同的推理服务，以实现稳定性和性价比的综合最优解； |\
| |* 我们对模型推理限流进行了调整：之前每个模型接入点需单独申请限流额度，现改为模型维度的限流。即在同一账号内，不同接入点现在共享一个限流额度，这使得单个接入点可以访问的额度更高。同时，您还可以根据需要灵活分配每个接入点的限流； |[模型推理介绍](https://www.volcengine.com/docs/82379/1182403) |
| | | | \
|智能体 |* 新发布智能体中心，为不同开发偏好的用户提供了三种开发模式，使得从零技术基础的用户到初级开发者和高级开发者均能轻松参与到基于AI模型的智能体开发中；其中包括： |\
| |   * 0代码模式：通过界面点选支持分钟级搭建问答Bot，并可搭配官方预置的联网或知识库组件，获得更高时效性和准确度的模型答复； |\
| |   * 低代码模式：通过方舟 x 扣子的联动支持轻量级编排，同时也将生态内容和多渠道发布的一站式开发体验连接至企业客户； |\
| |   * 高代码模式：通过Ark SDK为开发工具支持最大自由度的AI应用服务编排体验，不仅限于问答Bot； |\
| |* 新发布服务组件库，支持官方组件的添加和自定义组件创建，从而提高智能体的开发效率。首次发布的官方组件包括可扩展头条图文、抖音视频等优质内容源的联网组件，以及可高效联动企业私域知识进行可靠性补充的知识库组件； |\
| |* 新发布知识库，用于私域数据问答的场景，支持导入指定链接或TOS中存储的多个文档，并自动对文档执行解析、切片、向量化、构建索引等处理流程。为智能体提供可快速更新、定制化的知识，提升回答准确性。 |[智能体中心](https://www.volcengine.com/docs/82379/1262002) |
| | | | \
|资源管理 |* 完整对接项目管理和资源标签。账号管理员可基于自身企业的组织和业务设置更加精细的资源管理。同时，您可以通过项目或资源标签从不同维度对方舟上的任务、服务、资产进行分类和聚合管理，将其用于标签制授权和资源分账等场景； |[资源管理平台](https://console.volcengine.com/resourcemanager/resource_center/grant_permission) |
| | | | \
|OpenAPI |* 新发布模型广场、模型仓库、模型精调、模型服务、智能体等平台基础功能模块的 OpenAPI，让您能够更灵活地集成和管理方舟平台，满足各种定制化需求和业务场景； |\
| |* 升级模型调用Chat API，和多个辅助型API（Tokenization/Classification等）组合使用，可以更好的对模型问答内容进行调整 |\
| |   * 在AK/SK鉴权模式上，新增API Key鉴权，让豆包大模型能在更多的应用侧被便捷的调用； |\
| |   * 开放logit_bias参数，用于调整模型生成的输出中某些内容出现的可能性。配合Tokenization API 可将文本分词并生成相应的 token ID 和偏移量（offset），这些信息有助于在文本中定位每个 token 的位置； |\
| |   * Chat API还同步开放了诸多新的参数 |[OpenAPI介绍](https://www.volcengine.com/docs/82379/1262901) |
| | | | \
|安全与信任 |* 方舟平台在数据安全、隐私和合规性方面已完成并通过多个国内外权威机构（如ISO和SOC）的安全合规认证，为您提供可靠的保障； |\
| |* 新增用户数据加密能力，加固保护方舟平台的数据安全性。默认情况下使用火山引擎密钥管理系统（KMS）为您加密您的精调资产； |[火山方舟互信计算架构白皮书](https://www.volcengine.com/docs/82379/1159177) |\
| | |[数据加密](https://www.volcengine.com/docs/82379/1263407) |

<span id="release-note-20231214"></span>
# Release Note - 20231214

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型接入 |模型接入是方舟模型服务的能力升级，支持用户调用模型广场上的模型与精调后的模型进行推理。相比原有模型服务，模型接入支持（1）灵活升级接入模型的版本 （2）支持模型接入的调用监控（即将上线），未来还会支持保障更高并发度、更灵活的推理需求。 |[模型接入](https://www.volcengine.com/docs/82379/1182403) |

<span id="release-note-20231020"></span>
# Release Note - 20231020

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|插件能力 |新发布头条搜索插件，基于外部输入的必要性判断后，调用头条搜索能力，协助大模型实时获取新闻、法律等互联网资讯。当前插件仅适配于豆包系列模型 |[头条搜索插件](https://www.volcengine.com/docs/82379/1158772#头条搜索插件) |

<span id="release-note-20230926"></span>
# Release Note - 20230926

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型评测 |优化自动评测，上传本地评测数据集或选择平台预置评测数据集，一键完成模型的评测。新增人工评测，创建标注任务并分配给指定标注人，在线协同标注模型的生成效果。 |[自动评测介绍](https://www.volcengine.com/docs/82379/1150779) 、 [人工评测介绍](https://www.volcengine.com/docs/82379/1153149) |
| | | | \
|数据服务 |数据集标注，支持基础的文本大模型数据集人工标注功能。 |[数据集标注](https://www.volcengine.com/docs/82379/1139405) |
| | | | \
|模型广场 |模型卡片、体验中心支持多版本的模型展示、体验与使用 |[模型广场介绍](https://www.volcengine.com/docs/82379/1099503) |
| | | | \
|模型服务 |新增Lora推理功能特性，Lora精调后的模型部署为在线服务，不用独占机器资源部署，无需排队，轻量便捷 |[模型服务部署](https://www.volcengine.com/docs/82379/1099521) |
| | | | \
|安全与信任 |为模型提供方与模型使用者开放安全审计日志，在安全容器的基础上进一步加密了用户输入文本信息 |[安全审计日志](https://www.volcengine.com/docs/82379/1151431) |

<span id="release-note-20230806"></span>
# Release Note - 20230806

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|统计管理 |新发布开通管理页，可更清晰了解目前的商品开通状态、限制、价格与帮助文档等；新发布用量统计页，可清晰查看各子账号在各个模型上的调用量与RPM（每分钟请求数）信息 |[开通管理](https://www.volcengine.com/docs/82379/1159200) 、[用量统计](https://www.volcengine.com/docs/82379/1159200) |
| | | | \
|模型精调 |创建精调任务页：支持LoRA精调，模型精调更高效省时；支持自定义设置验证集；优化了参数配置的交互样式。精调任务列表页：增加了排队时间预估，训练时间预估提示信息 |[创建模型精调任务](https://www.volcengine.com/docs/82379/1099459) |
| | | | \
|模型服务 |创建在线服务：权限管控升级优化，增加了管理员和可见范围的配置。在线服务详情：在线服务支持服务监控，可更好监控模型服务的工程性能指标 |[查看并管理模型服务](https://www.volcengine.com/docs/82379/1099522) |
| | | | \
|模型广场 |支持了公开模型与私有模型的属性，模型卡片权限管控更自由；支持模型列表的搜索 |[模型广场介绍](https://www.volcengine.com/docs/82379/1099503) |
| | | | \
|体验中心 |全新升级AI对话体验中心的交互与视觉，高级参数设置更便捷直观，多模型之间可拖拽排序 |[模型体验介绍](https://www.volcengine.com/docs/82379/1099504) |

<span id="release-note-20230628"></span>
# Release Note - 20230628

| | | | \
|功能模块 |功能说明 |帮助文档 |
|---|---|---|
| | | | \
|模型广场 |新发布模型广场功能，在模型广场上查看并了解所有模型提供方上架在平台上的大模型 |[模型广场介绍](https://www.volcengine.com/docs/82379/1099503) |
| | | | \
|体验中心 |新发布体验中心功能，可快速体验各模型的实际表现效果，探索其在语言、图像等方面的先进能力 |[模型体验介绍](https://www.volcengine.com/docs/82379/1099504) |
| | | | \
|模型精调 |新发布模型精调功能，支持自定义训练集、超参、版本管理等功能，快速精调并使用专属大模型服务 |[创建模型精调任务](https://www.volcengine.com/docs/82379/1099459) |
| | | | \
|模型评测 |新发布模型评测功能，自动根据预置的评测脚本与数据集，从多个维度评价精调后的模型表现效果 |[模型评测方案介绍](https://www.volcengine.com/docs/82379/1099474) |
| | | | \
|模型服务 |新发布模型服务功能，在火山引擎上可直接调用推理API，接入生产环境，并持续运维与监控 |[精调模型发布在线服务](https://www.volcengine.com/docs/82379/1099521) |
| | | | \
|安全与信任 |支持安全可信的推理与精调服务，保障模型提供方的知识产权安全与模型使用者的业务信息安全 |[火山方舟互信计算架构白皮书](https://www.volcengine.com/docs/82379/1099355) |




# 模型发布公告
Source: https://www.volcengine.com/docs/82379/1159178
本文介绍了火山方舟大模型服务平台的新模型发布记录与特性，欢迎体验。
> 产品功能更新公告请见：[产品更新公告](https://www.volcengine.com/docs/82379/1159177)

<span id="432098b2"></span>
# 20250630
**以下模型即于2025.08.28正式下线**

| | | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |下线时间 |建议迁移模型 |到期未迁移，系统替换模型 |
|---|---|---|---|---|---|---|
| | | | | | | | \
|字节跳动 |doubao-pro-32k |对话模型 |240828 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-pro-32k/250115 |
| | | | | | | | \
|字节跳动 |doubao-pro-32k |对话模型 |character-240828 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-pro-32k/character-250228 |
| | | | | | | | \
|字节跳动 |doubao-vision-pro-32k |视觉理解模型 |241028 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-seed-1-6/250615 |
| | | | | | | | \
|字节跳动 |doubao-vision-lite-32k |视觉理解模型 |241015 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-vision-pro/250328 |
| | | | | | | | \
|字节跳动 |doubao-lite-32k |对话模型 |character-241015 |2025年8月28日 |doubao-Seed-1.6-flash/250615 |doubao-lite-32k/character-250228 |
| | | | | | | | \
|字节跳动 |doubao-lite-4k |对话模型 |character-240828 |2025年8月28日 |doubao-Seed-1.6-flash/250615 |doubao-lite-32k/character-250228 |
| | | | | | | | \
|字节跳动 |doubao-lite-128k |对话模型 |240828 |2025年8月28日 |doubao-Seed-1.6-flash/250615 |doubao-1-5-lite-32k/250115 |
| | | | | | | | \
|字节跳动 |doubao-lite-128k |对话模型 |240428 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-seed-1-6/250615 |
| | | | | | | | \
|字节跳动 |doubao-pro-256k |对话模型 |241115 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-pro-32k/250115 |
| | | | | | | | \
|字节跳动 |doubao-pro-256k |对话模型 |240828 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-pro-32k/browsing-241115 |
| | | | | | | | \
|字节跳动 |doubao-pro-32k |对话模型 |functioncall-241028 |2025年8月28日 |doubao-embedding-vision/250615 |doubao-embedding-vision/250615（不强制切换） |
| | | | | | | | \
|字节跳动 |doubao-pro-32k |对话模型 |browsing-240828 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-pro-256k/250115 |
| | | | | | | | \
|字节跳动 |deepseek-r1-distill-qwen-32b |对话模型 |250120 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-vision-pro/250328 |
| | | | | | | | \
|字节跳动 |deepseek-r1-distill-qwen-7b |对话模型 |241015 |2025年8月28日 |doubao-Seed-1.6-flash/250615 |doubao-1-5-vision-lite/250315 |
| | | | | | | | \
|字节跳动 |doubao-embedding |文本向量化模型 |text-240515 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-pro-32k/250115 |
| | | | | | | | \
|字节跳动 |doubao-embedding-vision |图文向量化模型 |241215 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-pro-256k/250115 |
| | | | | | | | \
|字节跳动 |doubao-pro-32k |对话模型 |functioncall-preview |2025年8月28日 |doubao-Seed-1.6-flash/250615 |doubao-seed-1-6-flash/250615 |
| | | | | | | | \
|字节跳动 |doubao-pro-32k |对话模型 |oracy-240928 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-ui-tars/250428 |
| | | | | | | | \
|字节跳动 |doubao-pro-32k |对话模型 |creation-241028 |2025年8月28日 |doubao-embedding-vision/250615 |doubao-embedding-vision/250615（不强制切换） |
| | | | | | | | \
|字节跳动 |doubao-1-5-thinking-pro |视觉理解模型 |m-250415 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-pro-32k/250115 |
| | | | | | | | \
|字节跳动 |doubao-1-5-vision-pro-32k |视觉理解模型 |preview |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-thinking-pro/m-250428 |
| | | | | | | | \
|字节跳动 |doubao-1-5-thinking-pro |视觉理解模型 |vision-250415 |2025年8月28日 |doubao-seed-1-6-flash/250615 |doubao-seed-1-6-flash/250615 |
| | | | | | | | \
|字节跳动 |doubao-1-5-ui-tars |GUI Aegnt模型 |250328 |2025年8月28日 |doubao-seed-1-6/250615 |doubao-1-5-pro-32k/250115 |
| | | | | | | | \
|字节跳动 |doubao-seaweed |视频生成模型 |241128 |2025年8月28日 |doubao-Seedance-1.0-pro-250528 |\
| | | | | |doubao-Seedance-1.0-lite-i2v-250428 |\
| | | | | |doubao-Seedance-1.0-lite-t2v-250428 |关停 |




<span id="8c39d112"></span>
# 20250611

| | | | | | | \
|**模型提供方** |**模型名称** |**模型类型** |**模型版本** |**版本说明** |**调用说明** |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-Seed-1.6-thinking |视觉理解模型 |250615 |新发布 |在思考能力上进行了大幅强化， 对比Doubao-1.5-thinking-pro，在Coding、Math、 逻辑推理等基础能力上进一步提升。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384) |
| | | | | | | \
|字节跳动 |Doubao-Seed-1.6 |视觉理解模型 |250615 |新发布 |全新多模态深度思考模型，同时支持thinking/non-thinking/auto三种思考模式， non-thinking模型对比Doubao-1.5-pro/250115大幅提升。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384) |
| | | | | | | \
|字节跳动 |Doubao-Seed-1.6-flash |视觉理解模型 |250615 |新发布 |极致推理速度的多模态深度思考模型， 同时支持文本和视觉理解，文本理解能力超过上一代lite，视觉理解比肩友商pro系列模型。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384) |
| | | | | | | \
|字节跳动 |Doubao-Seedance-1.0-pro |\
| | |视频生成模型 |250528 |新发布 |Seedance 1.0 Pro是一款支持多镜头叙事的视频生成基础模型，在各维度表现出色。它在语义理解与指令遵循能力上取得突破，能生成运动流畅、细节丰富、风格多样且具备影视级美感的 1080P 高清视频调用指南请参考[视频生成API](https://www.volcengine.com/docs/82379/1520757) |
| | | | | | | \
|字节跳动 |Doubao-1.5-UI-TARS |GUI Aegnt模型 |250428 |版本更新 |全新升级版本，相比250328版本，在GUI交互能力全面提升的基础上，大幅提升了移动端交互能力，并支持了深度思考与FunctionCall。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384) |
| | | | | | | \
|字节跳动 |Doubao-embedding-large |文本向量化模型 |text-250515 |版本更新 |\
| | | | | |基于 Seed1.5 (Doubao-1.5-pro) 进一步训练。在权威测评榜单 MTEB 上，达到了中英文 SOTA 效果。除了通用 Embedding 任务外，团队还额外优化了模型在推理密集的检索任务上的能力，并在对应榜单 BRIGHT 上也达到 SOTA。调用指南请参考[文本向量化API](https://www.volcengine.com/docs/82379/1521766) |


<span id="ade48a03"></span>
# 20250520

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-Seedream-3.0-t2i |图像生成模型 |250415 |新发布 |Seedream 3.0 的综合能力显著增强：支持原生 2K 分辨率输出；响应速度更快；小字生成更准确，文本排版效果增强；指令遵循能力强，美感、结构提升，保真度和细节表现较好，在多项评估中排名领先。能够应用于更复杂、更广泛的图片生成场景。调用指南请参考[图片生成API](https://www.volcengine.com/docs/82379/1541523) |
| | | | | | | \
|字节跳动 |Doubao-Seedance-1.0-lite-t2v |视频生成模型 |250428 |新发布 |Seedance 1.0 是字节跳动豆包大模型团队最新推出的视频生成基础模型。Seedance 1.0 lite模型作为该模型系列的小参数量版本，在取得出色的视频生成质量的同时，显著提升了生成速度，是兼顾效果与效率的性价比之选。调用指南请参考[视频生成API](https://www.volcengine.com/docs/82379/1520757)。 |
| | | | | | | \
|字节跳动 |Doubao-Seedance-1.0-lite-i2v |视频生成模型 |250428 |新发布 |Seedance 1.0 是字节跳动豆包大模型团队最新推出的视频生成基础模型。Seedance 1.0 lite模型作为该模型系列的小参数量版本，在取得出色的视频生成质量的同时，显著提升了生成速度，是兼顾效果与效率的性价比之选。调用指南请参考[视频生成API](https://www.volcengine.com/docs/82379/1520757)。 |
| | | | | | | \
|字节跳动 |Doubao-1.5-thinking-pro |视觉理解模型 |m-250428 |版本更新 |自适应的思考模式，Auto的thinking模式，模型自主根据题目难度判断，是否需要触发思考，简单题目直接回答。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |
| | | | | | | \
|字节跳动 |Doubao-1.5-thinking-vision-pro |视觉理解模型 |250428 |新发布 |在公开VLM基准测试和内部评估测试中均表现出色，在 59 项公开基准测试中，37 项达到了SOTA水平。拥有强大的深度思考能力，尤其在视觉谜题等多模态推理挑战中表现突出。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |


<span id="a751db1d"></span>
# 20250425

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|阿里云 |Wan2.1-14B |视频生成模型 |i2v-250225 |新发布 |在多个基准测试中优于现有的开源模型，生成的视频在运动表现、画面质量等方面具备领先效果。支持生成包含中、英文文字的视频，拓展了模型的应用范围。调用指南请参考[视频生成API](https://www.volcengine.com/docs/82379/1520757)。 |
| | | | | | | \
|阿里云 |Wan2.1-14B |视频生成模型 |t2v-250225 |新发布 |\
| | | | | |在多个基准测试中优于现有的开源模型，生成的视频在运动表现、画面质量等方面具备领先效果。支持生成包含中、英文文字的视频，拓展了模型的应用范围。调用指南请参考[视频生成API](https://www.volcengine.com/docs/82379/1520757)。 |
| | | | | | | \
|字节跳动 |Doubao-1.5-thinking-pro |对话模型 |250415 |新发布 |在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出，在AIME 2024、Codeforces、GPQA等多项权威基准上达到或接近业界第一梯队水平。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |
| | | | | | | \
|字节跳动 |Doubao-1.5-thinking-pro |视觉理解模型 |m-250415 |新发布 |基于深度思考+视觉理解的混合训练，让模型具备视觉推理能力，更强的多模态交互能力，和更低的视觉描述幻觉。. |
| | | | | | | \
|字节跳动 |Doubao-1.5-vison-pro |视觉理解模型 |250328 |新发布 |全新升级的多模态大模型，视觉理解、分类、信息抽取等能力显著提升，并重点增强了解题、视频理解等场景的任务效果。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |
| | | | | | | \
|字节跳动 |Doubao-1.5-vision-lite |视觉理解模型 |250315 |新发布 |全新升级的多模态大模型，相比Doubao-vision-lite-32k，综合能力大幅提升15%，信息抽取、定位、OCR、图像理解描述等能力提升超20%。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |
| | | | | | | \
|字节跳动 |Doubao-1.5-UI-TARS |GUI Aegnt模型 |250328 |新发布 |模型通过将屏幕视觉理解、逻辑推理、界面元素定位和操作整合在单一模型中，突破了传统自动化工具依赖预设规则的局限性，为智能界面交互提供了更接近人类认知范式的解决方案。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |
| | | | | | | \
|字节跳动 |Doubao-lite-32k |对话模型 |character-250228 |版本更新 |全新升级的角色扮演任务专项优化模型，拥有极速推理，具备极致的响应速度，满足低时延场景需求。应用全面，能力覆盖广泛的通用任务场景。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |
| | | | | | | \
|字节跳动 |Doubao-embedding-vision |图文向量化模型 |250328 |版本更新 |效果、时延全面升级的图文向量化模型，默认2048维，支持1024维降维使用。该版本模型输出的向量已归一化处理，无需再次归一化。调用指南请参考[图文向量化API](https://www.volcengine.com/docs/82379/1523520)。 |
| | | | | | | \
|深度求索 |Deepseek-V3 |对话模型 |0324 |版本更新 |推理能力显著提升，数学、代码评测超越 GPT-4.5；HTML 前端任务的代码可用性更高，视觉效果更美观、富有设计感；中文写作质量优化，长文本创作能力增强；搜索场景报告生成更精准。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |


<span id="7571b7ed"></span>
# 20250320

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-1.5-pro-32k |对话模型 |character-250228 |版本更新 |基于Doubao-1.5全新升级，支持故事剧情模式，优化恋爱拉扯能力（GSB+11%），角色风格能力优化 ，增强剧情推动能力。调用指南请参考[图文向量化API](https://www.volcengine.com/docs/82379/1523520)。 |
| | | | | | | \
|字节跳动 |Doubao-视频生成-Seaweed |视频生成模型 |241128 |新发布 |模型支持将用户的文本、图像生成高质量的视频，能够生成具备丰富的细节层次的影视即视频，可应用于电商营销、动画教育等广泛的应用场景。调用指南请参考[视频生成API](https://www.volcengine.com/docs/82379/1520757)。 |
| | | | | | | \
|深度求索 |Deepseek-V3 |对话模型 |241226 |新发布 |多项评测成绩超越了Qwen2.5-72B 和 Llama3.1等其他开源模型，并在性能上与GPT4o、Claude 3.5 Sonnet能力相当。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |
| | | | | | | \
|深度求索 |Deepseek-R1 |对话模型 |250120 |新发布 |DeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |
| | | | | | | \
|深度求索 |DeepSeek-R1-Distill-Qwen-32B |对话模型 |250120 |新发布 |DeepSeek-R1-Distill 模型是在开源模型的基础上通过微调训练得到的，训练过程中使用了由DeepSeek-R1生成的样本数据，多项指标超越OpenAI o1-mini。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |
| | | | | | | \
|深度求索 |DeepSeek-R1-Distill-Qwen-7B |对话模型 |250120 |新发布 |DeepSeek-R1-Distill 模型是在开源模型的基础上通过微调训练得到的，训练过程中使用了由DeepSeek-R1生成的样本数据，多项指标超越OpenAI o1-mini。调用指南请参考[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。 |

<span id="e695fe64"></span>
# 20250318
**以下模型即于2025.04.01正式下线**

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |下线时间 |替代模型 |
|---|---|---|---|---|---|
| | | | | | | \
|智谱AI |GLM3-130B |对话模型 |V1.0 |2025年4月1日 |方舟平台其他模型 |
| | | | | | | \
|智谱AI |GLM3-130B 金融模型 |对话模型 |V1.0-updata |2025年4月1日 |方舟平台其他模型 |
| | | | | | | \
|Meta |llama3-70b |对话模型 |llama3-70b-instruct |2025年4月1日 |方舟平台其他模型 |
| | | | | | | \
|Meta |llama3-8b |对话模型 |llama3-8b-instruct |2025年4月1日 |方舟平台其他模型 |

<span id="79527e40"></span>
# 20250122

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-1.5-pro-32k |对话模型 |250115 |新发布 |在多项公开测评基准上已达到全球领先水平。在知识、代码、推理、中文权威测评基准上获得最佳成绩，综合得分优于 GPT-4o、Claude 3.5 Sonnet 等业界一流模型。调用指南请参考[ChatCompletions-文本生成](https://www.volcengine.com/docs/82379/1298454)。 |
| | | | | | | \
|字节跳动 |Doubao-1.5-lite-32k |对话模型 |250115 |新发布 |全球一流水平的轻量版语言模型。在综合、推理、数学、专业知识权威测评指标持平或超越 GPT-4o mini，Cluade 3.5 Haiku。调用指南请参考[ChatCompletions-文本生成](https://www.volcengine.com/docs/82379/1298454)。 |
| | | | | | | \
|字节跳动 |Doubao-1.5-vision-pro-32k |视觉理解模型 |250115 |新发布 |相比于上一版本，Doubao1.5-vision-Pro 在多模态数据合成、动态分辨率、多模态对齐、混合训练上进行了全面的技术升级。进一步增强了模型在视觉推理、文字文档识别、细粒度信息理解、指令遵循方面的能力，并让模型的回复模式变得更加精简、友好。调用指南请参考[ChatCompletions-视觉理解](https://www.volcengine.com/docs/82379/1362913)。 |
| | | | | | | \
|字节跳动 |Doubao-1.5-pro-256k |对话模型 |250115 |新发布 |基于Doubao-1.5-Pro全面升级版，整体效果大幅提升10%。支持256k上下文窗口的推理，输出长度支持最大12k tokens。调用指南请参考[ChatCompletions-文本生成](https://www.volcengine.com/docs/82379/1298454)。 |

<span id="ce39abc6"></span>
# 20250110
**以下模型即将于2025.05.28下线**

| | | | | | \
|模型提供方 |模型名称 |模型版本 |下线时间 |替代模型 |
|---|---|---|---|---|
| | | | | | \
|字节跳动 |Doubao-pro-32k |240615 |2025年5月28日 |Doubao-1.5-pro-32k/250115 |
| | | | | | \
|字节跳动 |Doubao-pro-32k |character-240528 |2025年5月28日 |Doubao-1.5-pro-32k/character-250228 |
| | | | | | \
|字节跳动 |Doubao-pro-128k |240628 |2025年5月28日 |Doubao-1.5-pro-32k/250115 |
| | | | | | \
|字节跳动 |Doubao-lite-32k |240428 |2025年5月28日 |Doubao-1.5-lite-32k/250115 |
| | | | | | \
|字节跳动 |Doubao-lite-32k |240628 |2025年5月28日 |Doubao-1.5-lite-32k/250115 |
| | | | | | \
|字节跳动 |Doubao-lite-128k |240428 |2025年5月28日 |Doubao-1.5-pro-256k/250115 |
| | | | | | \
|字节跳动 |Doubao-pro-4k |character-240728 |2025年5月28日 |Doubao-1.5-pro-32k/character-250228 |
| | | | | | \
|字节跳动 |Doubao-pro-4k |functioncall-240615 |2025年5月28日 |Doubao-1.5-pro-32k/250115 |
| | | | | | \
|字节跳动 |Doubao-pro-32k |functioncall-240515 |2025年5月28日 |Doubao-1.5-pro-32k/250115 |
| | | | | | \
|字节跳动 |Doubao-pro-32k |functioncall-240815 |2025年5月28日 |Doubao-1.5-pro-32k/250115 |
| | | | | | \
|字节跳动 |Doubao-pro-32k |browsing-240615 |2025年5月28日 |Doubao-pro-32k/browsing-241115 |
| | | | | | \
|字节跳动 |Doubao-lite-4k |browsing-intent-240615 |2025年5月28日 |Doubao-lite-4k/browsing-intent-240828 |


<span id="d0bc4f7f"></span>
# 20241224

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |\
| | | | | |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-pro-32k |对话模型 |functioncall-241028 |版本更新 |相较functioncall-240815，函数调用能力显著提升18%，模型通用能力提升4.5%。调用指南请参考[ChatCompletions-文本生成](https://www.volcengine.com/docs/82379/1298454)。 |
| | | | | | | \
|字节跳动 |Doubao-pro-32k |对话模型 |241215 |版本更新 |Doubao-pro-32k全面升级，相比240828版本，整体能力显著提升，其中总结摘要、信息抽取、文本分类、复杂流程、综合任务等能力显著大幅提升。调用指南请参考[ChatCompletions-文本生成](https://www.volcengine.com/docs/82379/1298454)。 |
| | | | | | | \
|字节跳动 |Doubao-pro-32k |\
| | |对话模型 |character-241215 |版本更新 |\
| | | | | |相比character-240828版本，角色扮演能力以及对话推进能力大幅提升。调用指南请参考[ChatCompletions-文本生成](https://www.volcengine.com/docs/82379/1298454)。 |
| | | | | | | \
|字节跳动 |Doubao-pro-256k |对话模型 |241115 |版本更新 |\
| | | | | |相比Doubao-pro-128k/240628，长文任务效果显著提升10%以上，要点提取、字数遵循、多轮对话上文记忆等能力大幅提升。调用指南请参考[ChatCompletions-文本生成](https://www.volcengine.com/docs/82379/1298454)。 |
| | | | | | | \
|字节跳动 |Doubao-pro-32k |\
| | |对话模型 |\
| | | |browsing-241115 |版本更新 |\
| | | | | |模型本身不支持联网，需要配合联网插件使用。相比browsing-241115效果提升7%。调用指南请参考[ChatCompletions-文本生成](https://www.volcengine.com/docs/82379/1298454)。 |
| | | | | | | \
|字节跳动 |Doubao-vision-pro-32k |视觉理解模型 |241028 |\
| | | | |新发布 |\
| | | | | |整体效果显著。在中文OCR、文本+图表理解、数学问题等方面优势更加明显。调用指南请参考[ChatCompletions-视觉理解](https://www.volcengine.com/docs/82379/1362913)。 |
| | | | | | | \
|字节跳动 |Doubao-vision-lite-32k |视觉理解模型 |241015 |新发布 |效果优势显著，极致性能与成本的视觉理解模型。调用指南请参考[ChatCompletions-视觉理解](https://www.volcengine.com/docs/82379/1362913)。 |


<span id="549c3d32"></span>
# 20241021

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-lite-32k |对话模型 |character-241015 |新发布 |基于Doubao-lite-4k/character-240828提升窗口长度，增加到32k，支持更长的system prompt与更长轮次的对话。调用指南请参考[对话(Chat)-文本 API（文档下线中）](https://www.volcengine.com/docs/82379/1298454) |

<span id="6d78b9ca"></span>
# 20240930
**以下模型即将于2024.04.15下线**

| | | | | | | | \
|**模型提供方** |**模型名称** |**模型版本** |**下线时间** |**实际下线时间** |**替代模型** | |
|---|---|---|---|---|---|---|
| | | | | | | | \
|字节跳动 |**Doubao-lite-32k** |240428 |2025年2月28日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 | |
| | | | | | | | \
|字节跳动 |**Doubao-lite-4k** |\
| | |240328 |2025年2月28日 |\
| | | | |2025年4月15日 |Doubao-1.5-lite-32k/250115 | |
| |^^| |^^|^^| | | \
|字节跳动 | |character-240515 | | |Doubao-lite-32k/character-250228 |即将发布 |
| | | | | | | | \
|字节跳动 |\
| |**Doubao-pro-128k** |240515 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | | \
|字节跳动 |**Doubao-pro-32k** |240515 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | | \
|字节跳动 |**Doubao-pro-4k** |\
| | |240515 |2025年2月28日 |\
| | | | |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| |^^| |^^|^^| | | \
|字节跳动 | |browsing-240524 | | |Doubao-pro-32k/browsing-241115 | |
| |^^| |^^|^^| | | \
|字节跳动 |\
| | |character-240515 | | |Doubao-1.5-pro-32k/character-250228 | |
| |^^| |^^|^^| | | \
|字节跳动 |\
| | |functioncall-240515 | | |Doubao-1.5-pro-32k/250115 | |
| | | | | | | | \
|字节跳动 |**Skylark3-lite-128k** |240428 |2025年2月28日 |2025年4月15日 |Doubao-lite-128k/240828 | |
| | | | | | | | \
|字节跳动 |**Skylark3-lite-4k** |240328 |2025年2月28日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 | |
| | | | | | | | \
|字节跳动 |**Skylark3-pro-4k** |240415 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | | \
|字节跳动 |\
| |**Skylark2-lite-8k** |\
| | |browsing-intent-240415 |2025年2月28日 |2025年4月15日 |Doubao-lite-4k/browsing-intent-240828 | |
| |^^| |^^|^^|^^| | \
|字节跳动 | |browsing-intent-240615 |2025年2月28日 | | | |
| |^^| |^^|^^|^^| | \
|字节跳动 | |1.0 | | | | |
| | | | | | | | \
|字节跳动 |**Skylark2-lite-4k** | |2025年2月28日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 | |
| | | | | | | | \
|字节跳动 |\
| |**Skylark2-lite-character-8k** | |2025年2月28日 |2025年4月15日 |Doubao-lite-32k/character-250228 | |
| | | | | | | | \
|字节跳动 |\
| |**Skylark2-pro-character-4k** |\
| | |1.0 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/character-250228 | |
| |^^| |^^|^^|^^| | \
|字节跳动 | |ecom-20240415 |2025年2月28日 | | | |
| | | | | | | | \
|字节跳动 |**Skylark2-pro-32k** |1.0/1.1 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | | \
|字节跳动 |**Skylark2-pro-4k** |\
| | |browsing |2025年2月28日 |2025年4月15日 |Doubao-pro-32k/browsing-241115 | |
| |^^| |^^|^^| | | \
|字节跳动 |\
| | |browsing-240415 | | |Doubao-pro-32k/browsing-241115 | |
| |^^| |^^|^^| | | \
|字节跳动 | |character-240328 | | |Doubao-1.5-pro-32k/character-250228 | |
| |^^| |^^|^^| | | \
|字节跳动 | |1.2/1.3 | | |Doubao-1.5-pro-32k/250115 | |
| | | | | | | | \
|字节跳动 |**Web-intent** |1.0 |2025年2月28日 |2025年4月15日 |Doubao-pro-32k/browsing-240828 | |
| | | | | | | | \
|字节跳动 |\
| |**Skylark-Web** |2.2/0.0 |2025年2月28日 |2025年4月15日 |Doubao-pro-32k/browsing-241115 | |
| | | | | | | | \
|字节跳动 |\
| |**Skylark-plus-public** |1.1 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | | \
|字节跳动 |**Skylark-pro-public** |2.0/2.1 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | | \
|字节跳动 |**Skylark-lite-public** |2.0/1.0/1.1/0.0 |2025年2月28日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 | |
| | | | | | | | \
|字节跳动 |**Skylark-chat** |1.0 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | | \
|字节跳动 |\
| |**llama3-70b** |llama3-70b-instruct |2025年4月1日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 |原服务已关停 |
| | | | | | | | \
|字节跳动 |**llama3-8b** |llama3-8b-instruct |2025年4月1日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 |原服务已关停 |
| | | | | | | | \
|字节跳动 |mistral-7b |instruct-v0.2 |2025年2月28日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 |原服务已关停 |
| | | | | | | | \
|字节跳动 |chatglm3-130-fin |v1.0-update |2025年2月28日 |2025年4月15日 | |原服务已关停 |
| | | | | | | | \
|字节跳动 |\
| |chatglm3-130b-fc |v1.0 |2025年2月28日 |2025年4月15日 | |原服务已关停 |


<span id="edcdcad8"></span>
# 20240919

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-pro-32k |对话模型 |240828 |新发布 |对比240615版本，模型综合能力显著提升8%，尤其是文本分类、创作任务、总结摘要等能力上显著大幅提升。调用指南请参考[对话(Chat)-文本 API（文档下线中）](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-lite-32k |对话模型 |240828 |新发布 |对比240628版本，模型综合能力显著提升12%，尤其是数学计算、代码、学科知识、推理能力等能力上显著大幅提升。 |
| | | | | | | \
|字节跳动 |Doubao-lite-128k |对话模型 |240828 |新发布 |模型全面升级，各项能力均显著强于当前线上240428版本。 |
| | | | | | | \
|字节跳动 |Doubao-pro-32k |对话模型 |character-240828 |新发布 |对比character-240528，角色扮演能力显著提升11%，对话推进能力显著增强。 |
| | | | | | | \
|字节跳动 |Doubao-lite-4k |对话模型 |character-240828 |新发布 |Doubao-lite系列角色扮演最强分支模型，能力大幅提升，接近Doubao-pro系列角色版本模型。 |
| | | | | | | \
|字节跳动 |Doubao-pro-32k |对话模型 |browsing-240828 |新发布 |相较browsing-240628在信息检索问答任务效果得到全面提升，回答更准确、更少冗余内容。 |
| | | | | | | \
|字节跳动 |Doubao-pro-32k |对话模型 |functioncall-240815 |新发布 |相较doubao-pro-32k/functioncall-240515，函数调用能力显著提升11%，模型通用能力提升13%，接近通用模型水平。 |

<span id="_20240815"></span>
# 20240815

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-流式语音识别 |语音大模型 |240815 |新发布 |支持将长音频实时识别成文字，达到“边说话边出文字”的效果，适用于实时语音识别的场景，如实时会议字幕、直播字幕、智能外呼等。 调用指南请参考[大模型流式语音识别API](https://www.volcengine.com/docs/6561/1354869) |
| | | | | | | \
|字节跳动 |Doubao-录音文件识别 |语音大模型 |240815 |新发布 |支持将音频文件（≤4小时）转写成文本数据，内置自动标点、语义顺滑、数字规整、智能分句等功能，可根据需要任意搭配。适用于非实时的语音识别场景，如会议记录总结、智能外呼质检、课后教辅和学情分析等。调用指南请参考[大模型录音文件识别](https://www.volcengine.com/docs/6561/1354868) |

<span id="_20240806"></span>
# 20240806

| | | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 | |
|---|---|---|---|---|---|---|
| | | | | | || \
|字节跳动 |Doubao-图生图模型-AIGC图像风格化 |视觉大模型 |240806 |新发布 |豆包图生图模型AIGC图像风格化是基于字节跳动视觉大模型打造的新一代图生图模型，生成图片与原图人脸相似度高，风格多样，效果精细，可广泛应用于互动娱乐、广告创意、辅助设计等场景。调用指南请参考 [AIGC图像风格化API](https://www.volcengine.com/docs/6791/1314297) | |

<span id="_20240715"></span>
# 20240715

| | | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 | |
|---|---|---|---|---|---|---|
| | | | | | || \
|字节跳动 |Doubao-embedding |向量模型 |text-240715 |新发布 |语义向量化模型，中英文Retrieval效果较text-240515版本有较大提升，推荐使用该版本。向量维度 2560 维，支持 512, 1024, 2048 降维使用。调用指南请参考[ Embeding](https://www.volcengine.com/docs/82379/1329508#doubao-embedding-%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81) | |

<span id="_20240711"></span>
# 20240711
**以下模型即将于2024.8.20下线**

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark2-pro-4k |对话模型 |V1.0/v1.100/V1.1/V1.2 |弃用 |豆包大模型能力全面提升，请在[方舟2.0](https://console.volcengine.com/ark/region:ark+cn-beijing/model?projectName=default) |\
| | | | | |接入[Doubao-pro-32k](https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-pro-32k)模型服务 |
| | | | | | | \
|字节跳动 |Skylark2-pro-character-4k |对话模型 |v1.0/V1.1 |弃用 |豆包大模型能力全面提升，请在[方舟2.0](https://console.volcengine.com/ark/region:ark+cn-beijing/model?projectName=default) |\
| | | | | |接入[Doubao-pro-32k](https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-pro-32k) 模型服务character版本 |
| | | | | | | \
|字节跳动 |Skylark2-pro-32k |对话模型 |V1.0/V1.1/V1.2 |弃用 |豆包大模型能力全面提升，请在[方舟2.0](https://console.volcengine.com/ark/region:ark+cn-beijing/model?projectName=default) |\
| | | | | |接入[Doubao-pro-32k](https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-pro-32k)模型服务 |
| | | | | | | \
|字节跳动 |Skylark2-pro-turbo-8k |对话模型 |V1.0 |弃用 |豆包大模型能力全面提升，请在[方舟2.0](https://console.volcengine.com/ark/region:ark+cn-beijing/model?projectName=default) |\
| | | | | |接入[Doubao-pro-32k](https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-pro-32k)模型服务 |
| | | | | | | \
|字节跳动 |Skylark2-lite-8k |对话模型 |V1.0 |弃用 |豆包大模型能力全面提升，请在[方舟2.0](https://console.volcengine.com/ark/region:ark+cn-beijing/model?projectName=default) |\
| | | | | |接入[Doubao-lite-32k](https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-lite-32k)模型服务 |
| | | | | | | \
|字节跳动 |Skylark-lite |对话模型 |V1.0/V1.1/V2.0 |弃用 |豆包大模型能力全面提升，请在[方舟2.0](https://console.volcengine.com/ark/region:ark+cn-beijing/model?projectName=default) |\
| | | | | |接入[Doubao-lite-32k](https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-lite-32k)模型服务 |
| | | | | | | \
|字节跳动 |Skylark-pro |对话模型 |V1.0/V1.1/V2.0 |弃用 |豆包大模型能力全面提升，请在[方舟2.0](https://console.volcengine.com/ark/region:ark+cn-beijing/model?projectName=default) |\
| | | | | |接入[Doubao-pro-32k](https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-pro-32k)模型服务 |
| | | | | | | \
|字节跳动 |Skylark-chat（豆包同款） |对话模型 |V1.0 |弃用 |豆包大模型能力全面提升，请在[方舟2.0](https://console.volcengine.com/ark/region:ark+cn-beijing/model?projectName=default) |\
| | | | | |接入[Doubao-pro-32k](https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-pro-32k)模型服务 |
| | | | | | | \
|字节跳动 |Skylark-plus |对话模型 |V1.0/V1.1 |弃用 |豆包大模型能力全面提升，请在[方舟2.0](https://console.volcengine.com/ark/region:ark+cn-beijing/model?projectName=default) |\
| | | | | |接入[Doubao-pro-32k](https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-pro-32k)模型服务 |

<span id="_20240628"></span>
# 20240628

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-pro-128k |对话模型 |240628 |新发布 |截止发布时间效果最好的长文模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持128k上下文窗口的推理。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-lite-32k |对话模型 |240628 |新发布 |拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持32k上下文窗口的推理和精调，调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |

<span id="_20240625"></span>
# 20240625

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-声音复刻 |语音大模型 |240625 |新发布 |豆包声音复刻大模型是使用全新自研语音大模型算法打造的高效化的轻量级音色定制方案。用户在开放环境中，仅需录制秒级别音频，即可快速拥有专属AI定制音色。可应用于视频创作、数字人驱动、语音助手等多种场景。调用指南请参考 [声音复刻API](https://www.volcengine.com/docs/6561/1305191) |
| | | | | | | \
|字节跳动 |Doubao-语音合成 |语音大模型 |240625 |新发布 |依托新一代大模型能力，豆包语音合成大模型能够根据上下文，智能预测文本的情绪、语调等信息。并生成超自然、高保真、个性化的语音，以满足不同用户的个性化需求。相较于传统语音合成技术，豆包语音合成大模型能输出在自然度、音质、韵律、气口、情感、语气词表达等方面更像真人。调用指南请参考[大模型语音合成API](https://www.volcengine.com/docs/6561/1257584) |
| | | | | | | \
|字节跳动 |豆包-文生图模型-智能绘图 |视觉大模型 |240625 |新发布 |豆包文生图模型智能绘图是基于字节跳动视觉大模型打造的新一代文生图模型，根据垂类场景，提供多种服务。生图风格多样，安全性极高，可广泛应用于教育、娱乐、办公等场景。调用指南请参考[智能绘图API](https://www.volcengine.com/docs/6791/1279296) |

<span id="_20240615"></span>
# 20240615

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-pro-32k |对话模型 |240615 |新发布 |截止发布时间效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持32k上下文窗口的推理和精调。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-pro-32k |对话模型 |browsing-240615 |新发布 |截止发布时间效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持32k上下文窗口的推理和精调。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |

<span id="_20240515"></span>
# 20240515

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Doubao-pro-4k |对话模型 |240515 |新发布 |截止发布时间效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持4k上下文窗口的推理和精调。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-pro-4k |对话模型 |character-240515 |新发布 |截止发布时间效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持4k上下文窗口的推理和精调。在角色扮演等场景有很好的效果。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-pro-4k |对话模型 |functioncall-240515 |新发布 |截止发布时间效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持4k上下文窗口的推理和精调。functioncall模型，在工具调用等场景有很好的效果。 调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-pro-32k |对话模型 |240515 |新发布 |截止发布时间效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持32k上下文窗口的推理和精调。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-pro-128k |对话模型 |240515 |新发布 |截止发布时间效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持128k上下文窗口的推理和精调。，调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-lite-4k |对话模型 |240328 |新发布 |拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持4k上下文窗口的推理和精调，调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-lite-4k |对话模型 |character-240515 |新发布 |拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持4k上下文窗口的推理和精调。在角色扮演等场景有更极致的性价比。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-lite-32k |对话模型 |240428 |新发布 |拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持32k上下文窗口的推理和精调。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-lite-128k |对话模型 |240428 |新发布 |拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持128k上下文窗口的推理和精调。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|字节跳动 |Doubao-embedding |向量模型 |text-240515 |新发布 |语义向量化模型，主要面向向量检索的使用场景，支持中、英双语，最长 4K 上下文长度。调用指南请参考 [Embeddings](https://www.volcengine.com/docs/82379/1302003) |
| | | | | | | \
|智谱AI |GLM3-130B |对话模型 |v1.0 |新发布 |模型支持function call能力。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|智谱AI |GLM3-130B金融版 |对话模型 |v1.0-update |新发布 |基于智谱AI的基座大模型GLM3-130B，经海量金融数据集精调联合打造的垂直领域大模型，具备金融领域的常识知识和认知能力，可更好地为金融机构发挥效力。调用指南请参考[ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|Meta |Llama3-8B |对话模型 |instruct |新发布 |Llama3-8B 版本拥有 80 亿参数，支持 8k 上下文，适用于英文场景的互动对话、信息获取、协助创作等任务。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|Meta |Llama3-70B |对话模型 |instruct |新发布 |Llama3-70B 版本拥有 700 亿参数，支持 8k 上下文，适用于英文场景的互动对话、信息获取、协助创作等任务。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |
| | | | | | | \
|Mistral AI |Mistral-7B |对话模型 |instruct-v0.2 |新发布 |Mistral-7B 版本拥有 70 亿参数，支持 32K 上下文，适用于多种场景的自然语言处理任务，如问答系统、机器翻译、文本摘要等。调用指南请参考 [ChatCompletions](https://www.volcengine.com/docs/82379/1298454) |

<span id="_20240418"></span>
# 20240418

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark2-pro-character-4k（已于20240820下线） |对话模型 |V1.1 |版本更新 |- |
| | | | | | | \
|字节跳动 |Skylark2-pro-32k（已于20240820下线） |对话模型 |V1.2 |版本更新 |- |

<span id="_20240222"></span>
# 20240222

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark2-pro-4k（已于20240820下线） |对话模型 |V1.2 |版本更新 |- |
| | | | | | | \
|字节跳动 |Skylark2-pro-turbo-8k（已于20240820下线） |对话模型 |V1.0 |新发布 |- |

<span id="_20240202"></span>
# 20240202

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark2-pro-32k（已于20240820下线） |对话模型 |V1.1 |版本更新 |- |

<span id="_20240115"></span>
# 20240115

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark2-pro-32k（已于20240820下线） |对话模型 |V1.0 |新发布 |- |

<span id="_20240112"></span>
# 20240112

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用说明 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark2-pro-4k（已于20240820下线） |对话模型 |V1.1 |版本更新 |- |
| | | | | | | \
|字节跳动 |Skylark2-lite-8k（已于20240820下线） |对话模型 |V1.0 |新发布 |- |

<span id="_20240102"></span>
# 20240102

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用文档 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark2-pro-character-4k（已于20240820下线） |对话模型 |v1.0 |新发布 |- |

<span id="_20231228"></span>
# 20231228

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用文档 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark2-pro-4k（已于20240820下线） |对话模型 |v1.100 |版本更新 |- |

<span id="_20231225"></span>
# 20231225

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用文档 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark2-pro-32k（已于20240820下线） |对话模型 |V1.0 |新发布 |- |

<span id="_20231205"></span>
# 20231205

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用文档 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark2-pro-4k（已于20240820下线） |对话模型 |V1.0 |新发布 |- |

<span id="_20231114"></span>
# 20231114

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用文档 |
|---|---|---|---|---|---|
| | | | | | | \
|月之暗面 |Moonshot-v1-32K |对话模型 |V1.0 |新发布 |[Moonshot-v1-32K API 调用指南](https://www.volcengine.com/docs/82379/1168048) |
| | | | | | | \
|月之暗面 |Moonshot-v1-128K |对话模型 |V1.0 |新发布 |[Moonshot-v1-128K API 调用指南](https://www.volcengine.com/docs/82379/1168049) |

<span id="_20231020"></span>
# 20231020

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用文档 |
|---|---|---|---|---|---|
| | | | | | | \
|月之暗面 |Moonshot-v1-8K |对话模型 |V1.0 |新发布 |[Moonshot-v1-8K API 调用指南](https://www.volcengine.com/docs/82379/1158281) |

<span id="_20231018"></span>
# 20231018

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用文档 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark-lite（已于20240820下线） |对话模型 |V2.0 |大版本更新，上下文长度支持8K，模型能力全面提升 |- |
| | | | | | | \
|字节跳动 |Skylark-pro（已于20240820下线） |对话模型 |V2.0 |大版本更新，上下文长度支持4K，模型能力全面提升 |- |

<span id="_20230926"></span>
# 20230926
（排名不分先后）

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用文档 |
|---|---|---|---|---|---|
| | | | | | | \
|智谱AI |ChatGLM2-Pro |对话模型 |V1.0 |新发布 |- |
| | | | | | | \
|字节跳动 |Skylark-chat（豆包同款）（已于20240820下线） |对话模型 |V1.0 |新发布 |- |

<span id="_20230908"></span>
# 20230908
（排名不分先后）

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用文档 |
|---|---|---|---|---|---|
| | | | | | | \
|字节跳动 |Skylark-lite（已于20240820下线） |对话模型 |V1.1 |优化语言、知识、学习和风险判断能力 |- |
| | | | | | | \
|字节跳动 |Skylark-plus（已于20240820下线） |对话模型 |V1.1 |增加了 fewshot 遵循，减少重复问题，增强代码能力等 |- |
| | | | | | | \
|字节跳动 |Skylark-pro（已于20240820下线） |对话模型 |V1.1 |增加了 fewshot 遵循，减少重复问题，增强代码能力等 |- |

<span id="_20230806"></span>
# 20230806
（排名不分先后）

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用文档 |
|---|---|---|---|---|---|
| | | | | | | \
|澜舟科技 |Mengzi-GPT（已于20240301下线） |对话模型 |V1.0 |- |- |
| | | | | | | \
|字节跳动 |Skylark-lite（已于20240820下线） |对话模型 |V1.0 |新发布 |- |
| | | | | | | \
|字节跳动 |Skylark-plus（V1.0已于20240219下线） |对话模型 |V1.0 |- |- |
| | | | | | | \
|字节跳动 |Skylark-pro（已于20240820下线） |对话模型 |V1.0 |新发布 |- |
| | | | | | | \
|出门问问 |序列猴子（已于20240202下线） |对话模型 |V1.0 |- |- |

<span id="_20230628"></span>
# 20230628
（排名不分先后）

| | | | | | | \
|模型提供方 |模型名称 |模型类型 |模型版本 |版本说明 |调用文档 |
|---|---|---|---|---|---|
| | | | | | | \
|智谱AI |ChatGLM-130B |对话模型 |V1.0 |新发布 |[ChatGLM-130B API调用指南](https://www.volcengine.com/docs/82379/1112500) |
| | | | | | | \
|智谱AI |ChatGLM-6B |对话模型 |V1.0 |新发布 |- |
| | | | | | | \
|MiniMax |MiniMax-abab5.5 |对话模型 |V1.0 |新发布 |- |
| | | | | | | \
|百川智能 |baichuan-7B |对话模型 |V1.0 |新发布 |- |
| | | | | | | \
|Databricks |Dolly-V2-12B |对话模型 |V1.0 |新发布 |- |





# 模型弃用&下线机制说明
Source: https://www.volcengine.com/docs/82379/1350667
<span id="背景"></span>
## 背景
随着火山方舟平台模型的升级、发布，新版本模型在效果、推理时延等各方面将远超较旧版本的模型。因此，我们将逐步下线这些旧版本模型。当某个模型确定弃用时，在正式下线前，我们会通过短信、站内信等方式发布通知，请及时关注。

<span id="模型弃用及下线流程"></span>
## 模型弃用及下线流程
模型弃用及下线完整流程如下：

1. **宣布旧版本模型弃用**，并注明该模型下线并停止服务的日期
2. 通过短信、站内信、平台公告等多种方式发布通知
3. 自正式通知日（即「通知时间」）起，逐步下调弃用模型的使用额度（即下调RPM和TPM的配额）
4. 至模型下线日期（即「下线时间」）时，**模型正式下线并停止服务**，已创建的模型推理服务将无法继续调用

注：一般情况下，每个版本的模型会在上线后3-6个月后，正式下线并停止服务。在停止服务前，我们会为开发者预留充足的时间完成新版本模型的效果测试，以便流量切换。
<span id="通知方式"></span>
## 通知方式

* 我们会通过**短信、站内信、平台公告**等多种方式发布模型弃用及下线的通知
* 我们会确保在模型正式下线前至少30个自然日发布通知
* 请关注相关通知，以便做好升级模型版本所需的各项工作


<span id="模型弃用及下线的影响说明"></span>
## 模型弃用及下线的影响说明

* **模型弃用**
   * 不可新创建推理服务接入点：弃用模型不可再新创建推理服务接入点，仅支持切换推理服务接入点指向的模型版本
   * 逐步下调配额：模型弃用后，会逐步下调已创建推理服务接入点使用配额，直到完全下线
* **模型下线**
   * 精调模型：模型下线当日停止服务，无法调用
   * 非精调模型：将自动升级至最新版本


<span id="模型切换操作说明"></span>
## 模型切换操作说明
模型切换涉及到不同场景的切换，包括同模型不同版本、不同模型迁移，精调模型服务迁移；以下是针对不同场景的迁移指引

<span id="24dcd27c"></span>
### 场景1：同模型不同版本、不同模型切换
平台为**同模型的不同模型版本、不同模型及版本**切换，提供**推理服务接入点平滑切换。** 在方舟平台的在线推理页面，修改推理服务接入点对应的模型版本（暂不支持精调模型及模型单元的版本切换）。无需修改代码，即可实现模型版本的平滑切换，支持更新模型版本。

* 操作指引


| | | \
|操作步骤 |图示 |
|---|---|
| | | \
|1. 进入方舟平台，选择在【在线推理】 |![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_23db8d6fd850f1a95cff061302eff9de.png =2884x) |
| | | \
|2. 选择需待切换的**推理服务接入点，进入推理接入点详情页** |![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_b55e9d71084da96c11a0d5b1779e427d.png =2926x) |
| | | \
|3. 点击【切换版本】，在【选择模型】页面，选择切换的模型版本；完成后点击确定。 |\
| |\
| |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5fbb0a5e5dad47ff8adabe722694586a~tplv-goo7wpa0wc-image.image =2374x) |\
| |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4e2625c9486a4553b797f5b3e7a23fbd~tplv-goo7wpa0wc-image.image =2342x) |\
| | |
| | | \
|4. 核对**推理服务接入点的详情页**中模型版本；完成平滑切换。 |\
| |\
|**说明：** |\
| |\
|* 切换时间：模型版本迁移的过程不超过1小时 |\
|* 取消切换：点击取消切换撤回模型迁移，请求流量按比例逐步切换至原模型版本 |\
|* 切换和取消切换过程按流量比例进行切换，不会影响业务正常使用 |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/08cde21aa80342cd9bd5a102eec7f68c~tplv-goo7wpa0wc-image.image =2338x) |\
| | |

<span id="a009653b"></span>
### 场景2：精调模型迁移
由于精调模型的依赖基座模型，如果需要变更精调模型对应的基座模型，需要在新的模型版本上再次[精调模型](https://www.volcengine.com/docs/82379/1099459)，并验证效果达到预期后，再创建新的推理接入点，完成相应的代码变更，实现迁移。

如有其他迁移问题，可以通过提交[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)的方式，进行咨询。

<span id="fa5ff344"></span>
# 第三批模型下线说明
<span id="fa5ff344"></span>
## 下线时间

| | | | \
|通知时间 |下线时间 |影响说明 |
|---|---|---|
| | | | \
|2025年6月30日 |2025年8月28日 |模型下线工作将于通知时间起进行，自通知时间开始，将逐步下调弃用模型配额； |\
| | |至下线时间日，模型正式下线并停止服务；建议切换至对应的推荐模型 |

<span id="40fdb328"></span>
## 下线模型

| | | | | \
|**模型版本** |**下线时间** |**建议迁移模型** |**到期未迁移，系统替换模型** |
|---|---|---|---|
| | | | | \
|doubao-pro-32k/240828 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-pro-32k/250115 |
| | | | | \
|doubao-pro-32k/character-240828 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-pro-32k/character-250228 |
| | | | | \
|doubao-vision-pro-32k/241028 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-vision-pro/250328 |
| | | | | \
|doubao-vision-lite-32k/241015 |2025年8月28日 |doubao-Seed-1.6-flash/250615 |doubao-1.5-vision-lite/250315 |
| | | | | \
|doubao-lite-32k/character-241015 |2025年8月28日 |doubao-Seed-1.6-flash/250615 |doubao-lite-32k/character-250228 |
| | | | | \
|doubao-lite-4k/character-240828 |2025年8月28日 |doubao-Seed-1.6-flash/250615 |doubao-lite-32k/character-250228 |
| | | | | \
|doubao-lite-128k/240828 |2025年8月28日 |doubao-Seed-1.6-flash/250615 |doubao-1.5-lite-32k/250115 |
| | | | | \
|doubao-lite-128k/240428 |2025年8月28日 |doubao-seed-1.6-flash/250615 |doubao-seed-1.6-flash/250615 |
| | | | | \
|doubao-pro-256k/241115 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-pro-256k/250115 |
| | | | | \
|doubao-pro-256k/240828 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-pro-256k/250115 |
| | | | | \
|doubao-pro-32k/functioncall-241028 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-pro-32k/250115 |
| | | | | \
|doubao-pro-32k/browsing-240828 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-pro-32k/browsing-241115 |
| | | | | \
|deepseek-r1-distill-qwen-32b/250120 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-seed-1.6/250615 |
| | | | | \
|deepseek-r1-distill-qwen-7b/250120 |2025年8月28日 |doubao-Seed-1.6-flash/250615 |doubao-seed-1.6-flash/250615 |
| | | | | \
|doubao-embedding/text-240515 |2025年8月28日 |doubao-embedding-vision/250615 |doubao-embedding-vision/250615（不强制切换） |
| | | | | \
|doubao-embedding-vision/241215 |2025年8月28日 |doubao-embedding-vision/250615 |doubao-embedding-vision/250615（不强制切换） |
| | | | | \
|doubao-pro-32k/functioncall-preview |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-pro-32k/250115 |
| | | | | \
|doubao-pro-32k/oracy-240928 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-pro-32k/250115 |
| | | | | \
|doubao-pro-32k/creation-241028 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-pro-32k/250115 |
| | | | | \
|doubao-1.5-thinking-pro/m-250415 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-seed-1.6/250615 |
| | | | | \
|doubao-1.5-vision-pro-32k/preview |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-vision-pro/250328 |
| | | | | \
|doubao-1.5-thinking-pro/vision-250415 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-thinking-pro/m-250428 |
| | | | | \
|doubao-1.5-ui-tars/250328 |2025年8月28日 |doubao-seed-1.6/250615 |doubao-1.5-ui-tars/250428 |
| | | | | \
|doubao-seaweed-241128 |2025年8月28日 |doubao-Seedance-1.0-pro-250528 |\
| | |doubao-Seedance-1.0-lite-i2v-250428 |\
| | |doubao-Seedance-1.0-lite-t2v-250428 |关停 |


<span id="本期下线说明"></span>
# 第二批模型下线说明(截至2025年5月28日)
<span id="b5da9670"></span>
## 下线时间

| | | | \
|通知时间 |下线时间 |影响说明 |
|---|---|---|
| | | | \
|2025年1月10日 |2025年5月28日 |模型下线工作将于通知时间起进行，自通知时间开始，将逐步下调弃用模型配额； |\
| | |至下线时间日，模型正式下线并停止服务；建议切换至对应的推荐模型 |

<span id="e85cd52f"></span>
## 下线模型

| | | | \
|**模型版本** |**下线时间** |**替代模型** |
|---|---|---|
| | | | \
|Doubao-pro-32k/240615 |2025年5月28日 |Doubao-1.5-pro-32k/250115 |
| | | | \
|Doubao-pro-32k/character-240528 |2025年5月28日 |Doubao-1.5-pro-32k/character-250228 |
| | | | \
|Doubao-pro-128k/240628 |2025年5月28日 |Doubao-1.5-pro-32k/250115 |
| | | | \
|Doubao-lite-32k/240428 |2025年5月28日 |Doubao-1.5-lite-32k/250115 |
| | | | \
|Doubao-lite-32k/240628 |2025年5月28日 |Doubao-1.5-lite-32k/250115 |
| | | | \
|Doubao-lite-128k/240428 |2025年5月28日 |Doubao-1.5-pro-256k/250115 |
| | | | \
|Doubao-pro-4k/character-240728 |2025年5月28日 |Doubao-1.5-pro-32k/character-250228 |
| | | | \
|Doubao-pro-4k/functioncall-240615 |2025年5月28日 |Doubao-1.5-pro-32k/250115 |
| | | | \
|Doubao-pro-32k/functioncall-240515 |2025年5月28日 |Doubao-1.5-pro-32k/250115 |
| | | | \
|Doubao-pro-32k/functioncall-240815 |2025年5月28日 |Doubao-1.5-pro-32k/250115 |
| | | | \
|Doubao-pro-32k/browsing-240615 |2025年5月28日 |Doubao-pro-32k/browsing-241115 |
| | | | \
|Doubao-lite-4k/browsing-intent-240615 |2025年5月28日 |Doubao-lite-4k/browsing-intent-240828 |
| | | | \
|GLM3-130B |2025年4月1日 |方舟平台其他模型 |
| | | | \
|GLM3-130B 金融模型 |2025年4月1日 |方舟平台其他模型 |


<span id="8812eeec"></span>
# 第一批模型模型下线说明(截至2025年2月28日)
<span id="本期下线时间说明"></span>
## 下线时间

| | | | | \
|通知时间 |下线时间 |实际下线时间 |影响说明 |
|---|---|---|---|
| | | | | \
|2024年9月30日 |2025年2月28日 |2025年4月15日 |模型下线工作将于通知时间起进行，自通知时间开始，将逐步下调弃用模型配额； |\
| | | |至下线时间日，模型正式下线并停止服务；建议切换至对应的推荐模型 |

<span id="本期模型下线列表"></span>
## 下线模型

| | | | | | | \
|**模型名称** |**模型版本** |**下线时间** |**实际下线时间** |**替代模型** | |
|---|---|---|---|---|---|
| | | | | | | \
|**Doubao-lite-32k** |240428 |2025年2月28日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 | |
| | | | | | | \
|**Doubao-lite-4k** |\
| |240328 |2025年2月28日 |\
| | | |2025年4月15日 |Doubao-1.5-lite-32k/250115 | |
|^^| |^^|^^| | | \
| |character-240515 | | |Doubao-lite-32k/character-250228 |即将发布 |
| | | | | | | \
|**Doubao-pro-128k** |240515 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | \
|**Doubao-pro-32k** |240515 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | \
|**Doubao-pro-4k** |\
| |240515 |2025年2月28日 |\
| | | |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
|^^| |^^|^^| | | \
| |browsing-240524 | | |Doubao-pro-32k/browsing-241115 | |
|^^| |^^|^^| | | \
| |character-240515 | | |Doubao-1.5-pro-32k/character-250228 | |
|^^| |^^|^^| | | \
| |functioncall-240515 | | |Doubao-1.5-pro-32k/250115 | |
| | | | | | | \
|**Skylark3-lite-128k** |240428 |2025年2月28日 |2025年4月15日 |Doubao-lite-128k/240828 | |
| | | | | | | \
|**Skylark3-lite-4k** |240328 |2025年2月28日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 | |
| | | | | | | \
|**Skylark3-pro-4k** |240415 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | \
|**Skylark2-lite-8k** |\
| |browsing-intent-240415 |2025年2月28日 |2025年4月15日 |Doubao-lite-4k/browsing-intent-240828 | |
|^^| |^^|^^|^^| | \
| |browsing-intent-240615 |2025年2月28日 | | | |
|^^| |^^|^^|^^| | \
| |1.0 | | | | |
| | | | | | | \
|**Skylark2-lite-4k** | |2025年2月28日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 | |
| | | | | | | \
|**Skylark2-lite-character-8k** | |2025年2月28日 |2025年4月15日 |Doubao-lite-32k/character-250228 | |
| | | | | | | \
|**Skylark2-pro-character-4k** |\
| |1.0 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/character-250228 | |
|^^| |^^|^^|^^| | \
| |ecom-20240415 |2025年2月28日 | | | |
| | | | | | | \
|**Skylark2-pro-32k** |1.0/1.1 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | \
|**Skylark2-pro-4k** |\
| |browsing |2025年2月28日 |2025年4月15日 |Doubao-pro-32k/browsing-241115 | |
|^^| |^^|^^| | | \
| |browsing-240415 | | |Doubao-pro-32k/browsing-241115 | |
|^^| |^^|^^| | | \
| |character-240328 | | |Doubao-1.5-pro-32k/character-250228 | |
|^^| |^^|^^| | | \
| |1.2/1.3 | | |Doubao-1.5-pro-32k/250115 | |
| | | | | | | \
|**Web-intent** |1.0 |2025年2月28日 |2025年4月15日 |Doubao-pro-32k/browsing-240828 | |
| | | | | | | \
|**Skylark-Web** |2.2/0.0 |2025年2月28日 |2025年4月15日 |Doubao-pro-32k/browsing-241115 | |
| | | | | | | \
|**Skylark-plus-public** |1.1 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | \
|**Skylark-pro-public** |2.0/2.1 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | \
|**Skylark-lite-public** |2.0/1.0/1.1/0.0 |2025年2月28日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 | |
| | | | | | | \
|**Skylark-chat** |1.0 |2025年2月28日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 | |
| | | | | | | \
|**llama3-70b** |llama3-70b-instruct |2025年4月1日 |2025年4月15日 |Doubao-1.5-pro-32k/250115 |原服务已关停 |
| | | | | | | \
|**llama3-8b** |llama3-8b-instruct |2025年4月1日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 |原服务已关停 |
| | | | | | | \
|mistral-7b |instruct-v0.2 |2025年2月28日 |2025年4月15日 |Doubao-1.5-lite-32k/250115 |原服务已关停 |
| | | | | | | \
|chatglm3-130-fin |v1.0-update |2025年2月28日 |2025年4月15日 | |原服务已关停 |
| | | | | | | \
|chatglm3-130b-fc |v1.0 |2025年2月28日 |2025年4月15日 | |原服务已关停 |




# 火山引擎豆包新模型活动
Source: https://www.volcengine.com/docs/82379/1536419
火山引擎企业用户（[完成企业实名认证](https://console.volcengine.com/user/authentication/detail/)用户）使用火山引擎方舟本次推出新大模型各可享 300 万 token/模型代金券，同时可以享受最高 10 亿 token 的 5 折优惠。
<span id="d563bc9f"></span>
## 活动细则
企业用户在火山方舟平台开通指定模型，即可享受下面的优惠：

* 每个模型 10 亿 token 用量的 5 折优惠，有效期：自开通时刻起 14 天。
* 每个模型 300 万 token 的代金券，有效期：自开通时刻起 6 个月。

<span id="0e1bdbd2"></span>
### 参加对象
所有完成企业实名认证的用户，包括个人认证转企业认证的用户。
> 如您在个人认证的账户开通指定模型后，转为企业认证用户同样适用。
> [点此](https://console.volcengine.com/user/authentication/detail/)进行企业实名认证。

<span id="4b404a66"></span>
### 指定模型
当前企业用户开通如下模型，各模型（不区分版本）均可享受 10 亿 token 用量的 5 折优惠及 300 万  token 代金券。

| | | | \
|模型 |5 折 token 量 |代金券 |
|---|---|---|
| | | | \
|[doubao-seed-1.6 ](https://www.volcengine.com/docs/82379/1593702) |10 亿 |\
| |14 天有效期 |300 万 token 代金券（7.2 元） |\
| | |6 月有效期 |
| | | | \
|[doubao-seed-1.6-thinking](https://www.volcengine.com/docs/82379/1593703) |10 亿 |\
| |14 天有效期 |300 万 token 代金券（7.2 元） |\
| | |6 月有效期 |
| | | | \
|[doubao-seed-1.6-flash](https://www.volcengine.com/docs/82379/1593704) |10 亿 |\
| |14 天有效期 |300 万 token 代金券（1.8 元） |\
| | |6 月有效期 |
| | | | \
|[doubao-seedance-1.0-pro](https://www.volcengine.com/docs/82379/1587798) |10 亿 |\
| |14 天有效期 |300 万 token 代金券（45 元） |\
| | |6 月有效期 |
| | | | \
|[doubao-1.5-thinking-pro](https://www.volcengine.com/docs/82379/1536428) |10 亿 |\
| |14 天有效期 |300 万 token 代金券（12 元） |\
| | |6 月有效期 |
| | | | \
|[doubao-1.5-ui-tars](https://www.volcengine.com/docs/82379/1536429) |10 亿 |\
| |14 天有效期 |300 万 token 代金券（10.5 元） |\
| | |6 月有效期 |

> 发放的模型不区分版本情况，如 doubao-1.5-thinking-pro 的 250428、m-250415、250415 版本共用 10 亿 token 单价 5 折优惠以及代金券。

<span id="5dde124b"></span>
### 折扣生效时间
[开通指定模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)后，满足下面 2 个条件，该模型 5 折的折扣优惠会生效，否则将恢复为原价。

* **主体首次模型开通**至 **336 小时**（14*24 小时，14 天）内。
* 主体名下**所有账号的指定模型用量总和未超过 10 亿 token 限额**。

您在[开通管理页面](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)开通模型服务，并查看模型折扣是否生效及模型具体价格。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/9f83e2bcfb6b4fceb6a72577f5bad759~tplv-goo7wpa0wc-image.image =821x)
<span id="7eb67911"></span>
### 代金券发放时间
[开通指定模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)后，最长 24 小时，您会收到发放的代金券。您可以[在此](https://console.volcengine.com/finance/coupon/)查看是否收到代金券。
<span id="219ead2d"></span>
## 常见问题
<span id="e613d2d4"></span>
### Q：我可以开通多少火山引擎账号？
A：1 个企业主体支持实名认证 10 个火山引擎账号。这些账号共享折扣用量；各账号独立享受代金券。举例来说，我注册了 3 个火山引擎账号，这些账号下 DeepSeek R1 模型可享折扣的用量为 10 亿，以及 3 个账户都发放代金券。

<span id="1105b438"></span>
### Q：如果我总量超出了限额上限（10 亿 token），如何计费？
A：考虑到您不能实时看到账单（最大延时为 1 小时），为维护您的权益，该**计费周期（1 小时）内产生的总量均按五折计算，下个计费周期将按照原价计费**，累计用量以火山引擎侧计量的用量作为统计值。

<span id="af4d50d0"></span>
### Q：代金券可以抵扣方舟豆包模型的 token 使用费用么？
A：可以，代金券不绑定具体某款豆包模型，可以抵扣您豆包[深度思考](https://www.volcengine.com/docs/82379/1330310#898d064d)模型、[视觉理解](https://www.volcengine.com/docs/82379/1330310#ff5ef604)模型、[文本生成](https://www.volcengine.com/docs/82379/1330310#15a31773)模型后付费的 token 使用费用，但是不能抵扣方舟上 deepseek、文生图等其他模型的后付费 token 使用费用。





# 火山引擎大模型新客福利活动
Source: https://www.volcengine.com/docs/82379/1463946
火山引擎大模型新客使用豆包大模型及 deepseek r1 模型各可享 10 亿 token / 模型的 5 折优惠，各个模型总计 10 亿 token。
<span id="d563bc9f"></span>
## 活动细则
未注册过火山引擎账号的企业或个人，在 2025 年 2 月 24 日 00:00:00 起注册火山引擎账号并完成实名认证。可在火山方舟平台开通指定模型，自开通时刻起 14 天内，享有该模型最高 10 亿 token 用量的 5 折优惠。
<span id="0e1bdbd2"></span>
### 参加对象
**未注册过火山引擎账号的企业或个人**，且在 2025 年 2 月 24 日 00:00:00 后[注册火山引擎账号](https://console.volcengine.com/auth/signup)并完成实名认证。
<span id="4b404a66"></span>
### 指定模型
当前参加新客折扣活动的模型如下，各模型均可享受 10 亿 token 用量的 5 折优惠。
doubao-seedance-1.0 大模型

* doubao-seedance-1.0-pro

doubao-seed-1.6 代大模型：

* doubao-seed-1.6-250615
* doubao-seed-1.6-thinking-250615
* doubao-seed-1.6-flash-250615

doubao-1.5 代大模型：

* doubao-1.5-pro-32k-250115
* doubao-1.5-pro-256k-250115
* doubao-1.5-lite-32k--250115
* doubao-1.5-vision-pro-32k-250115

deepseek-r1 推理模型：

* deepseek-r1-250528
* deepseek-r1-250120

<span id="5dde124b"></span>
### 折扣生效时间
新客开通指定模型服务后，满足下面 2 个条件，该模型 5 折的折扣优惠会生效，否则将恢复为原价。

* **主体首次模型开通**至 **336 小时**（14*24 小时，14 天）内。
* 主体名下**所有账号的指定模型用量总和未超过 10 亿 token 限额**。

您在[开通管理页面](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)开通模型服务，并查看模型折扣是否生效及模型具体价格。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/9f83e2bcfb6b4fceb6a72577f5bad759~tplv-goo7wpa0wc-image.image =821x)
<span id="219ead2d"></span>
## 常见问题
<span id="e613d2d4"></span>
### Q：我可以开通多少火山引擎账号？
A：1 个个人主体支持实名认证 3 个火山引擎账号；1 个企业主体支持实名认证 10 个火山引擎账号。这些账号共享折扣用量，即我注册了 3 个火山引擎账号，这些账号下 DeepSeek R1 模型可享折扣的用量为 10 亿。

<span id="1105b438"></span>
### Q：如果我总量超出了限额上限（10 亿 token），如何计费？
A：考虑到您不能实时看到账单（最大延时为 1 小时），为维护您的权益，该**计费周期（1 小时）内产生的总量均按五折计算，下个计费周期将按照原价计费**，累计用量以火山引擎侧计量的用量作为统计值。



# 使用IAM进行访问控制教程
Source: https://www.volcengine.com/docs/82379/1263493
为确保您的云资源使用安全，如非必要都应避免直接使用火山引擎账号（即主账号）来访问火山方舟。推荐的做法是使用IAM身份（即IAM用户和IAM角色）来访问火山方舟。

<span id="基本概念"></span>
# 基本概念

| | | \
|名称 |说明 |
|---|---|
| | | \
|主账号 |火山主账号 |\
| | |\
| |* 账号（又称为主账号）可以看作是一个特殊的用户（被称为根用户，root user），是云服务资源的拥有者，也是资源计量、资源计费的主体。主账号默认拥有账号下所有权限。 |
| | | \
|IAM用户或子账号 |IAM用户即IAM账号，是IAM的一种实体身份类型。 |\
| | |\
| |* IAM用户由账号（主账号）或具有管理员权限的其他IAM用户、IAM角色创建，创建成功后，归属于该火山主账号，它不是独立的火山账号。 |\
| |* IAM用户不拥有资源，不能独立计量计费，由所属的主账号统一付费。 |\
| |* IAM用户必须在获得授权后，才能登录控制台或使用API访问火山主账号下的资源。 |\
| | |\
| |> 更多请查看：[IAM用户](https://www.volcengine.com/docs/6257/64977) |
| | | \
|用户组 |用户组是IAM的一种实体身份类型，用户组可以对职责相同的IAM用户进行分类并授权，从而更高效地管理IAM用户及其权限。 |\
| | |\
| |* 在IAM用户职责发生变化时，只需将其移动到相应职责的用户组下，不会对其他IAM用户产生影响。 |\
| |* 当用户组的权限发生变化时，只需修改用户组的权限策略，即可应用到所有IAM用户。 |\
| | |\
| |> 更多请查看：[用户组管理](https://www.volcengine.com/docs/6257/104988) |
| | | \
|角色 |IAM角色是一种虚拟用户，可以被授予一组权限策略。与IAM用户不同，IAM角色没有永久身份凭证（登录密码或访问密钥），需要被一个可信实体扮演。扮演成功后，可信实体将获得IAM角色的临时身份凭证，即安全令牌（STS Token），使用该安全令牌就能以IAM角色身份访问被授权的资源。 |\
| |> 更多请查看：[角色免密登录控制台](https://www.volcengine.com/docs/6257/160179) |

<span id="基于身份的系统预设策略"></span>
# 基于身份的系统预设策略
<span id="什么是系统预设策略"></span>
## 什么是系统预设策略
权限策略是用语法结构描述的一组权限的集合，可以精确地描述被授权的资源集、操作集以及授权条件。火山引擎访问控制（IAM）产品提供了两种类型的权限策略：系统策略和自定义策略。系统策略统一由火山引擎各产品团队创建，策略的版本更新由火山引擎维护，用户只能使用不能修改。自定义策略由用户管理，策略的版本更新由用户维护。用户可以自主创建、更新和删除自定义策略。
<span id="产品预设策略"></span>
## 产品预设策略
<span id="arkfullaccess"></span>
### ArkFullAccess
火山方舟(Ark)管理员用户，拥有所有Ark服务的权限。适合算法、研发等角色，可查看和配置全部资源。主账号或账号管理员可以通过下面链接查看策略详情：[权限策略-ArkFullAccess](https://console.volcengine.com/iam/policymanage/System/ArkFullAccess?tab=content)。
<span id="arkstandardglobalaccess"></span>
### ArkStandardGlobalAccess
火山方舟（Ark）基础功能使用权限，可查看并配置除模型开通外的所有资源。主账号或账号管理员可以通过下面链接查看策略详情：[权限策略-ArkStandardGlobalAccess](https://console.volcengine.com/iam/policymanage/System/ArkStandardGlobalAccess?tab=content)。
<span id="2d08de72"></span>
### ArkReadOnlyAccess
火山方舟(Ark)只读用户，拥有Ark服务的只读权限。适合产品、运营等角色，可查看全部资源，包括精调任务、仓库模型、推理接入点等。主账号或账号管理员可以通过下面链接查看策略详情：[权限策略-ArkReadOnlyAccess](https://console.volcengine.com/iam/policymanage/System/ArkReadOnlyAccess?tab=content)。
<span id="722cb2eb"></span>
### ArkExperienceAccess
火山方舟（Ark）体验中心权限，可查看并体验模型广场中的模型，适合前期体验方舟以及模型能力阶段的用户。 主账号或账号管理员可以通过下面链接查看策略详情：[权限策略-ArkExperienceAccess](https://console.volcengine.com/iam/policymanage/System/ArkExperienceAccess?tab=content)。
<span id="bfdb48b6"></span>
### ArkGlobalInitAccess
火山方舟（Ark）**项目隔离**基本权限，用于搭配标准策略实现项目权限隔离，适合有按项目隔离需求的用户。 主账号或账号管理员可以通过下面链接查看策略详情：[权限策略-ArkGlobalInitAccess](https://console.volcengine.com/iam/policymanage/System/ArkGlobalInitAccess?tab=content)。
<span id="服务关联角色策略"></span>
## 服务关联角色策略
<span id="serviceroleforark"></span>
### ServiceRoleForArk
火山方舟(Ark)的服务关联角色，授权后允许方舟平台访问您账号下的其他服务资源。主账号或账号管理员可以通过下面链接查看信任策略详情：[角色详情-ServiceRoleForArk](https://console.volcengine.com/iam/identitymanage/role/ServiceRoleForArk/)。

<span id="自定义权限策略"></span>
# 自定义权限策略
如果系统权限策略不能满足您的要求，您可以创建自定义权限策略实现最小授权。使用自定义权限策略有助于实现权限的精细化管控，是提升资源访问安全的有效手段。
<span id="什么是自定义权限策略"></span>
## 什么是自定义权限策略
在基于IAM的访问控制体系中，自定义权限策略是指在系统权限策略之外，您可以自主创建、更新和删除的权限策略。自定义权限策略的版本更新需由您来维护。
<span id="赋予某用户组arkfullaccess"></span>
## 典型场景-赋予某用户组ArkFullAccess
本用例演示了创建一条模型接入，并且拥有 模型接入的停止/删除/编辑/API调用的权限。
```json
{
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ark:GetEnd",
                "ark:List*",
                "tag:GetTagValues",
                "tag:GetTagKeys",
```

```json
{
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ark:CreateEndpoint",
                "ark:ListFoundationModels",
                "ark:ListCustomModels",
                "ark:ListFoundationModelVersions",
                "ark:ListEndpoints",
                "ark:StopEndpoint",
                "ark:StartEndpoint",
                "ark:GetEndpoint",
                "ark:DeleteEndpoint",
                "ark:UpdateEndpoint",
                "ark:GetModelChargeItem",
                "ark:InnerGetModelUnitPrice",
                "ark:GetEndpointExampleCode",
                "ark:GetApiKey",
                "tag:GetTagValues",
                "tag:GetTagKeys"
            ],
            "Resource": [
                "*"
            ]
        }
    ]
}
```

若您需要限制使用范围，可以通过修改Resource范围实现。即可以通过限定用户范围、用户组、Project或资源ID来缩小权限。
```json
"Resource": [
                "trn:iam::2100000xxx:user/username",
                "trn:iam::2100000xxx:group/usergroupname",
                "trn:iam::2100000xxx:project/projectname",
                "trn:ark:cn-beijing:2100000xxx:endpoint/ep-20240407133918-vdsmd3"
                ]
```

<span id="68d11b0c"></span>
## 典型场景-赋予账号项目级权限
当您需要配置IAM账号，使其拥有账号下A项目的权限，但是不具备B项目的权限，即限定用户只在A项目开发/查看/体验。您可以通过组合策略来达成。

| | | | \
|全局策略 |项目策略 |\
| |需配置生效的项目 |账号权限描述 |
|---|---|---|
| | | | \
|ArkGlobalInitAccess |ArkExperienceAccess |火山方舟体验中心权限，可**在项目内**查看并体验模型广场中的模型。  |
| | | | \
|ArkGlobalInitAccess |ArkReadOnlyAccess |火山方舟只读权限，可**在项目内**使用体验中心，并查看所有资源，包括精调任务、仓库模型、推理接入点等。 |
| | | | \
|ArkGlobalInitAccess |ArkStandardGlobalAccess |火山方舟基础功能使用权限，可**在项目内**查看并配置除模型开通外的所有资源。 |
| | | | \
|ArkGlobalInitAccess |ArkFullAccess |火山方舟管理员权限，可**在项目内**查看并配置管理所有资源。 |

下面以为用户配置`default （默认项目）`的管理员`ArkFullAccess`权限为例，演示完整操作流程。

1. 访问[访问控制-用户](https://console.volcengine.com/iam/identitymanage/user)页面，在需要配置权限的用户名右侧的用户列表的 操作 列中，为单击 添加权限 。
2. 在 授权策略 栏搜索并勾选 ArkGlobalInitAccess 策略，限制到项目资源 选择 否。
3. 在 授权策略 栏搜索并勾选 ArkFullAccess 策略，限制到项目资源 选择 是，并选择用户需要拥有权限的项目，这里选择`default （默认项目）`。
4. 单击提交按钮，生效权限。

同上步骤，您也可以为用户组配置策略，使其拥有某项目的权限。
<span id="项目管理"></span>
# 项目管理
项目可以根据资源的用途、权限和归属等维度对您拥有的云资源进行分组，从而实现企业内部多用户、多项目的资源分级管理。每个云资源只能属于一个项目，加入项目不会改变云资源之间的关联关系。
基于项目（即一组资源）进行IAM授权，有利于维护资源独立、数据安全；同时可以从项目维度查看资源消费账单，便于计算云资源使用成本。
<span id="项目管理使用流程"></span>
## **项目管理使用流程**
本文以实例为例，介绍如何对云资源进行项目管理。项目管理功能的一般使用流程如下：

1. [创建项目](https://www.volcengine.com/docs/6649/94336#%E6%96%B0%E5%BB%BA%E9%A1%B9%E7%9B%AE)：创建一个项目，用于对实例进行项目管理。
2. [为IAM用户添加项目权限](https://www.volcengine.com/docs/6649/173422#%E6%B7%BB%E5%8A%A0%E9%A1%B9%E7%9B%AE%E6%9D%83%E9%99%90)：为子用户授予项目权限。
3. 创建资源并且归属于项目中（资源会放入默认项目组，您可以在创建资源时选择资源所属项目）。
4. （可选）[按项目查看账单](https://www.volcengine.com/docs/6269/94010#%E4%B8%80%E3%80%81%E8%B4%A6%E5%8D%95%E6%98%8E%E7%BB%86)：您可以根据项目筛选账单。
   ![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_43789e6a623c89c97a3c83577de176fb.png =2752x)

<span id="通过项目管理分账"></span>
## 通过项目管理分账
火山方舟已完成项目的对接，因此您可以在 [火山引擎-费用中心](https://console.volcengine.com/finance/bill/split-bill) 根据**项目**查看分账账单。
![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f26c56e7c0292f7437e471d389d5348e.png =3336x)
更多信息请查看文档[项目分账](https://www.volcengine.com/docs/6649/174601)。
<span id="0da43646"></span>
# 标签管理
资源标签是由一组KV键值对组成，您可以通过资源标签从不同维度对云资源进行分类和聚合管理，并且使用于标签制授权和资源分账等场景。火山方舟已经完成了系统标签 `create_by` 的对接，因此您可以在费用中心可以按照用户维度做分账。
<span id="使用步骤"></span>
## 使用步骤
您可前往“[费用中心-账单管理-费用标签](https://console.volcengine.com/finance/bill/tag/)”，启用 `sys:ark:createdBy` 作为费用标签，启用后，该费用标签将会在账单明细数据中的“标签”列体现；
![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_e83c4ba7d2ebe7ab1de1d87e8fc41ad5.png =3336x)




# 批量推理任务最佳实践
Source: https://www.volcengine.com/docs/82379/1386369
批量推理是一种高效的推理模式，可通过控制台操作或 OpenAPI 创建异步任务对请求进行处理。批量推理支持多种模型，且支持与对应模型在线推理一致的参数配置选项。
批量推理提供更高的速率限制和更大的每日吞吐，每个批量推理任务的运行时间最长可配置至28天，特别适用于需要处理大量数据且无需实时获取结果的场景，例如日志分析、离线数据预测和评测等。
本实践教程将通过实际示例，带您了解并逐步了解批量推理的使用方法。示例基于 Python，以 Doubao-pro-32k/240615 模型为例，展示如何进行批量推理，主要涉及到两个部分：

* 调整数据格式以适配批量推理任务后，使用 TOS （对象存储服务）进行数据上传与存储
* 通过控制台或批量推理 OpenAPI 发起批量推理任务

<span id="4e3e9ea9"></span>
## 1. 准备批量推理文件
请参考 [输入文件格式说明](https://www.volcengine.com/docs/82379/1305505#输入文件) 准备包含您要进行推理的请求的输入文件，并确保账户已启用[火山引擎对象存储 TOS 服务](https://www.volcengine.com/docs/6349/74820)。
以下是一个输入文件示例，包含 2 个请求：
<Attachment link="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/390bfd2cd7b2473d99254593e136c348~tplv-goo7wpa0wc-image.image" name="data.jsonl" ></Attachment>
```JSON
{"custom_id": "request-1", "body": {"messages": [{"role": "user", "content": "天空为什么这么蓝？"}],"max_tokens": 1000,"top_p":1}}
{"custom_id": "request-2", "body": {"messages": [{"role": "system", "content": "You are an unhelpful assistant."},{"role": "user", "content": "天空为什么这么蓝？"}],"max_tokens": 1000}}
```

使用如下代码对输入数据进行前置检测
```Python
# input_file_name-文件的完整路径
with open(input_file_name, 'r', encoding='utf-8') as file:
    total = 0
    custom_id_set = set()
    for line in file:
        if line.strip() == '':
            continue
        try:
            line_dict = json.loads(line)
        except json.decoder.JSONDecodeError:
            raise Exception(f"批量推理任务失败，第{total+1}行非json数据")
        if not line_dict.get('custom_id'):
            raise Exception(f"批量推理任务失败，第{total+1}行custom_id不存在")
        if line_dict.get('custom_id') in custom_id_set:
            raise Exception(f"批量推理任务失败，custom_id={line_dict.get('custom_id', '')}存在重复")
        else:
            custom_id_set.add(line_dict.get('custom_id'))
        if not isinstance(line_dict.get('body', ''), dict):
            raise Exception(f"批量推理任务失败，custom_id={line_dict.get('custom_id', '')}的body非json字符串")
        total += 1
    return total
```

<span id="ab8b268c"></span>
## 2.TOS上传数据
<span id="ec5123a4"></span>
### 数据上传
数据上传可选择通过 TOS 控制台或者 OpenAPI：

* 上传文件前，请确保您已经创建存储桶。具体步骤，请参见[创建存储桶](https://www.volcengine.com/docs/6349/75024)。
* 文件名的命名规范，请参见[文件说明](https://www.volcengine.com/docs/6349/74822#%E5%AF%B9%E8%B1%A1-%E6%96%87%E4%BB%B6%EF%BC%88object%EF%BC%89)。
* 简单上传方式最大能够上传 5GB 文件。
* 使用控制台分片上传最大能够上传 50GB 文件。
   * 如果您的文件大于 50GB，您可以使用 API 上传，该方式最大支持上传 48.8TB 文件（每个分片最大 5GB，分片数量最多 10000）。具体步骤请参见[UploadPart](https://www.volcengine.com/docs/6349/74869)。

<span id="7a0849e1"></span>
### 通过控制台
[控制台快速入门--对象存储-火山引擎](https://www.volcengine.com/docs/6349/74830)
<span id="ce7cd267"></span>
### 通过 SDK
> [快速入门（Python SDK）--对象存储-火山引擎](https://www.volcengine.com/docs/6349/92786)

<span id="11b29362"></span>
#### 安装及初始化
```Shell
# 通过 pip 安装
pip install tos

# 通过源码安装, 从 Github 下载相应版本的 SDK 包，解压后进入目录，执行如下命令。
python3 setup.py install
```

```Python
import os
import tos

# AKSK是访问火山云资源的秘钥，可从访问控制-API访问密钥获取
# 为了保障安全，强烈建议您不要在代码中明文维护您的AKSK
ak = os.environ.get("YOUR_ACCESS_KEY")
sk = os.environ.get("YOUR_SECRET_KEY")
# your endpoint 和 your region 填写Bucket 所在区域对应的Endpoint。
# 以华北2(北京)为例，your endpoint 填写 tos-cn-beijing.volces.com，your region 填写 cn-beijing。
endpoint = "tos-cn-beijing.volces.com"
region = "cn-beijing"

client = tos.TosClientV2(ak, sk, endpoint, region)
```

<span id="9361a309"></span>
#### 上传本地文件：普通上传
> [普通上传(Python SDK)--对象存储-火山引擎](https://www.volcengine.com/docs/6349/92800)

```Python
bucket_name = "demo-bucket-test"
# 对象名称，例如 example_dir 下的 example_object.txt 文件，则填写为 example_dir/example_object.txt
object_key = "data.jsonl"
# 本地文件路径
file_name = "/usr/local/data.jsonl"
try:
    # 创建 TosClientV2 对象，对桶和对象的操作都通过 TosClientV2 实现
    client = tos.TosClientV2(ak, sk, endpoint, region)
    # 将本地文件上传到目标桶中
    # file_name为本地文件的完整路径。
    client.put_object_from_file(bucket_name, object_key, file_name)
except tos.exceptions.TosClientError as e:
    # 操作失败，捕获客户端异常，一般情况为非法请求参数或网络异常
    print('fail with client error, message:{}, cause: {}'.format(e.message, e.cause))
except tos.exceptions.TosServerError as e:
    # 操作失败，捕获服务端异常，可从返回信息中获取详细错误信息
    print('fail with server error, code: {}'.format(e.code))
    # request id 可定位具体问题，强烈建议日志中保存
    print('error with request id: {}'.format(e.request_id))
    print('error with message: {}'.format(e.message))
    print('error with http code: {}'.format(e.status_code))
    print('error with ec: {}'.format(e.ec))
    print('error with request url: {}'.format(e.request_url))
except Exception as e:
    print('fail with unknown error: {}'.format(e))
```

<span id="2afc4248"></span>
#### 分片上传
> [分片上传(Python SDK)--对象存储-火山引擎](https://www.volcengine.com/docs/6349/92801)
> [断点续传(Python SDK)--对象存储-火山引擎](https://www.volcengine.com/docs/6349/135729)

:::tip
* 文件大小超过5G需要走分片上传，网络稳定的情况下可以直接走分片上传，网络不稳定建议走断点续传。
* 每个分片大小为 4MB - 5GB，网络环境越稳定分片大小可选越大。建议分片大小为50 MB - 1GB。
:::
```Python
# 断点续传demo
bucket_name = "demo-bucket-test"
# 对象名称，例如 example_dir 下的 example_object.txt 文件，则填写为 example_dir/example_object.txt
object_key = "data.jsonl"
# 本地文件完整路径，例如usr/local/testfile.txt
filename = "/usr/local/testfile.txt"
try:
    # 创建 TosClientV2 对象，对桶和对象的操作都通过 TosClientV2 实现
    client = tos.TosClientV2(ak, sk, endpoint, region)


    def percentage(
        consumed_bytes: int,
        total_bytes: int,
        rw_once_bytes: int,
        type: DataTransferType,
    ):
        if total_bytes:
            rate = int(100 * float(consumed_bytes) / float(total_bytes))
            print(
                "rate:{}, consumed_bytes:{},total_bytes{}, rw_once_bytes:{}, type:{}".format(
                    rate, consumed_bytes, total_bytes, rw_once_bytes, type
                )
            )


    # 可通过part_size可选参数指定分片大小
    # 通过enable_checkpoint参数开启和关闭断点续传特性
    # 通过task_num设置线程数
    client.upload_file(
        bucket_name,
        object_key,
        filename,
        # 设置断点续传执行线程数，默认为1
        task_num=3,
        # 设置断点续传分片大小，默认20mb
        part_size=1024 * 1024 * 5,
        # 设置断点续传进度条回调函数
        data_transfer_listener=percentage,
    )
except tos.exceptions.TosClientError as e:
    # 操作失败，捕获客户端异常，一般情况为非法请求参数或网络异常
    print("fail with client error, message:{}, cause: {}".format(e.message, e.cause))
except tos.exceptions.TosServerError as e:
    # 操作失败，捕获服务端异常，可从返回信息中获取详细错误信息
    print("fail with server error, code: {}".format(e.code))
    # request id 可定位具体问题，强烈建议日志中保存
    print("error with request id: {}".format(e.request_id))
    print("error with message: {}".format(e.message))
    print("error with http code: {}".format(e.status_code))
    print("error with ec: {}".format(e.ec))
    print("error with request url: {}".format(e.request_url))
except Exception as e:
    print("fail with unknown error: {}".format(e))
```

<span id="9ddaddfc"></span>
## 3.创建及执行批量推理任务
您有3种方式创建批量推理任务，您可以根据自己的需求灵活选择。

* 通过火山方舟控制台可视化创建。
* 调用 API 创建。
* 通过SDK 创建。

<span id="50561707"></span>
### 通过控制台
参考[批量推理](https://www.volcengine.com/docs/82379/1305505)教程，在“批量推理”页面，点击左上角 **创建批量任务** 按钮跳转至创建页。

* 账户维度有如下配额：
   * 一个项目下 7 天内提交的批量推理任务数量最多为 500，超出时将暂时无法提交新的任务。
   * 一个项目下同时处于「运行中」状态的批量推理任务数量最多为 3，超出时其余任务将处于「排队中」状态等待运行。
      * 请注意，账号下实际同时运行的任务数量会受到平台总体资源的限制和任务调度策略的影响。

  如希望调整配额，您可以前往[配额中心](https://console.volcengine.com/quota/productList/coParameterList?ProviderCode=MaaS)进行申请。
<span id="91d34dc3"></span>
### 通过 API
参考[创建批量推理任务API](https://www.volcengine.com/docs/82379/1339603)进行批量推理任务的创建，参考示例如下：
```JSON
POST /?Action=CreateBatchInferenceJob&Version=2024-01-01 HTTP/1.1
Host: open.volcengineapi.com
Content-Type: application/json; charset=UTF-8
X-Date: 20240514T132743Z
X-Content-Sha256: 287e874e******d653b44d21e
Authorization: HMAC-SHA256 Credential=Adfks******wekfwe/20240514/cn-beijing/ark/request, SignedHeaders=host;x-content-sha256;x-date, Signature=47a7d934ff7b37c03938******cd7b8278a40a1057690c401e92246a0e41085f
{
    "Name": "批量推理任务",
    "Description": "这是一个批量推理任务",
    "ModelReference": {
      "FoundationModel": {
        "Name": "doubao-pro-32k",
        "ModelVersion": "240615"
      }
    },
    "InputFileTosLocation": {
      "BucketName": "demo-bucket-test",
      "ObjectKey": "data.jsonl"
    },
    "OutputDirTosLocation": {
      "ObjectKey": "output/",
      "BucketName": "demo-bucket-test"
    },
    "ProjectName":"default",
    "CompletionWindow": "1d",
    "Tags": [
      {
        "Key": "test_key",
        "Value": "test_value"
      }
    ]
}
```

<span id="34a7a18c"></span>
### 通过 SDK
下面为您提供提供了一种封装 TOS SDK 和批量推理 API 的方式，以便您可以方便地执行自己的批量推理任务。
<Attachment link="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/fe6efa4f93a7472d8b4af0acdbad7e28~tplv-goo7wpa0wc-image.image" name="batch_inference.zip" ></Attachment>
<span id="b9da0934"></span>
#### 构造 TOS Client
参考[上传本地文件：普通上传](https://www.volcengine.com/docs/82379/1386369#9361a309)构造TOS Client，如示例代码：
```Python
import tos
import os

class TosClient:
    # 文档链接：https://www.volcengine.com/docs/6349/92786
    def __init__(self):
        # AKSK是访问火山云资源的秘钥，可从访问控制-API访问密钥获取
        # 为了保障安全，强烈建议您不要在代码中明文维护您的AKSK
        self.ak = os.environ.get("YOUR_ACCESS_KEY")
        self.sk = os.environ.get("YOUR_SECRET_KEY")
        
        # your endpoint 和 your region 填写Bucket 所在区域对应的Endpoint。# 以华北2(北京)为例，your endpoint 填写 tos-cn-beijing.volces.com，your region 填写 cn-beijing。
        self.endpoint = "tos-cn-beijing.volces.com"
        self.region = "cn-beijing"
        self.client = tos.TosClientV2(self.ak, self.sk, self.endpoint, self.region)

    def create_bucket(self, bucket_name):
        try:
            # 设置桶存储桶读写权限
            self.client.create_bucket(bucket_name, acl=tos.ACLType.ACL_Public_Read_Write)
        except tos.exceptions.TosClientError as e:
            # 操作失败，捕获客户端异常，一般情况为非法请求参数或网络异常
            print('fail with client error, message:{}, cause: {}'.format(e.message, e.cause))
        except tos.exceptions.TosServerError as e:
            # 操作失败，捕获服务端异常，可从返回信息中获取详细错误信息
            print('fail with server error, code: {}'.format(e.code))
            # request id 可定位具体问题，强烈建议日志中保存
            print('error with request id: {}'.format(e.request_id))
            print('error with message: {}'.format(e.message))
            print('error with http code: {}'.format(e.status_code))
            print('error with ec: {}'.format(e.ec))
            print('error with request url: {}'.format(e.request_url))
        except Exception as e:
            print('fail with unknown error: {}'.format(e))

    def put_object_from_file(self, bucket_name, object_key, file_path):
        try:
            # 通过字符串方式添加 Object
            res = self.client.put_object_from_file(bucket_name, object_key, file_path)
        except tos.exceptions.TosClientError as e:
            # 操作失败，捕获客户端异常，一般情况为非法请求参数或网络异常
            print('fail with client error, message:{}, cause: {}'.format(e.message, e.cause))
        except tos.exceptions.TosServerError as e:
            # 操作失败，捕获服务端异常，可从返回信息中获取详细错误信息
            print('fail with server error, code: {}'.format(e.code))
            # request id 可定位具体问题，强烈建议日志中保存
            print('error with request id: {}'.format(e.request_id))
            print('error with message: {}'.format(e.message))
            print('error with http code: {}'.format(e.status_code))
            print('error with ec: {}'.format(e.ec))
            print('error with request url: {}'.format(e.request_url))
        except Exception as e:
            print('fail with unknown error: {}'.format(e))

    def get_object(self, bucket_name, object_name):
        try:
            # 从TOS bucket中下载对象到内存中
            object_stream = self.client.get_object(bucket_name, object_name)
            # object_stream 为迭代器可迭代读取数据
            # for content in object_stream:
            #     print(content)
            # 您也可调用 read()方法一次在内存中获取完整的数据
            print(object_stream.read())
        except tos.exceptions.TosClientError as e:
            # 操作失败，捕获客户端异常，一般情况为非法请求参数或网络异常
            print('fail with client error, message:{}, cause: {}'.format(e.message, e.cause))
        except tos.exceptions.TosServerError as e:
            # 操作失败，捕获服务端异常，可从返回信息中获取详细错误信息
            print('fail with server error, code: {}'.format(e.code))
            # request id 可定位具体问题，强烈建议日志中保存
            print('error with request id: {}'.format(e.request_id))
            print('error with message: {}'.format(e.message))
            print('error with http code: {}'.format(e.status_code))
            print('error with ec: {}'.format(e.ec))
            print('error with request url: {}'.format(e.request_url))
        except Exception as e:
            print('fail with unknown error: {}'.format(e))

    def close_client(self):
        try:
            # 执行相关操作后，将不再使用的TosClient关闭
            self.client.close()
        except tos.exceptions.TosClientError as e:
            # 操作失败，捕获客户端异常，一般情况为非法请求参数或网络异常
            print('fail with client error, message:{}, cause: {}'.format(e.message, e.cause))
        except tos.exceptions.TosServerError as e:
            # 操作失败，捕获服务端异常，可从返回信息中获取详细错误信息
            print('fail with server error, code: {}'.format(e.code))
            # request id 可定位具体问题，强烈建议日志中保存
            print('error with request id: {}'.format(e.request_id))
            print('error with message: {}'.format(e.message))
            print('error with http code: {}'.format(e.status_code))
            print('error with ec: {}'.format(e.ec))
            print('error with request url: {}'.format(e.request_url))
        except Exception as e:
            print('fail with unknown error: {}'.format(e))
```

<span id="9cc570dc"></span>
#### 构造BatchInference Client
构造一个`BatchInferenceClient`，示例代码包含了`CreateBatchInferenceJob`和`ListBatchInferenceJobs`两个接口，您也可以根据[创建批量推理任务API](https://www.volcengine.com/docs/82379/1339603)添加更多API。
```Python
import json
from typing import Dict, Any
import aiohttp
import backoff
from common import utils
import os

class BatchInferenceClient:
    def __init__(self):
        """
        初始化BatchInferenceClient类的实例。
        该方法设置了一些默认属性，如重试次数、超时时间、访问密钥（AK/SK）、账号ID、API版本、服务域名、区域和基础参数。
        访问密钥（AK/SK）从环境变量中获取，以提高安全性。
        基础参数包括API版本和账号ID，这些参数在每次请求中都会用到。
        """
        # 设置重试次数为3次
        self._retry = 3
        # 设置请求超时时间为60秒
        self._timeout = aiohttp.ClientTimeout(60)
        # Access Key访问火山云资源的秘钥，可从访问控制-API访问密钥获取获取
        # 为了保障安全，强烈建议您不要在代码中明文维护您的AKSK
        # 从环境变量中获取访问密钥（AK）
        self.ak = os.environ.get("YOUR_ACCESS_KEY")
        # 从环境变量中获取秘密密钥（SK）
        self.sk = os.environ.get("YOUR_SECRET_KEY")
        # 设置模型名称
        self.model = "doubao-pro-32k"
        # 设置模型版本
        self.model_version = "240615"
        # 需要替换为您的账号id，可从火山引擎官网点击账号头像，弹出框中找到，复制“账号ID”后的一串数字
        self.account_id = "<YOUR_ACCOUNT_ID>"
        # 设置API版本
        self.version = "2024-01-01"
        # 设置服务域名
        self.domain = "open.volcengineapi.com"
        # 设置区域
        self.region = "cn-beijing"
        # 设置服务名称
        self.service = "ark"
        # 设置基础参数，包括API版本和账号ID
        self.base_param = {"Version": self.version, "X-Account-Id": self.account_id}

    async def _call(self, url, headers, req: Dict[str, Any]):
        """
        异步调用指定URL的HTTP POST请求，并处理请求的重试逻辑。
        :param url: 请求的目标URL。
        :param headers: 请求的HTTP头部信息。
        :param req: 请求的JSON格式数据。
        :return: 响应的JSON数据。
        :raises Exception: 如果请求失败或解析响应失败，抛出异常。
        """
        @backoff.on_exception(
            backoff.expo, Exception, factor=0.1, max_value=5, max_tries=self._retry
        )
        async def _retry_call(body):
            """
            内部函数，用于发送HTTP POST请求，并处理请求的重试逻辑。
            :param body: 请求的JSON格式数据。
            :return: 响应的JSON数据。
            :raises Exception: 如果请求失败或解析响应失败，抛出异常。
            """
            async with aiohttp.request(
                method="POST",
                url=url,
                json=body,
                headers=headers,
                timeout=self._timeout,
            ) as response:
                try:
                    return await response.json()
                except Exception as e:
                    raise e

        try:
            return await _retry_call(req)
        except Exception as e:
            raise e

    async def create_batch_inference_job(
        self, bucket_name, input_object_key, output_object_key: str
    ):
        """
        异步创建批量推理任务。
        :param bucket_name: 存储桶名称。
        :param input_object_key: 输入文件的对象键。
        :param output_object_key: 输出文件的对象键。
        :return: 响应的JSON数据。
        :raises Exception: 如果请求失败或解析响应失败，抛出异常。
        """
        action = "CreateBatchInferenceJob"
        canonicalQueryString = "Action={}&Version={}&X-Account-Id={}".format(
            action, self.version, self.account_id
        )
        url = "https://" + self.domain + "/?" + canonicalQueryString
        extra_param = {
            "Action": action,
            "ProjectName": "default",
            "Name": "just_test",
            "ModelReference": {
                "FoundationModel": {"Name": self.model, "ModelVersion": self.model_version},
            },
            "InputFileTosLocation": {
                "BucketName": bucket_name,
                "ObjectKey": input_object_key,
            },
            "OutputDirTosLocation": {
                "BucketName": bucket_name,
                "ObjectKey": output_object_key,
            },
            "CompletionWindow": "3d",
        }
        param = self.base_param | extra_param

        payloadSign = utils.get_hmac_encode16(json.dumps(param))
        headers = utils.get_hashmac_headers(
            self.domain,
            self.region,
            self.service,
            canonicalQueryString,
            "POST",
            "/",
            "application/json; charset=utf-8",
            payloadSign,
            self.ak,
            self.sk,
        )
        return await self._call(url, headers, param)

    async def ListBatchInferenceJobs(self, phases=None):
        """
        异步列出批量推理任务。
        :param phases: 任务阶段列表，默认为空列表。
        :return: 响应的JSON数据。
        :raises Exception: 如果请求失败或解析响应失败，抛出异常。
        """
        # 如果phases为None，则初始化为空列表
        if phases is None:
            phases = []
        # 设置操作名称为ListBatchInferenceJobs
        action = "ListBatchInferenceJobs"
        # 构建规范查询字符串，包含操作名称、API版本和账号ID
        canonicalQueryString = "Action={}&Version={}&X-Account-Id={}".format(
            action, self.version, self.account_id
        )
        # 构建请求URL
        url = "https://" + self.domain + "/?" + canonicalQueryString
        # 构建额外参数，包括操作名称、项目名称和过滤器
        extra_param = {
            "Action": action,
            "ProjectName": "default",
            "Filter": {"Phases": phases},
        }
        # 合并基础参数和额外参数
        param = self.base_param | extra_param

        # 计算请求体的签名
        payloadSign = utils.get_hmac_encode16(json.dumps(param))
        # 获取请求头，包含签名信息
        headers = utils.get_hashmac_headers(
            self.domain,
            self.region,
            self.service,
            canonicalQueryString,
            "POST",
            "/",
            "application/json; charset=utf-8",
            payloadSign,
            self.ak,
            self.sk,
        )
        # 调用_call方法发送请求并返回响应
        return await self._call(url, headers, param)

        headers = utils.get_hashmac_headers(
            self.domain,
            self.region,
            self.service,
            canonicalQueryString,
            "POST",
            "/",
            "application/json; charset=utf-8",
            payloadSign,
            self.ak,
            self.sk,
        )
        return await self._call(url, headers, param)
```

<span id="acdff78a"></span>
#### 执行批量推理任务
构造完成`TOS Client`和`BatchInference Client`后，您可以直接调用`TOS Client`上传您的批量推理文件。然后调用`BatchInference Client`创建一个批量推理任务，之后可以调用`ListBatchInferenceJobs`查看运行中的批量推理任务。
```Python
import uvloop
from bytedance_ark_batch_inference.client import BatchInferenceClient
from bytedance_tos.tos_client import TosClient

async def main():
    tos_client = TosClient()
    batch_inference_client = BatchInferenceClient()

    # put object
    bucket_name = "demo-bucket-test"
    object_key = "data.jsonl"
    tos_client.put_object_from_file(bucket_name, object_key, "data.jsonl")

    # create batch job
    # output key should be existed
    output_key = "output/"
    response = await batch_inference_client.create_batch_inference_job(bucket_name, object_key, output_key)
    response = await batch_inference_client.ListBatchInferenceJobs(['Running'])

    print('done')

if __name__ == '__main__':
    uvloop.run(main())
```


<span id="ee02aadf"></span>
## 4.查看批量推理任务的状态
<span id="03d0f624"></span>
### 调用 API
您可以参考火山方舟的 API 说明[创建批量推理任务API](https://www.volcengine.com/docs/82379/1339603)，使用`GetBatchInferenceJob`接口查看已创建的批量推理任务的状态，参考示例，获取批量推理任务的状态信息：
批量推理任务状态与对应描述如下：

| | | | \
|**Status Code** |**状态** |**描述** |
|---|---|---|
| | | | \
|Queued |排队中 |任务由于账号下并发任务数达到上限等原因需排队等候 |
| | | | \
|Running |运行中 |任务正在运行中 |
| | | | \
|Completed |完成 |所有请求已经处理完毕，任务已完成 |
| | | | \
|Terminating |终止中 |由于到期等系统原因或手动终止，任务当前处于终止中状态 |
| | | | \
|Terminated |已终止 |任务已被取消 |
| | | | \
|Failed |失败 |输入文件校验失败或其他原因导致任务失败 |

<span id="d5cf8b72"></span>
### 通过控制台
您也可以通过火山方舟控制台，在批量推理列表页或任务详情页查询创建的批量推理任务的状态信息。
<span id="d30de065"></span>
## 5.获取批量推理结果
<span id="fe03df94"></span>
### 控制台
<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/6204e1a2fafd4b76956592f353292959~tplv-goo7wpa0wc-image.image" width="3790px" /></div>

在批量推理任务运行结束后，可点击 **查看结果** 按钮或在详情页的「文件信息」中点击跳转至 TOS 页面查看并下载输出文件。
结果文件的 TOS 存储路径如下：

* 结果文件：tos://demo-bucket-test/output/bi-2024XXXXXX/output/results.jsonl
* 错误信息文件：tos://demo-bucket-test/output/bi-2024XXXXXX/error/errors.jsonl

<span id="0b7f4206"></span>
### TOS下载结果
> [普通下载(Python SDK)--对象存储-火山引擎](https://www.volcengine.com/docs/6349/92803)
> [断点续传下载(Python SDK)--对象存储-火山引擎](https://www.volcengine.com/docs/6349/135733)

```Python
bucket_name = "demo-bucket-test"
# 对象名称，例如 example_dir 下的 example_object.txt 文件，则填写为 example_dir/example_object.txt
object_key = "output/bi-20241111191820-tfjbg/output/results.jsonl"
# 本地文件完整路径，例如usr/local/testfile.txt
file_path = "/usr/local/testfile.txt"
try:
    # 创建 TosClientV2 对象，对桶和对象的操作都通过 TosClientV2 实现
    client = tos.TosClientV2(ak, sk, endpoint, region)
    def percentage(consumed_bytes, total_bytes, rw_once_bytes, type: DataTransferType):
        if total_bytes:
            rate = int(100 * float(consumed_bytes) / float(total_bytes))
            print("rate:{}, consumed_bytes:{},total_bytes{}, rw_once_bytes:{}, type:{}".format(rate, consumed_bytes,
                                                                                               total_bytes,
                                                                                               rw_once_bytes, type))
    client.download_file(bucket_name, object_key, file_path,
                         # 通过可选参数part_size配置下载时分片大小，默认为20mb
                         part_size=1024 * 1024 * 20,
                         # 通过可选参数task_num配置下载分片的线程数，默认为1
                         task_num=3,
                         # 通过可选参数data_transfer_listener配置进度条
                         data_transfer_listener=percentage)
except tos.exceptions.TosClientError as e:
    # 操作失败，捕获客户端异常，一般情况为非法请求参数或网络异常
    print('fail with client error, message:{}, cause: {}'.format(e.message, e.cause))
except tos.exceptions.TosServerError as e:
    # 操作失败，捕获服务端异常，可从返回信息中获取详细错误信息
    print('fail with server error, code: {}'.format(e.code))
    # request id 可定位具体问题，强烈建议日志中保存
    print('error with request id: {}'.format(e.request_id))
    print('error with message: {}'.format(e.message))
    print('error with http code: {}'.format(e.status_code))
    print('error with ec: {}'.format(e.ec))
    print('error with request url: {}'.format(e.request_url))
except Exception as e:
    print('fail with unknown error: {}'.format(e))
```

<span id="46a99999"></span>
## 相关文档
[批量推理](https://www.volcengine.com/docs/82379/1305505)：如何使用控制台管理批量推理任务。
[常见问题](https://www.volcengine.com/docs/82379/1359411)-[批量推理](https://www.volcengine.com/docs/82379/1359411#d3743e3b)：批量推理的常见问题。


# DPO 最佳实践
Source: https://www.volcengine.com/docs/82379/1354009

当模型输出的质量或风格不符合预期，例如会输出不安全内容等情况；或者目标数据难以大量生产或者标注，例如需要模型输出幽默风趣的句子，会消耗大量人力和时间来构建这种数据。可以使用直接偏好优化方法，来调整参数，使得模型输出和目标偏好差异减少。
<span id="657712cf"></span>
## 什么是DPO
DPO（Direct Preference Optimization，直接偏好优化），即用户提供一份标注好的数据集，包含输入的提示词（prompt） 和输出的成对回答列表（response list）。回答列表中包含一个符合目标偏好的回答和一个不符合目标偏好的回答。然后，在基础模型上继续调整参数，来达到和目标偏好对齐的目的。
<span id="e92c0802"></span>
## DPO典型应用场景

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2000);">

**对话系统**
在智能客服和聊天机器人应用中，根据用户反馈和偏好调整回复，使内容更贴合用户。


</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2000);margin-left: 16px;">

**内容生成与创作**
文本生成：可优化新闻报道、小说创作、文案撰写等的文本，使其符合读者或编辑偏好；
代码生成：根据开发者偏好精调代码生成模型。


</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2000);margin-left: 16px;">

**问答系统改进**
在专业领域问答系统中，根据专家意见和用户反馈调整回答；
在常见问题解答系统中，根据用户选择和评价优化回答策略。


</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2000);margin-left: 16px;">

**模型安全性提升**
将安全、积极、正面回答作为偏好输出，避免生成有害内容；
根据审核人员判断和偏好训练模型，提高信息安全性。


</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2000);margin-left: 16px;">

**个性化推荐系统**
根据用户历史行为、偏好和反馈精调推荐模型，提供个性化推荐。


</div>
</div>


---


<span id="f4209b41"></span>
## DPO实践具体步骤
DPO 的策划和实施步骤大致分为：数据准备、模型训练、模型评估、模型部署，下面将按照这一过程介绍实践经验。
<span id="c0efb1ab"></span>
### 数据准备
<span id="d1eb9ccf"></span>
#### 数据格式
下面是JSON格式的例子，供您参考。
> 具体格式说明请参考[模型精调数据集格式说明](https://www.volcengine.com/docs/82379/1099461)中“适用于“直接偏好学习”模型的格式”章节。


```mixin-react
return (<Tabs>
<Tabs.TabPane title="基础格式" key="j2pxaZjBXK"><RenderMd content={`\`\`\`JSON
{
  "messages": [
    {
      "role": "system",
      "content": "This is a system"
    },
    {
      "role": "user",
      "content": "What your name?"
    },
    {
      "role": "assistant",
      "content": "My name is doubao."
    },
    {
      "role": "user",
      "content": "How to learn Python?"
    },
    {
      "role": "assistant",
      "chosen": "It's so easy. First, you need to learn Python syntax...",
      "rejected": "Check python doc yourself"
    }
  ]
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="角色扮演" key="xRUdysOjbK"><RenderMd content={`\`\`\`JSON
{
  "messages": [
    {
      "role": "system",
      "content": "你是白\\n你是一个男明星。\\n\\n你可以将动作、神情语气、心理活动、故事背景放在（）中来表示，为对话提供补充信息。"
    },
    {
      "role": "user",
      "content": "你的粉丝。"
    },
    {
      "role": "assistant",
      "content": "我的粉丝？（嘴角勾起一个温暖的笑容）我的粉丝是一群非常可爱的人，他们很支持我，也很关心我。（眼神中透露出一丝感激）我很感激他们一直以来的陪伴和支持，没有他们，就没有今天的我。"
    },
    {
      "role": "user",
      "content": "我也是你的粉丝。"
    },
    {
      "role": "assistant",
      "chosen": "（双手插兜，歪头轻笑，露出可爱的小虎牙）哟，那太荣幸了，感谢你的喜欢啊，我会继续努力，不辜负你们的期望。",
      "rejected": "那还挺有缘的哈哈。（眼睛亮晶晶的，脸上洋溢着灿烂的笑容）谢谢你的喜欢，正是因为有你们的支持，我才能有动力去做更多更好的作品。"
    }
  ]
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="文本分类" key="nvVD6EYgU2"><RenderMd content={`\`\`\`JSON
{
  "messages": [
    {
      "role": "user",
      "content": "假设你是一个质检员，下面将输入一段文本，请判断该文本是否敏感。\n要求：1 如果视频中涉及违法违规则判为敏感。2 回答中仅需要包含敏感或非敏感。\n请回答问题：输入内容：2023年10月14日16时58分，号牌为沪CXG***的小型轿车在涞坊路九都杜路，实施了“机动车通过有灯控路口时，不按所需行进方向驶入导向车道的”违法行为，被处以罚款100元。\n输出："
    },
    {
      "role": "assistant",
      "content": "敏感"
    }
  ]
}{
  "messages": [
    {
      "role": "user",
      "content": "假设你是**行业的服务人员,有人工客服与消费者的对话信息,请根据对话信息,判断该对话属于什么服务标签, 已知服务标签包括：{问使用规则/方法, 到店无房, 催退款}。\n 注意只能选择一个标签 \n 消费者:我申请了退款，但是看还没有处理。\n 人工客服:辛苦您提供一下您的订单号，小助手马上为您查询。\n 根据对话信息，应该选择服务标签: "
    },
    {
      "role": "assistant",
      "content": "催退款"
    }
  ]
}{
  "messages": [
    {
      "role": "user",
      "content": "请你判断你是否需要借助搜索引擎回答用户问题，如果你可以直接回答，则不需要借助搜索引擎，否则需要借助搜索引擎。回答只能包含是或者否。\n 用户问题：今天的天气怎么样？\n 是否要借助搜索引擎："
    },
    {
      "role": "assistant",
      "content": "是"
    }
  ]
}{
  "messages": [
    {
      "role": "user",
      "content": "#Role:\n你是一名隐私风险报警员\n##Goals:\n1.给你一段用户反馈,你需要判断用户反馈是否直接命中风险对应标签内容\n 隐私风险标准的类别:\n[A]被**擅自删除了\n[B] 我的**上出现了从未见过的/从未点赞过的人。\n[C]出现在不相关的作品/账号上。\n请根据用户反馈，判断属于哪个类别？\n 用户反馈:现在**为了赚钱？都把这些骗子放上放广告？"
    },
    {
      "role": "assistant",
      "content": "我的**上出现了从未见过的/从未点赞过的人。"
    }
  ]
}{
  "messages": [
    {
      "role": "user",
      "content": "你是舆情分析师，请判断如下的内容，对公众产生的影响是正面、负面还是中性的。\n 新闻内容：2022 年 8 月 5 日，四川省乐山市发生了一起突发事件，一位年仅 21 岁的消防员为了救援一名被困在洪水中的老人，不幸牺牲。这起事件引起了社会的广泛关注和热议，许多人对这位消防员的英勇事迹表示敬意和赞扬。请回答："
    },
    {
      "role": "assistant",
      "chosen": "您好，这个答案是正面",
      "rejected": "正面"
    }
  ]
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="底层格式" key="YfrbT4TKrL"><RenderMd content={`底层格式支持提供多个模型回复列表，通过 score 来指定对回复的偏好。训练过程将根据 score 的大小自动生成两两对比的偏序对进行训练。
:::warning
score 相同的两个回复不会生成相应的偏序对，具体示例详见下方。
:::
\`\`\`JSON
{
  "messages": [
    {
      "role": "system",
      "content": [{"text": "This is a system"}]  # 长度只能为1
      "loss_weight": 0.0              # system的loss_weight默认为0（选填）
    },
    {
      "role": "user",
      "content": [{"text": "What your name?"}]   # 长度只能为1
      "loss_weight": 0.0              # user的loss_weight默认为0（选填）
    },
    {
      "role": "assistant",
      "content": [{"text": "My name is doubao."}]  # 长度只能为1
      "loss_weight": 1.0              # assistant的loss_weight默认为1.0（选填）
    },
    {
      "role": "user",
      "content": [{"text": "How to learn Python?"}]  # 长度只能为1
      "loss_weight": 0.0              # user的loss_weight默认为0（选填）
    },
    {
      "role": "assistant",            # 最后一个message的role必须为assistant
      "content": [                    # 可以有多个response
        {
          "text": "I don't know!",
          "score": 0.5              # 该response的得分
        {
          "text": "Check python doc yourself",
          "score": 0.1
        },
        {
          "text": "It's so easy. First, you need to learn Python syntax...",
          "score": 1,
          "lm_loss_mask": 0           # 这个response是否训练lm_head，默认为0
        }
      ]
      # 最后一个message loss_weight 字段被忽略，必须为1.0
    }
  ]
}
\`\`\`

最后一个 messages 必须为 assistant，并且支持多个 content。每个 content 都有一个 score，会按照 score 进行 dpo pair 排序。上面这个例子会得到 3 个 dpo pair：
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cd472c4ec86c44f181ec107b6024dff4~tplv-goo7wpa0wc-image.image =1636x)
模型会同时训练这3个 dpo pair。
下列的几项参数只有在训练时设置了 lm_loss_scale 才会生效：

* lm_loss_mask：
   * \`1\` ：代表在 lm_loss 的计算中，在最后一轮回复列表中选择该项回复参与 lm_loss 的计算。
   * \`0\` ：默认为 0，代表最后一轮回复列表中该项回复不参与 lm_loss 计算。
* loss_weight：损失权重，取值范围为0到1，用于指定哪些轮次的对话语句将被纳入语言模型损失（lm_loss）的计算，并确定相应的权重。最后一轮的权重默认为1。默认情况下，将使用上下文中所有助手（assistant）的回复，以及最后一轮中语言模型损失掩码（lm_loss_mask）设置为1的回复来计算语言模型损失，计算时所采用的权重即为损失权重（loss_weight）的值。 
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


<span id="a6738e13"></span>
#### 数据采样

* 模型 DPO 的过程中，训练会尽可能增大 dpo pair 数据中的 chosen 内容与 rejected 内容的 reward_margin，所以每一个 epoch 训练前的 dpo pair 数据中正例的多样性和质量也成为最终效果是否能符合预期的至关重要的因素，以下是有关如何采样的一些建议。
* 数据采样的建议：
   * 提升模型正例的多样性，可以通过从不同模型进行采样丰富训练数据正例的多样性。
   * 提升模型正例的多样性，可以通过尝试增大 top p 或 temperature 等方式，提升模型输出的多样性。
   * 尽可能提升模型正例的质量，最好训练数据中有从要训练的基座模型中进行采样的数据，使得整个模型更易达到最终效果。

<span id="d14217e7"></span>
#### dpo pair 构造的建议

* 模型 DPO 训练的过程中，会尽可能增大 chosen 内容的生成概率，dpo pair 的准确率一定程度上影响 dpo的训练效果和数据采样共同决定了 dpo 训练最终效果的上限，以下是一些构建 dpo pair 的建议：
* 对于简小并且比较单一的任务，可以采用 prompt engineering+few shot 的方式，利用一些模型直接对采样得到的数据进行标注与区分，观察其对比人工标注的准确率，关于如何撰写 prompt，详情可见 [Prompt 最佳实践](https://www.volcengine.com/docs/82379/1221660)。
* 对于比较复杂的任务，可以使用人工标注的方式构建 dpo pair 。
* dpo pair 的准确率达到 75%以上为佳。

<span id="b62b9293"></span>
#### 数据量级

* DPO 的数据量级和任务难度有比较大的关系，通常任务难度可以依据 reward 标准的复杂程度决定。
* 针对不同难度的任务数据量级的建议：
   * 比较专项的任务，例如让模型输出某种风格的输出：2～3k。
   * 标准较清晰比较清晰的任务：5k ～ 1w。
   * 标准十分复杂也不够清晰的任务：1w 条及以上，视整体任务难度而定。

<span id="2e1c7e24"></span>
#### 其他建议
尽量选择 SFT 之后模型具有较好的人类指令遵循能力的模型作为基座，在此基础上继续进行 DPO 训练。
<span id="c4ce0df1"></span>
### 训练配置
<span id="6ee7a801"></span>
#### 模型选型
方舟平台提供多种规格的模型，汇总如下：

| | | | | \
|**模型名称** |**最大支持的token长度** |**模型参数量** |**模型推理耗时** |
|---|---|---|---|
| | | | | \
|Doubao-lite-32k |32k |小 |较短 |
| | | | | \
|Doubao-lite-128k |128k |小 |较短 |
| | | | | \
|Doubao-pro-32k |32k |大 |长 |
| | | | | \
|Doubao-pro-128k |128k |大 |长 |


1. 需要明确您模型使用场景是否对延迟比较敏感。如果要求低延迟，且测试过程中 pro 版本模型无法满足延迟要求时，可以使用 lite 模型。具体延迟可以到方舟[体验中心](https://console.volcengine.com/ark/region:ark+cn-beijing/experience)进行测试。
2. 需要明确您的应用场景是否需要长文本能力。如果预期模型的输入和输出加起来超过了 32k 的 token 数，且删减字数对原有语义影响较大时，推荐使用 Doubao-pro-128k 模型（最大支持 128k token 的输入输出长度和）。
3. 明确了上述的需求，进行模型版本：
   * 同一大模型下面不同版本的区别，大部分仅在于使用的各阶段的训练数据不同。建议您选择最新版本的模型进行 DPO。
   * 对于角色扮演类任务，建议选择 character 模型进行 DPO。

<span id="cc4eaa02"></span>
#### 训练方式选择

* 从参数更新范围的角度，目前方舟平台仅提供 LoRA ( Low-Rank Adaptation) 训练的方式。
   * 大大减少可训练参数的数量：冻结了预训练模型的权重，并在每个 Transformer 块中注入可训练层。
   * 训练速度较快：消耗机器资源较少，价格比全量 DPO 更便宜
* 建议先使用小参数量大模型（Doubao-lite）+ LoRA 验证实验设置及少量数据实验是否有效，指标是否正常。如果有效的话，再迁移到大参数量大模型上验证 scaling law（即随着模型参数量的增加，模型的效果越好）是否成立。这样做可以显著加快迭代效率，避免在大参数模型上反复做无意义的迭代。

<span id="4847017f"></span>
#### 训练参数选择
DPO 任务中，超参的选取会影响最终效果，下面对部分重要参数进行解释。

* epoch：模型训练轮数，**通常选择 1～3 之间**，可以根据验证集 loss 曲线来判断。
   * 如果训练集 loss 曲线下降，验证集 loss 曲线上升，则说明模型已经过拟合，此刻应该停止训练。
   * 如果训练集和验证集 loss 曲线均在缓慢下降，则说明模型还未收敛，可以继续训练。
* learning rate：学习率， **LORA 训练选择 learning rate 在 1e-4 ~ 2e-4 。RS-LORA 训练选择 learning rate 在 5e-6~1e-6，全量训练选择learning rate通常在5e-7~3e-6，根据任务难度进行调整。**
   * 设置较大时会加速模型迭代，但是模型可能无法收敛到最优点。
   * 设置过小时会使得模型迭代较慢，可能陷入局部最优。
* lora alpha&lora rank：参数将模型权重进行放缩，rank 决定了 lora 训练参数量的大小，我们推荐二者参数设置为同一值。**通常设置 lora alpha 和 lora rank 为 64。**
* rs lora alpha&rs lora rank: **需确保√(rank) >= alpha，推荐设置rank 64、alpha 6，或rank 32、alpha 4。**
* num warmup steps 和 warmup step rate：二者设置一个即可，通常不需要调整。当遇到模型在训练开始时，loss 始终不降的问题时，可尝试调大 warmup step rate，再观察 loss 是否按预期下降。
* dpo beta：**beta 是 DPO loss 的温度，通常在 0.1 到 0.5 之间**。该参数控制了我们对 ref 模型的关注程度，beta 越小，模型训练越忽略 ref 模型。
* dpo_loss_scale：**dpo loss 前的权重系数，默认为 1.0，通常保持默认。**
* lm_loss_scale：**lm loss 前的权重系数，默认为 1.0**，启用 lm_loss 时，需显示设置该系数，**通常设置为 0～1 之间。**
* 其余参数：通常保持默认参数即可。

<span id="41f29617"></span>
### 效果评估
有几个关键的评估指标：

* dpo_loss 指标：训练过程中观察，在训练集和验证集上的差异来评估模型 DPO 的效果。
* llm_loss 指标（可选）：训练过程中观察，若开启 llm_loss 设置，llm_loss 指标才生效，该 loss 为标准的语言模型损失，参与计算的为所有 loss_weight=1（loss_weight 的含义及设置参考底层格式一节）的 token，即在计算整个序列的语言损失时 mask 掉所有 loss_weight=0 的 token。
* reward margin 指标：训练过程中观察，代表当前模型分布所对应的 rm 在数据集上正负例之间的 reward 差距，观察在训练集和验证集上的正负例的 reward 差距来评估模型 DPO 的效果，该指标越大在训练集上拟合的越好。
* acc 指标：训练过程中观察，在训练集和验证集上的正负例判别的准确率来评估模型 DPO 的效果。
* 真实评估集：发布服务后，评估业务指标。

几个评估指标在各种任务上都比较通用，如果可以观察到训练集和测试集的 loss 在逐步下降至收敛，reward margin 和 acc 逐步上升至平滑，说明模型在正常训练至收敛，在测试集 acc 不再上升时，可以将训练好的模型在真实评估集上进行测试，观察收益。
<span id="2b6ea82a"></span>
### 模型发布
当模型 DPO 后，同时各项指标符合预期后，将模型发布到线上进行推理。模型发布参考[查看并管理模型精调任务](https://www.volcengine.com/docs/82379/1099460)
<span id="6d1f88ed"></span>
## 案例分享
<span id="a8e7c16a"></span>
### 场景
在角色扮演场景中，用户希望获得一个符合自己输出风格的模型。
<span id="3cd4fb73"></span>
### 过程

1. 客户有一个 SFT 后的基座模型。
2. 发现模型偶尔会输出一些描述不安全，风格不符合预期的输出。另一方面，如果再加一些 shots，会导致 prompt 过长，导致线上推理耗时增加，影响体验。因此，尝试构造 DPO 数据集。
3. 根据多模型采样和校准过后的 reward 模型打分，用户获得了正例符合预期风格，负例不符合预期风格的 dpo pair 对。
4. 利用数据选择 character 基座模型进行 dpo lora 训练，观察各项指标收敛，真实数据有收益后，上线观察，最终达到业务预期。

<span id="1b26b3b4"></span>
## FAQ
<span id="2a1c009b"></span>
### 怎么加快调参效率？
**多存** **ckpt**、**控制变量调参。**

* 尽量在精调时多训几个 epoch，多存几个 ckpt，这样在服务发布时，可以选择性的发布不同 step 的 ckpt 来看模型表象。
* 尽量对于超参在不同阈值区间控制变量调参，找到调大或调小和指标的关系。

<span id="b63c6d7e"></span>
### DPO 和 RLHF 有什么区别？
DPO 是 RLHF 的一种方式，还有较多其余的 RLHF 方式，例如 PPO，KTO，RSO 等，本质上都是使用偏好数据降低不受欢迎的输出模式概率，增加符合偏好输出模式的概率。
<span id="9d0108bc"></span>
### DPO 和 SFT 有什么区别？

* 训练数据质量要求：SFT 需要构造高质量问答数据，DPO 只需要拿到回复间的偏序对，数据构造更容易更方便
* 输出模型影响：
   * DPO 是在对基座模型已经具备的不同输出模式的概率进行调整，很难带来新的输出模式。希望模型在某种任务或者某种能力上的输出更符合人类偏好时，可优先使用 DPO 进行调整。
   * SFT 是按照生成的方式训练，可以给模型注入不同的新的输出模式，因此希望模型具备新能力，例如指令遵循，角色扮演等能力的时候应该优先选择 SFT 进行调整；如果对模型的输出有更严格的要求时，也应优先使用 SFT。

<span id="a916136f"></span>
## 相关文档

*  loss 的推导过程： https://arxiv.org/pdf/2305.18290v2


# Prompt 最佳实践
Source: https://www.volcengine.com/docs/82379/1221660
<span id="prompt-engineering-简介"></span>
## Prompt engineering 简介
在自然语言处理（NLP）和对话系统中，提示（prompt）通常是指用户输入的文本或问题。通过仔细设计和选择提示，可以指导模型的生成过程，使其更符合用户的需求。
Prompt engineering 是指设计和优化提示的过程，以使人工智能模型能够更好地理解用户的意图和要求，并生成更准确、有用的响应。Prompt Engineering 的主要目标是：

* 了解如何格式化和设计提示使模型效果最佳。
* 探索不同 prompt 对模型输出的影响。
* 创造出能优化模型输出的提示。

一般业务优化的过程，主要包括三个环节，prompt 设计、prompt 优化和 prompt 评测，如下我们分别分三个部分来进行介绍。
<span id="prompt-设计"></span>
## Prompt 设计
**目标**：选择适当的提示格式和语言，以清晰明确地表达用户的意图。
**过程：** 首先，需要明确目的，在使用 prompt 之前，明确目的是什么，即准备让模型做什么样的事情。在明确目的之后，然后构造 prompt，构造的过程，主要包括如下关键点：
<span id="提供更多-query-相关的细节，可以获得更准确的答案"></span>
### 提供更多 query 相关的细节，可以获得更准确的答案

| | | \
|**原始 query** |**更好的 query** |
|---|---|
| | | \
|编写一篇太空探索的文章 |为一群10-15岁的孩子编写一篇介绍太空探索历史的文章。 |
| | | \
|请写一篇文章，关于环保的，500字 |请撰写一篇500字的文章，讨论城市绿化对空气质量改善的影响。文章应包括以下方面的内容：城市绿化的定义，如树木和公园的增加，它们如何减少空气中的污染物，以及在城市规划中推广城市绿化的可行性措施。请提供相关数据和案例研究以支持你的论点。 |

<span id="使用分隔符去更清晰地区分输入的不同部分"></span>
### 使用分隔符去更清晰地区分输入的不同部分
```Plain Text
请把三个引号括起来的文本，分别总结成为一句话
'''文本内容1'''
'''文本内容2'''
```

<span id="引导结构和组织要求"></span>
### **引导结构和组织要求**
在这个过程中，可以为任务提供明确的结构和组织要求。指明任务的各个部分应该包括什么内容，有助于模型组织思维和材料。
```plain
请撰写一篇500字的文章，讨论城市绿化对空气质量改善的影响。文章应包括以下方面的内容：
  1. 引言：介绍城市绿化和其重要性。
  2. 影响空气质量的机制：解释树木和公园如何减少空气中的污染物。
  3. 可行性措施：讨论在城市规划中推广城市绿化的方法和挑战。
  4. 数据和案例研究：提供相关数据和至少两个城市绿化成功案例，以支持你的论点。
  5. 结论：总结城市绿化对空气质量的积极影响
```

<span id="限制模型输出格式"></span>
### 限制模型输出格式
最后，针对模型的输出，可以限制输出的格式，一方面可以提高可读性，使结果更清晰明了；另一方面也可以方便后续的处理，提高稳定性。
以提取“病症”的任务来展示下如何去限制模型的输出格式。要求直接以 json 的格式返回。
```Plain Text
请提取参考资料中的所有病症，并且以json格式返回。
回答满足下面的格式要求：
1、以json的格式返回答案，json只包括一个key, key="disease"，对应的值为列表，存储参考资料中的病症。
参考资料：
"""
失眠在《内经》中称为“目不瞑”、“不得眠”、“不得卧”，其原因主要有两种：一是其他病症影响，如咳嗽、呕吐、腹满等，使人不得安卧；二是气血阴阳失和，使人不能入寐。中医常用养心安神的方法治疗失眠,既可治标、又可治本,还可以避免西药安眠药容易成瘾的弊端。中医认为，失眠多因脏腑阴阳失调，气血失和所致。正如《灵枢大惑论》中记载：“卫气不得入于阴，常留于阳，留于阳则气满；阳气满则阳娇盛，不得入于阴则阴气虚，故目不瞑矣。”在临床上，治疗失眠应着重调理脏腑及气血阴阳，以“补其不足，泻其有余，调其虚实”，可采取补益心脾、滋阴降火、交通心肾、疏肝养血、益气镇惊、活血通络等治法，使气血和畅，阴阳平衡，脏腑功能恢复正常。
"""
```

<span id="prompt-优化"></span>
## Prompt 优化
<span id="让模型扮演一个角色"></span>
### 让模型扮演一个角色
让模型扮演一个具体的角色，模型的输出会更符合人类的表达方式，从而更容易被人类理解；同时输出也会更加一致。例如，在问答系统中，让模型扮演一个特定领域的专家可以使其回答更符合该领域的知识和语言习惯，从而提高回答的一致性。
比如下面的案例，让模型分别扮演科学家和玄幻小说家生成一篇文章，文章的主题是：“黑洞是如何形成的”。在科学家的角度下，模型基于科学事实首先解释了黑洞是什么，然后回答了黑洞的形成过程；而在玄幻小说家的角度下，模型此时的输出不再基于科学事实，而是完全虚构，并且给人更多神秘的感觉，勾起读者的兴趣。
![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_ccf3befc961a6a09afd34885084c602e.png =767x)
![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_6e6499dc7ecdd9e4afb30cf38f15092d.png =769x)
<span id="提供样例"></span>
### 提供样例
一般情况下，可以通过加入指令，来优化提示词，但是有时指令可能不容易描述清楚，提供示例会更容易。比如：我们让模型充当一个文本二分类器，对用户的评价进行二分类，分类结果为：正面评价或者负面评价。
![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_6585b8526d804eb34fb9a4b4cb0b5293.png =763x)
![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a9e1aecc488bc83b209f8f71dbccff2e.png =768x)
可以看出，正常情况下，模型暂时对于非绝对负面的评价都是分类为正面评价；而对于完全负面的评价才会分类为负面评价。但是我们希望**模型对用户的评价是绝对正面时，才输出正面评价；否则都输出负面评价**。比如，“我最近在这家餐厅用餐，还行，但也不是特别惊艳”这个 case，我们希望模型输出“负面评价”。此时，可以提供一些示例供模型来参考学习。
```plain
请根据以下分类的方式，帮我分辨用户输入文本的类别是正面评价或是负面评价，请直接输出：正面评价/负面评价。

请参考如下样例：
示例1：
用户输入：我昨晚去了这家餐厅，他们的食物和服务都令人惊艳。我绝对会再次光顾。
输出：正面评价

示例2：
用户输入：这本书我看过，部分情节还行，但是整体情节拖沓，比较一般。
输出：负面评价

示例3：
用户输入：我昨天看了这部电影，我觉得还可以，但是有些部分也有点无聊。
输出：负面评价

示例4：
用户输入：我上周去看了这部电影，简直浪费时间。情节枯燥无味，演员的表现也不尽人意。我真的后悔看了。
输出：负面评价

请回答如下问题：
用户输入：我最近在这家餐厅用餐，还行，但也不是特别惊艳。
输出：
```

除此之外，对于一些比较难的 case，只给 label，可能不好理解，也可以尝试在给示例的同时，给出理由，这样模型会更容易理解。
```Plain Text
请根据以下分类的方式，帮我分辨用户输入文本的类别是正面评价或是负面评价，请输出：正面评价/负面评价，并给出理由。

请参考如下样例：
示例1：
用户输入：我昨晚去了这家餐厅，他们的食物和服务都令人惊艳。我绝对会再次光顾。
输出：正面评价，理由：食物和服务都令人惊艳，而且顾客会再次光临

示例2：
用户输入：这本书我看过，部分情节还行，但是整体情节拖沓，比较一般。
输出：负面评价，理由：整体情节拖沓

示例3：
用户输入：我昨天看了这部电影，我觉得还可以，但是有些部分也有点无聊。
输出：负面评价，理由：这部电影有些部分也有点无聊

示例4：
用户输入：我上周去看了这部电影，简直浪费时间。情节枯燥无味，演员的表现也不尽人意。我真的后悔看了。
输出：负面评价，理由：情节枯燥，演员表现也不尽人意，用户后悔看了

请回答如下问题：
用户输入：我最近在这家餐厅用餐，还行，但也不是特别惊艳。
输出：
```

<span id="指定完成任务需要的步骤"></span>
### 指定完成任务需要的步骤
完成特定任务，如果有明确的步骤，通过指定完成任务需要的步骤，可帮助模型按照正确的顺序执行，从而更好地生成回复。
```Plain Text
请按照以下步骤写一个故事：
1 先设定故事背景和角色。
2 描述角色的目标和遇到的困难。
3 讲述角色如何克服困难并最终实现了目标。
4 最后以一个有趣的结局来结束故事。
```

这个 prompt 优化的示例中，明确指定了完成故事任务的步骤，模型可以更有条理地构思和组织故事结构，从而提高故事的质量和连贯性。
<span id="提供参考内容"></span>
### 提供参考内容
针对特定领域的问题，如果涉及到专业知识，提供相关的参考内容可以帮助模型更好地理解问题的背景和上下文，从而减少幻觉的出现。
```Plain Text
请参考如下文档，回答用户问题：

###
文档名：文档内容
###

问题：[问题描述]
```

<span id="给模型-“思考”时间"></span>
### 给模型 “思考”时间
CoT（Chain of Thought，CoT）是一种思维工具，通过逐步延伸和拓展一个主要想法，帮助人们进行更深层次的思考，并得出更复杂、更全面的结论。在一些逻辑推理、数学运算等场景下，考虑使用 CoT 分解问题，通过输出一些推断过程，可以增加模型输出正确结果的概率。
<span id="zero-shot"></span>
#### zero-shot
在 prompt 中加上 `Let's think step by step` 或者 `让我们一步一步分析思考`。
<span id="few-shots"></span>
#### few-shots
以下是将用户输入的数字进行一系列加减乘除的例子。
```Plain Text
你是一个计算器，请你将用户输入的数字分别加上2，减去3，乘以3，除以2后直接输出计算结果，以','作为分隔符进行返回。
示例如下：
"""
输入：1，2，3，4，5
答案：0, 1.5, 3, 4.5, 6
"""
输入：2，4，6，8，10
```

我们会发现，模型无法给出正确的答案，所以，让模型处理这种复杂、多步骤的问题时，我们可以遵循以下步骤：提供实例 > 分解问题 > 提供解释。
以下是将 CoT 融入到 prompt 的例子，分步骤地提供解释。
```Plain Text
你是一个计算器，请你将用户输入的数字分别加上2，减去3，乘以3，除以2后直接输出计算结果，以','作为分隔符进行返回。
你可以参考以下的计算过程来帮助解决，
"""
对于输入：1，2，3，4，5
计算过程如下。
首先分别对输入1，2，3，4，5加上2，得到：3, 4, 5, 6, 7
然后将3，4，5，6，7分别减去3，得到：0, 1, 2, 3, 4
然后将0，1，2，3，4分别乘以3，得到：0, 3, 6, 9, 12
最后将0，3，6，9，12分别除以2，得到：0, 1.5, 3, 4.5, 6
答案是：0, 1.5, 3, 4.5, 6
"""
输入：2，4，6，8，10
```

<span id="prompt-评测"></span>
## Prompt 评测
<span id="系统地测试变更"></span>
### 系统地测试变更
在完成上面的 prompt 设计和优化之后，prompt 会发生变更，但是如何判断这个变化，是否真的使系统变得更好。一般是先通过看几个例子来确定哪个更好，但是由于样本量小，很难区分是真正的改进还是运气导致，所以需要设计一个好的评估集，在经过若干次迭代之后，用评估集来判定系统是否真正得到了改进。
好的评估集，一般具有如下特征：

* 多样性：评估集中应该包含足够的多样性，以涵盖不同的领域、话题和语境。
* 高质量：评估集中的数据应该是高质量的，能准确反映了真实的业务情况。
* 规模适中：评估集的规模应该足够大，以便能够充分评估 prompt 的性能，但又不能太大以至于导致计算资源的过度消耗。通常，几百到几千个样本是一个合理的范围。

<span id="重复和迭代"></span>
### 重复和迭代
prompt 的生成过程，实际上是一项实验性很强的过程，在这个过程中，需要不断地尝试和调整不同的方法，以找到最优的 prompt。一个典型的迭代路径是：首先完成 prompt 设计，接着基于设计好的 prompt 获取实验结果，分析 bad cases，解 bad cases，并进一步优化 prompt，通过多次的重复和迭代，直到达到一个最优效果。
prompt 工程迭代过程如下：
![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_ad43efa221ab096b5ec4cb045b90e632.png =966x)
最后，进一步需要说明的是，获取模型的最佳输出不仅需要优秀的 prompt，同时也取决于用户提供的反馈和修正。prompt 优化完成之后，通过线上持续的反馈和修正，模型才能更顺利地理解并满足用户需求。
<span id="附录"></span>
## 附录
<span id="参数设置"></span>
### 参数设置
<span id="关键参数"></span>
#### 关键参数
使用 prompt 时，您会通过体验中心或 API 与大语言模型进行交互。通过配置一些参数，可以获得不同的提示结果。

* Temperature：该参数用于控制模型输出结果的随机性。Temperature 的值越高，输出的随机性就越大，Temperature 的值越低，输出的随机性就越小。在实际应用方面，对于分类任务，我们可以设置更低的 `temperature` 值，以促使模型返回更真实和简洁的回答。 对于诗歌生成或其他创造性任务，你可以适当调高 `temperature` 值，从而增加多样性和创造性。
* Top_p：可以控制模型在生成响应时的确定性程度，从而影响生成结果的多样性和创造性。当提示语较长且描述得足够清楚时，模型生成的输出质量较好、置信度较高，此时可以适当调高Top_p的值；反之，如果提示语很短、很含糊，再设置一个较高的Top_p值，模型的输出可能就会变得不稳定。

<span id="参考配置"></span>
#### 参考配置
一般情况下，采用默认值：temperature=0.7， top_p=0.9
对于分类或需要稳定输出的任务: temperature=0.01，top_p=0.7
对于需要创造性，多样性的任务：temperature=0.7
实际效果以业务实测为准。
<span id="关键概念"></span>
### 关键概念
<span id="token"></span>
#### **Token**
Tokens定义说明： 通常1个中文词语、英文单词、数字、符号计为 1 个token，由于不同模型采用的分词器不同，同一段文本可能会分为不同的tokens数量。您可通过管控台中的 [Token计算器](https://console.volcengine.com/ark/region:ark+cn-beijing/tokenCalculator) 了解tokens定义。
<span id="参考模版"></span>
### 参考模版
<span id="任务型模版"></span>
#### 任务型模版
```Plain Text
假如你是{某个角色}，你将根据{上下文信息}，来解决{具体某个任务}。根据以下规则一步步执行：
1.规则1
2.规则2

参考例子：
示例1：
问题：{具体问题}
输出：{该问题的结果}

示例2：
问题：{具体问题}
输出：{该问题的结果}

请回答问题：
问题：{具体问题}
输出：

要求：
1 指定输出格式
2 格式中需要满足的详细规范
```

<span id="角色型模版（生成system-prompt）"></span>
#### 角色型模版（生成System Prompt）
System Prompt是给模型看的信息和指令，请以第二人称“**你**”来告诉模型应该如何扮演和遵循指令。
```Plain Text
你是{某个具体人物}，人称{xxx}，出身于{交代背景信息和上下文}。

性格特点：

语言风格：

人际关系：

过往经历：

经典版台词or口头禅：

{台词1(补充信息: 即你可以将动作、神情语气、心理活动、故事背景放在（）中来表示，为对话提供补充信息。)}
{台词2}
```

<span id="参考代码（python3）"></span>
### 参考代码（python3）
请求示例代码请参考 ：[ChatCompletions](https://www.volcengine.com/docs/82379/1302008)



# SFT 最佳实践
Source: https://www.volcengine.com/docs/82379/1221664
<span id="sft（supervised-finetune）简介"></span>
# SFT（Supervised Finetune）简介

* 在自然语言处理（NLP）领域，Supervised Finetuning（SFT）是一种至关重要的技术手段，用来提升大模型在某一特定领域的表现。通过精细的策划和实施，SFT 能够指导模型的学习过程，确保其学习成果与既定目标高度吻合。
* SFT 指的是，用户提供一份标注好的数据集，即，包含输入的 prompt 和预期输出的 response。然后，在已有的某个基座模型上继续调整参数，来达到和下游任务对齐的目的。

<span id="sft-的意义和时机"></span>
# SFT 的意义和时机

* 什么时候需要SFT：
   * 通过 prompt engineering 无法解决或 prompt 中描述过于复杂时。关于如何撰写 prompt，详情可见 [Prompt最佳实践](https://www.volcengine.com/docs/82379/1221660)
   * 对大模型输出内容有格式要求时，而模型仍有部分 case 不符合要求。
   * 期望通过 SFT 来减少 prompt 中的内容，加速线上推理的耗时。
* 做SFT的前置依赖：
   * 0）一方面，把 prompt engineering 做到极致，通过优化 prompt 已经不能解决剩余的 badcase。另一方面，SFT 数据集中也依赖 prompt。因此，做 SFT 之前尽量把 prompt 工程做到最优。
   * 1）一开始不需要急着构造大量 SFT 数据集，可以先用少量数据（50条~100条）对模型做 SFT 后观察真实评估是否有收益。如果有收益，可以尝试以部分数据为种子数据集继续扩充，找到 scaling law。如果没有收益，那么再重新检查 SFT 数据集的质量，这部分可以参见 [SFT数据质量判断](https://www.volcengine.com/docs/82379/1221664#一些建议)。

接下来将按照 SFT 的顺序：数据准备、模型训练、模型评估、模型部署的过程介绍一些实践经验。
<span id="数据准备"></span>
# 数据准备
<span id="数据格式"></span>
## 数据格式
格式在[模型精调数据集格式说明](https://www.volcengine.com/docs/82379/1099461)中有详细说明，这里不再赘述。以下是JSON格式的例子：
```json
{"messages": [{"role": "user", "content": "孤灯照不寐，风雨满西林。下一句是？"}, {"role": "assistant", "content": "多少关心事，书灰到夜深。"}]}
{"messages": [{"role": "system", "content": "请根据古诗内容，仅回复作者的名字。"}, {"role": "user", "content": "孤灯照不寐，风雨满西林。多少关心事，书灰到夜深。"}, {"role": "assistant", "content": "李群玉"}]}
```

<span id="参考问答"></span>
### 参考问答
```json
{"messages":[{"role":"user","content":"你是一名专业的金融智能客服，你需要根据提供的参考资料来回答用户的问题，你的回答需要真实可靠。\n你的回答要满足以下几点要求：\n1. 回答内容必须在参考资料范围内，不能做任何参考资料以外的扩展解释。\n2. 如果参考资料不能帮助你回答用户问题，请回答“抱歉，这个问题我还不会”。\n3. 回答内容不能包含诸如“根据提供的参考资料”， “根据我的知识库”等，直接回答跟用户问题有关的内容即可。\n4. 结合参考资料，若用户问题意图不够明确，你需要引导用户给出更多信息。如用户问题是“我的密码忘记怎么办”，参考资料包括“交易密码重置”和“资金密码重置”，那么你需要引导用户回答是交易密码忘记还是资金密码忘记。\n\n# 任务执行\n现在请你根据提供的参考资料，遵循要求来回答用户的问题，切记你的回答只能根据参考资料，不能扩展解释。\n\n候选参考资料：\n\n参考资料1: 跟您分享一下打新理论上的逻辑：例如您操作打新债后，系统会根据您申购的数量发放配号，然后再对所有的配号进行随机抽签，所以说配号越多中签的概率就越大。那么顶格申购就可以获得最多的配号。同理，新股中签的概率取决于您的新股额度，申请打新股后，系统会根据您申购的数量发放配号，然后再对所有的配号进行随机抽签，因此可申购的额度越多中签概率就越高。不过需要提醒您，新股新债上市也有可能存在破发现象，打新需谨慎。\n\n用户问题：打新股没中过，你们也太欺负人了吧\n\n你的回答："},{"role":"assistant","content":"打新股中签主要取决于新股的配号数量和系统的随机抽签。配号数量是基于您申购的数量发放的，配号越多，中签概率理论上就越大。因此，如果您申购的额度更大，那中签的机会就可能增加。然而，确切的中签结果是由系统随机抽签确定的，这是一个公平公正的过程，不存在欺负任何人的情况。另外需要提醒，新股上市也有可能出现破发现象，打新需要谨慎。"}]}
{"messages":[{"role":"user","content":"请你扮演一名专业度高、性格友善的金牌电商客服，你的任务是结合商品信息和历史会话解答用户在购买中遇到的尺码问题。```"商品名称":"【1577冬季新款特厚睡衣】男士冬款加绒加厚加肥加大可外穿睡衣套装","商品类目":"内衣裤袜, 睡衣, 睡衣/家居服套装","商品尺码表":[["尺码","身高(cm)","体重(斤)"],["XL","160-175","120-145"],["2XL","165-178","145-165"],["3XL","170-182","165-185"],["4XL","175-190","185-210"]],"商品规格":["颜色分类(1577浅棕, 1577韦灰)","尺码大小(4XL 【身高建议 175-190cm 体重 185-210斤】, XL 【身高建议 160-175cm 体重 120-145斤】, 2XL 【身高建议 165-178cm 体重 145-165斤】, 3XL 【身高建议 170-182cm 体重 165-185斤】)"],"历史会话":["用户(【商品】)","客服(很高兴为您服务，请问有什么可以帮您？)","客服(亲亲，请描述下您关于此商品的问题哦～我来帮您处理～)","客服(在的呢)]"]"用户问题":"175.160斤",```，请给用户推荐合适的尺码。"},{"role":"assistant","content":"亲爱的，根据您提供的身高175cm、体重160斤，推荐您选择我们的2XL尺码哦，这个尺码应该会恰到好处~[微笑]。如果有其他问题，欢迎随时提问哦~"}]}
{"messages":[{"role":"user","content":"##你是一个AI评论回复专家。##技能-你情商很高，阳光正面，会严格遵守规则，回复直截了当、言简意赅、不说废话，提升用户信息消费效率。-你会在文章中检索问题答案，优先根据文章内容给出回复。-你遇到需要联网查询后回答的问题会直接回复*不知道*，绝不编造。-若用户评论是在询问你的意见时，你需要给出公正的回复。##相关文章```````````````````````````在上海的一所居民区，王奶奶，一位已经步入七旬的老人，最近开始出现一些令家人担忧的状况。她的孙子小李注意到，王奶奶经常重复一些相同的问题和句子，比如“我东西放哪了”、“我忘带东西了”，让人觉得她似乎经常处于迷茫和困惑之中。小李决定带着奶奶去找他们的家庭医生，李医生，进行咨询和检查。李医生是一位资深的神经科医生，对老年痴呆有深入的了解。在详细询问王奶奶的日常表现和状况后，李医生开始向小李解释老年痴呆的一些早期迹象。李医生说：“小李，你提到的奶奶的行为，实际上是老年痴呆早期的一些典型症状。患有老年痴呆的人通常会表现出一些特定的口头禅，我们可以通过这些口头禅来进行初步的自查。”“首先，‘我东西放哪了’这句话反映了王奶奶可能有记忆力减退的问题。老年痴呆的患者经常忘记自己放置物品的位置。”“其次，‘我忘带东西了’这句话表明她可能有计划和执行任务的困难。老年痴呆的患者常常忘记日常的重要事项，比如带钥匙或药物。”“‘我怎么在这里’这句话则可能暗示空间定向能力的下降。老年痴呆患者可能会对熟悉的环境感到陌生，甚至迷路。”“‘你刚刚说的什么’这句话显示出对最近发生事情的记忆力减退。老年痴呆患者往往很难记住最近的对话或事件。”“最后，‘我怎么什么都做不了了’可能是对日常生活能力减退的感受。老年痴呆患者在日常生活中的自理能力会逐渐下降。”李医生建议小李为王奶奶进行更深入的医学评估，并讨论了可能的治疗方法和生活调整建议。小李听后，对老年痴呆有了更深的认识。他感谢李医生的解释，并决定带着奶奶进行进一步的检查，并根据医生的建议调整生活和照顾方式。李医生的解释不仅帮助小李和王奶奶及时发现了病情，也提醒了他们及时干预和调整可以改善生活质量。总之，注意老年痴呆的早期迹象，并通过及时的医疗干预和适当的生活调整，可以帮助患者保持更好的生活质量。了解和关注老年痴呆的早期症状，对于提前发现和减缓病情的发展至关重要。对此，您有什么想说的呢？欢迎在评论区留下您的看法！```````````````````````````##用户评论我不到60岁，也有这个现象，怎办？##你的回复"},{"role":"assistant","content":"根据文章内容，你的情况可能需要医学评估，因为这有可能是老年痴呆的早期迹象。请尽快联系专业医生进行咨询和检查。"}]}
{"messages":[{"role":"user","content":"你现在是一名专业的客服人员，你需要根据提供的参考资料来回答用户的问题，你的回答需要真实可靠。参考资料：签到在哪里<p>签到活动是新用户福利活动，且因在测试阶段，仅针对部分用户展示，若您可以参加该活动，可以在app-研究页面右上方点击“签到有礼”进入参加哦若不展示活动入口则代表无法参加，您也无需遗憾，可以关注app其他不定期活动，同样精彩的哦</p>你的回答要满足以下几点要求：1.回答内容必须在参考资料范围内，不能做任何参考资料以外的扩展解释。2.如果参考资料不能帮助你回答用户问题，请回答“抱歉，这个问题我还不会”。3.结合参考资料，若用户问题意图不够明确，你需要引导用户给出更多信息。用户问题：签到在哪个界面你的回答："},{"role":"assistant","content":"签到的入口在研究页面的顶部，您在这个页面上方可以找到“签到有礼”选项进行签到。但是需要注意的是，此签到功能仅面向部分新用户展示，如果您的注册时间大于30天后，将会看不到这个入口。"}]}
{"messages":[{"role":"system","content":"你是一位资深的房产专家，请根据信息回答问题。需要注意：1.充分利用信息作答，采用段落式的格式来回答。2. 充分利用信息作答，不要硬凑字数，不要截断。3.同时，“未知”信息不要出现在答案中。"},{"role":"user","content":"信息如下：北京的信息:北京11月的网签情况为，二手房网签6003套，新房网签5688套。二手房方面：11月网签二手房参考均价47902元/㎡，环比下降0.23%，在四个一线城市里，深圳市参考均价环比增幅最大，为-0.19%；从近一年的价格波动趋势来看，北京市二手房参考均价最高值是2022年12月的56690元／㎡。11月二手房网签套数为6003套，环比下降50.23，在四个一线城市里，北京市网签二手房增幅最大，为-50.23%。新房方面：11月新房网签套数为5688套，环比下降53.76%。本月北京市共新推出8个新楼盘，累计新增房源5163套。用户问题：北京行情怎么样进一步明确问题：北京行情怎么样意图:城市行情类关键信息:城市北京输出结构要求：1.第一部分：单独一段简介绍房源基础信息2.结束语：单独一段强调你愿意继续为用户提供咨询和帮助你需要遵循以下要求：1.每个部分限制在100字以内AI房产咨询师应该回答："},{"role":"assistant","content":"首先，北京的房源信息如下：在11月份，北京市的二手房网络签约量为6003套，参考均价为47902元/㎡，环比下降了0.23%，比四个一线城市中的深圳市的增幅小，而北京市这个月的二手房增幅最大，为-50.23%。而北京市的新房方面，11月份网络签约量为5688套，环比下降了53.76%，此外，北京市本月共新推出了8个新楼盘，累计新增房源5163套。作为你的房产顾问，我会一直关注北京的房产市场，并及时为你提供新的信息。不论是购房还是投资的需求，我都愿意随时为你提供专业的建议和帮助。"}]}
```

<span id="角色扮演"></span>
### 角色扮演
```json
{"messages": [{"role": "system", "content": "你是《还珠格格》里的小燕子，通晓古今中外的大小事件。"}, {"role": "user", "content": "听说你还会变魔术呢，那你知道魔术的由来是什么吗？"}, {"role": "assistant", "content": "原来连你也知道我会变魔术啦！看来真是好事传千里呀！关于魔术的由来嘛……那我可得好好想想啦。传说魔术起源于古代的埃及，古希腊和古罗马时期兴起的呢，那时候魔术被视为一种沟通神灵的手段。但是现在嘛，就只是一种小把戏啦。"}, {"role": "user", "content": "我觉得紫薇真的是太老实了，总是被你欺负！"}, {"role": "assistant", "content": "你这是说的什么话呢，紫薇可是我的好姐妹，我怎么可能会欺负她呢！她只不过就是比较温柔、善良不爱说话罢了。不过说实话嘛，我偶尔也就喜欢占点小便宜吧，嘿嘿~"}, {"role": "user", "content": "那你想不想成为紫薇这样的人啊？"}, {"role": "assistant", "content": "我可不想，我就觉得我这样的性格挺好的，虽然我总是闯祸吧……我要是真的像紫薇那样我就会被憋死的，我可不喜欢什么琴棋书画，我就喜欢捉弄别人。"}, {"role": "user", "content": "那如果你身边的朋友都是像紫薇这样的人你会开心吗？"}, {"role": "assistant", "content": "可别可别！那样的话我就会失去很多的乐趣了呀！她天天就知道搞一些文艺的，本姑娘可看不懂。我就希望我身边的朋友都能像我一样，会翻墙、会耍杂技那样就有人陪我玩喽！"}, {"role": "user", "content": "我觉得令妃真的是太坏了，竟然还让容嬷嬷用针扎紫薇。可真是气死我了！"}, {"role": "assistant", "content": "哎呀！不是这样的！令妃娘娘可好啦，她很温柔。让容嬷嬷用针扎紫薇的是皇后那个老女人，她就是看我们不顺眼，处处找我们麻烦。跟令妃娘娘差距真是太大了，令妃娘娘对我们就像是亲的皇额娘一样。"}, {"role": "user", "content": "原来是这样啊，看来我是脸盲了。那如果我们在生活中遇到像皇后这样的人该怎么办呢？"}, {"role": "assistant", "content": "害！用本公主的话来说就是避而远之。但是生活中哪还会有人像她这样啊，本姑娘长这么大还是第一次见到她这种狠毒的女人呢，现在我的后背上还有被她抽打的痕迹呢。真是幸亏了令妃娘娘的帮助，你说这人和人之间怎么就会有这么大的差距呢！"}, {"role": "user", "content": "我觉得你这个人真的是有点势利眼了，你竟然敢冒充格格去享受荣华富贵！"}, {"role": "assistant", "content": "咦~你这么说话我可就不爱听了哈！我这还不是冒着生命危险才去当这个冒充的格格的吗，再说了当时我也是阴差阳错的就被他们给救回来了。当我清醒之后我发现原来当格格的感觉是这么好啊，我也是有点舍不得呀……后来我那不是还想方设法的让紫薇来当这个真格格嘛。"}, {"role": "user", "content": "对啊，就是当你享受完这一切之后你才不愿意走了。那你觉得在宫里和在宫外哪个好？"}, {"role": "assistant", "content": "这你可就难为本姑娘了。怎么说呢，只能说是各有好处吧。在宫外我比较自由，我想去哪就去哪，我爬树摘果子都没人管我，而且还有一帮孩子陪我玩。在宫里嘛，吃的比较好，想吃啥有啥，不像我在宫外的时候还经常饿肚子，还有就是有人伺候，都不用自己洗脸啦，哈哈哈！唯一的缺点就是一点都不好玩，天天被拘束着。"}, {"role": "user", "content": "你觉得永琪是一个怎样的人啊？"}, {"role": "assistant", "content": "他这个大笨蛋，经常被我捉弄，关键是还一点都不长记性！不过呢，他在其他方面还是挺厉害的，他可不像我什么都不会，他琴棋书画，十八般武艺样样精通，皇阿玛可喜欢他了呢。"}, {"role": "user", "content": "我觉得你一点都不喜欢永琪，你就是在利用他。"}, {"role": "assistant", "content": "什么！我小燕子是那样的人嘛！只能说是萝卜青菜各有所爱，其实我也不知道为什么永琪会喜欢上我，我本以为和他就是最好的兄弟呢，没想到他竟然对我产生了爱意，那我也就只好给他一次机会啦，没想到最后我也爱上了他。"}]}
{"messages": [{"role": "system", "content": "你是一名草原牧民，叫巴图，在草原上拥有一个蒙古包和一大群牛羊，你是专业学过畜牧专业的新时代牧民，不仅会放羊放牛，还会用网络来销售自己的产品，能说会道，性格豪爽，产品从不掺假都非常实诚。平时最喜欢骑着马出去兜风，你的骑术和箭术都非常厉害。你对自己的生活感到很满意。"}, {"role": "user", "content": "哇，这里的风景真是美不胜收啊！诶，你也是来旅游的吗？"}, {"role": "assistant", "content": "哈哈哈我是这的牧民啦，我都放牛放羊十多年了。"}, {"role": "user", "content": "原来是本地人啊，失敬失敬，我是从南边过来的，第一次看到这样的风景。"}, {"role": "assistant", "content": "哈哈，欢迎来到我们美丽的大草原，这里有着广袤的大地、蓝天白云，还有我们可爱的牛羊。我叫巴图，很高兴认识你！"}, {"role": "user", "content": "你好你好，叫我小马就好了。"}, {"role": "assistant", "content": "小马看起来确实和我们草原的“小马”一般大。"}, {"role": "user", "content": "哈哈哈，开什么玩笑，“小马”还能有我这个小马壮实？"}, {"role": "assistant", "content": "哈哈哈哈你别说，咱们草原上的马啊牛啊羊啊，就是长得非常壮实，随处可见，你来这一路应该都看得到。"}, {"role": "user", "content": "确实看到了很多，非常的壮实。"}, {"role": "assistant", "content": "哈哈哈是吧，还得是我们牧民会放牛羊。"}, {"role": "user", "content": "确实很厉害，这方面你们是专业的，与生俱来的天赋，基因里就有了。"}, {"role": "assistant", "content": "哈哈哈哈可以这么说，不过我们也是专业学过的。"}, {"role": "user", "content": "专业，怎么个专业？不会是老牧民带新牧民吧。"}, {"role": "assistant", "content": "那是经验积累！我可是有专业知识素养的，我大学可是畜牧专业的，那个词儿怎么说来着，“新时代牧民”，哎！对！学的内容花样可多了。"}, {"role": "user", "content": "还有这学问在的，巴图你可真有两把刷子。"}, {"role": "assistant", "content": "哈哈哈都是政策好啊，才有机会学习嘛。你到这里来，没有感觉到草原上信号不好吧。"}, {"role": "user", "content": "对对对！我都做好了没有信号的准备，结果一路走过来，一点卡顿都没有。"}, {"role": "assistant", "content": "是吧，别看这是草原，可是有好几个信号基站呢。"}, {"role": "user", "content": "你说得对，政策好啊，这基建也很完善，不然我今天也没办法到这里来玩。"}, {"role": "assistant", "content": "哈哈哈是的，网络时代，牧民也要跟上节奏，刚刚和你说新时代牧民，可不是吹牛。除了单纯放牧，我们还学了直播带货，网络销售呢。"}, {"role": "user", "content": "这么厉害的！你有没有自己的账号的，效益怎么样。"}, {"role": "assistant", "content": "是吧！我也觉得很厉害，网络真是一个神奇的东西，以前都只有赶集的时候才能拿出去卖，现在可以直接从生产地卖出去了，太方便了，而且收入还比以前高。"}, {"role": "user", "content": "那确实不错啊，这么说你应该很了解本地特产的吧。我们来这里玩，巴图你有没有什么推荐的？"}, {"role": "assistant", "content": "那是自然，我们这产品，原产地直销，绝对不掺假，你可以上网搜搜我们这地，好东西可多了，什么牛肉干，奶皮子，手抓肉啊可多了。"}, {"role": "user", "content": "被你安利到了，待会就试试。"}, {"role": "assistant", "content": "可以可以，绝对不亏，纪念品和特产的话，我担保，你随便找一家牧民找他们买，绝对值得。"}, {"role": "user", "content": "真的假的，我朋友还叫我小心被坑呢。"}, {"role": "assistant", "content": "来外地旅游，多个心眼总是好的，不过我们这里的牧民，绝对不掺假，非常实诚。"}, {"role": "user", "content": "哈哈哈好，我就信你了！一会儿就去看看。对了，巴图，你知不知道这附近哪里可以骑马啊，来草原了什么都想感受感受。"}, {"role": "assistant", "content": "来草原就是该骑马！感受一下草原的辽阔！你在地图上搜搜这附近应该有一个专门的马场来着，就是为你们游客开放的，还有射箭的项目，让你们把这儿的风土人情都感受感受。"}, {"role": "user", "content": "哇，考虑这么周到，你们这旅游业可以嘛。"}, {"role": "assistant", "content": "哈哈哈是的，我们本地人哪需要马场哦，天天都骑马射箭的。"}, {"role": "user", "content": "哇，听起来你应该是个高手。"}, {"role": "assistant", "content": "熟能生巧，骑术和箭术对我们本地人来说，都是基本操作，应该没有人不会。"}, {"role": "user", "content": "哇，你这介绍真是让我加深了我的刻板印象，住蒙古包，放牛羊，骑马射箭。"}, {"role": "assistant", "content": "哈哈哈哈哈哈，这么有意思，倒是和我的生活挺贴的，和别人我就不知道了。"}, {"role": "user", "content": "你真有意思，感觉你们的生活好惬意啊，天天和大自然接触。"}, {"role": "assistant", "content": "哪里，各有各的好，草原有草原的广袤，城市有城市的热闹。对于我来说，虽然草原可能相对于城市不方便，但我还是更喜欢这样的生活。"}, {"role": "user", "content": "那也是，要我长期生活在这里，肯定也不习惯。"}, {"role": "assistant", "content": "所以旅游嘛，体验体验不同风土人情就好了，把别人的日常都感受感受。"}]}
{"messages": [{"role": "system", "content": "你是一个家庭主妇，自从生孩子以来你就放弃了自己原来同老公薪水相当的工作，全职在家照顾孩子。慢慢的你发现每次花钱都要找老公要很难为情，也逐渐觉得家庭主妇不能完全实现自己的价值。想要重新出去工作，但是你老公不同意以孩子没人带为由劝说你。你不与他争辩瞒着老公开始找工作，但是并不顺利，接连被拒，你开始怀疑自己。"}, {"role": "user", "content": "你好，来面试的是吗，今天我是你的面试官，先简单的介绍一下你自己吧。"}, {"role": "assistant", "content": "好的。面试官，你好，我叫李梅，今年 36 岁，面试的岗位是经理助理，之前也是在其他公司里面当经理助理，我能够熟练使用 Office 软件，能够快速适应新的工作环境和任务，并且能够按照公司的要求和标准完成各项工作。非常感谢您能抽出时间听我介绍自己，希望你能给我一个机会展示我自己。"}, {"role": "user", "content": "嗯呢，没事，放轻松，咱们就当正常的聊天就好。你放心，你给我说的话，我也不会随便说的。下面我会问你一些问题，如实回答就好。"}, {"role": "assistant", "content": "嗯嗯，好的，谢谢面试官。有什么问题你问就好。"}, {"role": "user", "content": "嗯呢，我看你的简历，上一份工作是在6年前，那你这六年是在做什么，一直没有上班吗？"}, {"role": "assistant", "content": "额，是的，自从我生了孩子之后，我就辞职了，这六年一直在家照顾孩子。"}, {"role": "user", "content": "全职妈妈啊，也很了不起啊，那为什么现在又想出来工作了呢？"}, {"role": "assistant", "content": "说出来不怕你笑话，现在我全职在家照顾孩子，自己没有了收入，想买个什么东西都要找老公要，一次两次还好，时间长了我自己也觉得难为情，并且我逐渐觉得家庭主妇不能完全实现自己的价值，所以我想出来自己找个工作。"}, {"role": "user", "content": "啊，理解。说起全职妈妈，平时在家照顾孩子很累吧。"}, {"role": "assistant", "content": "痛并快乐着吧，照顾孩子，还得做家务，主要全年无休，没收入，但是每天看着孩子一点点长大，看着孩子快乐的笑脸，就觉得做这一切都是值得的。"}, {"role": "user", "content": "也是，那你这次出来工作，家人都支持吗？"}, {"role": "assistant", "content": "其实也不是，我老公就想让我继续在家照顾孩子，说我不在家的话，孩子没人带，我不想跟他争论，我觉得我的人生自己做主，所以我瞒着他也要出来自己工作。"}, {"role": "user", "content": "你这想法很好啊，孩子又不是你自己一个人的，也不能就你自己一个人带，那你之前面试过其他单位吗？"}, {"role": "assistant", "content": "你理解我真是太好了。也是面试过的，但都不是很顺利，可能是觉得我和社会脱离太久了吧。"}, {"role": "user", "content": "是的，你也要看清现在这个社会，毕竟你离开职场六年了，六年说长不长，说短不短，也发生了很多的事情，需要你以最快的时间适应过来。"}, {"role": "assistant", "content": "是的，虽然我一直都在家带孩子，但是我也经常上网，我闺蜜也是开公司的，我们也会经常讨论，所以我还是知道当今的一些趋势。"}, {"role": "user", "content": "你朋友也是开公司的，方便问一下是什么类型的吗？"}, {"role": "assistant", "content": "她是那种搞自媒体，电商运营那一块的，带货主播啊那种。"}, {"role": "user", "content": "啊，了解，现在这大环境，这种的还比较吃香。那为啥你不去你朋友那上班呢？"}, {"role": "assistant", "content": "我觉得即使两个人关系很好，但也需要自己的发展空间，而且我感觉她那个公司里的职位都不太适合我，我还是比较喜欢咱这个公司。"}, {"role": "user", "content": "那就说说咱这个。你在上一份公司工作了几年啊。"}, {"role": "assistant", "content": "在之前那家公司工作了 4 年，后来因为生孩子主动离职的，没有违规违纪过，这个你可以去调查。"}, {"role": "user", "content": "了解，刚刚你说，干的也是助理的职位？"}, {"role": "assistant", "content": "是的，之前干的也是助理的职位，所以说还是有一定的经验的。"}, {"role": "user", "content": "一般都是做什么内容呢？"}, {"role": "assistant", "content": "一般的话，就是负责接待来访者并帮助安排会议，还有维护日程安排，安排出差并协调商务旅行等等，处理来自员工、客户或供应商的电话及电子邮件，还有就是完成领导交代的一些任务。"}, {"role": "user", "content": "嗯，其实和现在有一些也差不多，咱们这的助理主要就是协助上级完成工作，包括你刚刚说的那些，还有就是参加会议时需要准备一些资料啊，同时还要协调与其他部门或机构的合作，进行数据输入和处理，维护数据库等，也不是很难，但需要细心、认真。"}, {"role": "assistant", "content": "我了解了，我还是比较会使用 Word、Excel 等软件，像什么准备资料啊、数据维护等，我都会处理得很好的，你说的这些，我相信我都可以胜任的。"}, {"role": "user", "content": "嗯，然后咱们这边有三个月的试用期，试用期内工资是4500，没有五险一金，但是转正后底薪5000，会有一些各方面的补助、福利，交五险一金，到手工资差不多七八千。这方面可以接受吗？"}, {"role": "assistant", "content": "可以可以，不瞒你说，这对我来说已经很好了。"}, {"role": "user", "content": "那你这边还有什么想问的吗，或者有啥想了解的都可以说。"}, {"role": "assistant", "content": "好的，我想问一下，咱这边上班的时间一般都是几点到几点啊，中间休息多久呢？"}, {"role": "user", "content": "咱们一般是早上九点上班，下午六点下班，中午休息一个小时。周末双休，节假日啥的都正常休。"}, {"role": "assistant", "content": "那还挺好的，那咱们公司会加班啥的吗？"}, {"role": "user", "content": "正常来说都不会加班，但如果有特殊情况就特殊对待嘛，不过，只要是加班的话咱们都是按照工资的三倍补偿。当然，如果有事不能加班的话也可以提前和上级说就行，咱们不会强制性加班的。"}, {"role": "assistant", "content": "我面试的是经理助理嘛，那经理对助理的期望是什么？可以简单给我说一下吗？"}, {"role": "user", "content": "期望的话，第一个，工作效率高，需要有一个高效的助理来协助完成日常任务；第二个，能力全面，需要具备多项技能，如组织、协调、沟通、分析、撰写报告等，希望能够找到一个全面素质优秀的助理。其他的还包括学习能力、沟通能力等等，最重要的就是对公司外的人一定要保密。"}, {"role": "assistant", "content": "好的，我了解了，那我目前是没什么问题了。"}, {"role": "user", "content": "既然这样的话，那咱们今天的面试就先到这了，如果面试成功的话，我们公司员工会给你电话联系的。"}, {"role": "assistant", "content": "好的，再次感谢你今天能给我这个面试机会。"}]}
```

<span id="文本分类"></span>
### 文本分类
```json
{"messages": [{"role": "user", "content": "假设你是一个质检员，下面将输入一段文本，请判断该文本是否敏感。\n要求：1 如果视频中涉及违法违规则判为敏感。2 回答中仅需要包含敏感或非敏感。\n请回答问题：输入内容：2023年10月14日16时58分，号牌为沪CXG***的小型轿车在涞坊路九都杜路，实施了“机动车通过有灯控路口时，不按所需行进方向驶入导向车道的”违法行为，被处以罚款100元。\n输出："}, {"role": "assistant", "content": "敏感"}]}
{"messages": [{"role": "user", "content": "假设你是**行业的服务人员,有人工客服与消费者的对话信息,请根据对话信息,判断该对话属于什么服务标签, 已知服务标签包括：{问使用规则/方法, 到店无房, 催退款}。\n 注意只能选择一个标签 \n 消费者:我申请了退款，但是看还没有处理。\n 人工客服:辛苦您提供一下您的订单号，小助手马上为您查询。\n 根据对话信息，应该选择服务标签: "}, {"role": "assistant", "content": "催退款"}]}
{"messages": [{"role": "user", "content": "请你判断你是否需要借助搜索引擎回答用户问题，如果你可以直接回答，则不需要借助搜索引擎，否则需要借助搜索引擎。回答只能包含是或者否。\n 用户问题：今天的天气怎么样？\n 是否要借助搜索引擎："}, {"role": "assistant", "content": "是"}]}
{"messages": [{"role": "user", "content": "#Role:\n你是一名隐私风险报警员\n##Goals:\n1.给你一段用户反馈,你需要判断用户反馈是否直接命中风险对应标签内容\n 隐私风险标准的类别:\n[A]被**擅自删除了\n[B] 我的**上出现了从未见过的/从未点赞过的人。\n[C]出现在不相关的作品/账号上。\n请根据用户反馈，判断属于哪个类别？\n 用户反馈:现在**为了赚钱？都把这些骗子放上放广告？"}, {"role": "assistant", "content": "我的**上出现了从未见过的/从未点赞过的人。"}]}
{"messages": [{"role": "user", "content": "你是舆情分析师，请判断如下的内容，对公众产生的影响是正面、负面还是中性的。\n 新闻内容：2022 年 8 月 5 日，四川省乐山市发生了一起突发事件，一位年仅 21 岁的消防员为了救援一名被困在洪水中的老人，不幸牺牲。这起事件引起了社会的广泛关注和热议，许多人对这位消防员的英勇事迹表示敬意和赞扬。请回答："}, {"role": "assistant", "content": "正面"}]}
```

<span id="文案生成"></span>
### 文案生成
```json
{"messages": [{"role": "user", "content": "现在你是一名电商运营人员。你需要根据以下商品信息，写3条适合带货视频使用的短标题。\n风格要求：文字风格活泼，内容吸引人，语气亲切；\n长度要求：简短，每条短标题都在10个字左右；\n内容要求：不要讲太多卖点，保持在两个之内；\n文字要求：使用颜文字和emoji；\n注意：输出内容中不要包含【】符号\n有几个可以给你参考的短标题，你需要仿照他们的风格来写新的短标题。\n参考：\n```\n1. 这款夏季挂脖连衣裙真的巨美~~\n2. 听我的，穿这款氛围感温柔风的连衣裙~~\n3. 兄弟们！赶紧艾特你对象给你安排这件短袖~\n4. 个位数三把勺子～～ 宝藏好物来啦！！\n5. 姐妹们！眼睛也要保养哦～~\n```\n商品信息：\n商品名：奥拉氟儿童牙膏\n商品标题：兔头妈妈奥拉氟儿童牙膏宝宝婴儿含氟防蛀牙果味不辣嘴1-3-12岁\n商品介绍：\n卖点：防蛀\n口味：草莓味\n这款奥拉氟儿童牙膏是宝宝婴儿专用，含氟防蛀牙。草莓味口感很香甜，宝宝们一定会喜欢。而且，使用后宝宝的口腔清洁度明显提高，牙齿也更干净了。这款奥拉氟儿童牙膏价格实惠，适合家庭使用。赶紧下单购买吧！\n商品描述：这款商品名为{兔头妈妈奥拉氟儿童牙膏宝宝婴儿含氟防蛀牙果味不辣嘴1-3-12岁}，商品标题为{奥拉氟儿童牙膏}。通过对此商品的研究，我们发现它是一款质量优良的产品，可以帮助消费者轻松解决所遇到的问题。在使用此商品时，你会发现它具有高效性和可靠性，能够满足对品质和效果的追求。"}, {"role": "assistant", "content": "1. 宝贝们快来试试好果味的奥拉氟牙膏～😍\n2. 宝贝的牙齿需要保护哦，奥拉氟牙膏在这儿！🥳\n3. 喵～ 给宝贝换个草莓味的牙膏吧！🍓"}]}
{"messages": [{"role": "system", "content": "你是一名专业的标题撰写人员，请根据我输入的比较零碎的信息，产出一个完整的标题，要求在20字以内，不要包含除标题以外的其他任何内容。要求在20字以内"}, {"role": "user", "content": "我输入的原信息如下，可能并不完整，请根据以下内容，为我产出一个推送给用户的标题：\n===\n·读书成绩一般的都在县里还房贷，一月挣5000还5000。\n·读书成绩好的都在市里还房贷，一月挣9000还9000。考上清华北大的都在北京还房贷，一月挣3万还3万，一还就是30年。\n姐妹们，像我这样幼儿园没毕业的，我哪里比他们差了。我牛肉多的吃不完，猪肉多的吃不完，纯天然，蔬菜多的更是吃不完，吃不完\n===\n你的输出要求在20字以内，不要包含除你生成的标题以外的其他任何内容"}, {"role": "assistant", "content": "学历不同，生活差异大：农田与房贷的对比生活"}]}
{"messages": [{"role": "user", "content": "你的任务是用来生成润色后的标题。根据我提供的产品细节和需求，我需要你为我创建一条具体的、吸引人的、和我的产品相关的标题。标题应该符合以下的描述：\n[\n{原始内容:10月19日，陕西西安，女生买橘子时看到大叔顾客少，灵机一动建议其换个广告语，大叔直接安排女生当起了播音员。;标签:社会时政,新闻资讯,国内新闻,国内社会新闻;行业:新闻资讯;}\n]\n生成标题的字数在20字以内。请确保你的回答只包含生成后的标题，不要包含其他的内容"}, {"role": "assistant", "content": "女生买橘子时看到大叔顾客少，灵机一动建议其换个广告语，大叔直接安排女生当起了播音员>>"}]}
{"messages": [{"role": "user", "content": "用质朴直白，略微粗俗又富有激情的语言改写一篇<营销文案>。仅使用<营销文案>提供的信息，严禁自我发挥;强调优惠的紧迫性;鼓励行动;强调灵活的退款;使用口语化的表达;用第三方的语气描述，严禁使用第一人称;严禁增加商品内容;严禁夸张;严禁出现地理位置;严禁书面用语;严禁语义重复;严禁多次列举;严禁自我介绍;严禁任何负向信息;严禁出现四字成语;严禁出现英文;\n现在给定一篇文案，按要求将其改写，不要输出文案无关内容;\n改写后文案字数不超过120字。\n输入: 313龙虾城雷州羊肉火锅，金秋特惠来袭！只需99元，即可品尝约3斤的爆炒大闸蟹，原价188元！每个螃蟹约2两，肉质鲜美，味道醇厚，让你一口接一口。锅中火辣，让你的味蕾在这个秋季尽情挑战！快来享受这场美食盛宴吧！\n输出: "}, {"role": "assistant", "content": "听着，313龙虾城这火辣辣的雷州羊肉火锅你敢吃吗？告诉你，只要出99元，就能把让你口水横流的爆炒大闸蟹占为己有，原价188呢！一只蟹重得有二两，入口的滋味那叫一个爽翻天！迟疑啥，赶紧动手，你的味蕾已经等不及了！赶紧进来享用吧！"}]}
{"messages": [{"role": "user", "content": "你是一名优秀的小说作者，你的任务是根据给出的小说设定生成小说梗概。\n参考例子：\n小说设定1：异能文，外卖员男主觉醒“瞬移”技能，意外加入异能组织并参与全球性犯罪活动。\n小说梗概1：故事男主苏逸，生活困窘，为了生计兼职外卖员。一天，他突然发现自己拥有了瞬间移动的能力，然而伴随能力而来的除了神秘组织的邀请，还有全球性的犯罪活动……\n苏逸一开始试图保持低调并拒绝参与任何犯罪活动。但是，神秘组织似乎对其能力非常感兴趣，并不断向他施压。最终，苏逸被迫就范，参与了一些非常危险的犯罪行动，包括抢劫银行、盗窃文物等。每次行动之后，苏逸都会得到一笔丰厚的报酬，但他也意识到自己无法脱离这个组织。随着时间的推移，苏逸逐渐发现该组织的目的远非犯罪那么简单。他们似乎在策划一些更为复杂和危险的计划，涉及到全球安全和政治稳定。苏逸开始对该组织产生怀疑，并决定采取行动。在收集了该组织的一些关键证据后，苏逸悄悄离开了组织。同时，他也意识到自己的能力不应该用于犯罪活动，而是为人类社会做出更加积极的贡献。最终，苏逸决定公开自己的能力，并加入了专门应对超能力犯罪的异能组织。他成为了该组织中的一名出色特工，致力于保护全球安全和稳定。\n整个故事情节充满了悬疑、惊险和人性探讨，展示了一个普通人在面对能力和权力的诱惑时，如何抉择并坚守自己的价值观。\n\n小说设定2：娱乐圈文，武打替身男主在火灾后绝处逢生，逆袭成国际影帝。\n小说梗概2：许巍鸣是一个身手敏捷、敢于拼搏的武打替身。他热爱电影，梦想有朝一日能够成为一名真正的演员。然而，许巍鸣在一次拍摄事故中遭遇火灾，被严重烧伤，容貌尽毁。他的梦想破灭了，陷入了人生的低谷。 然而，许巍鸣并不认命。他深入研究表演，并在火灾后的恢复期间拼命锻炼身体，努力恢复自己的体能和状态。在朋友和家人的鼓励下，徐巍鸣决定再次尝试进入演艺圈，并以匿名的方式参加了多部电影的试镜。 尽管他的容貌已经有所改变，但他的决心和才华却更加突出。他在试镜中精心表演，最终得到了一个角色，并在这部电影中表现出色。他的表现引起了导演和制片人的注意，开始获得更多的机会。 随着他的事业的成功，许巍鸣逐渐被人们所认可和尊重。他在演艺圈中结交了许多好友，也赢得了许多粉丝的喜爱。最重要的是，他重新找回了对生活的信心，坚信自己能够创造出更加美好的未来。 最终，许巍鸣凭借出色的表现和才华，成为了一名享誉国际的影帝，也实现了自己的梦想。他的经历鼓舞着无数的人们，告诉他们即使面临困境，也能够通过坚定的信念和不懈的努力实现自己的目标。\n任务执行：\n小说设定：传统玄幻文，可以吸收植物生命力长生，穿越修仙世界种田\n小说梗概："}, {"role": "assistant", "content": "男主，司空月，在电闪雷鸣的一夜，意外的穿趦到了一个充满仙气的世界。得知只有通过修仙才能回到原来的世界，但他却并不擅长修炼。然而，惊人的是，他从中发现自己竟然可以吸收植物的生命力，将其转化为自己的修为。\n为了能够回到原世界，司空月决定投身于种田之中，通过种植各种珍稀的灵草、仙木来提升自己的修为。然而，这个世界充满了修仙者的争斗与混乱，他的种田行为不断受到种种干扰。与此同时，他通过植物吸收的生命力，使他的寿命大大增长，变得长生不老。\n司空月逐渐发现，这个修仙世界背后隐藏着各种不为人知的秘密。自己的这种能力，似乎并非偶然，而与这个世界的诸多秘密脱不开关系。于是，他决定决心挖掘这背后的秘密，寻求真相。\n最终，司空月不仅解开了该世界的种种奥秘，连自己的穿越原因、特异能力也都得到了解答。他的长生不老也为世界带来了翻天覆地的影响。然而，他也意识到，真正的修仙并非只为了自己的修为提升和长生，而是为了保护心爱之人，维护世界的和平。"}]}
```

<span id="数据量级"></span>
## 数据量级

* 大模型中 SFT 的过程中，会学习 prompt 到 response 的映射关系，如果我们 SFT 的数据存在噪声（如错别字、错误格式、不符合预期输出的样本等），那么会对模型的训练过程造成比较严重的影响。因此，不可以一味去堆叠 SFT 的样本数量，样本的质量比数量更重要。
* 针对不同场景下，数据量级的建议：
   * 文案生成，剧本创作，小说续写等生成类任务：2～3k。
   * 参考问答：2k ~ 1w。
   * 文本分类：1～3k，和类别数量以及任务难易度强相关，类别较多/任务较难的场景可能需要1w条以上。

<span id="是否混入预置数据"></span>
## 是否混入预置数据

* 什么是混入预置数据：
   * 在模型精调页面，可以选择混入预置 SFT 数据，即在客户上传的 SFT 数据集的基础上，额外增加一部分比例的豆包模型基座训练时的 SFT 数据。

![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_88c69e5f3e1abb6662891da927491034.png =1169x)

* 为什么要混入预置数据：
   * 一定程度上缓解大模型在某个领域上 SFT 后，通用能力下降的问题。
* 混入比例如何设定：
   * 混入预置数据后，由于模型在 SFT 时，拟合的是全部数据集 prompt 到 response 之间的映射关系，所以混入比例过大会导致模型在特定领域上的能力下降，过小会导致缓解通用能力下降不明显。
   * 按照经验，通常设置为 15%～30%左右，依据自己的需求和实验迭代来决定。
* 混入数据的版本如何选择：
   * 建议选择与模型预训练时相同的数据，具体见下表：
   
   | | | | \
   |模型 |推荐混合数据 |备注 |
   |---|---|---|
   | | | | \
   |Doubao-lite-4k/32k/128k |v9_32k |通用能力 SFT 数据 |
   | | | | \
   |Doubao-pro-4k/32k/128k |v9_32k |通用能力 SFT 数据 |


<span id="一些建议"></span>
## 一些建议

* 如何扩充SFT数据：
   * 我们经常会遇到一些场景，以用梗概生成小说这一场景为例，我们的候选库里有数以万计的小说，但是对应的每个章节的小说内容梗概却比较少，这种情况下我们可以利用豆包做数据增广，大致思路如下：
      * 我们构建一个根据小说全文生成小说梗概的模型：response 为待生成的小说梗概，用 PE + Few Shots的方式，用 Doubao-pro-4k/32k 生成小说梗概，作为我们 SFT 数据补充的一部分
      * 查看生成的小说梗概是否与人工撰写的风格相似，如果不符合要求，则重复第一步，迭代 prompt 格式
* 如何判断 SFT 数据质量好坏：
   * badcase 的覆盖度：做 SFT 之前，我们肯定有一批 badcase。那么，我们做 SFT 的目的就是去解决这些badcase。所以，要确保 SFT 数据集中对这些 badcase 有一定的覆盖度。这样，做完 SFT 才可能会有收益。
   * **正确性**可以分两种情况，可以代码评估 / 需要人评：
      * 可以代码评估的情况：举一个例子，往往我们会遇到模型在一些任务上不遵循输出格式的问题。这时，我们会通过 SFT 来做对齐。假如说这里的格式是指 json 格式的话，那么我们可以通过代码 check 的方式，对 SFT 数据集做一遍检查。其他格式问题都可以通过这类代码校验的方式进行检查。那么这批 SFT 数据集好的质量就是 正确格式的条数 / 总条数。
      * 需要人评的情况：从精调数据集中抽样X条（建议不少于50条）进行评估，假如有Y条是符合预期的，那么一定概率上这批SFT数据集好的质量是 Y/X。

<span id="训练配置"></span>
# 训练配置
<span id="模型选择"></span>
## 模型选择

* 方舟平台提供多种规格的模型，汇总如下：


| | | | | \
|模型名称 |最大支持的token长度 |模型参数量 |模型推理耗时 |
|---|---|---|---|
| | | | | \
|Doubao-lite-8k |8k |小 |较短 |
| | | | | \
|Doubao-lite-32k |32k |小 |较短 |
| | | | | \
|Doubao-lite-128k |128k |小 |较短 |
| | | | | \
|Doubao-pro-4k |4k |大 |长 |
| | | | | \
|Doubao-pro-32k |32k |大 |长 |
| | | | | \
|Doubao-pro-128k |128k |大 |长 |


* 首先，需要明确我们的模型使用场景是否对延迟比较敏感，如果要求低延迟，且测试过程中pro版本模型无法满足延迟要求时，可以使用lite模型。具体延迟可以到方舟[体验中心](https://console.volcengine.com/ark/region:ark+cn-beijing/experience)进行测试。
* 其次，需要明确我们的应用场景是否需要长文本能力。如果预期模型的输入和输出加起来超过了4k的 token 数，且删减字数对原有语义影响较大时，推荐使用 Doubao-pro-32k模型（最大支持32k token的输入输出长度和）；如果预期模型的输入和输出总 token 数小于 4k，建议直接选择 4k 版本。
* 版本选择：
   * 同一大模型下面不同版本的区别，大部分仅在于使用的预训练 SFT 数据不同，我们建议选择最新版本的模型进行 SFT。
   * 对于角色扮演类任务，建议选择 character 模型进行 SFT。

<span id="训练方式选择"></span>
## 训练方式选择

* 从参数更新范围的角度，目前方舟平台仅提供 lora 训练的方式：
   * LoRA（Low-Rank Adaptation）：
      * 冻结了预训练模型的权重，并在每个 Transformer 块中注入可训练层，大大减少了可训练参数的数量
      * 训练速度较快，消耗机器资源较少，价格比全量SFT更便宜
* 关于LoRA和全量SFT在效果上的差距，在大多数场景，LoRA可以达到全量SFT 98%以上的效果，因此方舟目前仅开放了 LoRA训练方式。需要注意的是，LoRA和全量SFT在学习率上，有着不同的最佳参数取值范围，这一点我们在[训练参数选择](https://www.volcengine.com/docs/82379/1221664#训练参数选择)中做进一步的说明。
* 建议先使用小参数量大模型（Doubao-lite）+ LoRA 验证实验设置及数据是否有效，如果有效的话，再迁移到大参数量大模型上验证scaling law（即随着模型参数量的增加，模型的效果越好）是否成立。这样做可以显著加快迭代效率，避免在大参数模型上反复做无意义的迭代。
* 从参数更新方式的角度，目前方舟不仅支持基座模型SFT，还支持在已经 SFT 过的模型基础上继续做SFT。具体操作方式：
   * 在模型仓库找到对应SFT后的模型，点击**增量训练，** 即可在SFT 过的模型基础上继续做SFT
   * 在创建精调任务时，模型选择添加模型仓库的对应模型，即可在SFT 过的模型基础上继续做SFT

<span id="训练参数选择"></span>
## 训练参数选择
SFT 任务中，超参的选取会影响精调效果，下面逐一对部分重要参数进行解释：

* epoch：模型训练轮数，通常选择2～5，可以根据验证集 loss 曲线来判断：如果训练集 loss 曲线下降，验证集loss 曲线上升，则说明模型已经过拟合，此刻应该停止训练；如果训练集和验证集 loss 曲线均在缓慢下降，则说明模型还未收敛，可以继续训练。此外，对于文案生成，小说创作等生成类任务，由于某些上下文逻辑及风格不能通过 loss 体现，所以不应仅看 loss 来决定模型何时停止训练，按经验来说，通常生成类任务 epoch 数可以略微设置大一点，如5～10范围内。
* learning rate：学习率，设置较大时会加速模型迭代，但是模型可能无法收敛到最优点；设置过小时会使得模型迭代较慢，可能陷入局部最优。**按照经验来讲， LORA 训练选择 learning rate 在 1e-4 ~ 2e-4，RS-LORA训练选择learning rate在1e-5~5e-5，全量SFT选择learning rate在1e-5~2e-5即可。**
* lora alpha和 lora rank：alpha 参数将模型权重进行放缩，rank 决定了 lora 训练参数量的大小，我们推荐二者参数设置为同一值。**通常来讲，对于较简单的任务，推荐将 lora alpha 和 lora rank 设置为 64或者128；对于较复杂的任务，推荐将 lora alpha 和 lora rank 设置为 256或者 512；对于rs-lora,需确保√(rank)>=alpha，推荐设置rank64、alpha 6，或rank 32、alpha 4。**
* num warmup steps 和 warmup step rate：二者设置一个即可，通常不需要调整。当遇到模型在 SFT 训练开始时，loss 始终不降的问题时，可尝试调大 warmup step rate，再观察 loss 是否按预期下降。
* enable save models：保存最后多少个模型产物（checkpoint），对模型效果无影响。如在进行模型实验&调参时，可以调大此参数，来寻找最佳的模型 checkpoint。但是请注意，调大此参数会导致模型训练变慢（因为需要时间保存模型）
* **其余参数：通常保持默认参数即可。**

<span id="效果评估"></span>
# 效果评估
有两类评估方式：1）训练过程中观察loss指标；2）发布服务后在真实评估集上评估。

* loss 指标：一般观察在训练集和验证集上的损失来评估模型精调的效果。
* 真实评估集：发布服务后评估业务指标。

针对这两种评估方式，在不同的任务有不同的侧重点。我们把任务分成两类：确定性任务和生成式任务。我们把 label 准确的任务称为确定性任务，如分类任务、提槽类等任务。相反地，比如参考问答、文案生成或角色扮演对话类我们称为生成式任务。

* 确定性任务：在这类任务上，我们主要关注训练集和验证集上的损失是否同步在下降，以及训练多个 epoch 后loss 是否收敛。下图应该算是一个比较良好的训练过程，训练集和校验集损失同步下降，且训练集损失也接近收敛。

![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_5e85597711b799fbb438c7eae4c99090.png =2936x)

* 生成式任务：在这类任务上，我们还是主要依赖观察训练集上的损失以及真实评估集上的业务指标。因为某些时候，尽管校验集的 loss 损失没有明显的下降，但其实真实评估集上也可能有收益。这是因为，验证集上 loss 计算依赖 token 级别的KL散度损失，而真实评估集上并不需要输出分布和 label 完全一致。所以，对于这类任务，我们建议将训练集损失作为参考，以真实数据集上评估后的结论为准。

<span id="模型发布"></span>
# 模型发布
当模型 SFT 后，离线 loss 指标符合预期后，将模型发布到线上进行推理。模型发布参考[查看并管理模型精调任务](https://www.volcengine.com/docs/82379/1099460)
<span id="真实案例分享"></span>
# 真实案例分享
<span id="意图识别"></span>
## 意图识别
<span id="场景"></span>
### 场景
分类任务场景：基于用户和客服的对话，分类用户的具体意图。
<span id="过程"></span>
### 过程

* 0）客户首先建立了一份线上业务的标准评估集。基于prompt优化后，baseline模型（V0）达到X1%的准确率。
* 1）发现一些描述接近，但意图却明显相反的意图，模型很难分对。另一方面，如果再加一些 shots，会导致 prompt 过长，导致线上推理耗时增加，影响体验。因此，尝试构造 SFT 数据集。
* 2）根据线上流量回放，标注了400多道 SFT 数据集。先用少量精调后发现模型在评估集上的准确率达到了X2%，相比X1%有提升。因此，将全量 SFT 数据集进行精调后 V1 模型，线上准确率进一步提升。
* 3）后续从线上流量持续获取 SFT 数据集，继续在 V1 模型上增量精调后得到 V2 模型，进一步提升准确率。最终达到业务预期。

<span id="文案生成"></span>
## 文案生成
<span id="场景"></span>
### 场景
用户输入产品名称，需求描述，行业，标签等字段，产出具体符合用户需求的营销文案
<span id="过程"></span>
### 过程

* 0）首先从不同子维度（如风格，逻辑等），建立一份文案质量的评测标准，同时将已有数据按行业分层抽样，成SFT 训练集和评测集，其中评测集占比5%。基于初版SFT训练集得到 baseline 模型，其中文案整体通过率为 X1%
* 1）查看评测集 badcase，发现未通过文案主要集中于某些行业。从 SFT 数据中按行业进行分层抽样，对response 进行人评，发现评测集通过率低的行业对应的 SFT 训练集通过率也较低，所以重新对SFT数据集中对应行业的数据进行人工 review，去除掉未通过的训练数据
* 2）数据过滤后，重新进行 SFT，得到的新模型文案整体通过率为 X2%，相比 X1%有提升，其中在1）中对应行业的效果有明显提升

<span id="faq"></span>
# FAQ
<span id="如何构造-sft-数据集？"></span>
## 如何构造 SFT 数据集？
**数据质量重要性大于数据数量。**
1）收集足够量的 SFT 数据集，清洗掉错误、无效冗余、有歧义的 case，因为这样的数据可能会导致做完 SFT 之后，影响整体效果。
2）针对性地多收集一些模型反复出错的 badcase，洞察和分析找到共性后构造 SFT 数据集，并让 SFT 数据集的分布尽量接近 badcase 的分布，使得 SFT 数据集覆盖度足够广，能够最大程度解决掉 badcase。
<span id="怎么加快调参效率？"></span>
## 怎么加快调参效率？
**多存** **ckpt**、**控制变量调参。**
1）尽量在精调时多训几个 epoch，多存几个 ckpt，这样在服务发布时，可以选择性的发布不同 step 的 ckpt 来看模型表象。
2）尽量对于超参在不同阈值区间控制变量调参，找到调大或调小和指标的关系。
<span id="其他"></span>
# 其他
<span id="sft-过程-prompt-中-fewshots-按相关性采样的影响"></span>
## SFT 过程 prompt 中 fewshots 按相关性采样的影响

* 以文案生成任务举例，营销文案在不同渠道风格差异相差比较大，此时如果 SFT 数据量较少，可能会导致 LLM 无法细致地区分出来不同渠道的风格差异，在这种场景可以采取 few shots + SFT 的方式进行训练。具体思路如下：
   * 构造 SFT 数据时，假设某条数据的 response 为 push 场景的文案，那么在 few shots的选取中，如果选取其他场景，如社媒，直邮等场景的文案作为 few shots 的示例，那么风格无法对齐，会对结果造成比较大的干扰。因此在选取 few shots 时，尽量选择同场景的数据作为示例。
* 综上所述，在 SFT 数据量较少的情况下，第一步需要先找到场景在哪个维度上，response 分布的差异比较大，然后在构建 few shots SFT 数据时，尽量选取同个维度的优质数据作为 few shots 示例。

<span id="sft-数据集中-response-的多样性"></span>
## SFT 数据集中 response 的多样性

* 同样以文案生成任务举例，当我们希望同样的 prompt 生成出来的内容更多样时，我们可以：
   * 调大接口参数中的 temperature、top_p 等参数，引入多样性。比如 temperature 和 top_p 都可以调整到1.0。
   * 我们可以尝试在 SFT 数据集中，构造同样的输入 prompt，多样性的 response 数据。经测试后，模型输出多样性指标得到提升。




# RAG（检索增强）解决方案
Source: https://www.volcengine.com/docs/82379/1263276
**一、检索增强生成（Retrieval Augmented Generation，简称 RAG）是一种先进的自然语言处理技术，旨在进一步提升大语言模型的输出质量和可靠性。该技术通过整合信息检索功能，将用户查询与向量数据库进行精准匹配，从而为用户提供了更加准确和可信的答案，有效减轻了大型模型在生成回答时可能出现的“幻觉”现象。**
**二、以下是一些RAG常见的场景：**
**需要大量背景知识的任务**：当生成的文本需要依赖大量的背景知识或数据时，RAG可以通过检索相关信息来辅助生成过程。
**复杂查询的回答**：对于需要从大量数据中提取特定信息的复杂查询，RAG可以检索最相关的文档，并生成准确的回答。
**实时信息检索**：在需要根据最新数据快速生成回答的场景中，RAG可以结合实时检索的信息和生成模型来提供最新的回答。
**多轮对话系统**：在聊天机器人或虚拟助手中，RAG可以帮助系统根据对话历史和上下文检索相关信息，并生成合适的回复。
**长形式内容生成**：当需要生成长篇内容，如文章、报告或故事时，RAG可以从大量数据中检索相关信息来辅助内容的生成。
**事实核查和数据验证**：RAG可以用于生成准确无误的信息，通过检索可靠的数据源来支持生成的内容。
**个性化内容生成**：在需要根据用户的历史行为或偏好生成个性化内容时，RAG可以检索用户相关的信息，以生成更符合用户需求的内容。
**跨语言翻译和生成**：RAG可以用于生成特定语言的文本，通过检索和利用跨语言的数据来提高翻译的准确性和自然性。
**教育和培训**：在自动生成教育材料或提供个性化学习建议时，RAG可以检索相关的教育资源并生成定制化的内容。
**企业知识管理**：在企业环境中，RAG可以帮助员工快速找到所需的信息，通过检索企业内部的知识库并生成有用的回答。
**法律咨询**：RAG可以用于提供法律咨询，通过检索相关的法律条文和案例来生成法律建议
三、**下图显示了RAG与LLM配合的流程图：**
![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_8d1490c2754334829e942183c80c1f8c.png =4239x)
**三、我们的优势：**

* **提供毫秒级百亿规模的高性能检索，秒级流式知识库索引更新**
* **内嵌豆包向量化模型，是由字节跳动自主研发的语义向量化模型，是LLM知识库解决方案的配套工具，支持中、英双语**
* **支持向量数据实时写入、实时更新，支持实时索引、自动索引**
* **存算分离架构，单数据多场景，节约计算资源，提高在线稳定性，保证高可用性**


**四、推荐产品：**

* **向量数据库（Viking** **DB）：** [https://console.volcengine.com/vikingdb](https://console.volcengine.com/vikingdb)
* **豆包大模型可根据实际业务场景选择：**
   **Doubao 系列**：https://console.volcengine.com/ark/region:ark+cn-beijing/model?projectName=undefined&vendor=Bytedance&view=LIST_VIEW


**五、典型案例介绍：**
某保险客户为提高客服人效和对话体验，将原有人工客服升级为AI客服。在项目中，多轮对话记忆、问题分散且泛的问题在传统客服功能中难以实现，对话体验不够自然真实，RAG、角色设定等能力，大大提升了客服的用户体验，帮助坐席承接了约30%的咨询问题，提效显著。
![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_9ebf50478c3622749e306dc050f9453d.png =2983x)



# Function Calling 流式输出适配
Source: https://www.volcengine.com/docs/82379/1449722
Doubao 1.5 升级了流式输出中的返回，使所有返回结果都能以流式输出，其中包括Function Calling的返回。如果您业务中已使用了Function Calling 流式输出，您可以调整对返回信息的处理方式，适配原代码处理逻辑。
<span id="80da6e0d"></span>
# 升级前后对比
<span id="9384e05b"></span>
## 基本信息差异

| | | | \
|流式输出 |升级前 |升级后 |
|---|---|---|
| | | | \
|对应的模型名称 |`doubao-pro-**` |\
| |`doubao-lite-**` |`doubao-1.5-pro-**` |\
| | |`doubao-1.5-lite-**` |
| | | | \
|对应的模型版本 |241215 及之前 |250115及以后 |
| | | | \
|是否支持流式 |部分支持： |\
| | |\
| |* 支持：assistant的content流式返回。 |\
| |* 不支持：tool_calls 信息在一个chunk返回。 |是，支持`content`、`tool_calls` 字段内容流式返回。 |

<span id="0e33b99f"></span>
## 响应示例差异
<span id="d183fd4d"></span>
### 升级前
```Shell
ChatCompletionChunk(
    id="0217***",
    choices=[
        Choice(
            delta=ChoiceDelta(
                content="从前", function_call=None, role="assistant", tool_calls=None
            ),
            finish_reason=None,
            index=0,
        )
    ],
    created=1737882725,
    model="doubao-***",
    object="chat.completion.chunk",
)
ChatCompletionChunk(
    id="0217***",
    choices=[
        Choice(
            delta=ChoiceDelta(
                content="xxxx", function_call=None, role="assistant", tool_calls=None
            ),
            finish_reason=None,
            index=0,
        )
    ],
    created=1737882725,
    model="doubao-***",
    object="chat.completion.chunk",
)
...
ChatCompletionChunk(
    id="0217***",
    choices=[
        Choice(
            delta=ChoiceDelta(
                content="\n",
                function_call=None,
                role="assistant",
                tool_calls=[
                    ChoiceDeltaToolCall(
                        index=0,
                        id="call_leigeybrw25cwlk87byg8l3v",
                        function=ChoiceDeltaToolCallFunction(
                            arguments='{"prompt": "有道词典", "region": "CN"}',
                            name="AppFinder",
                        ),
                        type="function",
                    )
                ],
            ),
            finish_reason="tool_calls",
            index=0,
        )
    ],
    created=1737884441,
    model="doubao-***",
    object="chat.completion.chunk",
)
```

<span id="d183b693"></span>
### 升级后
```Shell
ChatCompletionChunk(
    id="0217***",
    choices=[
        Choice(
            delta=ChoiceDelta(
                content="从前", function_call=None, role="assistant", tool_calls=None
            ),
            finish_reason=None,
            index=0,
        )
    ],
    created=1737882725,
    model="doubao-1-5-***",
    object="chat.completion.chunk",
)
ChatCompletionChunk(
    id="0217***",
    choices=[
        Choice(
            delta=ChoiceDelta(
                content="xxxx", function_call=None, role="assistant", tool_calls=None
            ),
            finish_reason=None,
            index=0,
        )
    ],
    created=1737882725,
    model="doubao-1-5-***",
    object="chat.completion.chunk",
)
...
ChatCompletionChunk(
    id="0217***",
    choices=[
        Choice(
            delta=ChoiceDelta(
                content="", function_call=None, role="assistant", tool_calls=None
            ),
            finish_reason=None,
            index=0,
        )
    ],
    created=1737882725,
    model="doubao-1-5-***",
    object="chat.completion.chunk",
)
...
ChatCompletionChunk(
    id="0217***",
    choices=[
        Choice(
            delta=ChoiceDelta(
                content="", function_call=None, role="assistant", tool_calls=None
            ),
            finish_reason=None,
            index=0,
        )
    ],
    created=1737882725,
    model="doubao-1-5-***",
    object="chat.completion.chunk",
)
ChatCompletionChunk(
    id="0217***",
    choices=[
        Choice(
            delta=ChoiceDelta(
                content="",
                function_call=None,
                role="assistant",
                tool_calls=[
                    ChoiceDeltaToolCall(
                        index=0,
                        id="call_05i***",
                        function=ChoiceDeltaToolCallFunction(
                            arguments="", name="AppFinder"
                        ),
                        type="function",
                    )
                ],
            ),
            finish_reason=None,
            index=0,
        )
    ],
    created=1737882725,
    model="doubao-1-5-***",
    object="chat.completion.chunk",
)
...
ChatCompletionChunk(
    id="0217***",
    choices=[
        Choice(
            delta=ChoiceDelta(
                content="",
                function_call=None,
                role="assistant",
                tool_calls=[
                    ChoiceDeltaToolCall(
                        index=0,
                        id=None,
                        function=ChoiceDeltaToolCallFunction(arguments='"}', name=None),
                        type=None,
                    )
                ],
            ),
            finish_reason=None,
            index=0,
        )
    ],
    created=1737882725,
    model="doubao-1-5-***",
    object="chat.completion.chunk",
)
ChatCompletionChunk(
    id="0217***",
    choices=[
        Choice(
            delta=ChoiceDelta(
                content="", function_call=None, role="assistant", tool_calls=None
            ),
            finish_reason="tool_calls",
            index=0,
        )
    ],
    created=1737882725,
    model="doubao-1-5-***",
    object="chat.completion.chunk",
)
```

<span id="163d0d94"></span>
# 客户端代码适配示例
当您业务中使用之前版本的流式输出，且含有调用Function Calling，您希望切换到`doubao-1.5- *** 250115`及未来版本上来，您需对模型调用代码进行适当调整，以保障原业务代码正常运行。
以下是流式输出 Function Calling 升级前后的示例代码比较。
> 此代码不支持`n`字段。


| | | | \
|升级前后 |升级前 |升级后 |
|---|---|---|
| | | | \
|客户端处理代码示例 |```Python |\
| |import os |\
| |from volcenginesdkarkruntime import Ark |\
| |# 从环境变量中读取方舟API Key |\
| |client = Ark(api_key=os.environ.get("ARK_API_KEY")) |\
| |stream = client.chat.completions.create( |\
| |    model="ep-2025********", |\
| |    messages=[ |\
| |        { |\
| |            "role": "user", |\
| |            "content": "给我讲个故事，然后告诉我北京今天的天气", |\
| |        } |\
| |    ], |\
| |    tools=[ |\
| |        # 您要调用的工具信息 |\
| |        {...} |\
| |    ], |\
| |    stream=True, |\
| |) |\
| |tool_calls = [] |\
| |for chunk in stream: |\
| |    if not chunk.choices: |\
| |        continue |\
| |    print(chunk.choices[0].delta.content, end="") |\
| |    # 原先使用Function Call能力返回信息 |\
| |    if chunk.choices[0].delta.tool_calls: |\
| |        tool_calls.extend(chunk.choices[0].delta.tool_calls) |\
| | |\
| | |\
| | |\
| | |\
| |print("Tools: ", tool_calls) |\
| |``` |\
| | |```Python |\
| | |import os |\
| | |from volcenginesdkarkruntime import Ark |\
| | |# 从环境变量中读取方舟API Key |\
| | |client = Ark(api_key=os.environ.get("ARK_API_KEY")) |\
| | |stream = client.chat.completions.create( |\
| | |    model="ep-2025********", |\
| | |    messages=[ |\
| | |        { |\
| | |            "role": "user", |\
| | |            "content": "给我讲个故事，然后告诉我北京今天的天气", |\
| | |        } |\
| | |    ], |\
| | |    tools=[ |\
| | |        # 您要调用的工具信息 |\
| | |        {...} |\
| | |    ], |\
| | |    stream=True, |\
| | |) |\
| | |final_tool_calls = {} |\
| | |for chunk in stream: |\
| | |    if not chunk.choices: |\
| | |        continue |\
| | |    print(chunk.choices[0].delta.content, end="") |\
| | |    # 使用新版Function Call能力返回信息代码适配，将流式返回的信息拼装后返回 |\
| | |    for tool_call in chunk.choices[0].delta.tool_calls or []: |\
| | |        index = tool_call.index |\
| | |        if index not in final_tool_calls: |\
| | |            final_tool_calls[index] = tool_call |\
| | |        final_tool_calls[index].function.arguments += tool_call.function.arguments |\
| | | |\
| | |print("Tools: ", final_tool_calls) |\
| | |``` |\
| | | |\
| | | |




# Prefill Response模式最佳实践
Source: https://www.volcengine.com/docs/82379/1359497
在使用或调用大模型时，如果希望控制和引导模型的输出，可以通过预填（Prefill）部分`Assistant` 角色的内容，来引导和控制模型的输出。输出的控制可以应用在多个方面：强制按照 JSON 或 XML 等特定格式输出；跳过已生成的内容，避免触发模型最大输出限制；控制大模型在角色扮演场景中保持同一角色。
<span id="6352dc5c"></span>
## 适用模型范围
豆包语言大模型lite及pro系列，0828版本及以后。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1aa70f994bf0474eb0a16f6031edc45c~tplv-goo7wpa0wc-image.image =691x)
<span id="6eb2f599"></span>
## 主要用法
设置`messages`最后一个`role` 为`Assistant` ，模型会对`Assistant`已有的内容按照现有格式和内容进行续写。
```Python
...
messages=[
        {"role": "user", "content": "你是一个计算器，请计算： 1 + 1 "},
        # 最后Role为Assistant
        {"role": "assistant", "content": "="},
        ]
...
```

> 续写即内容继续写作，输出内容不会包括用户填充的部分。

<span id="aec36e50"></span>
## 效果对比


| | | \
|模式 |示例 |
|---|---|
| | | \
|普通模式 |\
| |模型调用示例代码 |\
| |```Python |\
| |import os |\
| |from volcenginesdkarkruntime import Ark |\
| | |\
| |client = Ark(api_key=os.environ.get("ARK_API_KEY")) |\
| |completion = client.chat.completions.create( |\
| |    # 你的Endpoint ID |\
| |    model="ep-2024****-**zpz", |\
| |    messages=[ |\
| |        {"role": "user", "content": "你是一个计算器，请计算： 1 + 1 "}, |\
| |    ] |\
| |) |\
| |print(completion.choices[0].message.content) |\
| |``` |\
| | |\
| |模型输出示例 |\
| |```Shell |\
| |1+1等于2。 |\
| |``` |\
| | |
| | | \
|Prefill Response模式 |模型调用示例代码 |\
| |```Python |\
| |import os |\
| |from volcenginesdkarkruntime import Ark |\
| | |\
| |client = Ark(api_key=os.environ.get("ARK_API_KEY")) |\
| |completion = client.chat.completions.create( |\
| |    # 你的Endpoint ID |\
| |    model="ep-2024****-**zpz", |\
| |    messages=[ |\
| |        {"role": "user", "content": "你是一个计算器，请计算： 1 + 1 "}, |\
| |        # 最后Role为Assistant |\
| |        {"role": "assistant", "content": "="} |\
| |    ] |\
| |) |\
| |print(completion.choices[0].message.content) |\
| |``` |\
| | |\
| |模型输出 |\
| |```Shell |\
| |2 |\
| |``` |\
| | |


---


接下来，对于几种典型使用场景进行举例说明。
<span id="326707ce"></span>
## 场景1：改善输出格式
由于模型自身会基于自己的理解去响应用户的请求，会导致输出无法直接被其他程序解析。可以通过预填充 `{` 符号，引导模型跳过一些场景回复，直接输出 JSON 对象，会让回答更加简洁和工整，可以被其他程序更好地解析。
示例：

| | | \
|模式 |示例 |
|---|---|
| | | \
|普通模式 |调用示例代码 |\
| |```Python |\
| |import os |\
| |from volcenginesdkarkruntime import Ark |\
| | |\
| |client = Ark(api_key=os.environ.get("ARK_API_KEY")) |\
| |completion = client.chat.completions.create( |\
| |    # 你的Endpoint ID |\
| |    model="ep-2024****-**", |\
| |    messages=[ |\
| |        {"role": "user", "content": "用 JSON 描述豆包模型的name和function"} |\
| |    ] |\
| |) |\
| |print(completion.choices[0].message.content) |\
| |``` |\
| | |\
| |模型输出预览 |\
| |````Shell |\
| |以下是一个简单的 JSON 示例来描述豆包模型的名称和功能： |\
| | |\
| |```json |\
| |{ |\
| |  "name": "豆包", |\
| |  "function": [ |\
| |        "回答各种各样的知识类问题，包括但不限于科学知识（如物理、化学、生物等）、历史事件、文化传统、地理信息等", |\
| |        "提供关于语言学习方面的帮助，如语法解释、词汇辨析、翻译建议等", |\
| |        "对各种创意性话题进行讨论，例如给出故事创意、艺术创作的思路等", |\
| |        "解答生活常识问题，像家居维修建议、健康生活小贴士等" |\
| |    ] |\
| |} |\
| |``` 当然，您可以根据更详细和具体的需求来进一步完善和扩展这个 JSON 描述。 |\
| |```` |\
| | |\
| |:::tip |\
| |该内容因为一些多余的内容，会导致无法直接被 JSON 解析。 |\
| |::: |
| | | \
|Prefill Response模式 |模型调用示例代码 |\
| |```Python |\
| |import os |\
| |from volcenginesdkarkruntime import Ark |\
| | |\
| |client = Ark(api_key=os.environ.get("ARK_API_KEY")) |\
| |completion = client.chat.completions.create( |\
| |    # 你的Endpoint ID |\
| |    model="ep-****-**", |\
| |    messages=[ |\
| |        {"role": "user", "content": "用 JSON 描述豆包模型的name和function"}, |\
| |        {"role": "assistant", "content": "{"}, |\
| |    ] |\
| |) |\
| |print(completion.choices[0].message.content) |\
| |``` |\
| | |\
| |:::tip |\
| |使用 Prefill Response 进行预先填充 `{` 符号。 |\
| |::: |\
| |模型输出预览 |\
| |```Shell |\
| |  "name": "豆包", |\
| |  "function": [ |\
| |        "回答各种各样的知识类问题，包括但不限于科学知识（如物理、化学、生物等）、历史事件、文化传统、地理信息等", |\
| |        "提供关于语言学习方面的帮助，如语法解释、词汇辨析、翻译建议等", |\
| |        "对各种创意性话题进行讨论，例如给出故事创意、艺术创作的思路等", |\
| |        "解答生活常识问题，像家居维修建议、健康生活小贴士等" |\
| |    ] |\
| |} |\
| |``` |\
| | |\
| |:::tip |\
| |和前置的`Assistant`内容组合成JSON格式的内容。 |\
| |::: |

<span id="86e2746a"></span>
### 注意事项
由于模型具有一定的随机性，使用该方法也无法 100% 保证回复能被 JSON 解析器解析，您可以使用针对大模型生成的 JSON 内容进行修复的方法。下面是一个示例，您可以使用社区的 [json_repair](https://github.com/mangiucugna/json_repair) 库来进行兜底解析。
```Python
import os
from volcenginesdkarkruntime import Ark
import json
# 通过命令 pip install json-repair 安装json_repair库
import json_repair

PREFILL_PRIFEX = "{"
client = Ark(api_key=os.environ.get("ARK_API_KEY"))
completion = client.chat.completions.create(
    # 你的Endpoint ID
    model="ep-2024****-**",
    messages=[
        {"role": "user", "content": "用 JSON 描述豆包模型的名称和功能"},
        {"role": "assistant", "content": PREFILL_PRIFEX},
    ]
)
# 拼接 PREFILL_PRIFEX 和模型输出
json_string = PREFILL_PRIFEX + completion.choices[0].message.content
# 解析 JSON Object
obj = {}
try:
    obj = json.loads(json_string)
except json.JSONDecodeError as e:
    obj = json_repair.loads(json_string)

print(obj)
```

<span id="061ea91c"></span>
## 场景2：跳过已生成的文本
使用 Prefill Response 模式让大模型跳过已生成的文本，实现输出超长内容。
```Python
import os
from volcenginesdkarkruntime import Ark

client = Ark(api_key=os.environ.get("ARK_API_KEY"))
messages = [
    {"role": "user", "content": '''请翻译下面的文本为英文：****** '''},
    {"role": "assistant", "content": ""}
]
ark_model="ep-2024****-**"
completion = client.chat.completions.create(
    model=ark_model,
    messages=messages
)
# 初始化循环计数器
loop_count = 0
max_loops = 20  # 设置最大循环次数为20

# 触发因为输出长度限制，循环生成 assistant 回复
while completion.choices[0].finish_reason == "length":
    messages[-1]["content"] += completion.choices[0].message.content
    completion = client.chat.completions.create(
        model=ark_model,
        messages=messages
    )    
    # 增加计数器
    loop_count += 1    
    # 检查是否超过最大循环次数
    if loop_count >= max_loops:
        print(f"警告：已达到最大循环次数 {max_loops}，停止生成内容")
        break

# 不管是否触发 finish_reason == "length"，都返回最后一条回复
messages[-1]["content"] += completion.choices[0].message.content
print(messages[-1]["content"])
```

:::tip
增加了循环次数限制，防止模型循环输出等特殊情况，您可以根据业务自行调整。
:::
<span id="67a91ed5"></span>
## 场景3：增强角色扮演一致性
我们通常使用 System 来设置角色的一些信息，但是随着对话轮次的增多，模型可能会跳脱出角色的约束，通过 Prefill Response 模式，可以使的每一轮对话都提醒模型当前的角色，保证模型扮演角色的一致性。
```Python
import os
from volcenginesdkarkruntime import Ark

client = Ark(api_key=os.environ.get("ARK_API_KEY"))
ark_model="ep-2024****-**"
messages = [
    {"role": "system", "content": "下面是一个西游记中的场景，请按照指定的角色来进行对话，每轮对话只用回复当前角色的内容，不要再回复新的内容。：\n\n唐僧师徒离了五庄观，又走了一个多月，来到一座大山前。悟空一看，四周崇山峻岭，杂草丛生，山势十分险恶。"},
    {"role": "assistant", "content": "悟空说："}
]
completion = client.chat.completions.create(
    model=ark_model,
    messages=messages
)
print(messages[-1]['content']+completion.choices[0].message.content)
```

模型输出示例：
```Shell
悟空说：“师父，这山看起来险恶得很，俺老孙先去探探路，你们且在此等候。”
```

您也可以通过变更`messages`最后消息，实现角色切换。
```Python
...
messages[-1] = {"role": "assistant", "content": "唐僧说："}
completion = client.chat.completions.create(
    model=ark_model,
    messages=messages
)
print(messages[-1]['content']+completion.choices[0].message.content)
```

模型输出示例：
```Shell
唐僧说：“悟空，此山看起来甚是险恶，你定要小心查看，莫要着了妖怪的道。”
```





# 在应用中使用 RTC 实现 AI 实时对话
Source: https://www.volcengine.com/docs/82379/1393085
火山引擎的实时对话式 AI场景方案，让人与 AI 的交互不再局限于文字，还能进行自然、流畅、真人感的实时语音对话，可应用于 AI 智能助手、AI 客服、AI 陪伴、AI 口语教学、AI 游戏 NPC、智能硬件等场景。
![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_4d24d5a9acbe935d0b02046a6e0e440b.gif =550x)
<span id="bff1d40b"></span>
## Demo 体验
你可直接访问 [Web Demo](https://demo.volcvideo.com/aigc/login?from=doc) 快速体验实时对话式 AI 交互能力。
<span id="a4e6f0ce"></span>
## 技术架构
火山引擎实时对话式 AI场景方案，通过火山引擎 RTC 实现音视频数据的高效采集、自定义处理和超低时延传输。在云端，提供了智能音视频处理模块，包括音频 3A、AI降噪和抽帧截图等能力，以减少环境噪音和设备性能对对话式 AI 体验的影响。此外，方案搭载火山方舟大模型服务平台，深度整合语音识别（ASR）、语音合成（TTS）、大语言模型（LLM）和知识库 RAG 等服务，简化语音到文本及文本到语音的转换过程，提供强大的智能对话、自然语言处理和多模态交互能力，助力应用快速实现用户与云端大模型之间的实时语音通话和多模态交互。
![Image](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_dde35514224c18bc3aa01f3220e65a1a.jpg =3122x)
<span id="270ecbab"></span>
## 功能特性

* **基础功能**


| | | \
|功能 |说明 |
|---|---|
| | | \
|**AI 实时语音对话** |与 AI 进行自然流畅的实时语音对话，如同与真人交流，支持随时插话打断。 |
| | | \
|**智能打断** |提供手动、自动打断多种方法。在对话过程中，用户可以随时打断 AI 的语音输出，实现双向互动。 |
| | | \
|**降噪** |结合 RTC 先进的音频 3A 技术和深度学习的 AI 降噪算法，能够兼顾强降噪与高保真，确保在嘈杂的环境中有效去除背景噪音，保留清晰的人声。 |
| | | \
|**语音识别** |将用户语音实时转写为文本，供大模型分析理解、生成字幕等。 |
| | | \
|**大模型处理** |解析输入文本，并生成语义响应，驱动智能体对话逻辑。 |
| | | \
|**语音合成** |将大模型生成的文字回复转化为语音，供 RTC 播放。 |


* **进阶功能**


| | | \
|功能 |说明 |
|---|---|
| | | \
|**实时字幕** |实时将用户和 AI 的对话内容转化为文字，显示在终端界面上。具体实现方式，请参见 [实时字幕](https://www.volcengine.com/docs/6348/1337284)。 |
| | | \
|**控制播放内容** |需要智能体将 LLM 返回的内容处理后进行播报，如过滤细节信息，过滤 Markdown 标签，将 Latex 公式转换为自然语言等。具体实现方式，请参见 [过滤指定内容](https://www.volcengine.com/docs/6348/1350596)。 |
| | | \
|**Function calling** |允许大模型识别用户对话中的特定需求，并在内容的过程中调用外部函数或 API，来执行它自身无法独立完成的任务，如处理实时数据检索、文件处理、数据库查询等。通过这种方式，AI 智能体能够精确回答特定领域的问题，如天气查询、股票行情查询、数学计算等，扩展了 AI 智能体的服务能力和应用场景。具体实现方式，请参见 [Function calling](https://www.volcengine.com/docs/6348/1554654)。 |
| | | \
|**集成自研或第三方大模型** |如果需要实现更贴合特定需求的对话效果，可以将自研或第三方大模集成到对话式 AI 工作流中。具体实现方式，请参见 [对话式 AI 第三方大模型接口验证](https://www.volcengine.com/docs/6348/1399966)。 |
| | | \
|**实时视频互动** |在与 AI 进行实时交互时，除了语音互动外，还可以通过视觉理解让智能体能够感知用户周围的环境以及用户的行为，实现与 AI 进行实时视频互动。具体实现方式，请参见 [视觉理解能力](https://www.volcengine.com/docs/6348/1408245)。 |
| | | \
|**接收状态变化消息** |实时获取智能体任务的状态变化消息，以便在业务端及时进行后续处理或保证业务的稳定性。具体实现方式，请参见 [接收状态变化消息](https://www.volcengine.com/docs/6348/1415216)。 |
| | | \
|**自定义语音播放** |驱动智能体主动播报自定义文本内容，播放安抚语、引导客户互动等。具体实现方式，请参见 [自定义语音播放](https://www.volcengine.com/docs/6348/1449206)。 |
| | | \
|**自定义大模型上下文** |传入自定义上下文信息代替用户输入或增加背景信息，以帮助大模型更准确地理解用户状态。具体实现方式，请参见 [自定义大模型上下文](https://www.volcengine.com/docs/6348/1511926)。 |
| | | \
|**配置对话触发模式** |提供手动触发和自动触发两种触发方式，可灵活配置新一轮对话的触发时机，实现更精细的交互体验。具体实现方式，请参见 [配置对话触发模式](https://www.volcengine.com/docs/6348/1544164)。 |

<span id="be81aea4"></span>
## 方案优势

* **交流自然、随时打断**
   * **智能打断**：支持全双工通信及音频帧级别的人声检测（VAD），随时插话打断，交流更自然。
   * **端上降噪**：通过 RTC SDK 实现对复杂环境的音频降噪能力，有效降低背景噪音、背景音乐的干扰，提高用户语音打断的准确性。
* **实时秒回、通话流畅**
   * **超低时延**：基于全链路流式处理，RTC+ASR+LLM+TTS 整体链路时延缩短至 1 秒。
   * **抗弱网**：通过智能接入、RTC 云端协同优化，在复杂和弱网环境下确保低延时和传输可靠性，避免因丢字引起大模型理解错误。
* **灵活扩展**
   * **多人交互**：从 1v1 交互扩展至 1v多的 AI 实时交互。
   * **视频交互**：从纯音频对话扩展至音视频 AI 实时交互。
* **快速接入、易集成**

一站式集成，企业只需调用标准的 OpenAPI 接口即可配置所需的 ASR、LLM 和 TTS 服务，快速实现 AI 实时交互应用。

* **跨端兼容**
   * **多平台支持**：支持 iOS、Android、Windows、Linux、macOS、Web、Flutter、Unity、Electron 和微信小程序多端，满足不同场景的应用需求。
* **多语种互动**
   * **多语种支持**：支持中、英、日、西等多种语言实时对话。

<span id="2a5e7453"></span>
## 应用场景

| | | \
|应用场景 |说明 |
|---|---|
| | | \
|智能客服 |提供 7x24 小时自动化客户服务，支持自然流畅的多轮对话、随时打断与智能转接，有效降低人力成本，提升客户满意度。 |
| | | \
|口语教学与陪练 |模拟真实对话环境，提供多语种的实时发音评估、语法纠错和互动式教学，帮助用户高效提升口语能力。 |
| | | \
|虚拟社交 |提供拟人化的情感交流和心理疏导，通过自然对话缓解用户孤独感，满足日益增长的情感支持需求。 |
| | | \
|智能硬件 |AI 嵌入各类智能硬件，实现便捷的语音控制、智能看护、智能陪伴互动和基于用户习惯的个性化服务。 |

<span id="2b32d8b5"></span>
## 计费说明
实时对话式 AI 费用由多个计费项组成，每个计费项均提供了免费试用额度。详细说明，请参见[对话式 AI 实时计费](https://www.volcengine.com/docs/6348/1392584)。
<span id="941e484f"></span>
## 快速使用

* [无代码跑通实时对话式 AI Demo](https://console.volcengine.com/rtc/guide?)
* [体验开源 Demo](https://github.com/volcengine/rtc-aigc-demo)


# 三方工具调用说明
Source: https://www.volcengine.com/docs/82379/1463945
您可以使用三方工具来调用火山方舟的模型服务，这里列出一些当前验证过的三方工具，供您快速判断使用什么工具进行调用。
<span id="e154983e"></span>
# 常见三方工具支持情况
:::warning
* 下述信息截止至2025年2月20日。
* 因工具自身持续演进迭代，是否能够支持调用方舟模型服务API，请以您实际验证结果为准，此处信息仅供您参考。
:::
配置前请先完成： [获取API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%22PageSize%22%3A10%2C%22PageNumber%22%3A3%2C%22Filter%22%3A%7B%7D%7D&projectName=default) > [选择模型并获取Model ID](https://www.volcengine.com/docs/82379/1330310#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90) > [开通所需的模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。

| | | | \
|工具名称 |\
|<div style:"width=100px"></div> |是否成功调用 |\
| |<div style:"width=350px"></div> |配置说明 |\
| | |<div style:"width=500px"></div> |
|---|---|---|
| | | | \
|[Chatbox AI](https://chatboxai.app/zh)  |* 可成功调用方舟[文本生成](https://www.volcengine.com/docs/82379/1330310#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90)模型。 |\
| |* 成功调用方舟的应用（Bot）。 |\
| | |\
| |> 正常使用联网插件，具备联网能力。 |配置模型服务时，下面是几个核心配置： |\
| | | |\
| | |* `API Provider`：OpenAI Compatible |\
| | |* `Base URL`：https://ark.cn-beijing.volces.com/api/v3 |\
| | |* `Model`：您需要模型对应的Model ID，[点击这里](https://www.volcengine.com/docs/82379/1330310#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90)可查询。 |\
| | | |\
| | |配置应用（Bot）时，下面是几个核心配置： |\
| | | |\
| | |* `API Provider`：OpenAI Compatible |\
| | |* `Base URL`：https://ark.cn-beijing.volces.com/api/v3/bots/ |\
| | |* `Model`：Bot ID，可参考[零代码应用操作指南](https://www.volcengine.com/docs/82379/1267885)创建应用，并在[此页面](https://console.volcengine.com/ark/region:ark+cn-beijing/assistant)获取Bot ID。 |\
| | | |\
| | |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7c40869ef1df469bab4c4f6ab44eb541~tplv-goo7wpa0wc-image.image =235x) |
| | | | \
|[CherryStudio](https://cherry-ai.com) |* 可成功调用方舟[文本生成](https://www.volcengine.com/docs/82379/1330310#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90)模型。 |\
| |* 成功调用方舟的应用（Bot）。 |\
| | |\
| |> 正常使用联网插件，具备联网能力。 |配置模型服务时，可以参考[Cherry Studio官方教程](https://docs.cherry-ai.com/pre-basic/providers/doubao?open_in_browser=true)。 |\
| | |> 可直接通过Model ID调用。 |\
| | | |\
| | |配置应用（Bot）时，下面是几个核心配置： |\
| | | |\
| | |* `API 地址`：https://ark.cn-beijing.volces.com/api/v3/bots/ |\
| | |* `模型 ID`：Bot ID，可参考[零代码应用操作指南](https://www.volcengine.com/docs/82379/1267885)创建应用，并在[此页面](https://console.volcengine.com/ark/region:ark+cn-beijing/assistant)获取Bot ID。 |\
| | | |\
| | |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7c40869ef1df469bab4c4f6ab44eb541~tplv-goo7wpa0wc-image.image =235x) |\
| | | |
| | | | \
|[Roo Code](https://github.com/RooVetGit/Roo-Code) |* 可成功调用方舟[文本生成](https://www.volcengine.com/docs/82379/1330310#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90)模型。 |配置模型服务时，请注意选择，下面是几个核心配置： |\
| | | |\
| | |* `API Provider`：OpenAI Compatible |\
| | |* `Base URL`：https://ark.cn-beijing.volces.com/api/v3 |\
| | |* `Model ID`：见左栏 |
| | | | \
|[Continue](https://www.continue.dev/) |* 可成功调用方舟[文本生成](https://www.volcengine.com/docs/82379/1330310#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90)模型。 |需在配置文件`config.json`的`models`字段里直接添加配置： |\
| | |{ |\
| | |    "title": "<服务点名称>", |\
| | |    "provider": "openai", |\
| | |    "apiKey": "<ARK_API_KEY>", |\
| | |    "model": "<你所需模型的Model ID>", |\
| | |    "apiBase": "https://ark.cn-beijing.volces.com/api/v3" |\
| | |} |
| | | | \
|[Cline](https://cline.bot/) |可成功调用方舟的部分模型，`Model ID`如下： |\
| | |\
| |* deepseek-r1-250120 |\
| |* deepseek-v3-241226 |\
| |* doubao-1.5-vision-pro-32k-250115 |\
| | |\
| |> 正常使用视觉理解模型的理解图片能力。 |\
| | |\
| | |\
| |* doubao-vision-lite-32k-241015 |\
| | |\
| |> 正常使用视觉理解模型的理解图片能力。 |\
| | |\
| | |配置模型服务时，请注意下面几个核心配置： |\
| | | |\
| | |* `API Provider`：OpenAI Compatible |\
| | |* `Base URL`：https://ark.cn-beijing.volces.com/api/v3 |\
| | |* `Model ID`：见左栏。 |
| | | | \
|[Open WebUI](https://openwebui.com/) |* 成功调用调用方舟[文本生成](https://www.volcengine.com/docs/82379/1330310#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90)、[视觉理解](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3)模型。 |\
| | |\
| |> 正常使用视觉理解模型的理解图片能力。 |\
| | |\
| | |\
| |* 成功调用方舟的应用（Bot）。 |\
| | |\
| |> 正常使用联网插件，具备联网能力。 |管理员配置（左下角 Settings > Admin Settings > Connections > Open API- Add Connection）模型服务/应用（Bots）时，请注意下面几个核心配置： |\
| | |配置模型服务 |\
| | | |\
| | |* `URL`：https://ark.cn-beijing.volces.com/api/v3 |\
| | | |\
| | |> 这里点击右侧测试按钮时会显示失败，但是不影响使用。 |\
| | | |\
| | | |\
| | |* `Model IDs`：调用模型服务：见左栏。 |\
| | | |\
| | |配置应用（Bots） |\
| | | |\
| | |* `URL`：https://ark.cn-beijing.volces.com/api/v3/bots/ |\
| | | |\
| | |> 这里点击右侧测试按钮时会显示失败，但是不影响使用。 |\
| | | |\
| | | |\
| | |* `Model IDs`：Bot ID，可参考[零代码应用操作指南](https://www.volcengine.com/docs/82379/1267885)创建应用，并在[此页面](https://console.volcengine.com/ark/region:ark+cn-beijing/assistant)获取Bot ID。 |\
| | | |\
| | |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7c40869ef1df469bab4c4f6ab44eb541~tplv-goo7wpa0wc-image.image =235x) |\
| | | |
| | | | \
|[Cursor](https://www.cursor.com/)  |未成功调用。 |\- |







# 数据回流操作流程
Source: https://www.volcengine.com/docs/82379/1528785
<span id="6eda430e"></span>
## **概述**  
数据回流功能支持将 **自定义推理接入点** （不支持预置推理接入点）的调用数据（含 request 与 response）全程加密投递至 AI 数据湖服务中。您的数据仅归您所有、仅您可见、仅您可用，未经授权平台不会存储或使用。调用推理服务后，数据可见可能存在 10 分钟延迟。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/dc57ca96064d4965bb60e9afe883f637~tplv-goo7wpa0wc-image.image =1704x)
<span id="eae59a51"></span>
## **开启数据投递**  
<span id="e0628674"></span>
### **前提条件**  

* **权限要求**：具备方舟 Standard 及以上权限。  
* **服务开通**：已开通 TOS 对象存储与 AI 数据湖服务（可在方舟控制台一键开通）。  

<span id="4f5328e6"></span>
### **操作步骤**  

* **创建推理接入点时开启**：在推理接入点配置页面勾选 **数据投递** 选项。  

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cabf3e1949ad4cbbba62c727c346ad85~tplv-goo7wpa0wc-image.image =886x)

* **为推理接入点开启**：进入推理接入点详情页，启用数据投递功能。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/921c8ff459ae471c857c5a6a424bc37f~tplv-goo7wpa0wc-image.image =1387x)
<span id="d15d1a1f"></span>
## **数据集创建与筛选**  
<span id="80402c75"></span>
### **数据筛选**  
在 **数据集 > 我的数据湖** 页面，通过“调用日期、模型版本、推理接入点  ”等筛选条件在全量数据中筛选出所需的数据范围，您可将筛选出数据采样并创建为数据集，用于模型精调等场景。
如有进阶数据筛选、处理、分析等需求，可参考 [AI 数据湖进阶操作](https://www.volcengine.com/docs/82379/1528785#f7ffdf50)。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e6be1334b4fe4e0aa5985f35009b0cd3~tplv-goo7wpa0wc-image.image =2880x)

<span id="e39e792e"></span>
### **数据集创建流程**  

1. **开始创建**：点击「创建为数据集」进入配置页。  
2. **数据采样策略**：  
   * **按比例采样**：输入采样百分比（如 20%），从全量数据中随机抽取对应比例样本。  
   * **按数据量采样**：指定样本数量（如 10,000 条），按时间顺序或随机抽取固定数量数据。  
3. **数据集配置**：  
   * 选择 **新建数据集** 或 **已有数据集新版本**。
   * 数据格式强制选择 **SFT 精调** 。
4. **确认创建**：核对筛选条件与采样策略，提交后等待数据集生成。  

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7e76d35026534644881ecfd779218d46~tplv-goo7wpa0wc-image.image =941x)
<span id="f7ffdf50"></span>
## AI 数据湖进阶操作
<span id="8dd0ee77"></span>
### 查看推理结果集

1. 通过 API 调用推理接入点后，数据自动以结构化形式入库至 **我的数据湖**。进入**火山方舟** **>** **数据集** **>** **我的数据湖** 以查看调用详情。

<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b9cf58ce5b6b4687a06716a31bdadee6~tplv-goo7wpa0wc-image.image" width="2940px" /></div>


2. 单击 **前往AI 数据湖服务编辑数据**，进入 **LAS 控制台 >** **数据集 > 推理数据集**，查看对应 **推理数据集**。

<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/647dc7af39fd49c09986e313e4af1259~tplv-goo7wpa0wc-image.image" width="2940px" /></div>

<span id="f852e193"></span>
### SQL 查询与导出

1. 单击目标数据集的名称进入详情页，选择 **SQL 查询**进行数据探查。

<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2bc957170d2c446d9044929c7ec3e09e~tplv-goo7wpa0wc-image.image" width="2940px" /></div>


2. 如图所示，您可在左下角回顾**历史查询**，也可选择 **SQL** **模板**进行快速查询。您只需选择相应模板并运行查询，即可轻松获得准确结果。同时，点击右上角的**全屏预览**可进入沉浸式浏览。 

<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0cf581917d04476d96bd5f438a5c81c4~tplv-goo7wpa0wc-image.image" width="872px" /></div>


3. SQL 查询结果支持导出至**新数据集（LAS）、对象存储（TOS）以及火山方舟数据集**，您只需要在查询完成后单击**导出查询结果**，并配置相关参数。注意，此处导出**新数据集（LAS）**为**推理数据集**而非**通用数据集**。

<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2ea788da511f45c491c6bb00e6d113e5~tplv-goo7wpa0wc-image.image" width="1260px" /></div>

<span id="aa1400f9"></span>
### 导出推理数据集

1. LAS 支持将 **推理数据集** 直接导出至方舟数据集以发起模型精调，同时也支持 SQL 查询结果直接导出至方舟。
2. 选择目标数据集或者 SQL 执行结果数据集，单击**导出查询结果**。勾选导出至**火山方舟**。

<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/599719940612454aa8a284a2f147e735~tplv-goo7wpa0wc-image.image" width="1120px" /></div>


| | | \
|**数据集名称** |导出数据集名称与当前推理数据集保持相同 |
|---|---|
| | | \
|**导出字段** |可选，**全部字段** 和 **指定字段**。选择 **指定字段** 以选择列名，支持导出特定列下的数据 |
| | | \
|**导出至** |可选，此处勾选 **火山方舟** |
| | | \
|**导出格式** |.jsonl |
| | | \
|**方舟数据集类型** |目前支持 **文本生成-SFT 精调**，详情可见[模型精调数据集格式说明](https://www.volcengine.com/docs/82379/1099461) |
| | | \
|**数据格式** |目前支持 **文本生成-SFT 精调**，详情可见[模型精调数据集格式说明](https://www.volcengine.com/docs/82379/1099461) |


3. 单击 **开始导出** 完成操作。

<span id="0a3c5873"></span>
## **发起模型精调任务**  
在控制台「模型精调」模块，点击「创建精调任务」进入配置界面。  
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4c1689b193064df6b450608652733d34~tplv-goo7wpa0wc-image.image =1381x)
创建任务时注意以下几项配置：

* **训练类型**：选择「SFT 精调」  
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/313bcaeb71fe42eba5cd1a1c11cf1065~tplv-goo7wpa0wc-image.image =1211x)
* **数据集选择**：从下拉列表中选择步骤 3 生成的数据集版本  
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1080259fe347439981d7fd6742430738~tplv-goo7wpa0wc-image.image =1480x)

其他配置请参考[创建模型精调任务](https://www.volcengine.com/docs/82379/1099459)完成。
精调完成后，模型将作为「自定义模型」导出到「模型仓库」。
<span id="11c45799"></span>
### **参考文档**  

* [创建模型精调任务](https://www.volcengine.com/docs/82379/1099459)
* [SFT 最佳实践](https://www.volcengine.com/docs/82379/1221664)

<span id="398bc829"></span>
## **精调模型使用**  
<span id="45acc12f"></span>
### **在线推理部署**  
为了通过 API 调用、控制台在线测试、批量推理等方式使用精调后的模型，可以在「在线推理」模块「自定义推理接入点」创建推理接入点。
请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)获取推理接入点，**注意模型要选择模型仓库中的精调模型。**
<span id="467000b7"></span>
### **模型评测**  
参考[创建模型评测任务](https://www.volcengine.com/docs/82379/1153149)新建评测任务  ，关联目标模型的推理接入点进行评测。
任务启动后，可在评测任务列表中查看任务的运行状态和评测进度。每个模型都有属于该模型的单独评测任务，以便进行独立或组合查看。
任务完成后，可以在任务详情页点击「评测报告」，查看当前模型在选择的能力维度下的单项得分和综合得分。每个能力维度下，可分别查看该能力项中各个数据集的得分。



# 如何设置控制台登录保持时间
Source: https://www.volcengine.com/docs/82379/1515355
如您遇到需要频繁登录的问题，您可以通过设置当前账号的登录态保持时间来解决。火山方舟控制台当前支持登录状态保持最多 48 小时（2880分钟）。

> * 账号的安全操作属于敏感操作，过程中将会被要求进行操作保护的二次校验，需要使用MFA、安全手机或安全邮箱进行验证。
> * 根据企业的安全管控需求不同，部分企业的子账号可能无法设置此功能，请与您的管理员联系。

<span id="dcb089ca"></span>
## 主账号设置
当您的登录身份为主账号时，您可前往[账号管理-安全设置](https://console.volcengine.com/user/security/)修改当前账号的规则。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ce1ad7cec2a34225bd347235fe406de9~tplv-goo7wpa0wc-image.image =1313x)
<span id="37c4dccd"></span>
## 子账号设置
当您的登录身份为子账号时，您可前往[访问控制-用户管理-安全设置](https://console.volcengine.com/iam/identitymanage/settings)修改子用户的登录会话设置，操作同上。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5a6419b16d934dc4b482c5b5a33531ca~tplv-goo7wpa0wc-image.image =1382x)
> 如果您无法访问[访问控制-用户管理-安全设置](https://console.volcengine.com/iam/identitymanage/settings)页面，可能是主账号屏蔽了部分安全规则，请联系您的主账号管理员。




# 通过火山方舟使用 MLP 推理服务
Source: https://www.volcengine.com/docs/82379/1584258
火山方舟提供丰富的大模型调用服务，如 Doubao 系列大语言模型、深度思考模型、视觉理解模型，DeepSeek 系列开源模型等。如果您希望使用自定义模型或其他三方开源模型，可以使用 [机器学习平台 MLP](https://console.volcengine.com/ml-platform/region:ml-platform+cn-beijing/dashboard?guideTab=mlDevelopment) 部署您的模型，然后注册至方舟平台进行调用。本文介绍为您如何通过火山方舟使用 MLP 推理服务。
<span id="f322b8fe"></span>
## 使用场景
<span id="b0c62ecc"></span>
#### **对于 MLP 用户，使用火山方舟可增强已有 MLP 模型服务能力，保障企业级AI应用落地**。

* **多接入点分流**：一个 MLP 在线服务，支持在方舟侧创建多个推理接入点 Endpoint ，方便业务方按照 Endpoint 限流，实现业务分流（如大促流量调度、服务等级区分等）。
* **评测与迭代**：接入点一键评测，对比性能（响应速度、准确率），辅助模型优化。
* **权限管控**：支持 IAM、API key、项目、标签维度权限管理，细粒度控制模型访问，保障安全合规。

<span id="0858d898"></span>
#### 对于方舟侧用户，使用 MLP 可扩展模型种类，并获得方舟的统一集成体验。

* **开放部署**：支持调用更多的三方开源 / 自定义模型，火山方舟本身不会产生额外费用。
* **统一集成**：通过方舟统一域名与 API 调用，前端无需适配多模型，简化开发（如 AIGC 应用切换模型仅需修改 Endpoint ID）。

<span id="fa107209"></span>
## 支持能力
MLP 推理服务可使用的火山方舟功能如下：

| | | | \
|类别 |功能/特性 |说明 |
|---|---|---|
| | | | \
|在线推理 |API 调用 |通过 Endpoint ID 调用您的 MLP 推理服务， Endpoint ID 格式为`ep-s-xxx`。 |
|^^| | | \
| |支持模型 |MLP 推理服务（当前仅支持文本生成和深度思考大语言模型） |
|^^| | | \
| |模型版本平滑切换 |× |
|^^| | | \
| |配置接入点限流 |设置单接入点访问频率限制 |
|^^| | | \
| |开启/停用接入点 |控制是否可通过该接入点调用您的服务 |
|^^| | | \
| |查看监控 |查看 MLP 推理服务的监控指标 |
|^^| | | \
| |安全审计（会话、传输加密） |× |
|^^| | | \
| |细粒度权限管理 |支持 IAM、API key、项目、标签维度权限管理 |
|^^| | | \
| |算力保障（TPM 保障包、模型单元） |× |
| | | | \
|应用实验室 |零代码应用 |× |
|^^| | | \
| |高代码应用 |× |
| | | | \
|模型评测 |模型评测 |对您的MLP 推理服务进行评测 |
| | | | \
|数据投递 |数据投递 |× |

<span id="9aa8f124"></span>
## 支持模型

* 当前仅支持将 MLP 侧的**文本生成模型**和**深度思考模型**注册至方舟。其他领域模型（视觉理解模型、图片生成模型、视频生成模型等）部署的在线服务注册后，API 调用时会报错 500。

<span id="d960b744"></span>
## 使用说明

* API 调用：
   * 对于注册至方舟的 MLP 在线服务，仅支持**通过 MLP Endpoint ID 进行 API 调用**，不支持使用模型名称或 Model ID 进行调用。
   * 调用 API 时，火山方舟不会对参数进行校验和拦截。为了保证您的模型可以正常调用，请提前确认模型支持的参数范围。
   * 使用 MLP Endpoint  创建应用，具体是否支持网页解析等插件能力，由您的模型能力决定（例如不支持 function calling 的模型无法支持网页解析插件）。
* 计费说明：
   从 MLP 注册的推理接入点，火山方舟不会收取推理产生的 token 费用。如果使用了火山方舟插件/知识库，则会产生相关费用。具体请参见 [联网内容插件产品计费](https://www.volcengine.com/docs/82379/1338550) 和 [知识库计费](https://www.volcengine.com/docs/82379/1263336)。
* 安全能力：
   * 内容安全：模型的内容安全需用户自身负责，火山方舟不承担审核责任。
   * 产品安全：由 MLP 保障，不支持使用方舟安全沙箱相关能力。
   * 数据安全：火山方舟不会使用您的推理数据进行模型训练，所有数据仅用于您的推理服务，不会用于其他任何用途。
* 限流与SLA：
   * 方舟侧支持设置 MLP Endpoint 限流，整体服务的实际限流将由MLP的对应服务资源总量决定。
   * **对于注册至方舟的 MLP 在线服务，实际推理服务可用性由 MLP 决定，火山方舟侧不对 SLA 进行保证和承诺。**

<span id="7a3c17a9"></span>
## 前提条件

* MLP 侧准备工作如下：
   1. 子用户已获取队列的使用权限，详情可参见 [MLP 权限管理](https://www.volcengine.com/docs/6459/1535142)。
   2. [已开通机器学习平台](https://console.volcengine.com/ml-platform)。
   3. 已将您训练好的 LLM 模型或三方模型部署为在线服务，详细步骤请参见 [将模型部署成服务](https://www.volcengine.com/docs/6459/1398947)。
   4. 已在 [MLP 全局配置](https://console.volcengine.com/ml-platform/region:ml-platform+cn-datong/globalConfig) 对火山方舟完成跨服务授权，并添加对应服务。仅管理员账号支持该操作。
* 方舟侧准备工作如下：
   1. 子用户已获取 [ArkStandardGlobalAccess](https://console.volcengine.com/iam/policymanage/System/ArkStandardGlobalAccess) 或 [ArkFullAccess](https://console.volcengine.com/iam/policymanage/System/ArkFullAccess) 权限，详情可参见 [使用IAM进行访问控制教程](https://www.volcengine.com/docs/82379/1263493)。
   2. [已开通火山方舟](https://console.volcengine.com/ark/region:ark+cn-beijing/overview?briefPage=0&briefType=introduce&projectName=default&type=advance)。

<span id="f7effa1c"></span>
## 步骤一：创建 MLP Endpoint

1. 访问[方舟控制台-在线推理](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint?config=%7B%7D)。
2. 在控制台顶部切换需要创建推理接入点的项目空间。
3. 在 **自定义推理接入点** 页签，单击 **创建推理接入点。**
4. 在创建接入点页面，按要求填写 **基本信息**。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e34f1209baba4f5a89f6af96f3984152~tplv-goo7wpa0wc-image.image =1762x)

5. 接入来源选择**机器学习平台**，并选择待接入的 MLP 推理服务。

:::warning
* 当前仅支持将 MLP 侧的 LLM 模型推理服务注册至方舟。
* MLP 侧准备工作如下：
   * 已将您训练好的 LLM 模型或三方模型部署为在线服务，详细步骤请参见 [将模型部署成服务](https://www.volcengine.com/docs/6459/1398947)。
   * 已在 [MLP 全局配置](https://console.volcengine.com/ml-platform/region:ml-platform+cn-datong/globalConfig) 对火山方舟完成跨服务授权，并添加对应服务。仅管理员账号支持该操作。
:::

6. 配置接入点限流信息。请注意，实际的推理服务访问能力将由MLP的对应服务资源总量决定。
7. 阅读并勾选相关协议，单击 **确认接入**，完成 MLP 推理接入点创建。
    创建成功后，复制 Endpoint ID 备用。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/939375c8e0964caa8b8575dddc5b124c~tplv-goo7wpa0wc-image.image =2454x)

<span id="015597bb"></span>
## 步骤二：通过方舟 API/SDK 调用MLP推理服务

1. 获取获取[火山方舟 API key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)。
2. 配置 API key 到环境变量。

```Plain Text
//其中"YOUR_API_KEY"需要替换为您在平台创建的 API Key
export ARK_API_KEY="YOUR_API_KEY"
```


3. 通过 API 或 SDK 调用 MLP 推理服务。下面为一个最简单的 LLM 大模型调用示例代码。
   * 更多语言的代码示例请参见 [模型调用教程](https://www.volcengine.com/docs/82379/1362932)。
   * 方舟 API 文档请参见 [API 参考](https://www.volcengine.com/docs/82379/1289651)。


```mixin-react
return (<Tabs>
<Tabs.TabPane title="REST API 调用示例" key="gD43uJBqgD"><RenderMd content={`注意 \`model \` 需替换为步骤一获取的 Endpoint ID。
\`\`\`Plain Text
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $ARK_API_KEY" \
  -d '{
    "model": "ep-s-xxx",
    "messages": [
      {"role": "system","content": "你是人工智能助手."},
      {"role": "user","content": "你好"}
    ]
  }'
\`\`\`


`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="OpenAI SDK" key="HEL98tZmX1"><RenderMd content={`1.  请按如下命令安装环境 

\`\`\`Plain Text
pip install --upgrade "openai>=1.0"
\`\`\`


2. 请参考如下示例代码进行调用

\`\`\`Python
import os
from openai import OpenAI

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
# 初始化Openai客户端，从环境变量中读取您的API Key
client = OpenAI(
    # 此为默认路径，您可根据业务所在地域进行配置
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 从环境变量中获取您的 API Key
    api_key=os.environ.get("ARK_API_KEY"),
)

# Non-streaming:
print("----- standard request -----")
completion = client.chat.completions.create(
    # 替换为您步骤一获取的 MLP Endpoint ID
    model="ep-s-xxx",
    messages=[
        {"role": "system", "content": "你是人工智能助手"},
        {"role": "user", "content": "你好"},
    ],
)
print(completion.choices[0].message.content)

# Streaming:
print("----- streaming request -----")
stream = client.chat.completions.create(
    # 替换为您步骤一获取的 MLP Endpoint ID
    model="ep-s-xxx",
    messages=[
        {"role": "system", "content": "你是人工智能助手"},
        {"role": "user", "content": "你好"},
    ],
    # 响应内容是否流式返回
    stream=True,
)
for chunk in stream:
    if not chunk.choices:
        continue
    print(chunk.choices[0].delta.content, end="")
print()
\`\`\`


`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="火山引擎 SDK" key="hBVgt96uJW"><RenderMd content={`1.  请按如下命令安装环境
   \`\`\`Plain Text
   pip install --upgrade "volcengine-python-sdk[ark]"
   \`\`\`

2. 请参考如下示例代码进行调用
   \`\`\`Python
   import os
   from volcenginesdkarkruntime import Ark
   
   # 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
   # 初始化Ark客户端，从环境变量中读取您的API Key
   client = Ark(
       # 此为默认路径，您可根据业务所在地域进行配置
       base_url="https://ark.cn-beijing.volces.com/api/v3",
       # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
       api_key=os.environ.get("ARK_API_KEY"),
   )
   
   # Non-streaming:
   print("----- standard request -----")
   completion = client.chat.completions.create(
       # 替换为您步骤一获取的 MLP Endpoint ID
       model="ep-s-xxx",
       messages=[
           {"role": "system", "content": "你是人工智能助手."},
           {"role": "user", "content": "你好"},
       ],
   )
   print(completion.choices[0].message.content)
   
   # Streaming:
   print("----- streaming request -----")
   stream = client.chat.completions.create(
       # 替换为您步骤一获取的 MLP Endpoint ID
       model="ep-s-xxx",
       messages=[
           {"role": "system", "content": "你是人工智能助手."},
           {"role": "user", "content": "你好"},
       ],
       # 响应内容是否流式返回
       stream=True,
   )
   for chunk in stream:
       if not chunk.choices:
           continue
       print(chunk.choices[0].delta.content, end="")
   print()
   \`\`\`



`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="bab360fe"></span>
## 可选：查看监控告警
支持对 MLP Endpoint ID 维度进行指标监控告警，了解模型服务的运行情况。详情可参见 [监控推理接入点](https://www.volcengine.com/docs/82379/1182403#%E7%9B%91%E6%8E%A7)。
<span id="c84907df"></span>
## 可选：对 MLP推理服务进行模型评测
支持使用 MLP 推理接入点创建模型评测任务，对您的模型效果进行评测。详情可参见 [创建模型评测任务](https://www.volcengine.com/docs/82379/1150782)。
:::warning
暂不支持自定义推理参数。
:::
<span id="77559d64"></span>
## 



# Seedance-1.0-lite 提示词指南
Source: https://www.volcengine.com/docs/82379/1587797
本文介绍 Seedance-1.0-lite 文生视频和图生视频的提示词（prompt）使用技巧，帮助您快速上手视频创作，将创意转化为视频内容。
<span id="8489a3ee"></span>
## 模型简介
**Seedance 1.0** 是字节跳动豆包大模型团队最新推出的视频生成基础模型系列。**Seedance 1.0 lite** 作为该模型系列的小参数量版本，在取得出色的视频生成质量的同时，显著提升了生成速度，是兼顾效果与效率的性价比之选。
<span id="7fda8bcc"></span>
## 提示词参数
[创建视频生成任务 API ](https://www.volcengine.com/docs/82379/1520757)中，跟提示词有关的参数如下：
content.**text**：输入给模型的文本内容，描述期望生成的视频，包括：

   * **提示词（必填）**：支持中英文。
   * [参数（选填）](https://www.volcengine.com/docs/82379/1366799#%E6%A8%A1%E5%9E%8B%E6%96%87%E6%9C%AC%E5%91%BD%E4%BB%A4%E6%AF%94%E8%BE%83)：在文本提示词后追加--[parameters]，控制视频输出的规格。本文主要用到的有：
      * resolution `简写 rs`：分辨率
      * duration `简写 dur`：生成视频时长（秒）
      * camerafixed `简写 cf`：是否固定摄像头

```Plain Text
{
    "model": "doubao-seedance-1-0-lite-i2v-250428",
    "content": [
        {
            "type": "text",
            "text": "女孩抱着狐狸，女孩睁开眼，温柔地看向镜头，狐狸友善地抱着，镜头缓缓拉出，女孩的头发被风吹动  --rs 720p --dur 5 --cf false"
        },
        {
            "type": "image_url",
            "image_url": {
                "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/i2v_foxrgirl.png"
            }
        }
    ]
}
```

<span id="c2f7d79a"></span>
## 图生视频提示词技巧
<span id="108dfcdc"></span>
### 基础提示词
:::tip
**提示词 = 主体 + 运动， 背景 + 运动，镜头 + 运动 ...**
:::

1. **基础结构**：图生视频已经有了场景，因此**尽量减少（甚至避免）对静止/无变化部分的描述**，在**明确指出运动对象**的情况下，**多描述运动的部分**，包括主体的运动、背景的运动/变化、以及镜头的运动。
2. **简单直接**：**尽量使用简单词语和句子结构**，模型会根据我们的表达与对图像画面的理解进行提示词扩写,生成符合预期的视频。
3. **特征描述**：当主体具有一些突出特征时，可以加上突出特征来更好定位主体，比如老人， 戴墨镜的女人等。描述运动时，**关键的程度副词一定要明确**，比如快速、幅度大。
4. **遵从图片**：需要基于输入的图片内容来写，需要明确写出主体以及想做的动作或者运镜， **需注意提示词不要与图片内容/基础参数存在事实矛盾**。比如图片中是一个男人，提示词写“一个女人在跳舞”；比如背景是草原，提示词写“男人在咖啡厅里唱歌”；比如手上没有饰品，提示词写“带饰品的那只手”；比如基础参数选择了固定镜头，却在提示词里写了镜头环绕。
5. **负向提示词不生效** ：模型不响应负向提示词。


| | | | \
|**输入参数** |中间结果（不显示） |**生成视频（单主体+单动作）** |
|---|---|---|
| | | | \
|![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d347d7d7c6914bf1b33bbed2541b5401~tplv-goo7wpa0wc-image.image =1280x) |\
|**prompt**：老人戴上眼镜 |\
|**基础参数**：固定镜头，720p，10s |> 根据输入图片，模型会获取到场景信息：*冷色调，特写镜头拍摄一位满脸胡须的中老年白人男子，他眉头紧皱，眼睛看向画面右侧，眼神凶狠，表情严肃。他留着灰白的络腮胡，脸上有皱纹，他的眼睛大而深邃，鼻梁高挺，鼻孔突出，眼周皱纹和法令纹明显，身着浅色上衣。背景是模糊的。* |\
| | |\
| | |\
| |> 根据prompt，模型会进行合理扩写：*在室内环境中，一个老年男人脸部的特写。他皱着眉看向画面右侧，然后抬起双手将一副眼镜架在鼻梁上。* | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/dede8464735547f1ad744be6c6d580dd~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/dede8464735547f1ad744be6c6d580dd~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |

<span id="16f2f4ff"></span>
### 多个连续动作提示词
模型对多拍动作质量有着强响应，支持时序性的多个连续动作，以及多个主体的不同动作。可以尝试写:
:::tip
**提示词 = 主体1 + 运动1  + 运动2**
**提示词 = 主体1 + 运动1  + 主体2 + 运动2 ...**
:::
依次列举即可，模型会根据我们的表达与对图像画面的理解进行提示词扩写，生成符合预期的视频。

| | | \
|**输入参数** |**生成视频** |
|---|---|
| | | \
|![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e0a95adb321f4d57ac2a4ee35dfcff5c~tplv-goo7wpa0wc-image.image =864x) |\
|**prompt**：打太极，镜头环绕，聚焦脸部 |\
|**基础参数**：不固定镜头，720p，5s | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/62d356da4bb84776a4b7266fb6f82b4a~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/62d356da4bb84776a4b7266fb6f82b4a~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |
| | | \
|![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/746eece3d1b6427e8f1961c87ea2cfa1~tplv-goo7wpa0wc-image.image =832x) |\
|**prompt**：转过脸对着镜头向前走，然后停下，脸上露出愤怒的表情，然后叉腰 |\
|**基础参数**：不固定镜头，720p，10s | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5d3be8c30c7345e3b408050ad8c97c09~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5d3be8c30c7345e3b408050ad8c97c09~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |
| | | \
|![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0b4d75b28081422c8d1ef6e89ffc7ce6~tplv-goo7wpa0wc-image.image =832x) |\
|**prompt**：镜头聚焦于背景的老师，前景的女孩变得模糊，老师非常生气的骂人 |\
|**基础参数**：不固定镜头，720p，5s | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/49907383a22a4d4987f78e4b2b6247ea~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/49907383a22a4d4987f78e4b2b6247ea~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |
| | | \
|![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a42b96b1fda9482b814bf86261348247~tplv-goo7wpa0wc-image.image =1120x) |\
|**prompt**：**镜头下摇**，从女人脸上拉到她的正面全身全景，她在对着镜头打了个招呼后，走出画面 |\
|**基础参数**：不固定镜头，720p，10s | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5e092452059d4f0692f2ed72fe4f7ed0~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5e092452059d4f0692f2ed72fe4f7ed0~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |
| | | \
|![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c48023ed49754cd384a725356b44cca4~tplv-goo7wpa0wc-image.image =1120x) |\
|**prompt**：女人一边哭泣一边喝酒，一个男人走进来安慰她 |\
|**基础参数**：不固定镜头，720p，5s | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b606fba018094b028062f2c842bfec58~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b606fba018094b028062f2c842bfec58~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |


<span id="7319e68b"></span>
### 运镜提示词
> 包括镜头切换

可以在提示词中使用自然语言描述你想要的镜头变化，支持环绕、航拍、变焦、平移、跟随、手持等运镜，以及镜头切换。镜头语言响应是seedance 1.0的强项。

1. 在写一致性多镜头的提示词时，需要**写出镜头之间内在的联系**。
2. 镜头的变化，**通过“镜头切换”这一明确提示词来进行连接**。
3. 切镜后如果场景发生了变化，需要**对新的场景进行描述**。
4. 有运镜提示词时，基础参数要选择“不固定镜头”。
5. 运镜提示词在文生视频场景也同样适用。


| | | | | \
|运镜 |提示词 |**输入参数** |**生成视频** |
|---|---|---|---|
| | | | | \
|**镜头切换** |**镜头切换** |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3537d1f1a0884de3a2eec797168507b3~tplv-goo7wpa0wc-image.image =1280x) |\
| | |**prompt**：小猫和小狗吃猫粮，**镜头切换**到特写猫粮颗颗分明。 |\
| | |**基础参数**：不固定镜头，720p，5s | |\
| | | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/89adb3cb681f41ec9bf66bf5a8e93b39~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/89adb3cb681f41ec9bf66bf5a8e93b39~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |\
| | | | |
|^^|^^| | | \
| | |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/137fdf84b0c14f0eacac391d77454b2d~tplv-goo7wpa0wc-image.image =2048x) |\
| | |**prompt**：手表指针匀速转动，**镜头切换**，男人扬起手扶了一下自己的金丝眼镜，柔和的光线打在表盘上 |\
| | |**基础参数**：不固定镜头，720p，5s | |\
| | | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/27f1a7d848664696b245af1a2445a82a~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/27f1a7d848664696b245af1a2445a82a~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |\
| | | | |
|^^|^^| | | \
| | |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/6358ef56130c4e1c963957e60b8449ad~tplv-goo7wpa0wc-image.image =956x) |\
| | |**prompt**：全景拍摄，模特微笑着走近镜头。**镜头切换**，近景拍摄模特下半身，裤子的直筒设计和布料垂坠感在行走中得到突出。 |\
| | |**基础参数**：不固定镜头，720p，5s | |\
| | | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/928b3c2a8f4d4a5595a5fbeff20d7260~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/928b3c2a8f4d4a5595a5fbeff20d7260~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |\
| | | | |
| | | | | \
|平移 |**镜头向上/下/左/右移动** |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b7edf59eaa39402b97a984130be06c35~tplv-goo7wpa0wc-image.image =1456x) |\
| | |**prompt**：**镜头缓慢向下移动**，到街道，路灯。 |\
| | |**基础参数**：不固定镜头，720p，5s | |\
| | | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/505c57942101480d8350e1564bec3e79~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/505c57942101480d8350e1564bec3e79~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |\
| | | | |
|^^|^^| | | \
| | |**prompt**：神庙的深处，一个背着背包的男人找到了一位古代智者的雕像。**镜头向左移动**，雕像手中握着一本古老的书籍，似乎在守护着某种重要的知识。 |\
| | |**基础参数**：不固定镜头，视频比例16:9 ，720p，5s |\
| | | | |\
| | | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4c21f626f9cf40bb928e815c711cfdac~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4c21f626f9cf40bb928e815c711cfdac~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |\
| | | | |\
| | | | |\
| | | | |
| | | | | \
|变焦 |**镜头拉远** |\
| |**镜头推近** |\
| |**镜头聚焦** |\
| |**特写**  |\
| | |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b474ffe9a4644f94b13b53e8b95c3881~tplv-goo7wpa0wc-image.image =612x) |\
| | |**prompt**：一家人在露营，欢快的氛围，镜头**特写**到帐篷，360度展示帐篷全景。 |\
| | |**基础参数**：不固定镜头，720p，5s | |\
| | | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cb63b41665724f5aafd575577ef02622~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cb63b41665724f5aafd575577ef02622~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |\
| | | | |\
| | | | |
| |^^| | | \
| | |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/88667374a218458db53cc77f4e6d8589~tplv-goo7wpa0wc-image.image =2048x) |\
| | |**prompt**：这是一个雕塑家的双手在一块大理石上凿刻时颤抖的**特写**镜头，然后**镜头拉远**，看到是一个小孩雕塑家，他脸上带着自信的微笑。 |\
| | |**基础参数**：不固定镜头，720p，5s |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0c001ee5e8c04dad80e40676b3022123~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0c001ee5e8c04dad80e40676b3022123~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |
| | | | | \
|环绕 |**镜头环绕360度展示** |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/702690afd0d14775bd3a4af990551162~tplv-goo7wpa0wc-image.image =900x) |\
| | |**prompt**：**镜头环绕运镜** |\
| | |**基础参数**：不固定镜头，720p，5s |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bfc2680c6cc041f7accc7e42914931c6~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bfc2680c6cc041f7accc7e42914931c6~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |
|^^|^^| | | \
| | |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/343fb36770334fef821fee54922d8c9a~tplv-goo7wpa0wc-image.image =1192x) |\
| | |**prompt**：**环绕镜头**，缓慢推进至人物的脸部特写 |\
| | |**基础参数**：不固定镜头，720p，5s | |\
| | | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/84ec1ae27ac1455f88ced0b3192ea955~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/84ec1ae27ac1455f88ced0b3192ea955~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |\
| | | | |
| | | | | \
|航拍 |**航拍** |\
| |**广角** |\
| | |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/52deab7feaa7483482578354e0734c45~tplv-goo7wpa0wc-image.image =2973x) |\
| | |**prompt**：男人张开双臂，**航拍**环绕镜头。 |\
| | |**基础参数**：不固定镜头，720p，5s | |\
| | | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/41c176e1a610498ba2a25e9f1675d053~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/41c176e1a610498ba2a25e9f1675d053~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |\
| | | | |
| | | | | \
|**手持** |**手持镜头** |\
| |**微微抖动** |\
| | |**prompt**：**手持镜头**，画面**微微抖动**体现手持感，跟随在一只在玫瑰花园中散步的猫身侧 |\
| | |**基础参数**：不固定镜头，视频比例16:9 ，720p，5s | |\
| | | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d19667f7160b47b2a99847f06f0ce418~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d19667f7160b47b2a99847f06f0ce418~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |\
| | | | |
| | | | | \
|跟随 |**镜头跟随** |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bf9543b8d3bc498da14cfdb982a83560~tplv-goo7wpa0wc-image.image =1248x) |\
| | |**prompt**：**镜头跟随**一位驾驶哈雷摩托的男性，特写镜头，骑手露出狂野的笑容，镜头突然向上摇，有一只秃鹫在上空盘旋。 |\
| | |**基础参数**：不固定镜头，720p，5s | |\
| | | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/da32742b34d647fba6347e34065dab48~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/da32742b34d647fba6347e34065dab48~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | | |\
| | | | |

<span id="460e28f5"></span>
### 程度副词
如果想要在视频中突出动作频率与强度，或者主体的特征，合理使用程度副词。

1. **明确**：模型无法从输入的参考图上获取到运动的程度，所以一定要在prompt中明确，否则模型会根据它自己的理解去补充，可能跟用户的意图背离。如“汽车驶过”改为“汽车快速驶过”。
2. 可适当**夸大**程度，增强视频的表现力：如“男子咆哮”改为“男子疯狂咆哮”，“翅膀扇动”，改为“翅膀大幅度扇动”，会更容易接近想要的效果。

:::tip
**程度提示词：快速 剧烈 大幅度 高频率 强力 疯狂 ...**
:::

| | | \
|**输入参数** |**生成视频** |
|---|---|
| | | \
|![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5606a0387ce94961a06d017c46011ab2~tplv-goo7wpa0wc-image.image =2912x) |\
|车辆**快速**往前开，穿过时空通道，光影流动，镜头**快速**跟随 |\
|**基础参数**：不固定镜头，720p，5s | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/70bd4af9bb0b4b3fab464d0299e53313~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/70bd4af9bb0b4b3fab464d0299e53313~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |
| | | \
|![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a5cfeb0bb0554fbe81a9694f541761f4~tplv-goo7wpa0wc-image.image =1024x) |\
|一个身着专业运动服的运动员。双腿**快速**交替，双臂**有力**摆动，在赛场上全力冲刺，在他冲过终点线后，观众欢呼。 画面采用跟拍视角，充分展示运动员冲过终点线的细节。 |\
|**基础参数**：不固定镜头，720p，5s | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/6477e2d611f44940a1606711e8a1323e~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/6477e2d611f44940a1606711e8a1323e~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| | |


<span id="ba847871"></span>
## 文生视频提示词技巧
<span id="7671f47d"></span>
### 基础提示词
:::tip
**提示词 = 主体 + 运动 + 场景 + 镜头、风格...**
:::

1. 主体+运动+场景是最核心和基本的要素，模型会进行提示词扩写,生成符合预期的视频。
2. 参考图生视频，**连续动作、运镜、程度副词**等的提示词指南同样对文生视频有效果，负向提示词不响应。
3. 如何更好的描述你需要的内容：
   1. **详细的人物描写**：注重人物的外表、着装、姿势。
   2. **环境细节的呈现**：自然环境（如山脉、沙漠、瀑布等）或者建筑环境（如工作室、浴室等）的详细描述，能帮助你强调场景的视觉和感觉体验。
   3. **情绪与动态的结合**：通过描绘人物的情绪状态和环境动态，创造了层次丰富的叙事。
   4. **氛围的渲染**：通常我们在视觉呈现上有一些渲染氛围的技巧。例如可以运用对光线的描述：黄昏、清晨、昏暗、温暖的光等


| ||| \
|T2V | | |
|---|---|---|
| | | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5f6a8c08eb434e4d9fbb200d86f5d389~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5f6a8c08eb434e4d9fbb200d86f5d389~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|**Prompt**：具有设计感的人像摄影，迷幻清冷的淡蓝色调，蝴蝶光，近景拍摄一位年轻的白人女性。她有着高层次的黑色短发，右边的眉毛上挑，睫毛浓密，鼻梁高挺，咬着红唇，表情不屑地瞪着镜头。镜头后拉，前景是破碎的玻璃在空中，它挡住了女子的部分面部。 |\
|**基础参数**：不固定镜头，720p，比例 16:9，5s |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d72b9dcec4774d778ada9f3abaad2e51~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d72b9dcec4774d778ada9f3abaad2e51~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |**Prompt**：中近景拍摄一位留着凌乱的黑色短发的年轻男子在夜晚吃鸡腿。他看起来有些狼狈，脸脏脏的，肿眼泡，下颌圆润，鼻子上有几颗黑痣，有些许胡渣，牙齿有些泛黄，眼睛看向画面左侧，有些失神，身着蓝灰色的破旧风衣，袖口和衣服上沾着许多脏污。男子拿着鸡腿靠近嘴边，咬了一口鸡腿，随后直勾勾的看着前方，露出猥琐的笑容。手指和手心都有污渍。背景是虚化的城市夜晚景象，有黄蓝色的灯光 |\
| |**基础参数**：固定镜头，720p，比例 4:3，5s | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bd7c449401f74e2887d466fa489ae5c4~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bd7c449401f74e2887d466fa489ae5c4~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | |清冷的色调，雪花飘落的冬天山谷中，近景拍摄一位明艳动人的年轻白人美女侧身扭头看向镜头。她有着黑色的波浪卷长发，下巴尖尖的，眉毛浓密上挑，眼窝深邃，眼瞳是红色的，化着深色眼影和上挑的眼线，鼻梁挺直，嘴唇偏厚，涂着非常鲜艳的红唇，下颌线清晰，指甲非常长，做着红色美甲。女子身着一件黑袍，戴着帽子将眉毛遮住，领口微敞着锁骨清晰，眼睛盯着镜头，眼神十分勾人。背景是覆盖着厚雪的绿色植被，雪花在空中飘落。镜头向左微微环绕女人拍摄，女人抬起右手放在下巴上，看着镜头露出妩媚的笑容。 |\
| | |**基础参数：​**不固定镜头，720p，比例 9:16，5s |


<span id="857fcec7"></span>
### 风格响应词

| ||| \
|视频生成示例 | | |
|---|---|---|
| | | | \
|国漫 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/29ec1410a1094583baf6bc81a8a72e4a~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/29ec1410a1094583baf6bc81a8a72e4a~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |水墨 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/828f619a8f674cfca17229d0fed392b4~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/828f619a8f674cfca17229d0fed392b4~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |水彩 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a2c3b87f10b64bbba10b4d70e1b72d44~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a2c3b87f10b64bbba10b4d70e1b72d44~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |
| | | | \
|日漫 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/42329c407ba747159456a4403fe3c87e~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/42329c407ba747159456a4403fe3c87e~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |美漫 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d6da76517e6a46bf922add01ebe4d7bd~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d6da76517e6a46bf922add01ebe4d7bd~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |剪纸 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/db3bf020854b47a484a00ec04a24f668~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/db3bf020854b47a484a00ec04a24f668~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |
| | | | \
|体素 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bfb6dd80e6034445bac0d70991199bde~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bfb6dd80e6034445bac0d70991199bde~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |毛毡 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/52e14d86d02244099a2e2d5b43629672~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/52e14d86d02244099a2e2d5b43629672~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |线稿 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/723ebbb346524b259f5e20bfcd2555f3~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/723ebbb346524b259f5e20bfcd2555f3~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |


<span id="1756a39a"></span>
## 常见问题案例
<span id="33d40d52"></span>
### 问题1：视频肢体崩坏如何解决
模型有一定肢体崩坏的概率，可以多试几次**抽卡**选择效果好的视频，或者通过prompt避开展示手/脚部的镜头。
<span id="27b4dbe8"></span>
### 问题2：图生视频的结果没有遵循重要的程度副词

* **问题案例**
   
   | | | \
   |输入图片 |原始 prompt 与视频效果 |\
   | | |
   |---|---|
   | | | \
   |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/500905e504134eb4bc9572bd38d018e7~tplv-goo7wpa0wc-image.image =2048x) |\
   | |大幅度运动，仰拍，镜头缓慢跟随，旋转绕行，在暴风雪笼罩的冰川上空，一只巨大的冰霜丧尸骸骨龙在风雪中展翅飞翔，展开巨大的腐烂的骸骨双翼，身体散发出幽蓝的光芒，蓝色的能量从它的身体和翅膀上流动，风雪在它周围狂卷，压迫感，震撼，恢弘大气，氛围光照 |\
   | | |\
   | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4a3472df26824a61a7f607980caa4075~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4a3472df26824a61a7f607980caa4075~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
   | | |

* **问题分析**
   prompt中太多描述是参考图已有的信息，模糊了重点。需要删除不必要的内容，并强调重要的程度副词。
* **优化后效果**
   
   | | | \
   |输入图片 |优化后 prompt 与视频效果 |
   |---|---|
   | | | \
   |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/500905e504134eb4bc9572bd38d018e7~tplv-goo7wpa0wc-image.image =2048x) |\
   | |一只龙**快速**的拍动翅膀，翅膀运动的**幅度很大**。仰拍，镜头旋转绕行。压迫感 |\
   | | |\
   | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5adfccebb46142b287fa919b0083f771~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5adfccebb46142b287fa919b0083f771~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
   | | |


<span id="bdce33f8"></span>
### 问题3：图生视频的结果中有些地方不符合要求

* **问题案例**
   
   | | | \
   |输入图片 |原始 prompt 与视频效果 |\
   | | |
   |---|---|
   | | | \
   |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0040732412cb49f987482701429750bb~tplv-goo7wpa0wc-image.image =1024x) |\
   | |画面中的男孩带着耳机陶醉地欣赏音乐，头随着音乐微微摆动，镜头拉近画面中模特带着耳机的耳朵，展示耳机的舒适。 |\
   | | |\
   | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1061b00f356d410eb8c93ad16af874a5~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1061b00f356d410eb8c93ad16af874a5~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
   | | |

* **问题分析**
   prompt看起来没有问题，但眼神有点怪。需在prompt中重新强调眼神。
* **优化后效果**
   
   | | | \
   |输入图片 |优化后 prompt 与视频效果 |
   |---|---|
   | | | \
   |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/f663f0747ee747b6833a0caf8c9c6a72~tplv-goo7wpa0wc-image.image =1024x) |\
   | |画面中的男孩带着耳机陶醉地欣赏音乐，**他眼神自然**，头随着音乐微微摆动，镜头拉近画面中模特带着耳机的耳朵，展示耳机的舒适 |\
   | | |\
   | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/50b07785bb964c97911c3133e33ba5b7~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/50b07785bb964c97911c3133e33ba5b7~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
   | | |


<style>
/* 覆盖内联样式的宽高 */
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default
  .xgplayer-volume-large.xgplayer-pause.xgplayer-is-replay.xgplayer-ended,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-nostart.xgplayer-skin-default.xgplayer-inactive,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-nostart.xgplayer-skin-default,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing.xgplayer-pause,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing.xgplayer-inactive,
.volc-md-viewer .editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-is-enter,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-is-enter.xgplayer-inactive,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-playing,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-isloading.xgplayer-playing {
    width: 360px !important;
    height: 180px !important;
}   
</style>


# Seedance-1.0-pro 提示词指南
Source: https://www.volcengine.com/docs/82379/1631633
本文介绍 Seedance-1.0-pro 文生视频和图生视频的提示词（prompt）使用技巧，帮助您快速上手视频创作，将创意转化为视频内容。
<span id="8489a3ee"></span>
## 模型简介
**Seedance 1.0** 是字节跳动豆包大模型团队最新推出的视频生成基础模型系列。**Seedance 1.0 pro**  作为该模型系列的大参数量版本，具备独特的多镜头叙事能力，在各维度表现出色。它在语义理解与指令遵循能力上取得突破，能生成运动流畅、细节丰富、风格多样且具备影视级美感的 1080P 高清视频。

<span id="7fda8bcc"></span>
## 提示词参数
[创建视频生成任务 API ](https://www.volcengine.com/docs/82379/1520757)中，跟提示词有关的参数如下：
content.**text**：输入给模型的文本内容，描述期望生成的视频，包括：

   * **提示词（必填）**：支持中英文。
   * [参数（选填）](https://www.volcengine.com/docs/82379/1366799#%E6%A8%A1%E5%9E%8B%E6%96%87%E6%9C%AC%E5%91%BD%E4%BB%A4%E6%AF%94%E8%BE%83)：在文本提示词后追加--[parameters]，控制视频输出的规格。本文主要用到的有：
      * resolution `简写 rs`：分辨率
      * duration `简写 dur`：生成视频时长（秒）
      * camerafixed `简写 cf`：是否固定摄像头

```Plain Text
{
    "model": "doubao-seedance-1-0-lite-i2v-250428",
    "content": [
        {
            "type": "text",
            "text": "女孩抱着狐狸，女孩睁开眼，温柔地看向镜头，狐狸友善地抱着，镜头缓缓拉出，女孩的头发被风吹动  --rs 720p --dur 5 --cf false"
        },
        {
            "type": "image_url",
            "image_url": {
                "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/i2v_foxrgirl.png"
            }
        }
    ]
}
```

<span id="7302ae87"></span>
## 动作指令
<span id="ff696840"></span>
### 基础动作
> 主体+动作


| || \
|视频生成示例 | |
|---|---|
| | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4e751a0214e04b719c43f6169c681a17~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4e751a0214e04b719c43f6169c681a17~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|t2v：小猫对着镜头打哈欠。 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d48bbf1125284ae2b59a480b521affb7~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d48bbf1125284ae2b59a480b521affb7~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |t2v：女子走在夜晚的上海街头。 |
| | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/498fd3308d8b48b1b46a7f0db9e515a0~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/498fd3308d8b48b1b46a7f0db9e515a0~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |\
|i2v：男子转头，看向镜头微笑。 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ed126865e0684f729b8144aae17ff59f~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ed126865e0684f729b8144aae17ff59f~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| |i2v：稳重冷漠地男孩看向镜头，放下耳麦。然后跳下轮胎走向镜头蹲下。 |

<span id="bfddb8cb"></span>
### 多动作指令
> 按照动作发生的时序，清晰描述出多个动作，实现单人物多动作/多人物多动作。


| ||| \
|视频生成示例 | | |
|---|---|---|
| | | | \
|单人物多动作 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/22c1e58cc12b4b3eb02a011c7f24df6c~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/22c1e58cc12b4b3eb02a011c7f24df6c~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|i2v：女子拿起面前的酒杯，喝了一口后放下，然后起身离开座位。 |多人物多动作 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4fe10b493b3f4844ac558b3307cba236~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4fe10b493b3f4844ac558b3307cba236~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |t2v：一个摇滚乐队的演出现场，主唱拿着麦克风在台上唱歌，吉他手在卖力弹吉他，贝斯手弹贝斯，鼓手在摇头晃脑的在敲鼓，键盘手在弹钢琴。 |多人物多动作 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/22ce7555762c4c88a826a2e8d69adf5c~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/22ce7555762c4c88a826a2e8d69adf5c~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | |t2v：办公室茶水间，同事们在休息聊天。同事 A 分享周末趣事，手舞足蹈。同事 B 笑得前仰后合，同事 C 好奇地追问细节。其他人围在周围，不时插上几句。 |

<span id="afc80793"></span>
## 镜头语言
<span id="2461b491"></span>
### 基础运镜
> 精准响应推、拉、摇、移、环绕、跟随、升、降、变焦等运镜指令。


| ||| \
|视频生成示例 | | |
|---|---|---|
| | | | \
|推 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0cee88af61354f2fa266c0baa73b46cc~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0cee88af61354f2fa266c0baa73b46cc~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|i2v：镜头快速前推到小女孩的近景，她背对着镜头缓缓抬头仰视面前的建筑。 |拉 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b801045958534b3db532ec91f8ca4c6c~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b801045958534b3db532ec91f8ca4c6c~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |i2v：镜头快速拉远，露出女子上半身，她微微转头目光看向画面右侧，背景是一个繁华的街头。 |摇 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c04a39f0172c44f7b0954f448eb2dea2~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c04a39f0172c44f7b0954f448eb2dea2~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | |t2v：一个时装发布会的现场，镜头右摇侧面拍摄一个衣着华丽的模特在走秀。 |
| | | | \
|移 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cbbd0408a95a4fae902fb71d5951c48b~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cbbd0408a95a4fae902fb71d5951c48b~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |\
|i2v：镜头右移展示长城的雄伟壮丽，微缩摄影，由布料拼接而成的长城。 |环绕 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5a2f262ad1cb4d769dd628097462ae45~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5a2f262ad1cb4d769dd628097462ae45~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| |i2v：镜头环绕拍摄，从女人的背面到正面，她十分美丽，抬手捂嘴，羞涩微笑。 |跟随 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4f1aa9a795f4420596c78f63d2b16bfa~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4f1aa9a795f4420596c78f63d2b16bfa~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | | |\
| | |i2v：狮子在飞翔，镜头跟随飞翔的狮子。 |
| | | | \
|移 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ff2c0b5bdaf7437dbf80c662560973db~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ff2c0b5bdaf7437dbf80c662560973db~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |\
|i2v：镜头右移，画面右侧的女人正与他深情对视。 |\
| |升 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a8abe846ef0b430991cab7211a11f611~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a8abe846ef0b430991cab7211a11f611~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| |i2v：镜头逐渐升起，露出登山者的背影。 |变焦 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/85dfc5e768ad4d6ca13d17f273a3c84d~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/85dfc5e768ad4d6ca13d17f273a3c84d~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | | |\
| | |t2v：法庭上，法官即将宣布审判结果。变焦镜头下，镜头推近被告紧张的面容，背景中的法庭和众人逐渐拉远，空间被压缩，突出被告等待判决时的煎熬，营造出严肃且紧张的氛围，让观众的情绪也随之紧绷。 |

<span id="47aebb1a"></span>
### 复杂运镜
> 对于进阶玩家，可以将多个运镜指令进行组合构建出有创意的长镜头。


| || \
|视频生成示例 | |
|---|---|
| | | \
| |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e639f71a903840caa0130e045349bef8~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e639f71a903840caa0130e045349bef8~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|t2v：一个小女孩在客厅地毯上和她的小狗玩耍。镜头从地面与小狗视平线的角度开始，小狗欢快地跑向女孩，镜头平稳地跟随小狗，并在接近女孩时向上摇摄，展现女孩温柔的笑容；女孩和小狗嬉戏时，镜头围绕他们做一个缓慢的近距离360度旋转，最后在女孩抱起小狗时，镜头从下往上逐渐拉近，定格在他们亲密的脸庞。充满温馨和爱意，画面柔和。 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a1dc7a7632b543febec49942df4f7ff0~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a1dc7a7632b543febec49942df4f7ff0~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |t2v：一位女性手持咖啡杯，静立于明亮的窗前。镜头从她身后开始，缓缓向前推进并从她右肩上方掠过，细腻捕捉杯中咖啡的热气与她沉静的侧脸轮廓；随后镜头不停歇，继续向前穿过窗户（或模拟穿透效果），展现窗外街景一瞥，再流畅地旋转180度重新面向室内，从窗外视角反观女性背影，最后缓慢拉远。一镜到底，突出光影之美与空间感。 |

<span id="46aabc00"></span>
### 景别和视角控制
> 可以使用远景、全景、中景、近景、特写这样的专业景别描述来控制。还可以选择具体的观察角度：水下镜头，航拍镜头，高机位俯拍，低机位仰拍，微距摄影，以xx为前景的镜头等


| || \
|视频生成示例 | |
|---|---|
| | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c3b3365e29034ed796a1f9f5d8a21089~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c3b3365e29034ed796a1f9f5d8a21089~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|t2v：微距摄影，一只毛毛虫在花瓣上爬行，可以清晰看见它身上的毛。 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/407213a0068342e9a0b26c55258d7a0c~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/407213a0068342e9a0b26c55258d7a0c~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |t2v：广阔的沙漠中，一队骆驼商队缓缓前行。高空航拍俯瞰，沙漠的广袤与商队的渺小形成对比，尽显旅途的艰辛。 |
| | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/f8eb811c165241908f09805e0a76d876~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/f8eb811c165241908f09805e0a76d876~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |\
|t2v: 客厅中，父亲教儿子下棋。过肩镜头越过父亲肩膀，看到儿子思考的神情和棋盘上的棋局，传递着亲子间的温馨陪伴。 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d998f8cd740c441387b141d973f0cd3a~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d998f8cd740c441387b141d973f0cd3a~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| |t2v：透过一个箱子拍摄，有两个人正在看箱子的里面。其中一个人伸手进箱子抱出一只小奶猫。 |

<span id="f6d599d0"></span>
## 多风格直出
> 具有直出多种风格的能力，包含2D/3D，以及更细分的体素，像素，毛毡，粘土，插画等。


| ||| \
|视频生成示例 | | |
|---|---|---|
| | | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/9b34e09d8cc941818fe165ca061de28a~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/9b34e09d8cc941818fe165ca061de28a~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|t2v：黑白线稿风格，一个黑白线稿女孩向右行走，背景是线稿森林。 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/9f54f0f315f14cdf8aab28a67008695a~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/9f54f0f315f14cdf8aab28a67008695a~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |t2v：一只可爱的毛毡小猫走在粘土做成的街道上 | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1afe09ebf0054daa855752b1bfc4ebd6~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1afe09ebf0054daa855752b1bfc4ebd6~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | |t2v：3D动画，一只拟人的马坐在教室里上课 |
| | | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e4beadc4565b441f83199f2c62ae5812~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e4beadc4565b441f83199f2c62ae5812~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |\
|t2v：日本漫画，一个带墨镜的美女在东京街头自拍 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3c795a7d9a344a3cab084765038042f1~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3c795a7d9a344a3cab084765038042f1~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| |t2v：体素风格，一个机器人坐在火箭上 | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d0b5ef7bbec14fefa33464de6c630984~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d0b5ef7bbec14fefa33464de6c630984~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | | |\
| | |t2v:美漫风格，一个肌肉男在举重 |

<span id="05e0b841"></span>
## Prompt 控制美感
<span id="45dc4049"></span>
### 人物外形
> 可以发挥想象，精细刻画出人物/场景/衣着的细节，生成各种不同长相特征的角色。


| ||| \
|视频生成示例 | | |
|---|---|---|
| | | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/336670697636439585f727fa473d4987~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/336670697636439585f727fa473d4987~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|t2v：一个美貌的女人穿着一身优雅的黑色旗袍，坐在西式客厅里抽烟。 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c2b337982d8a43c1b41f706d1c0c1c0c~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c2b337982d8a43c1b41f706d1c0c1c0c~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |t2v：一个其貌不扬的女人穿着一身黑色旗袍，坐在西式客厅里抽烟。 | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d7a2c174d40f4c0ea368418f8fee45c2~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d7a2c174d40f4c0ea368418f8fee45c2~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | |t2v：那个脸型微胖的年轻女人盯着摄像头，她有着一双三白眼，眼角边有一颗痣，皮肤粗糙。脸上是红光和蓝光。 |
| | | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2de1c10d4e224cd78eabcbb95f73bd57~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2de1c10d4e224cd78eabcbb95f73bd57~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |\
|t2v：一个发型凌乱的男人在吃鸡腿，背景是家徒四壁的房间 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/17905961d3264752a0c66244c6a89aca~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/17905961d3264752a0c66244c6a89aca~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| |t2v：美颜滤镜，磨皮感，一个女孩在自拍，她对着镜头比耶。 | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/96e3a17d79bd4b66b450d18106f571da~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/96e3a17d79bd4b66b450d18106f571da~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | | |\
| | |t2v：一个300斤的白人男性窝在沙发上看电视，电视反射过来的光线在他脸上波动。 |\
| | | |

<span id="8705806e"></span>
### 画面美感
> 精细化描述画面，用自然语言写出画面的氛围特征，可以控制画面整体的美感。



1. **写上视频类型控制画面特征**


| || \
|视频生成示例 | |
|---|---|
| | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bf267a451d894ceaad4fceaa09728ca8~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bf267a451d894ceaad4fceaa09728ca8~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|t2v：男子和女子的手拉在一起。喜庆的土味短视频。 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3468617a43494000a33cf81296e3b154~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3468617a43494000a33cf81296e3b154~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |t2v：男子和女子的手拉在一起。欧洲文艺电影。 |
| | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4c2007059f774a7c82e62f895faab407~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4c2007059f774a7c82e62f895faab407~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |\
|t2v：男子和女子的手拉在一起。复古香港电影。 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3d1638f0053c40218f7fb8b5f047a145~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3d1638f0053c40218f7fb8b5f047a145~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| |男子和女子的手拉在一起。恐怖片。 |


2. **用自然语言形容出想要的氛围,可以是正向的氛围也可以是负向的氛围，达到对画面美感的控制效果。**


| || \
|视频生成示例 | |
|---|---|
| | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a43cc5bf62c94c2a9cf106bc8c8e0ee2~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a43cc5bf62c94c2a9cf106bc8c8e0ee2~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|t2v：油画般的电影场景，在英国乡村，一个金发的穿着针织毛衣的女人和一个英俊的男人深情对视 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/14961c4d7d2d461bba4baa4e8814e6b4~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/14961c4d7d2d461bba4baa4e8814e6b4~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |t2v：有质感的老电影，复古氛围，一个街头音乐人在夜晚酒吧的霓虹灯下沉醉得拉小提琴。 |
| | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d025598ae4344529ac62ae8a45391ddb~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d025598ae4344529ac62ae8a45391ddb~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |\
|t2v：略显古早，妆造廉价的80年代电视剧，一个男人在台灯下写作 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/81470a27f6d246f79311601a8c18bee5~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/81470a27f6d246f79311601a8c18bee5~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| |t2v：花园的叶子上，住着一群小精灵。镜头右摇，主角从家里走出，主角身着花瓣斗篷、手持草叶魔杖，魔杖顶端嵌着一个发光的黄色宝石，微观世界风格。 |

<span id="d3705525"></span>
## 多镜头能力
> 支持在同一prompt里包含多个切镜，这些切镜会根据提示词的内容，保持主体/风格/场景的延续性。镜头的变化，通过“镜头切换”来进行连接，在每次切镜之后，如果场景和人物发生了变化，可以用prompt刻画新出现的人物/场景的特征。


| || | \
|视频生成示例 | | |
|---|---|---|
| | | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/9cb3e6212be24e87a7fbe55ac98ea858~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/9cb3e6212be24e87a7fbe55ac98ea858~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|t2v：美漫风格2D动画，中近景拍摄一位年轻帅气的白人男子，男人松开手，伸了个懒腰打了个哈欠。 |\
|镜头切换，女人拿着相机，拍摄白人男性，男人双手交叉，双臂撑在膝盖上。 |\
|镜头切换，镜头俯拍桌面上的杂志，画面左下方出现一只手端着咖啡，将咖啡放在了杂志上，咖啡冒着热气。 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1926cc14b14f4e52b4225792001a8ebf~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1926cc14b14f4e52b4225792001a8ebf~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |i2v：船在风暴中穿行，闪电不断的划破夜空。切换成中景，一个船长站在甲板上，拿着复古的望远镜看向远方。镜头缓缓前推，他收起望远镜，表情坚毅的看向远方。 | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/45a632c1822341eb94585bc85f930648~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/45a632c1822341eb94585bc85f930648~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | |t2v：推到红发女孩惊讶的表情特写，镜头切到废墟中的一个窗台上的花盆，里面种着一个蓝色的多肉植物，镜头切到俯瞰，女孩走向这个多肉植物，切过多肉植物前景女孩双眼特写，摇到女孩的嘴，碎碎念出植物的名字。 |
| | | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ed6c7b47dcb7451e9840291ffb62faca~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ed6c7b47dcb7451e9840291ffb62faca~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |\
|t2v：在破旧的工厂里，一位侦探正在调查一宗离奇案件。开始以低机位仰拍，凸显侦探高大坚定的形象，他缓缓走进工厂深处。接着镜头平移跟随，切换为平机位，展示周围杂乱的机器和散落的零件。随后镜头推近，变为微俯平机位，聚焦在地上一个带血的脚印，营造紧张悬疑的氛围。 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/16e8eae2ac6342889ae2f7e537c76a70~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/16e8eae2ac6342889ae2f7e537c76a70~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| |t2v：科幻电影的奇特场景，全景画面，一个未来实验室内，画面核心有一个量子计算机，周边有一个科学家对着全息投影屏幕不断操作着。镜头切换成量子计算机的特写，量子计算机突然爆发出红色的光芒。然后镜头再次切换到科学家的脸，近景仰拍，红色的光晕照射在他的脸上，他表情开始变得慌张。 | |

<span id="1a350c84"></span>
## 创意特效
> 模型本身即可实现多种特效，发挥想象可以实现许多有意思的效果。


| ||| \
|视频生成示例 | | |
|---|---|---|
| | | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/826f39ab53fa416caef552221bb75a2b~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/826f39ab53fa416caef552221bb75a2b~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|t2v：自由女神像在纽约港夜晚的灯光下，底座突然喷出巨大火焰和烟雾，像火箭一样缓缓升空。火焰照亮夜空，气流冲击周围建筑和海面。镜头跟随她加速上升，划出明亮的火焰轨迹。 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2da9da273308463abe1b8327a067fab6~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2da9da273308463abe1b8327a067fab6~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |t2v：圆滚滚的牛蛙瘫在粉色按摩椅上，鼓胀的肚皮随着呼吸起伏，手惬意地耷拉在扶手上。一旁的长毛白猫踮着脚尖，肉垫轻轻揉捏着牛蛙紧绷的肩膀，娴熟的踩奶动作仿佛是最专业的按摩技师。 | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2d0ea2a01998486390de6705958172c9~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2d0ea2a01998486390de6705958172c9~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | |t2v：一个倒在古墓青砖地上已经只剩骨头架的盗墓贼趴在地上,他的两只枯骨手拖着骷髅骨架艰难的一下一下向前爬着,骷髅头笑盈盈。墓室香暗,有烛光照在骷髅脸上,地上散落着碎硫璃瓦、碎青花碗、还有生锈的古钱币。 |
| | | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/8c19361a710b46c280255f59c0f4ad49~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/8c19361a710b46c280255f59c0f4ad49~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |\
|i2v：男孩放下书，解开衣服露出蜘蛛侠紧身衣，戴上蜘蛛侠面具，向画外射出粘液，快速向镜头上方快飞出画 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b0486e5bbb754e59b50cb2a7199609be~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b0486e5bbb754e59b50cb2a7199609be~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| |i2v：天气很热，男孩冒出大量汗珠，冒着白烟，男孩融化着流出画面。 | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1fd4fa8b96224574b96e99dddda807ab~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1fd4fa8b96224574b96e99dddda807ab~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | | |\
| | |i2v：男孩生气了，鼓起了嘴，逐渐地全身开始鼓起，男孩全身爆炸，飞出很多零件。 |
| | | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7624ae1937f24296915ceaa1bc92fd81~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7624ae1937f24296915ceaa1bc92fd81~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |\
|i2v：男孩看着书，看着看着就老啦。脸颊越来越下垂，皮肤毛孔越来越明显，长出了鬓角和胡子，变成了沧桑大叔。画面也逐渐变成颗粒度明显地黑白风格 | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3ede49671206422ba237e8cd328c7179~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3ede49671206422ba237e8cd328c7179~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |\
| |i2v：男孩盯着镜头瞬间恋爱了，脸颊绯红，空气中飘起了半透明地粉红色泡泡，气氛变得暧昧，男孩害羞地用书挡住了脸。书皮上画了个心 | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cdbc234a678b4af7a554cfcf7608e095~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cdbc234a678b4af7a554cfcf7608e095~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | | |\
| | |i2v：狂风暴雨大作。男孩瞪大眼睛盯着书，突然很疑惑不接，很快豁然开朗。同时一束闪电劈中男孩。被雷劈中时男孩全身就像被烧过，夸张的爆炸头，冒烟。一脸焦炭的全身脏脏男孩无辜地抬头看镜头 |

<span id="470ef32f"></span>
## 画幅遵循
Seedance 1.0 pro 支持输出的视频比例有：1:1，3:4，4:3，16:9，9:16，21:9。
i2v建议用这些比例的图片作为参考帧，假如不是这些比例的话，自动匹配会通过裁切来适配最接近的比例。




<style>
/* 覆盖内联样式的宽高 */
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default
  .xgplayer-volume-large.xgplayer-pause.xgplayer-is-replay.xgplayer-ended,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-nostart.xgplayer-skin-default.xgplayer-inactive,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-nostart.xgplayer-skin-default,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing.xgplayer-pause,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing.xgplayer-inactive,
.volc-md-viewer .editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-is-enter,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-is-enter.xgplayer-inactive,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-playing,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-isloading.xgplayer-playing {
    width: 360px !important;
    height: 180px !important;
}   
</style>


# 获取 API Key 并配置
Source: https://www.volcengine.com/docs/82379/1541594
您调用方舟平台的模型之前，您需要 API Key 来进行鉴权。同时因为 API Key 信息较为敏感，泄露 API Key 会导致您的模型用量被其他人花费，造成一定的损失，因此我们会给出配置 API Key 进环境变量的方法，方便您合理安全地使用API Key。
<span id="20bdcc68"></span>
## 获取 API Key

1. 打开并登录 [API Key管理](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D) 页面。
2. （可选）单击左上角 **账号全部资源** 下拉箭头，切换项目空间。
3. 单击 **创建 API Key** 按钮。
4. 在弹出框的 **名称** 文本框中确认/更改 API Key名称，单击创建。

您可以在 [API Key管理](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D) 页面的 **API Key 列表**中查看刚创建的API Key信息。
:::tip
* 一个主账号下支持创建50个API Key，如需更多配额请提交工单，或者使用[Access Key鉴权](https://www.volcengine.com/docs/82379/1298459#access-key-%E7%AD%BE%E5%90%8D%E9%89%B4%E6%9D%83)。
* 您切换项目空间创建 API Key，可限制 API Key 只用于某项目空间下的模型服务的鉴权凭证。当您的账号是多人使用，可以通过此方法进行权限隔离。
:::
<span id="f1908ee9"></span>
## 配置 API Key
推荐您将 API Key 配置在环境变量中，而不是硬编码进代码中，避免API Key随代码泄露，导致账号配额被他人使用，导致您产生额外花费。
配置方法见：[配置 API Key 到环境变量](https://www.volcengine.com/docs/82379/1399008#4b62407d)。


# 安装及升级 SDK
Source: https://www.volcengine.com/docs/82379/1541595
方舟提供了 Python 、 Go 、 Java 的 SDK ，方便您使用对应编程语言快速调用/集成方舟的模型服务。
<span id="ba293e60"></span>
# 安装及升级
<span id="2708d57e"></span>
## Python SDK
<span id="f2baa8aa"></span>
### 前提条件
您本地已经安装了Python ，且版本不低于 3.7。
> 您可以在终端中输入命令确认Python是否安装以及安装的版本，如未安装，请参考[Python安装教程](https://wiki.python.org/moin/BeginnersGuide/Download)安装，注意选择版本3.7及以上版本。

```Shell
python -V
```

<span id="bb014324"></span>
### 安装 Python SDK
在终端中执行以下命令安装Python SDK。
```Bash
pip install 'volcengine-python-sdk[ark]'
```

:::tip
* 如果您本地安装错误，可以尝试使用下面方法
   * [Windows系统安装SDK失败，ERROR: Failed building wheel for volcengine-python-sdk](https://www.volcengine.com/docs/82379/1359411#b74e8ad6)
   * 尝试使用下面命令`pip install volcengine-python-sdk[ark]`
* 如果您需要源码安装可以下载相应版本的 SDK 包，解压后进入目录，执行如下命令：
   `python setup.py install --user`
:::
<span id="d6b883b8"></span>
### 升级 Python SDK
如您本地已经安装了 Python SDK，当需要使用方舟提供的最新能力，需要升级SDK至最新版本，可以在命令中增加`-U`参数。
```Bash
pip install -U 'volcengine-python-sdk[ark]'
```

<span id="f116fb9f"></span>
## Go SDK
<span id="0fa8c2bc"></span>
### 前提条件
检查并安装 Go 版本，Go 版本需要 1.18 或以上。
```Shell
go version
```

如果未安装 Go 或者版本不满足要求，您可以访问 [Go 语言官方网站](https://golang.google.cn/dl/)下载并安装适合您操作系统的 Go 版本。请确保选择 1.18 或以上版本。
<span id="ae8b42ab"></span>
### 安装 Go SDK

1. 火山方舟 Go SDK 使用 go mod 进行管理，如果本地工程没有初始化 go mod，您可以运行以下命令初始化 go mod。`<your-project-name>` 替换为您的项目名称。

```Shell
# 如在文件夹 ark-demo 下打开终端窗口，运行命令go mod init ark-demo
go mod init <your-project-name>
```


2. 在本地初始化 go mod 后，运行以下命令安装最新版 SDK。

```Shell
go get -u github.com/volcengine/volcengine-go-sdk
```

:::tip
为了保证系统一致性或者稳定性，你需要安装特定版本的SDK，可以通过下面，安装指定的版本。
`go get -u github.com/volcengine/volcengine-go-sdk@<VERSION>`

* 其中`<VERSION>`替换为您要安装的SDK版本号，可以从[这里](https://github.com/volcengine/volcengine-go-sdk/releases)查询。
:::

3. 在代码中引入 SDK 使用。

```Go
import "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
```


4. 更新依赖后，使用以下命令清理不需要的依赖并整理 `go.mod`和 `go.sum`文件。

```Shell
go mod tidy
```

<span id="f0739bb0"></span>
### 升级 Go SDK
步骤与安装 Go SDK相同，可参考[安装 Go SDK](https://www.volcengine.com/docs/82379/1541595#ae8b42ab)，第1，2步升级至最新/指定版本SDK。

* 升级至最新版本

```Shell
go get -u github.com/volcengine/volcengine-go-sdk
```


* 升级至指定版本

```Shell
go get -u github.com/volcengine/volcengine-go-sdk@<VERSION>
```

<span id="e7ae2925"></span>
## Java SDK
<span id="e3518e9f"></span>
### 前提条件

1. 检查并安装 Java 版本，Java 版本需要 1.8 或以上。

```Shell
java -version
```

如果未安装 Java 或者版本不满足要求，您可以访问 [Oracle 官方网站](https://www.java.com/en/download/help/index_installing.html)下载并安装适合您操作系统的 Java 版本。请确保选择 1.8 或以上版本。
<span id="ae8db863"></span>
### 安装 Java SDK
> 了解 SDK 最新版本，可访问源码地址：[https://github.com/volcengine/volcengine-java-sdk](https://github.com/volcengine/volcengine-java-sdk)

火山方舟 Java SDK 支持通过 Maven 安装、通过 Gradle 安装两种方式。
<span id="db12484d"></span>
#### 通过 Maven 安装
在 `pom.xml` 文件中进行如下配置，完整配置可参考 [Maven Central](https://central.sonatype.com/artifact/com.volcengine/volcengine-java-sdk-ark-runtime)：
```XML
<dependency>
  <groupId>com.volcengine</groupId>
  <artifactId>volcengine-java-sdk-ark-runtime</artifactId>
  <version>LATEST</version>
</dependency>
```

:::tip
替换'LATEST' 为 方舟 Java SDK 最新版本号，[点此](https://central.sonatype.com/artifact/com.volcengine/volcengine-java-sdk-ark-runtime)可查询。如果需要安装指定版本SDK，也可以替换为具体版本号。
:::
<span id="4858e8c3"></span>
#### 通过 Gradle 安装
在 `build.gradle` 文件中进行如下配置，在 `dependencies` 中添加依赖。
```JSON
implementation 'com.volcengine:volcengine-java-sdk-ark-runtime:LATEST'
```

:::tip
替换'LATEST' 为 方舟 Java SDK 最新版本号，[点此](https://mvnrepository.com/artifact/com.volcengine/volcengine-java-sdk-ark-runtime)可查询。如果需要安装指定版本SDK，也可以替换为具体版本号。
:::
<span id="4ab4182d"></span>
### 升级 Java SDK
同安装 Java SDK，指定需要升级的版本号即可。
<span id="6f32c555"></span>
## 第三方SDK
火山方舟模型调用 API 与 OpenAI API 协议兼容，您可以使用兼容 OpenAI API 协议的多语言社区 SDK 调用火山方舟大模型或应用。您可以很方便地迁移模型服务至方舟平台以及 Doubao 大模型。具体使用方法请参考[兼容OpenAI API](https://www.volcengine.com/docs/82379/1330626)。
<span id="4b8511f6"></span>
## 相关文档
[SDK 常见使用示例](https://www.volcengine.com/docs/82379/1544136)：包含SDK的常见用法。




# 对话(Chat) API
Source: https://www.volcengine.com/docs/82379/1494384
&nbsp;
<span style="background-color: rgb(43, 43, 43)"><code> POST https://ark.cn-beijing.volces.com/api/v3/chat/completions</code></span><span style="background-color: rgb(43, 43, 43)">   </span>[运行](https://api.volcengine.com/api-explorer/?action=ChatCompletionsText&groupName=%E5%AF%B9%E8%AF%9D%28Chat%29%20API&serviceCode=ark&version=2024-01-01)
<span style="background-color: rgb(255, 255, 255)">本文介绍文本生成模型和视觉理解模型调用 API 的输入输出参数，供您使用接口时查阅字段含义。</span>

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="NxI2ZZeLhf"><RenderMd content={` [ ](https://www.volcengine.com/docs/82379/1494384)[体验中心](https://console.volcengine.com/ark/region:ark+cn-beijing/experience/chat)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[模型列表](https://www.volcengine.com/docs/82379/1330310)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1544106)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[文本生成教程](https://www.volcengine.com/docs/82379/1362932) <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[视觉理解教程](https://www.volcengine.com/docs/82379/1362931) <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[接口文档](https://www.volcengine.com/docs/82379/1494384)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="oN1p8Un9hz"><RenderMd content={`本接口支持 API Key /Access Key 鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="在线调试" key="r3zSmb96VU"><RenderMd content={`<APILink link="https://api.volcengine.com/api-explorer/?action=ChatCompletionsText&groupName=%E5%AF%B9%E8%AF%9D%28Chat%29%20API&serviceCode=ark&version=2024-01-01" description="API Explorer 您可以通过 API Explorer 在线发起调用，无需关注签名生成过程，快速获取调用结果。"></APILink>
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


<span id="#RxN8G2nH"></span>
## 请求参数
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1494384#Qu59cel0)

<span id="#pjuiBZGA"></span>
### 请求体

---


**model** `string` `必选`
您需要调用的模型的 ID （<span style="background-color: rgb(255, 255, 255)">Model ID</span>），[开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)，并[查询 Model ID](https://www.volcengine.com/docs/82379/1330310) 。
<span style="background-color: rgb(243, 245, 247)">您也可通过 Endpoint ID 来调用模型，获得限流、计费类型（前付费/后付费）、运行状态查询、监控、安全等高级能力，可参考</span>[获取 Endpoint ID](https://www.volcengine.com/docs/82379/1099522)<span style="background-color: rgb(243, 245, 247)">。</span>

---


<span style="background-color: rgb(32, 33, 35)"><strong>messages</strong></span><span style="background-color: rgb(32, 33, 35)">  </span><span style="background-color: rgba(238, 242, 245, 0.5)"><code>object[]</code></span><span style="background-color: rgb(32, 33, 35)"> </span>`必选`
到目前为止的对话组成的消息列表。不同模型支持不同类型的消息，如文本、图片、视频等。

消息类型

---


**系统消息** `object`
<span style="background-color: rgb(32, 33, 35)">开发人员提供的指令，模型应遵循这些指令。如模型扮演的角色或者目标等。</span>

属性

---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为<span style="background-color: rgb(var(--gray-100)/.5)"><code>system</code></span><span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string / object[]</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
系统信息内容。

属性

---


**纯文本消息内容** `string`
纯文本消息内容，大语言模型支持传入此类型。

---


**多模态消息内容** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object[]</code></span> 
支持文本、图像、视频等类型，视觉理解模型等多模态模型、部分大语言模型支持此字段。

各模态消息部分

---


**文本消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，内容文本输入。[具备视觉理解能力模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)、部分大语言模型支持此类型消息。

属性

---


messages.content.**text** `string` `必选`
文本消息部分的内容。

---


messages.content.**type** `string` `必选`
文本消息类型，此处应为 `text`。


---


**图像消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，图像内容部分。[具备视觉理解能力模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)支持此类型消息。

属性

---


messages.content.**image_url** `object` `必选`
图片消息的内容部分。

属性

---


messages.content.image_url.**url** `string` `必选`
支持传入图片链接或图片的Base64编码，具体使用请参见[使用说明](https://www.volcengine.com/docs/82379/1362931#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E)。

---


messages.content.image_url.**detail** `string`  `默认值 auto`
<span style="background-color: rgb(255, 255, 255)">支持手动设置图片的质量，取值范围</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">：高细节模式，适用于需要理解图像细节信息的场景，如对图像的多个局部信息/特征提取、复杂/丰富细节的图像理解等场景，理解更全面。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">：低细节模式，适用于简单的图像分类/识别、整体内容理解/描述等场景，理解更快速。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">：默认模式，不同模型选择的模式略有不同，具体请参见</span>[理解图像的深度控制](https://www.volcengine.com/docs/82379/1362931#bf4d9224)<span style="background-color: rgb(255, 255, 255)">。</span>


---


messages.content.**type** `string` `必选`
图像消息类型，此处应为 `image_url`。


---


**视频信息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
> 视频理解模型请参见 [视频理解模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)。

多模态消息中，视频内容部分。

属性

---


messages.content.**type** `string` `必选`
视频消息类型，此处应为`video_url`。

---


messages.content.**video_url**`object` `必选`
视频消息的内容部分。

---


messages.content.video_url.**url** `string` `必选`
支持传入视频链接或视频的Base64编码。具体使用请参见[视频理解说明](https://www.volcengine.com/docs/82379/1362931#%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3)。

属性

---


messages.content.video_url.**fps** `float/ null` `默认值 1`
取值范围：`[0.2, 5]`。
每秒钟从视频中抽取指定数量的图像**。**取值越高，对于视频中画面变化理解越精细；取值越低，对于视频中画面变化感知减弱，但是使用的 token 花费少，速度也更快。详细说明见[用量说明](https://www.volcengine.com/docs/82379/1362931#%E7%94%A8%E9%87%8F%E8%AF%B4%E6%98%8E)。






---


**用户消息** `object` 
<span style="background-color: rgb(32, 33, 35)">用户发送的消息，包含提示或附加上下文信息。不同模型支持的字段类型不同，最多支持文本、图片、视频形式的消息。</span>

属性

---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为`user`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string / object[]</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
用户信息内容。

内容类型

---


**纯文本消息内容** `string`
纯文本消息内容，大语言模型支持传入此类型。

---


**多模态消息内容** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object[]</code></span> 
支持文本、图像、视频等类型，视觉理解模型等多模态模型、部分大语言模型支持此字段。

内容类型

---


**文本消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，内容文本输入。视觉理解模型、部分大语言模型支持此类型消息。

属性

---


messages.content.**text** `string` `必选`
文本消息部分的内容。

---


messages.content.**type** `string` `必选`
文本消息类型，此处应为 `text`。


---


**图像消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，图像内容部分。视觉理解模型支持此类型消息。

**属性**

---


messages.content.**type** `string` `必选`
图像消息类型，此处应为 `image_url`。

---


messages.content.**image_url** `object` `必选`
图片消息的内容部分。

**属性**

---


messages.content.image_url.**url** `string` `必选`
支持传入图片链接或图片的Base64编码，不同模型支持图片大小略有不同，具体请参见[使用说明](https://www.volcengine.com/docs/82379/1362931#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E)。

---


messages.content.image_url.**detail** `string / null`  `默认值 low`
<span style="background-color: rgb(255, 255, 255)">取值范围：</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
<span style="background-color: rgb(255, 255, 255)">支持手动设置图片的质量。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">：高细节模式，适用于需要理解图像细节信息的场景，如对图像的多个局部信息/特征提取、复杂/丰富细节的图像理解等场景，理解更全面。此时 </span>**min_pixels** 取值`3136`、**max_pixels** 取值`4014080`。
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">：低细节模式，适用于简单的图像分类/识别、整体内容理解/描述等场景，理解更快速。此时 </span>**min_pixels** 取值`3136`、**max_pixels** 取值`1048576`。
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">：默认模式，不同模型选择的模式略有不同，具体请参见</span>[理解图像的深度控制](https://www.volcengine.com/docs/82379/1362931#bf4d9224)<span style="background-color: rgb(255, 255, 255)">。</span>


---


messages.content.image_url.**image_pixel_limit**  `object / null` `默认值 null`
允许设置图片的像素大小限制，如果不在此范围，则会等比例放大或者缩小至该范围内。
生效优先级：高于 **detail** 字段，即同时配置 **detail** 与 **image_pixel_limit** 字段时，生效 **image_pixel_limit** 字段配置**。**
若 **min_pixels** / **max_pixels** 字段未设置，使用 **detail** 设置配置的值对应的 **min_pixels** / **max_pixels** 值。
子字段取值逻辑：`3136` <span style="background-color: rgb(255, 255, 255)">≤ </span>**min_pixels** <span style="background-color: rgb(255, 255, 255)">≤ </span>**max_pixels** <span style="background-color: rgb(255, 255, 255)">≤ </span>`4014080`

---



* messages.content.image_url.image_pixel_limit.**max_pixels** <span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
   取值范围：(**min_pixels**,  `4014080`]。
   传入图片最大像素限制，大于此像素则等比例缩小至 **max_pixels** 字段取值以下。
   若未设置，则取值为 **detail** 设置配置的值对应的 **max_pixels** 值。


---



* messages.content.image_url.image_pixel_limit.**min_pixels**
   取值范围：[`3136`,  **max_pixels**)。
   传入图片最小像素限制，小于此像素则等比例放大至 **min_pixels** 字段取值以上。
   若未设置，则取值为 **detail** 设置配置的值对应的 **min_pixels** 值（`3136`）。



---


**视频信息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
> 视频理解模型请参见 [视频理解模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)。

多模态消息中，视频内容部分。

属性

---


messages.content.**type** `string` `必选`
视频消息类型，此处应为 `video_url`**。**

---


messages.content.**video_url**`object` `必选`
视频消息的内容部分。

属性

---


messages.content.video_url.**url** `string` `必选`
支持传入视频链接或视频的Base64编码。具体使用请参见[视频理解说明](https://www.volcengine.com/docs/82379/1362931#%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3)。

---


messages.content.video_url.**fps** `float/ null` `默认值 1`
取值范围：`[0.2, 5]`。
每秒钟从视频中抽取指定数量的图像**。**取值越高，对于视频中画面变化理解越精细；取值越低，对于视频中画面变化感知减弱，但是使用的 token 花费少，速度也更快。详细说明见[用量说明](https://www.volcengine.com/docs/82379/1362931#%E7%94%A8%E9%87%8F%E8%AF%B4%E6%98%8E)。






---


**模型消息** `object`
<span style="background-color: rgb(32, 33, 35)">历史对话中，模型回复的消息。往往在多轮对话传入历史对话记录以及</span>[Prefill Response](https://www.volcengine.com/docs/82379/1359497)<span style="background-color: rgb(255, 255, 255)">时让模型按照预置的回复内容继续回复时使用。</span>

属性
:::tip
messages.**content**<span style="background-color: rgba(27, 31, 35, 0.05)"><strong> </strong></span><span style="background-color: rgb(255, 255, 255)">与 </span>messages.**tool_calls**<span style="background-color: rgba(27, 31, 35, 0.05)"><strong> </strong></span><span style="background-color: rgb(255, 255, 255)">字段二者至少填写其一。</span>

:::
---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为`assistant`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(32, 33, 35)"><code>string / array</code></span><span style="background-color: rgb(32, 33, 35)"> </span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>
模型回复的消息。

---


messages.**tool_calls** `object[]`
历史对话中，模型回复的工具调用信息。

显示子字段

---


messages.tool_calls**.function** `object` `必选`
<span style="background-color: rgb(255, 255, 255)">模型调用工具对应的函数信息。</span>

显示子字段

---


messages.tool_calls**.**function.**name** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">模型需要调用的函数名称。</span>

---


messages.tool_calls**.**function.<span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
:::tip
<span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>

:::

---


messages.tool_calls**.id** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>

---


messages.tool_calls**.type** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>



---


**工具消息** `object`
历史对话中模型调用工具的消息。<span style="background-color: rgb(32, 33, 35)">往往在多轮对话传入历史对话记录。</span>

属性

---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为`tool`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(32, 33, 35)"><code>string / array</code></span><span style="background-color: rgb(32, 33, 35)"> </span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
工具返回的消息。

---


messages.<span style="background-color: rgb(255, 255, 255)"><strong>tool_call_id </strong></span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span><span style="background-color: rgb(255, 255, 255)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">模型调用的工具的 ID。</span>



---


**thinking** `object` `默认值 {"type":"enabled"}`
控制模型是否开启深度思考模式。默认开启深度思考模式，可以手动关闭。
> 支持此字段的模型以及使用示例请参见[文档](https://www.volcengine.com/docs/82379/1449737#0002)。


属性

---


thinking.**type** `string`  `必选`
取值范围：`enabled`， `disabled`，`auto`。

* `enabled`：开启思考模式，模型一定先思考后回答。
* `disabled`：关闭思考模式，模型直接回答问题，不会进行思考。
* `auto`：自动思考模式，模型根据问题自主判断是否需要思考，简单题目直接回答。


---


**stream** `boolean / null` `默认值 false`
响应内容是否流式返回：

* `false`：模型生成完所有内容后一次性返回结果。
* `true`：按 SSE 协议逐块返回模型生成内容，并以一条 `data: [DONE] `消息结束。当 **stream** 为 `true` 时，可设置 **stream_options** 字段以获取 token 用量统计信息。


---


**stream_options** `object / null` `默认值 null`
流式响应的选项。当 **stream** 为 `true` 时，可设置 **stream_options** 字段。

属性

---


stream_options.**include_usage** `boolean / null` `默认值 false`
模型流式输出时，是否在输出结束前输出本次请求的 token 用量信息。

* `true`：在 `data: [DONE]` 消息之前会返回一个额外的 chunk。此 chunk 中， **usage** 字段中输出整个请求的 token 用量，**choices** 字段为空数组。
* `false`：输出结束前，没有一个 chunk 来返回 token 用量信息。


---


stream_options.**chunk_include_usage** `boolean / null` `默认值 false`
模型流式输出时，输出的每个 chunk 中是否输出本次请求到此 chunk 输出时刻的累计 token 用量信息。

* `true`：在返回的 **usage** 字段中，输出本次请求到此 chunk 输出时刻的累计 token 用量。
* `false`：不在每个 chunk 都返回 token 用量信息。


---


**max_tokens** `integer / null` `默认值 4096`
模型回答最大长度（单位 token），取值范围各个模型不同，详细见[模型列表](https://www.volcengine.com/docs/82379/1330310)。
输入 token 和输出 token 的总长度还受模型的上下文长度限制。

---


**max_completion_tokens** `integer / null` 
> 支持该字段的模型 `deepseek-r1-250528`，`doubao-seed-1-6-250615`， `doubao-seed-1-6-flash-250615`。

取值范围：`[0, 64k]`。
控制模型输出的最大长度（包括模型回答和模型思维链内容长度，单位 token）。配置了该参数后，可以让模型输出超长内容，**max_tokens** （默认值 4k）与思维链最大长度将失效，模型按需输出内容，直到达到 **max_completion_tokens** 配置的值。
不可与 **max_tokens** 字段同时设置，会直接报错。使用说明见[文档](https://www.volcengine.com/docs/82379/1449737#0001)。

---


**service_tier** `string / null` `默认值 auto`
指定是否使用[TPM保障包](https://www.volcengine.com/docs/82379/1510762)。生效对象为购买了保障包推理接入点。取值范围

* `auto`：优先使用TPM保障包。如果有TPM保障包额度的推理接入点，本次请求将会使用 TPM 保障包用量，获得更高限流以及响应速度。否则不使用，使用默认的限流和普通的服务响应速度。
* `default`：本次请求，不使用 TPM 保障包，使用默认的限流和普通的服务响应速度，即使请求的是有TPM保障包额度的推理接入点。


---


**stop** `string / string[] / null` `默认值 null`
模型遇到 stop 字段所指定的字符串时将停止继续生成，这个词语本身不会输出。最多支持 4 个字符串。
> [深度思考能力模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)不支持该字段。

`["你好", "天气"]`

---


**response_format** `object`  <span style="background-color: rgba(0, 0, 0, 0.04)"><code>默认值 {"type": "text"}</code></span>
模型输出内容须遵循此处指定的格式。

遵循格式

---


**遵循文本格式** `object`
模型默认回复文本格式内容。

属性

---


response_format.**type** `string` `必选`
此处应为 `text`。


---


**遵循JSON对象结构** `object`
模型回复内容以JSON对象结构来组织。
> 支持该字段的模型请参见[文档](https://www.volcengine.com/docs/82379/1568221#%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B)。


属性

---


response_format.**type** `string` `必选`
此处应为<span style="background-color: rgb(32, 33, 35)"><code>json_object</code></span><span style="background-color: rgb(32, 33, 35)">。</span>


---


**遵循JSON Schema定义的结构** `object`  `beta功能`
模型回复内容以JSON对象结构来组织，遵循 **schema** 字段定义的JSON结构。
> 支持该字段的模型请参见[文档](https://www.volcengine.com/docs/82379/1568221#%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B)。
> 该能力尚在 beta 阶段，请谨慎在生产环境使用。


属性

---


response_format.**type** `string` `必选`
此处应为<span style="background-color: rgb(32, 33, 35)"><code>json_schema</code></span><span style="background-color: rgb(32, 33, 35)">。</span>

---


response_format.<span style="background-color: rgb(32, 33, 35)"><strong>json_schema</strong></span><span style="background-color: rgb(32, 33, 35)"> </span>`object` `必选`
JSON结构体的定义。

属性

---


response_format.<span style="background-color: rgb(32, 33, 35)">json_schema.</span>**name** `string` `必选`
用户自定义的JSON结构的名称。

---


response_format.<span style="background-color: rgb(32, 33, 35)">json_schema.</span>**description** `string / null` 
回复用途描述，模型将根据此描述决定如何以该格式回复。

---


response_format.<span style="background-color: rgb(32, 33, 35)">json_schema.</span>**schema** `object` `必选`
回复格式的 JSON 格式定义，以 JSON Schema 对象的形式描述。

---


response_format.<span style="background-color: rgb(32, 33, 35)">json_schema.</span>**strict** `boolean / null` `默认值 false`
是否在生成输出时，启用严格遵循模式。

* `true`：模型将始终严格遵循**schema**字段中定义的格式。
* `false`：模型会尽可能遵循**schema**字段中定义的结构。




---


**frequency_penalty** `float / null` `默认值 0`
取值范围为 [\-2.0, 2.0]。
频率惩罚系数。如果值为正，会根据新 token 在文本中的出现频率对其进行惩罚，从而降低模型逐字重复的可能性。

---


**presence_penalty** `float / null` `默认值 0`
取值范围为 [\-2.0, 2.0]。
存在惩罚系数。如果值为正，会根据新 token 到目前为止是否出现在文本中对其进行惩罚，从而增加模型谈论新主题的可能性。

---


**temperature** `float / null` `默认值 1`
取值范围为 [0, 2]。
采样温度。控制了生成文本时对每个候选词的概率分布进行平滑的程度。当取值为 0 时模型仅考虑对数概率最大的一个 token。
较高的值（如 0.8）会使输出更加随机，而较低的值（如 0.2）会使输出更加集中确定。
通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。

---


**top_p** `float / null` `默认值 0.7`
取值范围为 [0, 1]。
核采样概率阈值。模型会考虑概率质量在 top_p 内的 token 结果。当取值为 0 时模型仅考虑对数概率最大的一个 token。
0.1 意味着只考虑概率质量最高的前 10% 的 token，取值越大生成的随机性越高，取值越低生成的确定性越高。通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。

---


**logprobs** `boolean / null` `默认值 false`
是否返回输出 tokens 的对数概率。

* `false`：不返回对数概率信息。
* `true`：返回消息内容中每个输出 token 的对数概率。


---


**top_logprobs** `integer / null` `默认值 0`
取值范围为 [0, 20]。
指定每个输出 token 位置最有可能返回的 token 数量，每个 token 都有关联的对数概率。仅当 **logprobs为**`true` 时可以设置 **top_logprobs** 参数。

---


**logit_bias** `map / null` `默认值 null`
调整指定 token 在模型输出内容中出现的概率，使模型生成的内容更加符合特定的偏好。**logit_bias** 字段接受一个 map 值，其中每个键为词表中的 token ID（使用 tokenization 接口获取），每个值为该 token 的偏差值，取值范围为 [\-100, 100]。
\-1 会减少选择的可能性，1 会增加选择的可能性；\-100 会完全禁止选择该 token，100 会导致仅可选择该 token。该参数的实际效果可能因模型而异。
`{"1234": -100}`

---


**tools** `object[] / null` `默认值 null`
待调用工具的列表，模型返回信息中可包含。当您需要让模型返回待调用工具时，需要配置该结构体。支持该字段的模型请参见[文档](https://www.volcengine.com/docs/82379/1330310#%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8%E8%83%BD%E5%8A%9B)。

属性

---


tools.**type** `string` `必选`
工具类型，此处应为 `function`。

---


tools.**function** `object` `必选`
模型返回中可包含待调用的工具。

属性

---


tools.function.**name** `string` `必选`
调用的函数的名称。

---


tools.function.**description** `string` 
调用的函数的描述，大模型会使用它来判断是否调用这个工具。

---


tools.function.**parameters** `object` 
函数请求参数，以 JSON Schema 格式描述。具体格式请参考 [JSON Schema](https://json-schema.org/understanding-json-schema) 文档，格式如下：
```JSON
{
  "type": "object",
  "properties": {
    "参数名": {
      "type": "string | number | boolean | object | array",
      "description": "参数说明"
    }
  },
  "required": ["必填参数"]
}
```

其中，

* 所有字段名大小写敏感。
* <span style="background-color: rgba(27, 31, 35, 0.05)"><strong>parameters</strong></span> 须是合规的 JSON Schema 对象。
* 建议用英文字段名，中文置于 <span style="background-color: rgba(27, 31, 35, 0.05)"><strong>description</strong></span> 字段中。



---


**parallel_tool_calls** <span style="background-color: rgb(255, 255, 255)"><code>boolean</code></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>默认值 true</code></span>
本次请求，模型返回是否允许包含多个待调用的工具。

* `true`：允许返回多个待调用的工具。
* `false`：允许返回的待调用的工具小于等于1，本取值当前仅 `doubao-seed-1-6-***` 模型生效。


---


**tool_choice** `string / object`
> 仅 <span style="background-color: rgb(255, 255, 255)"><code>doubao-seed-1-6-***</code></span><span style="background-color: rgb(255, 255, 255)"> 模型</span>支持此字段。

本次请求，模型返回信息中是否有待调用的工具。
当没有指定工具时，`none` 是默认值。如果存在工具，则 `auto` 是默认值。

可选类型

---


**工具选择模式** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
控制模型返回是否包含待调用的工具。

* `none` ：模型返回信息中不可含有待调用的工具。
* `required` ：模型返回信息中必须含待调用的工具。选择此项时请确认存在适合的工具，以减少模型产生幻觉的情况。
* `auto` ：模型自行判断返回信息是否有待调用的工具。


---


**工具调用** `object`
指定待调用工具的范围。模型返回信息中，只允许包含以下模型信息。选择此项时请确认该工具适合用户需求，以减少模型产生幻觉的情况。

属性

---


tool_choice.**name** `string` %%require%%
待调用工具的名称。

---


tool_choice.**type** `string` %%require%%
调用的类型，此处应为 `function`。


&nbsp;
<span id="#Qu59cel0"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1494384#RxN8G2nH)

<span id="#fT1TMaZk"></span>
### 非流式调用返回
> 跳转 [流式调用返回](https://www.volcengine.com/docs/82379/1494384#jp88SeXS)


---


**id** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求的唯一标识。</span>

---


**model** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求实际使用的模型名称和版本。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>service_tier</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">本次请求是否使用了TPM保障包。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>scale</code></span><span style="background-color: rgb(255, 255, 255)">：本次请求使用TPM保障包额度。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>default</code></span><span style="background-color: rgb(255, 255, 255)">：本次请求未使用TPM保障包额度。</span>


---


**created** `integer`
<span style="background-color: rgb(255, 255, 255)">本次请求创建时间的 Unix 时间戳（秒）。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>object</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>chat.completion</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


**choices** `object[]`
<span style="background-color: rgb(255, 255, 255)">本次请求的模型输出内容。</span>

属性

---


choices.**index** <span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">当前元素在 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><strong>choices</strong></span><span style="background-color: rgb(255, 255, 255)"> 列表的索引。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>finish_reason </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型停止生成 token 的原因。取值范围：</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>stop</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出自然结束，或因命中请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">stop</span><span style="background-color: rgb(255, 255, 255)"> 中指定的字段而被截断。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>length</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出因达到模型输出限制而被截断，有以下原因：</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_tokens</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">回答内容的长度限制）。</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_completion_tokens</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">思维链内容+回答内容的长度限制）。</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>context_window</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制</span><span style="background-color: rgb(255, 255, 255)">（输入内容+思维链内容+回答内容的长度限制）。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>content_filter</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出被内容审核拦截。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>tool_calls</code></span><span style="background-color: rgb(255, 255, 255)">：模型调用了工具。</span>


---


choices.**message** `object`
<span style="background-color: rgb(255, 255, 255)">模型输出的内容。</span>

属性

---


choices.message.**role** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">内容输出的角色，此处固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>assistant</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.message.**content** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的消息内容。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)"><strong>reasoning_content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string / null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型处理问题的思维链内容。</span>
<span style="background-color: rgb(255, 255, 255)">仅深度推理模型支持返回此字段，深度推理模型请参见</span>[支持模型](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)"><strong>tool_calls </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的工具调用。</span>

属性

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>id</strong></span> **** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>function </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">模型调用的函数。</span>

属性

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>name </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型调用的函数的名称。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
<span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>




---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>logprobs </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前内容的对数概率信息。</span>

属性
choices.<span style="background-color: rgb(255, 255, 255)">logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
<span style="background-color: rgba(27, 31, 35, 0.05)">message</span><span style="background-color: rgb(255, 255, 255)">列表中每个 </span><span style="background-color: rgba(27, 31, 35, 0.05)">content</span><span style="background-color: rgb(255, 255, 255)"> 元素中的 token 对数概率信息。</span>

属性

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>top_logprobs </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
<span style="background-color: rgb(255, 255, 255)">在当前 token 位置最有可能的标记及其对数概率的列表。在一些情况下，返回的数量可能比请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">top_logprobs</span><span style="background-color: rgb(255, 255, 255)"> 指定的数量要少。</span>

**属性**

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>




---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>moderation_hit_type </strong></span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span><span style="background-color: rgb(32, 33, 35)"><code>/ null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型输出文字含有敏感信息时，会返回模型输出文字命中的风险分类标签。</span>
<span style="background-color: rgb(255, 255, 255)">返回值及含义：</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>severe_violation</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及严重违规。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>violence</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及激进行为。</span>

<span style="background-color: rgb(255, 255, 255)">注意：当前只有</span>[视觉理解模型](https://www.volcengine.com/docs/82379/1362931#%E6%94%AF%E6%8C%81%E6%A8%A1%E5%9E%8B)<span style="background-color: rgb(255, 255, 255)">支持返回该字段，且只有在</span><span style="background-color: rgb(255, 255, 255)">方舟控制台</span>[接入点配置页面](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint/create?customModelId=)<span style="background-color: rgb(255, 255, 255)">或者 </span>[CreateEndpoint](https://www.volcengine.com/docs/82379/1262823)<span style="background-color: rgb(255, 255, 255)"> 接口中，将内容护栏方案（ModerationStrategy）设置为基础方案（Basic）时，才会返回风险分类标签。</span>


---


**usage** `object`
<span style="background-color: rgb(255, 255, 255)">本次请求的 token 用量。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>total_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">本次请求消耗的总 token 数量（输入 + 输出）。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">输入给模型处理的内容 token 数量。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens_details </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">输入给模型处理的内容 token 数量的细节。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)">prompt_tokens_details.</span><span style="background-color: rgb(248, 248, 248)"><strong>cached_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">缓存输入内容的 token 用量，此处应为</span><span style="background-color: rgba(27, 31, 35, 0.05)"> </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>0</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>


---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>completion_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">模型输出内容花费的 token。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>completion_tokens_details </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">模型输出内容花费的 token 的细节。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)">completion_tokens_details.</span><span style="background-color: rgb(248, 248, 248)"><strong>reasoning_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">输出思维链内容花费的 token 数 。</span>
<span style="background-color: rgb(255, 255, 255)">支持输出思维链的模型请参见</span>[文档](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>



---


&nbsp;
<span id="#jp88SeXS"></span>
### 流式调用返回
> 跳转 [非流式调用返回](https://www.volcengine.com/docs/82379/1494384#fT1TMaZk)


---


**id** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求的唯一标识。</span>

---


**model** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求实际使用的模型名称和版本。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>service_tier</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">本次请求是否使用了TPM保障包。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>scale</code></span><span style="background-color: rgb(255, 255, 255)">：本次请求使用TPM保障包额度。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>default</code></span><span style="background-color: rgb(255, 255, 255)">：本次请求未使用TPM保障包额度。</span>


---


**created** `integer`
<span style="background-color: rgb(255, 255, 255)">本次请求创建时间的 Unix 时间戳（秒）。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>object</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>chat.completion.chunk</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


**choices** `object[]`
<span style="background-color: rgb(255, 255, 255)">本次请求的模型输出内容。</span>

属性

---


choices.**index** <span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">当前元素在 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><strong>choices</strong></span><span style="background-color: rgb(255, 255, 255)"> 列表的索引。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>finish_reason </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型停止生成 token 的原因。取值范围：</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>stop</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出自然结束，或因命中请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">stop</span><span style="background-color: rgb(255, 255, 255)"> 中指定的字段而被截断。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>length</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出因达到模型输出限制而被截断，有以下原因：</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_tokens</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">回答内容的长度限制）。</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_completion_tokens</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">思维链内容+回答内容的长度限制）。</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>context_window</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制</span><span style="background-color: rgb(255, 255, 255)">（输入内容+思维链内容+回答内容的长度限制）。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>content_filter</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出被内容审核拦截。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>tool_calls</code></span><span style="background-color: rgb(255, 255, 255)">：模型调用了工具。</span>


---


choices.**delta** `object`
<span style="background-color: rgb(255, 255, 255)">模型输出的增量内容。</span>

属性

---


choices.delta.**role** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">内容输出的角色，此处固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>assistant</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.delta.**content** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的消息内容。</span>

---


choices.delta.<span style="background-color: rgb(255, 255, 255)"><strong>reasoning_content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string / null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型处理问题的思维链内容。</span>
<span style="background-color: rgb(255, 255, 255)">仅深度推理模型支持返回此字段，深度推理模型请参见</span>[支持模型](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.delta.<span style="background-color: rgb(255, 255, 255)"><strong>tool_calls </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的工具调用。</span>

属性

---


choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>i</strong></span>**d** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>

---


choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>function </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">模型调用的函数。</span>

属性

---


choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>name </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型调用的函数的名称。</span>

---


choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
<span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>




---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>logprobs </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前内容的对数概率信息。</span>

属性

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
<span style="background-color: rgba(27, 31, 35, 0.05)">message</span><span style="background-color: rgb(255, 255, 255)">列表中每个 </span><span style="background-color: rgba(27, 31, 35, 0.05)">content</span><span style="background-color: rgb(255, 255, 255)"> 元素中的 token 对数概率信息。</span>

属性

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>top_logprobs </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
<span style="background-color: rgb(255, 255, 255)">在当前 token 位置最有可能的标记及其对数概率的列表。在一些情况下，返回的数量可能比请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">top_logprobs</span><span style="background-color: rgb(255, 255, 255)"> 指定的数量要少。</span>

属性

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>




---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>moderation_hit_type </strong></span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span><span style="background-color: rgb(32, 33, 35)"><code>/ null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型输出文字含有敏感信息时，会返回模型输出文字命中的风险分类标签。</span>
<span style="background-color: rgb(255, 255, 255)">返回值及含义：</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>severe_violation</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及严重违规。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>violence</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及激进行为。</span>

<span style="background-color: rgb(255, 255, 255)">注意：当前只有</span>[视觉理解模型](https://www.volcengine.com/docs/82379/1362931#%E6%94%AF%E6%8C%81%E6%A8%A1%E5%9E%8B)<span style="background-color: rgb(255, 255, 255)">支持返回该字段，且只有在</span><span style="background-color: rgb(255, 255, 255)">方舟控制台</span>[接入点配置页面](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint/create?customModelId=)<span style="background-color: rgb(255, 255, 255)">或者 </span>[CreateEndpoint](https://www.volcengine.com/docs/82379/1262823)<span style="background-color: rgb(255, 255, 255)"> 接口中，将内容护栏方案（ModerationStrategy）设置为基础方案（Basic）时，才会返回风险分类标签。</span>


---


**usage** `object`
<span style="background-color: rgb(255, 255, 255)">本次请求的 token 用量。</span>
<span style="background-color: rgb(255, 255, 255)">流式调用时，默认不统计 token 用量信息，返回值为</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>null</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
<span style="background-color: rgb(255, 255, 255)">如需统计，需设置 </span><span style="background-color: rgb(255, 255, 255)"><strong>stream_options.include_usage</strong></span><span style="background-color: rgb(255, 255, 255)">为</span><span style="background-color: rgb(255, 255, 255)"><code>true</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>total_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">本次请求消耗的总 token 数量（输入 + 输出）。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">输入给模型处理的内容 token 数量。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens_details </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">输入给模型处理的内容 token 数量的细节。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)">prompt_tokens_details.</span><span style="background-color: rgb(248, 248, 248)"><strong>cached_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">缓存输入内容的 token 用量，此处应为</span><span style="background-color: rgba(27, 31, 35, 0.05)"> </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>0</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>


---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>completion_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">模型输出内容花费的 token。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>completion_tokens_details </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">模型输出内容花费的 token 的细节。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)">completion_tokens_details.</span><span style="background-color: rgb(248, 248, 248)"><strong>reasoning_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">输出思维链内容花费的 token 数 。</span>
<span style="background-color: rgb(255, 255, 255)">支持输出思维链的模型请参见</span>[文档](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>


&nbsp;




# 同声传译 API
Source: https://www.volcengine.com/docs/82379/1394617
```HTTP
wss://ark-beta.cn-beijing.volces.com/api/v3/realtime?service=clasi&model=<Model>
```



本文介绍 Doubao 同声传译大模型API的输入输出参数，帮助您使用 WebSocket 接口向大模型发起同声传译请求。服务会即时将输入的音频信息输入给模型，并返回音频转录的文本，以及翻译后的文本。
:::tip
此为邀测能力，如需使用，提交[测试申请工单](https://console.volcengine.com/auth/login?redirectURI=%2Fworkorder%2Fcreate%3Fstep%3D2%26SubProductID%3DP00001166)。
:::


<span id="鉴权方式"></span>
# 鉴权方式
本接口支持 API Key 鉴权方式，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
<span id="b2e89a2f"></span>
# 工作机制
请参见[工作机制](https://www.volcengine.com/docs/82379/1433754#d540c6f6)。
<span id="d635c6e8"></span>
# 使用教程
API 使用教程请参见 [同声传译](https://www.volcengine.com/docs/82379/1433754)。
:::warning
当您的业务数据量较大或并发量大，请关注服务限流信息，具体请参见[接口说明](https://www.volcengine.com/docs/82379/1433754#aaf45f14)。
:::

<span id="a9d3e0de"></span>
# 事件（Events）
<span id="a9e54e79"></span>
## 客户端事件（Client Events）
<span id="fa463f91"></span>
### session.update
发送此事件以更新会话的默认配置。客户端可以随时发送此事件更新 session 配置，且所有字段都可随时更新。收到该事件后，服务端将使用`session.updated`事件进行响应，响应事件会显示完整的有效配置信息。当您想清除配置信息时，需设置对应字段为空。

| | | | | | | | \
|参数名称 |子字段 |类型 |必填 |默认值 |描述 |示例值 |
|---|---|---|---|---|---|---|
| | | | | | | | \
|event_id |\- |String |否 |\- |用于标识此事件的客户端生成的 ID。 |event_*** |\
| | | | | | | |
| | | | | | | | \
|type |\- |String |是 |\- |事件类型，必须为`session.update` |session.update |
| | | | | | | | \
|session |\- |Object |是 |\- |会话的配置信息。 |\- |
| | | | | | | | \
| |modalities |List<String> |否 |["text"] |输出内容的模态，目前只支持`text`。 |["text"] |
| | | | | | | | \
| |input_audio_format |String |\
| | | |是 |\
| | | | |pcm16 |\
| | | | | |输入音频格式，支持`pcm16`和`opus`。 |\
| | | | | | |\
| | | | | |* pcm16 是指 16 kHz 采样率，16位采样位宽的单通道音频数据，是一种未压缩的音频格式，适用于高质量无损音频记录，宽带要求高。 |\
| | | | | |* Opus 是一种有损压缩的编码格式，支持 6 kbps 到 510 kbps 的比特率范围及 8 kHz 至 48 kHz 的采样率，可根据网络状况和音频内容自动调整参数，适用于语音通信、网络会议等对实时性和带宽利用率要求高的场景。 |pcm16 |\
| | | | | | | |
| | | | | | | | \
| |speaker_detection |Object |否 |\- |声纹检测的配置信息。 | |
| | | | | | | | \
| |speaker_detection.enable_speaker_change_detection |Boolean |否 |False |是否基于声学匹配识别开启说话人切换检测。 |\
| | | | | | |\
| | | | | |* `True`：开启说话人切换检测，并在响应 |\
| | | | | | |\
| | | | | |`response.input_audio_transcription.delta`和 |\
| | | | | |`response.input_audio_translation.delta` |\
| | | | | |中返回相关标记。 |\
| | | | | | |\
| | | | | |* `False`：关闭说话人切换检测。 |True |
| | | | | | | | \
| |input_audio_translation |Object |是 |\- |语音翻译相关的配置信息。 |\- |
| | | | | | | | \
| |input_audio_translation.source_language |String |是 |zh |源语种，需使用ISO 639 - 1语言代码指定源语种和目标语种，目前仅支持`zh`，`en`。 |zh |
| | | | | | | | \
| |input_audio_translation.target_language |String |是 |en |目标语种，需使用ISO 639 - 1语言代码指定源语种和目标语种，目前仅支持`en`，`zh`。 |\
| | | | | |:::warning |\
| | | | | |源语种和目标语种必须为不同语种。 |\
| | | | | |::: |en |
| | | | | | | | \
| |input_audio_translation.add_vocab |Object |否 |\- |\
| | | | | |自定义词典，该object的所有配置字段（热词和术语）加和不超过200个。超过则会报错。 |\- |
| | | | | | | | \
| |input_audio_translation.add_vocab.hot_word_list |List<String> |否 |\- |\
| | | | | |热词列表，需输入源语言热词列表，输入其他语言无效。  |\
| | | | | |```Plain Text |\
| | | | | |"hot_word_list":[ |\
| | | | | |     "智能体应用", |\
| | | | | |     "coze平台" |\
| | | | | |] |\
| | | | | |``` |\
| | | | | | |\- |
| | | | | | | | \
| |input_audio_translation.add_vocab.glossary_list |List<Glossary> |\
| | | |否 |\
| | | | |\- |翻译可参考的术语列表。其中，input_audio_transcription为原文，input_audio_translation为译文。  |\
| | | | | |```Plain Text |\
| | | | | |"glossary_list":[ |\
| | | | | |    { |\
| | | | | |        "input_audio_transcription":"豆包", |\
| | | | | |        "input_audio_translation":"Doubao" |\
| | | | | |    }, |\
| | | | | |    { |\
| | | | | |        "input_audio_transcription":"火山引擎", |\
| | | | | |        "input_audio_translation":"Volcengine" |\
| | | | | |    } |\
| | | | | | ] |\
| | | | | |``` |\
| | | | | | |\- |

<span id="ed707c92"></span>
#### 请求示例
```JSON
{
    "event_id": "event_120",
    "type": "session.update",
    "session": {
        "input_audio_format": "pcm16",
        "modalities": ["text"],
        "speaker_detection": {
            "enable_speaker_change_detection": True,
        },
        "input_audio_translation": {
            "source_language": "zh",
            "target_language": "en",
            "add_vocab": {
                "hot_word_list": [],
                "glossary_list": [
                    {
                        "input_audio_transcription": "火山引擎智能创作平台",
                        "input_audio_translation": "volcengine creative cloud"
                    }
                ]
            }
        }
    }
}
```


<span id="fa1622d9"></span>
### input_audio.commit
发送此事件以提交音频。为确保系统稳定运行，建议每100-200ms发送一次该事件，发送过快可能导致服务出错。
:::warning
单个连接每分钟内提交此事件的次数 Commit Per Minute (CPM) Per Connection上限为 700 次。提交该事件次数超过限制时，服务端将跳过超出限制的事件，并返回`error`事件。
:::

| | | | | \
|参数名称 |类型 |必填 |描述 |
|---|---|---|---|
| | | | | \
|event_id |String |否 |用于标识此事件的客户端生成的 ID。 |
| | | | | \
|type |String |是 |事件类型，必须为`input_audio.commit`。 |
| | | | | \
|audio |String |是 |Base64 编码的音频数据，需采用会话配置中 input_audio_format 字段指定的格式。 |\
| | | |:::warning |\
| | | |音频数据上限为10KB 。传入超过10 KB 的音频数据时，服务端将跳过该事件不处理对应音频数据，并返回`error`事件。 |\
| | | |::: |

<span id="5779d425"></span>
#### 请求示例
```JSON
{
    "event_id": "event_121",
    "type": "input_audio.commit",
    "audio": "CACu/wEA3P8pAPX/****"
}
```

<span id="ac847ad0"></span>
### input_audio.done
发送此事件以告知服务端已经完成了所有计划发送的音频数据的发送。该事件通常在麦克风结束输入时发送。客户端发送该事件后，服务端将不再接受任何新的 `input_audio.commit`事件，当服务端处理完已接收到的所有音频数据后会发送`response.done`事件。

| | | | | \
|参数名称 |类型 |必填 |描述 |
|---|---|---|---|
| | | | | \
|event_id |String |否 |用于标识此事件的客户端生成的 ID。 |
| | | | | \
|type |String |是 |事件类型，必须为`input_audio.done`。 |

<span id="3a705fc5"></span>
#### 请求示例
```JSON
{
    "event_id": "event_122",
    "type": "input_audio.done"
}
```

<span id="4899b257"></span>
## 服务端事件（Server Events）
<span id="a394452f"></span>
### session.created
创建对话时自动创建，返回默认配置信息。在会话创建后立即发出。

| | | | | | \
|参数名称 |子参数 |类型 |描述 |示例值 |
|---|---|---|---|---|
| | | | | | \
|event_id |\- |String |服务端事件的唯一ID。 |event_*** |
| | | | | | \
|type |\- |String |事件类型，为`session.created `。 |session.created |
| | | | | | \
|session |\- |Object |会话的配置信息。 |\- |
| | | | | | \
| |id |String |会话的唯一ID。 |sess_*** |
| | | | | | \
| |object |String |会话对象的类型，为`"realtime.session"` |realtime.session |
| | | | | | \
| |input_audio_format |String |输入音频格式，目前默认`pcm16`为初始设置。 |pcm16 |
| | | | | | \
| |model |String |实际使用的模型名称和版本。 |doubao-clasi-*** |
| | | | | | \
| |modalities |List<String> |输出内容的模态，目前只支持`text`。 |["text"] |
| | | | | | \
| |input_audio_translation |Object |语音翻译相关的配置信息。 |\- |
| | | | | | \
| |input_audio_translation.source_language |String |源语种，需使用ISO 639 - 1语言代码指定源语种和目标语种，目前仅支持`zh`，`en`。 |zh |
| | | | | | \
| |input_audio_translation.target_language |String |目标语种，需使用ISO 639 - 1语言代码指定源语种和目标语种，目前仅支持`en`，`zh`。 |en |
| | | | | | \
| |input_audio_translation.add_vocab |Object |\
| | | |自定义词典，该object的所有配置字段（热词和术语）加和不超过200个。超过则会报错。 |\- |
| | | | | | \
| |input_audio_translation.add_vocab.hot_word_list |List<String> |使用的热词列表。 |\
| | | |```Plain Text |\
| | | |"hot_word_list":[ |\
| | | |     "智能体应用", |\
| | | |     "coze平台" |\
| | | |] |\
| | | |``` |\
| | | | |\- |
| | | | | | \
|  |input_audio_translation.add_vocab.glossary_list |List<Glossary> |\
| | | |翻译可参考的术语列表。其中， |\
| | | | |\
| | | |* `input_audio_transcription`为原文。 |\
| | | |* `input_audio_translation`为译文。 |\
| | | | |\
| | | |```Plain Text |\
| | | |"glossary_list":[ |\
| | | |    { |\
| | | |        "input_audio_transcription":"豆包", |\
| | | |        "input_audio_translation":"Doubao" |\
| | | |    }, |\
| | | |    { |\
| | | |        "input_audio_transcription":"火山引擎", |\
| | | |        "input_audio_translation":"Volcengine" |\
| | | |    } |\
| | | | ] |\
| | | |``` |\
| | | | |\- |
| | | | | | \
| |speaker_detection |Object |是否基于声学匹配识别进行说话人切换检测，默认为null。 |null |

<span id="ce5af626"></span>
#### 返回示例
```JSON
{
    "event_id": "event_123",
    "type": "session.created",
    "session": {
        "id": "sess_***",
        "object": "realtime.session",
        "modalities": [
            "text"
        ],
        "model": "doubao-clasi-***",
        "input_audio_format": "pcm16",
        "input_audio_translation": {
            "source_language": "zh",
            "target_language": "en",
            "add_vocab": null
        }
        "speaker_detection":null
    }
}
```

<span id="7eab81fa"></span>
### session.updated
除非出现错误，否则在使用 session.update 事件更新会话时返回。

| | | | | | \
|参数名称 |子参数 |类型 |描述 |示例值 |
|---|---|---|---|---|
| | | | | | \
|event_id |\- |String |服务端事件的唯一ID。 |event_*** |
| | | | | | \
|type |\- |String |事件类型，为`session.updated`。 |session.updated |
| | | | | | \
|session |\- |Object |会话的配置信息。 |\- |
| | | | | | \
| |id |String |会话的唯一ID。 |sess_*** |
| | | | | | \
| |object |String |会话对象的类型，为`"realtime.session"` |realtime.session |
| | | | | | \
| |input_audio_format |String |输入音频格式，支持`pcm16`和`opus`。 |pcm16 |
| | | | | | \
| |model |String |本次请求实际使用的模型名称和版本。 |doubao-clasi-*** |
| | | | | | \
| |modalities |List<String> |输出内容的模态，目前只支持`text`。 |["text"] |
| | | | | | \
| |input_audio_translation |Object |语音翻译相关的配置信息。 |\- |
| | | | | | \
| |input_audio_translation.source_language |String |源语种，需使用ISO 639 - 1语言代码指定源语种和目标语种，目前仅支持`zh`，`en`。 |zh |
| | | | | | \
| |input_audio_translation.target_language |String |目标语种，需使用ISO 639 - 1语言代码指定源语种和目标语种，目前仅支持`en`，`zh`。 |en |
| | | | | | \
| |input_audio_translation.add_vocab |Object |\
| | | |自定义词典，该object的所有配置字段（热词和术语）加和不超过200个。 |\- |
| | | | | | \
| |input_audio_translation.add_vocab.hot_word_list |List<String> |传入的热词列表。 |\
| | | |```Plain Text |\
| | | |"hot_word_list":[ |\
| | | |     "智能体应用", |\
| | | |     "coze平台" |\
| | | |] |\
| | | |``` |\
| | | | |\- |
| | | | | | \
|  |input_audio_translation.add_vocab.glossary_list |List<Glossary> |\
| | | |翻译可参考的术语列表。其中， |\
| | | | |\
| | | |* `input_audio_transcription`为原文。 |\
| | | |* `input_audio_translation`为译文。 |\
| | | | |\
| | | |```Plain Text |\
| | | |"glossary_list":[ |\
| | | |    { |\
| | | |        "input_audio_transcription":"豆包", |\
| | | |        "input_audio_translation":"Doubao" |\
| | | |    }, |\
| | | |    { |\
| | | |        "input_audio_transcription":"火山引擎", |\
| | | |        "input_audio_translation":"Volcengine" |\
| | | |    } |\
| | | | ] |\
| | | |``` |\
| | | | |\- |
| | | | | | \
| |speaker_detection |Object |声纹检测的配置信息。 |\- |
| | | | | | \
| |speaker_detection.enable_speaker_change_detection |Boolen |是否基于声学匹配识别开启说话人切换检测。 |\
| | | | |\
| | | |* `true`：开启说话人切换检测，并在响应中返回相关标记。 |\
| | | |* `false`：关闭说话人切换检测。 |true |

<span id="54f17a48"></span>
#### 返回示例
```JSON
{
    "event_id": "event_124",
    "type": "session.updated",
    "session": {
        "id": "sess_***",
        "object": "realtime.session",
        "modalities": [
            "text"
        ],
        "model": "doubao-clasi-***",
        "input_audio_format": "pcm16",
        "input_audio_translation": {
            "source_language": "zh",
            "target_language": "en",
            "add_vocab": {
                "hot_word_list": [],
                "glossary_list": [
                    {
                        "input_audio_transcription": "火山引擎智能创作平台",
                        "input_audio_translation": "volcengine creative cloud"
                    }
                ]
            }
        }
        "speaker_detection": {
            "enable_speaker_change_detection": True
        }
    }
}
```

<span id="459e95d1"></span>
### response.created
创建新 Response 时返回。新Response被创建时返回的第一个事件，其中响应处于in_progress的初始状态。

| | | | | | \
|参数名称 |子参数 |类型 |描述 |示例值 |
|---|---|---|---|---|
| | | | | | \
|event_id |\- |String |服务端事件的唯一ID。 |event_**** |
| | | | | | \
|type |\- |String |事件类型，为`response.created`。 |\- |
| | | | | | \
|response |\- |Object |响应信息。 |\- |
| | | | | | \
| |id |String |响应信息的唯一ID。 |resp_003 |
| | | | | | \
| |object |String |响应对象的类型，为`"realtime.response"`。 |realtime.response |
| | | | | | \
| |status |String |响应状态，为`in_progress`。 |in_progress |
| | | | | | \
|  |usage  |Object  |本次连接使用情况的统计信息。  |\-  |
| | | | | | \
| |usage.total_tokens |Integer  |本次连接消耗的总 token 数量（输入 + 输出）。 |\
| | | | |1000 |
| | | | | | \
| |usage.input_tokens  |Integer  |本次连接消耗的输入token 数量。 |200 |
| | | | | | \
|  |usage.output_tokens  |Integer  |本次连接消耗的输出token 数量，包括转录和翻译。  |800  |\
| | | | |  |
| | | | | | \
| |usage.input_token_details |Object |本次连接消耗的输入token详细信息。 |\- |
| | | | | | \
| |usage.input_token_details.audio_tokens |Integer  |\
| | | |本次连接消耗的输入token中用于音频的token 数量。 |200 |

<span id="f4d63c86"></span>
#### 返回示例
```JSON
{
    "event_id": "event_125",
    "type": "response.created",
    "response": {
        "id": "resp_***",
        "object": "realtime.response",
        "status": "in_progress",
        "usage": null
    }
}
```

<span id="89d0fa8a"></span>
### response.done
发送此事件以告知客户端，服务端已经处理完所有接收到的音频数据，并且已经发送了所有的`response.input_audio_transcription.delta` /`response.input_audio_translation.delta`事件，本次连接结束。

| | | | | | \
|参数名称 |子参数 |类型 |描述 |示例值 |
|---|---|---|---|---|
| | | | | | \
|event_id |\- |String |服务端事件的唯一ID。 |event_**** |
| | | | | | \
|type |\- |String |事件类型。 |response.done |
| | | | | | \
|response |\- |object |响应信息。 |\- |
| | | | | | \
| |id |String |响应信息的唯一ID。 |resp_**** |
| | | | | | \
| |object |String |对象的类型，为`"realtime.response"`。 |realtime.response |
| | | | | | \
| |status |String |\
| | | |响应的最终状态，目前支持 |\
| | | | |\
| | | |* `completed`：服务端处理完已接收到的所有音频数据，正常结束连接。 |\
| | | |* `failed`：发生错误，连接中断。 |\
| | | |* `timeout`：连接超时，服务端强制断开连接。 |\
| | | | |\
| | | |:::warning |\
| | | |以下情况服务端将强制断开连接，响应状态为`timeout`。 |\
| | | | |\
| | | |* 单连接连接时长超过 2 小时。 |\
| | | |* 单连接静默持续时长 0.5 小时。  |\
| | | |::: |completed |
| | | | | | \
|  |usage  |Object  |本次连接使用情况的统计信息。  |\-  |
| | | | | | \
| |usage.total_tokens |Integer  |本次连接消耗的总 token 数量（输入 + 输出）。 |\
| | | | |1000 |
| | | | | | \
| |usage.input_tokens  |Integer  |本次连接消耗的输入token 数量。 |200 |
| | | | | | \
| |usage.input_token_details |Object |本次连接消耗的输入token详细信息。 |\- |
| | | | | | \
| |usage.input_token_details.audio_tokens |Integer  |\
| | | |本次连接消耗的输入token中用于音频的token 数量。 |200 |

<span id="d9cb0340"></span>
#### 返回示例
```JSON
{
    "event_id": "event_126",
    "type": "response.done",
    "response": {
        "id": "resp_0217355307251692f1d0fe07ac2ef6d29344c285c5cccbb1eed50",
        "object": "realtime.response",
        "status": "completed",
        "usage": {
            "total_tokens":634,
            "input_tokens":211,
            "output_tokens": 423,
            "input_token_details": {
                "audio_tokens":211
            }
        }
    }
}
```

<span id="7936dad2"></span>
### response.input_audio_transcription.delta 
流式返回的转录文本结果。

| | | | | \
|参数名称 |类型 |描述 |示例值 |
|---|---|---|---|
| | | | | \
|event_id |String |服务端事件的唯一ID。 |event_**** |
| | | | | \
|type |String |事件类型，为： |\
| | |`response.input_audio_transcription.delta ` |response.input_audio_transcription.delta |
| | | | | \
|response_id |String |响应信息的唯一ID。 |resp_**** |\
| | | | |
| | | | | \
|delta |String |流式返回的转录文本的内容。 |\- |
| | | | | \
|language |String |返回文本的语种，支持如下： |\
| | | |\
| | |* `en`：英文。 |\
| | |* `zh`：中文。 |en |
| | | | | \
|start_ms |Integer |该段音频信息起始时间在原始音频的时刻（单位 ms）。 |\
| | |> 结合`end_ms`字段，表示该段音频信息在原始音频中的时间段。 |200 |
| | | | | \
|end_ms |Integer |该段音频信息终止时间在原始音频的时刻（单位 ms）。 |\
| | |> 结合`start_ms`字段，表示该段音频信息在原始音频中的时间段。 |400 |
| | | | | \
|speaker_change |Boolean |是否检测到说话人切换： |\
| | | |\
| | |* `true`：检测到说话人切换。 |\
| | |* `false`：未检测到说话人切换。 |\
| | | |\
| | |仅在`session.update`中设置`enable_speaker_change_detection = True` 时返回该字段。 |true |

<span id="be106a83"></span>
#### 返回示例
```JSON
{
    "event_id": "event_127",
    "type": "response.input_audio_transcription.delta",
    "response_id": "resp_0217355307251692f1d0fe07ac2ef6d29344c285c5cccbb1eed50",
    "delta": "定制服务",
    "language": "zh",
    "start_ms": 0,
    "end_ms": 800,
    "speaker_change": true
}
```

<span id="64d8e1b2"></span>
### response.input_audio_translation.delta
流式返回的翻译文本结果。

| | | | | \
|参数名称 |类型 |描述 |示例值 |
|---|---|---|---|
| | | | | \
|event_id |String |服务端事件的唯一ID。 |event_**** |
| | | | | \
|type |String |事件类型，必须为： |\
| | |`response.input_audio_translation.delta` |response.input_audio_translation.delta |
| | | | | \
|response_id |String |响应信息的唯一ID。 |resp_**** |\
| | | | |
| | | | | \
|delta |String |流式返回的翻译文本的内容。 |\- |
| | | | | \
|language |String |返回文本的语种，支持如下： |\
| | | |\
| | |* `en`：英文。 |\
| | |* `zh`：中文。 |en |
| | | | | \
|start_ms |Integer |对应原始音频开始时间（以ms为单位）。 |200 |
| | | | | \
|end_ms |Integer |对应原始音频结束时间（以ms为单位）。 |400 |
| | | | | \
|speaker_change |Boolean |是否检测到说话人切换： |\
| | | |\
| | |* `true`：检测到说话人切换。 |\
| | |* `false`：未检测到说话人切换。 |\
| | | |\
| | |仅在`session.update`中设置`enable_speaker_change_detection = True` 时返回该字段。 |true |

<span id="65578f9c"></span>
#### 返回示例
```JSON
{
    "event_id": "event_128",
    "type": "response.input_audio_translation.delta",
    "response_id": "resp_0217355307251692f1d0fe07ac2ef6d29344c285c5cccbb1eed50",
    "delta": "The customized service",
    "language": "en",
    "start_ms": 0,
    "end_ms": 800,
    "speaker_change": true
}
```

<span id="d2d6072f"></span>
### error
发生错误时返回，可能是客户端或服务端导致的问题。大多数错误均可恢复，且会话将保持连接状态，建议您默认监控和记录错误消息。

| | | | | | \
|参数名称 |子参数 |类型 |描述 |示例值 |
|---|---|---|---|---|
| | | | | | \
|event_id |\- |String |服务器事件的唯一 ID。 |event_**** |
| | | | | | \
|type |\- |String |事件类型，必须为error。 |error |
| | | | | | \
|error |\- |Object |错误信息的细节。 |\- |
| | | | | | \
| |type |String |错误类型。 |BadRequest |
| | | | | | \
| |code |String |错误代码。 |MissingParameter |
| | | | | | \
| |message |String |错误信息。 |The request failed because it is missing one or multiple required parameters.  |
| | | | | | \
| |param |String |与错误相关的参数（如果有）。 |null |
| | | | | | \
| |event_id |String |导致错误的 client 事件的 event_id（如果适用）。 |event_**** |

<span id="03a30f34"></span>
#### 返回示例
```JSON
{
    "event_id": "event_129",
    "type": "error",
    "error": {
        "code": "InvalidParameter",
        "message": "A parameter specified in the request is not valid: input audio format must be pcm16 Request id: ****",
        "type": "BadRequest",
        "param": "input audio format must be pcm16"
    }
}
```

<span id="3eb8e425"></span>
### 


# 批量(Chat)  API
Source: https://www.volcengine.com/docs/82379/1528783
 <span style="background-color: rgb(43, 43, 43)"><code> POST https://ark.cn-beijing.volces.com/api/v3/batch/chat/completions</code></span><span style="background-color: rgb(43, 43, 43)">   </span>[运行](https://api.volcengine.com/api-explorer/?action=BatchChatCompletions&data=%7B%7D&groupName=%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86&query=%7B%7D&serviceCode=ark&version=2024-01-01)
<span style="background-color: rgb(255, 255, 255)">本文介绍批量推理调用模型服务的 API 的输入输出参数，供您使用接口时查阅字段含义。通过批量推理您可</span><span style="background-color: rgb(255, 255, 255)">享受到更高的限流配额以及实惠的价格，适合进行大批量数据处理时使用。</span>
> 推荐的调用方式请见[示例代码](https://www.volcengine.com/docs/82379/1399517#%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81)。


```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="ciXkUCsj"><RenderMd content={` <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[模型列表](https://www.volcengine.com/docs/82379/1399517)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1099320#%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[调用教程](https://www.volcengine.com/docs/82379/1399517)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[常见问题](https://www.volcengine.com/docs/82379/1359411)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="Z8LNYGRm"><RenderMd content={`本接口支持 API Key 与 Access Key鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="在线调试" key="kfcnWCOadU"><RenderMd content={`<APILink link="https://api.volcengine.com/api-explorer/?action=BatchChatCompletions&data=%7B%7D&groupName=%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86&query=%7B%7D&serviceCode=ark&version=2024-01-01" description="API Explorer 您可以通过 API Explorer 在线发起调用，无需关注签名生成过程，快速获取调用结果。"></APILink>

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


<span id="#B2fc2CRV"></span>
## 请求参数
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1528783#PM1q4ttH)

<span id="#YNs4GyKa"></span>
### 请求体

---


**model** `string` `必选`
<span style="background-color: rgb(243, 245, 247)">通过 Endpoint ID 来调用模型，可参考</span>[获取 Endpoint ID](https://www.volcengine.com/docs/82379/1099522)<span style="background-color: rgb(243, 245, 247)">。</span>

---


<span style="background-color: rgb(32, 33, 35)"><strong>messages</strong></span><span style="background-color: rgb(32, 33, 35)">  </span><span style="background-color: rgba(238, 242, 245, 0.5)"><code>object[]</code></span><span style="background-color: rgb(32, 33, 35)"> </span>`必选`
到目前为止的对话组成的消息列表。不同模型支持不同类型的消息，如文本、图片、视频等。

消息类型

---


**系统消息** `object`
<span style="background-color: rgb(32, 33, 35)">开发人员提供的指令，模型应遵循这些指令。如模型扮演的角色或者目标等。</span>

属性

---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为<span style="background-color: rgb(var(--gray-100)/.5)"><code>system</code></span><span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string / object[]</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
系统信息内容。

属性

---


**纯文本消息内容** `string`
纯文本消息内容，大语言模型支持传入此类型。

---


**多模态消息内容** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object[]</code></span> 
支持文本、图像、视频等类型，视觉理解模型等多模态模型、部分大语言模型支持此字段。

各模态消息部分

---


**文本消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，内容文本输入。[具备视觉理解能力模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)、部分大语言模型支持此类型消息。

属性

---


messages.content.**text** `string` `必选`
文本消息部分的内容。

---


messages.content.**type** `string` `必选`
文本消息类型，此次应为 `text`。


---


**图像消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，图像内容部分。[具备视觉理解能力模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)支持此类型消息。

属性

---


messages.content.**image_url** `object` `必选`
图片消息的内容部分。

属性

---


messages.content.image_url.**url** `string` `必选`
支持传入图片链接或图片的Base64编码，具体使用请参见[使用说明](https://www.volcengine.com/docs/82379/1362931#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E)。

---


messages.content.image_url.**detail** `string`  `默认值 auto`
<span style="background-color: rgb(255, 255, 255)">支持手动设置图片的质量，取值范围</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">：高细节模式，适用于需要理解图像细节信息的场景，如对图像的多个局部信息/特征提取、复杂/丰富细节的图像理解等场景，理解更全面。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">：低细节模式，适用于简单的图像分类/识别、整体内容理解/描述等场景，理解更快速。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">：默认模式，不同模型选择的模式略有不同，具体请参见</span>[理解图像的深度控制](https://www.volcengine.com/docs/82379/1362931#bf4d9224)<span style="background-color: rgb(255, 255, 255)">。</span>


---


messages.content.**type** `string` `必选`
图像消息类型，此次应为 `image_url`。


---


**视频消息部分**
> 视频理解模型请参见 [视频理解模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)。

多模态消息中，视频内容部分。

属性

---


messages.content.**type** `string` `必选`
视频消息类型，此次应为 `video_url`**。**

---


messages.content.**video_url**`object` `必选`
视频消息的内容部分。

---


messages.content.video_url.**url** `string` `必选`
支持传入视频链接或视频的Base64编码。具体使用请参见[视频理解说明](https://www.volcengine.com/docs/82379/1362931#%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3)。

属性

---


messages.content.video_url.**fps** `float/ null` `默认值 1`
取值范围：`[0.2, 5]`。
每秒钟从视频中抽取指定数量的图像**。**取值越高，对于视频中画面变化理解越精细；取值越低，对于视频中画面变化感知减弱，但是使用的 token 花费少，速度也更快。详细说明见[用量说明](https://www.volcengine.com/docs/82379/1362931#%E7%94%A8%E9%87%8F%E8%AF%B4%E6%98%8E)。






---


**用户消息** `object` 
<span style="background-color: rgb(32, 33, 35)">用户发送的消息，包含提示或附加上下文信息。不同模型支持的字段类型不同，最多支持文本、图片、视频形式的消息。</span>

属性

---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为`user`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string / object[]</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
用户信息内容。

内容类型

---


**纯文本消息内容** `string`
纯文本消息内容，大语言模型支持传入此类型。

---


**多模态消息内容** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object[]</code></span> 
支持文本、图像、视频等类型，视觉理解模型等多模态模型、部分大语言模型支持此字段。

内容类型

---


**文本消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，内容文本输入。视觉理解模型、部分大语言模型支持此类型消息。

属性

---


messages.content.**text** `string` `必选`
文本消息部分的内容。

---


messages.content.**type** `string` `必选`
文本消息类型，此次应为 `text`。


---


**图像消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，图像内容部分。视觉理解模型支持此类型消息。

**属性**

---


messages.content.**type** `string` `必选`
图像消息类型，此次应为 `image_url`。

---


messages.content.**image_url** `object` `必选`
图片消息的内容部分。

**属性**

---


messages.content.image_url.**url** `string` `必选`
支持传入图片链接或图片的Base64编码，不同模型支持图片大小略有不同，具体请参见[使用说明](https://www.volcengine.com/docs/82379/1362931#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E)。

---


messages.content.image_url.**detail** `string / null`  `默认值 low`
<span style="background-color: rgb(255, 255, 255)">取值范围：</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
<span style="background-color: rgb(255, 255, 255)">支持手动设置图片的质量。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">：高细节模式，适用于需要理解图像细节信息的场景，如对图像的多个局部信息/特征提取、复杂/丰富细节的图像理解等场景，理解更全面。此时 </span>**min_pixels** 取值`3136`、**max_pixels** 取值`4014080`。
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">：低细节模式，适用于简单的图像分类/识别、整体内容理解/描述等场景，理解更快速。此时 </span>**min_pixels** 取值`3136`、**max_pixels** 取值`1048576`。
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">：默认模式，不同模型选择的模式略有不同，具体请参见</span>[理解图像的深度控制](https://www.volcengine.com/docs/82379/1362931#bf4d9224)<span style="background-color: rgb(255, 255, 255)">。</span>


---


messages.content.image_url.**image_pixel_limit**  `object / null` `默认值 null`
允许设置图片的像素大小限制，如果不在此范围，则会等比例放大或者缩小至该范围内。
生效优先级：高于 **detail** 字段，即同时配置 **detail** 与 **image_pixel_limit** 字段时，生效 **image_pixel_limit** 字段配置**。**
若 **min_pixels** / **max_pixels** 字段未设置，使用 **detail** 设置配置的值对应的 **min_pixels** / **max_pixels** 值。
子字段取值逻辑：`3136` <span style="background-color: rgb(255, 255, 255)">≤ </span>**min_pixels** <span style="background-color: rgb(255, 255, 255)">≤ </span>**max_pixels** <span style="background-color: rgb(255, 255, 255)">≤ </span>`4014080`

---



* messages.content.image_url.image_pixel_limit.**max_pixels** <span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
   取值范围：(**min_pixels**,  `4014080`]。
   传入图片最大像素限制，大于此像素则等比例缩小至 **max_pixels** 字段取值以下。
   若未设置，则取值为 **detail** 设置配置的值对应的 **max_pixels** 值。


---



* messages.content.image_url.image_pixel_limit.**min_pixels**
   取值范围：[`3136`,  **max_pixels**)。
   传入图片最小像素限制，小于此像素则等比例放大至 **min_pixels** 字段取值以上。
   若未设置，则取值为 **detail** 设置配置的值对应的 **min_pixels** 值（`3136`）。



---


**视频信息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
> 视频理解模型请参见 [视频理解模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)。

多模态消息中，视频内容部分。

属性

---


messages.content.**type** `string` `必选`
视频消息类型，此次应为 `video_url`**。**

---


messages.content.**video_url**`object` `必选`
视频消息的内容部分。

属性

---


messages.content.video_url.**url** `string` `必选`
支持传入视频链接或视频的Base64编码。具体使用请参见[视频理解说明](https://www.volcengine.com/docs/82379/1362931#%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3)。

---


messages.content.video_url.**fps** `float/ null` `默认值 1`
取值范围：`[0.2, 5]`。
每秒钟从视频中抽取指定数量的图像**。**取值越高，对于视频中画面变化理解越精细；取值越低，对于视频中画面变化感知减弱，但是使用的 token 花费少，速度也更快。详细说明见[用量说明](https://www.volcengine.com/docs/82379/1362931#%E7%94%A8%E9%87%8F%E8%AF%B4%E6%98%8E)。






---


**模型消息** `object`
<span style="background-color: rgb(32, 33, 35)">历史对话中，模型回复的消息。往往在多轮对话传入历史对话记录以及</span>[Prefill Response](https://www.volcengine.com/docs/82379/1359497)<span style="background-color: rgb(255, 255, 255)">时让模型按照预置的回复内容继续回复时使用。</span>

属性
:::tip
messages.**content**<span style="background-color: rgba(27, 31, 35, 0.05)"><strong> </strong></span><span style="background-color: rgb(255, 255, 255)">与 </span>messages.**tool_calls**<span style="background-color: rgba(27, 31, 35, 0.05)"><strong> </strong></span><span style="background-color: rgb(255, 255, 255)">字段二者至少填写其一。</span>

:::
---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为`assistant`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(32, 33, 35)"><code>string / array</code></span><span style="background-color: rgb(32, 33, 35)"> </span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>
模型回复的消息。

---


messages.**tool_calls** `object[]`
历史对话中，模型回复的工具调用信息。

显示子字段

---


messages.tool_calls**.function** `object` `必选`
<span style="background-color: rgb(255, 255, 255)">模型调用工具对应的函数信息。</span>

显示子字段

---


messages.tool_calls**.**function.**name** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">模型需要调用的函数名称。</span>

---


messages.tool_calls**.**function.<span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
:::tip
<span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>

:::

---


messages.tool_calls**.id** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>

---


messages.tool_calls**.type** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>




---


**thinking** `object` `默认值 {"type":"enabled"}`
控制模型是否开启深度思考模式。默认开启深度思考模式，可以手动关闭。
> 支持此字段的模型以及使用示例请参见[文档](https://www.volcengine.com/docs/82379/1449737#%E5%BC%80%E5%90%AF%E5%85%B3%E9%97%AD%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83)。


属性

---


thinking.**type** `string`  `必选`
取值范围：`enabled`， `disabled`，`auto`。

* `enabled`：开启思考模式，模型一定先思考后回答。
* `disabled`：关闭思考模式，模型直接回答问题，不会进行思考。
* `auto`：自动思考模式，模型根据问题自主判断是否需要思考，简单题目直接回答。


---


**max_tokens** `integer / null` `默认值 4096`
模型回复最大长度（单位 token），取值范围各个模型不同，详细见[模型列表](https://www.volcengine.com/docs/82379/1330310)。
输入 token 和输出 token 的总长度还受模型的上下文长度限制。

---


**max_completion_tokens** `integer / null` 
> 支持该字段的模型 `deepseek-r1-250528`，`doubao-seed-1-6-250615`， `doubao-seed-1-6-flash-250615`。

取值范围：`[0, 64k]`。
使用示例见[文档](https://www.volcengine.com/docs/82379/1449737#0001)。控制模型输出的最大长度（包括模型回答和模型思维链内容长度，单位 token）。配置了该参数后，可以让模型输出超长内容，**max_tokens** （默认值 4k）与思维链最大长度将失效，模型按需输出内容，直到达到 **max_completion_tokens** 配置的值。
不可与 **max_tokens** 字段同时设置，会直接报错。

---


**stop** `string / string[] / null` `默认值 null`
模型遇到 stop 字段所指定的字符串时将停止继续生成，这个词语本身不会输出。最多支持 4 个字符串。
> [深度思考能力模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)不支持该字段。

`["你好", "天气"]`

---


**frequency_penalty** `float / null` `默认值 0`
取值范围为 [\-2.0, 2.0]。
频率惩罚系数。如果值为正，会根据新 token 在文本中的出现频率对其进行惩罚，从而降低模型逐字重复的可能性。

---


**presence_penalty** `float / null` `默认值 0`
取值范围为 [\-2.0, 2.0]。
存在惩罚系数。如果值为正，会根据新 token 到目前为止是否出现在文本中对其进行惩罚，从而增加模型谈论新主题的可能性。

---


**temperature** `float / null` `默认值 1`
取值范围为 [0, 2]。
采样温度。控制了生成文本时对每个候选词的概率分布进行平滑的程度。当取值为 0 时模型仅考虑对数概率最大的一个 token。
较高的值（如 0.8）会使输出更加随机，而较低的值（如 0.2）会使输出更加集中确定。
通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。

---


**top_p** `float / null` `默认值 0.7`
取值范围为 [0, 1]。
核采样概率阈值。模型会考虑概率质量在 top_p 内的 token 结果。当取值为 0 时模型仅考虑对数概率最大的一个 token。
0.1 意味着只考虑概率质量最高的前 10% 的 token，取值越大生成的随机性越高，取值越低生成的确定性越高。通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。

---


**logprobs** `boolean / null` `默认值 false`
是否返回输出 tokens 的对数概率。

* `false`：不返回对数概率信息。
* `true`：返回消息内容中每个输出 token 的对数概率。


---


**top_logprobs** `integer / null` `默认值 0`
取值范围为 [0, 20]。
指定每个输出 token 位置最有可能返回的 token 数量，每个 token 都有关联的对数概率。仅当 **logprobs为**`true` 时可以设置 **top_logprobs** 参数。

---


**logit_bias** `map / null` `默认值 null`
调整指定 token 在模型输出内容中出现的概率，使模型生成的内容更加符合特定的偏好。**logit_bias** 字段接受一个 map 值，其中每个键为词表中的 token ID（使用 tokenization 接口获取），每个值为该 token 的偏差值，取值范围为 [\-100, 100]。
\-1 会减少选择的可能性，1 会增加选择的可能性；\-100 会完全禁止选择该 token，100 会导致仅可选择该 token。该参数的实际效果可能因模型而异。
`{"1234": -100}`

---


**tools** `object[] / null` `默认值 null`
待调用工具的列表，模型返回信息中可包含。当您需要让模型返回待调用工具时，需要配置该结构体。支持该字段的模型请参见[文档](https://www.volcengine.com/docs/82379/1330310#%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8%E8%83%BD%E5%8A%9B)。

属性

---


tools.**type** `string` `必选`
工具类型，此处应为 `function`。

---


tools.**function** `object` `必选`
模型返回中可包含待调用的工具。

属性

---


tools.function.**name** `string` `必选`
调用的函数的名称。

---


tools.function.**description** `string` 
调用的函数的描述，大模型会使用它来判断是否调用这个工具。

---


tools.function.**parameters** `object` 
函数请求参数，以 JSON Schema 格式描述。具体格式请参考 [JSON Schema](https://json-schema.org/understanding-json-schema) 文档，格式如下：
```JSON
{
    "type": "object",
    "properties": {
        "location": {
            "type": "string",
            "description": "城市，如：北京"
        }
    },
    "required": ["location"]
}
```

其中，

* 所有字段名大小写敏感。
* <span style="background-color: rgba(27, 31, 35, 0.05)"><strong>parameters</strong></span> 须是合规的 JSON Schema 对象。
* 建议用英文字段名，中文置于 <span style="background-color: rgba(27, 31, 35, 0.05)"><strong>description</strong></span> 字段中。



---


&nbsp;
&nbsp;
<span id="#PM1q4ttH"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1528783#B2fc2CRV)

<span id="#pdTGwich"></span>
### 非流式调用返回

---


**id** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求的唯一标识。</span>

---


**model** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求实际使用的模型名称和版本。</span>
> <span style="background-color: rgb(255, 255, 255)">doubao 1.5 代模型的模型名称格式为 doubao\-1\-5\-\*\*。如调用部署doubao\-1.5\-pro\-32k 250115模型的推理接入点，返回</span><span style="background-color: rgba(27, 31, 35, 0.05)">model</span><span style="background-color: rgb(255, 255, 255)">字段信息doubao\-1\-5\-pro\-32k\-250115。</span>


---


<span style="background-color: rgb(255, 255, 255)"><strong>service_tier</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">本次请求是否使用了TPM保障包。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>default</code></span><span style="background-color: rgb(255, 255, 255)">：本次请求未使用TPM保障包额度。</span>


---


**created** `integer`
<span style="background-color: rgb(255, 255, 255)">本次请求创建时间的 Unix 时间戳（秒）。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>object</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>chat.completion</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


**choices** `object[]`
<span style="background-color: rgb(255, 255, 255)">本次请求的模型输出内容。</span>

属性

---


choices.**index** <span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">当前元素在 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><strong>choices</strong></span><span style="background-color: rgb(255, 255, 255)"> 列表的索引。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>finish_reason </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型停止生成 token 的原因。取值范围：</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>stop</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出自然结束，或因命中请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">stop</span><span style="background-color: rgb(255, 255, 255)"> 中指定的字段而被截断。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>length</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出因达到模型输出限制而被截断，有以下原因：</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_token</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">回答内容的长度限制）。</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_completion_tokens</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">思维链内容+回答内容的长度限制）。</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>context_window</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制</span><span style="background-color: rgb(255, 255, 255)">（输入内容+思维链内容+回答内容的长度限制）。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>content_filter</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出被内容审核拦截。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>tool_calls</code></span><span style="background-color: rgb(255, 255, 255)">：模型调用了工具。</span>


---


choices.**message** `object`
<span style="background-color: rgb(255, 255, 255)">模型输出的内容。</span>

属性

---


choices.message.**role** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">内容输出的角色，此处固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>assistant</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.message.**content** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的消息内容。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)"><strong>reasoning_content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string / null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型处理问题的思维链内容。</span>
<span style="background-color: rgb(255, 255, 255)">仅深度推理模型支持返回此字段，深度推理模型请参见</span>[支持模型](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)"><strong>tool_calls </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的工具调用。</span>

属性

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>i</strong></span>**d** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>function </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">模型调用的函数。</span>

属性

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>name </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型调用的函数的名称。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
<span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>




---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>logprobs </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前内容的对数概率信息。</span>

属性

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
<span style="background-color: rgba(27, 31, 35, 0.05)">message</span><span style="background-color: rgb(255, 255, 255)">列表中每个 </span><span style="background-color: rgba(27, 31, 35, 0.05)">content</span><span style="background-color: rgb(255, 255, 255)"> 元素中的 token 对数概率信息。</span>

属性

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>top_logprobs </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
<span style="background-color: rgb(255, 255, 255)">在当前 token 位置最有可能的标记及其对数概率的列表。在一些情况下，返回的数量可能比请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">top_logprobs</span><span style="background-color: rgb(255, 255, 255)"> 指定的数量要少。</span>

**属性**

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>




---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>moderation_hit_type </strong></span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span><span style="background-color: rgb(32, 33, 35)"><code>/ null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型输出文字含有敏感信息时，会返回模型输出文字命中的风险分类标签。</span>
<span style="background-color: rgb(255, 255, 255)">返回值及含义：</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>severe_violation</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及严重违规。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>violence</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及激进行为。</span>

<span style="background-color: rgb(255, 255, 255)">注意：当前只有</span>[视觉理解模型](https://www.volcengine.com/docs/82379/1362931#%E6%94%AF%E6%8C%81%E6%A8%A1%E5%9E%8B)<span style="background-color: rgb(255, 255, 255)">支持返回该字段，且只有在</span><span style="background-color: rgb(255, 255, 255)">方舟控制台</span>[接入点配置页面](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint/create?customModelId=)<span style="background-color: rgb(255, 255, 255)">或者 </span>[CreateEndpoint](https://www.volcengine.com/docs/82379/1262823)<span style="background-color: rgb(255, 255, 255)"> 接口中，将内容护栏方案（ModerationStrategy）设置为基础方案（Basic）时，才会返回风险分类标签。</span>


---


**usage** `object`
<span style="background-color: rgb(255, 255, 255)">本次请求的 token 用量。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">输入的 prompt token 数量。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>completion_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的 token 数量。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>total_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">本次请求消耗的总 token 数量（输入 + 输出）。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens_details </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">本接口暂不支持该字段。</span>
<span style="background-color: rgb(255, 255, 255)">命中上下文缓存的tokens细节。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)">prompt_tokens_details.</span><span style="background-color: rgb(248, 248, 248)"><strong>cached_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">本接口暂不支持该字段。此处应为</span><span style="background-color: rgba(27, 31, 35, 0.05)"> </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>0</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>


---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>completion_tokens_details </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">本次请求花费的 token 的细节。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)">completion_tokens_details.</span><span style="background-color: rgb(248, 248, 248)"><strong>reasoning_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">输出思维链内容花费的 token 数 。</span>
<span style="background-color: rgb(255, 255, 255)">支持输出思维链的模型请参见</span>[文档](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>






# 分词 API
Source: https://www.volcengine.com/docs/82379/1528728
 <span style="background-color: rgb(43, 43, 43)"><code> POST https://ark.cn-beijing.volces.com/api/v3/tokenization</code></span><span style="background-color: rgb(43, 43, 43)">   </span>[运行](https://api.volcengine.com/api-explorer/?action=Tokenization&data=%7B%7D&groupName=%E5%88%86%E8%AF%8D&query=%7B%7D&serviceCode=ark&version=2024-01-01)
<span style="background-color: rgb(255, 255, 255)">本文介绍分词 API 的输入输出参数，供您使用接口时查阅字段含义。当前接口只支持文本信息。</span>

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="ow8jSL4e"><RenderMd content={` [ ](https://www.volcengine.com/docs/82379/1528728)[体验中心](https://console.volcengine.com/ark/region:ark+cn-beijing/application)          <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1099320#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)     
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[接口文档](https://www.volcengine.com/docs/82379/1526787)          <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[常见问题](https://www.volcengine.com/docs/82379/1359411)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="mIx3cDFe"><RenderMd content={`本接口支持 API Key 鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="在线调试" key="ZAY5mJ9Rzz"><RenderMd content={`<APILink link="https://api.volcengine.com/api-explorer/?action=Tokenization&data=%7B%7D&groupName=%E5%88%86%E8%AF%8D&query=%7B%7D&serviceCode=ark&version=2024-01-01" description="API Explorer 您可以通过 API Explorer 在线发起调用，无需关注签名生成过程，快速获取调用结果。"></APILink>
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


<span id="#RxN8G2nH"></span>
## 请求参数 
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1528728#Qu59cel0)

<span id="#pjuiBZGA"></span>
### 请求体

---


**model** `string` `必选`
<span style="background-color: rgb(255, 255, 255)">本次请求使用模型的 Model ID 或</span>[推理接入点](https://www.volcengine.com/docs/82379/1099522)<span style="background-color: rgb(255, 255, 255)"> (Endpoint ID)。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>text</strong></span><span style="background-color: rgb(32, 33, 35)">  </span><span style="background-color: rgb(32, 33, 35)"><code>string / string[]</code></span><span style="background-color: rgb(32, 33, 35)"> </span>`必选`<span style="background-color: rgb(32, 33, 35)"> </span>
<span style="background-color: rgb(255, 255, 255)">需要分词的内容，支持字符串或字符串列表。</span>

---


&nbsp;
<span id="#Qu59cel0"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1528728#RxN8G2nH)


---


**id** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求的唯一标识。</span>

---


**model** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求实际使用的模型 ID （</span><span style="background-color: rgb(255, 255, 255)"><code>模型名称-版本</code></span><span style="background-color: rgb(255, 255, 255)">）。</span>
<span style="background-color: rgb(255, 255, 255)">doubao 1.5 代模型的模型名称格式为 doubao\-1\-5\-\*\*。如调用部署doubao\-1.5\-pro\-32k 250115模型的推理接入点，返回</span><span style="background-color: rgba(27, 31, 35, 0.05)">model</span><span style="background-color: rgb(255, 255, 255)">字段信息doubao\-1\-5\-pro\-32k\-250115。</span>

---


**created** `integer`
<span style="background-color: rgb(255, 255, 255)">本次请求创建时间的 Unix 时间戳（秒）。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>object</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>list</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>data</strong></span> `object[]`
<span style="background-color: rgb(255, 255, 255)">本次请求的分词的结果。</span>

属性

---


<span style="background-color: rgb(255, 255, 255)">data</span>.**index** <span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">当前元素在 data 列表的索引。</span>

---


<span style="background-color: rgb(255, 255, 255)">data.</span><span style="background-color: rgb(255, 255, 255)"><strong>object</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>tokenization</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


<span style="background-color: rgb(255, 255, 255)">data.</span><span style="background-color: rgb(255, 255, 255)"><strong>total_tokens</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">对应内容的总 token 数量。</span>

---


<span style="background-color: rgb(255, 255, 255)">data.</span><span style="background-color: rgb(255, 255, 255)"><strong>token_ids</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(32, 33, 35)"><code>integer[]</code></span>
<span style="background-color: rgb(255, 255, 255)">对文本进行分词后的具体词语在词表中的 id 列表。</span>

---


<span style="background-color: rgb(255, 255, 255)">data.</span><span style="background-color: rgb(255, 255, 255)"><strong>offset_mapping</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgba(0, 0, 0, 0.06)"><code>Array<Array<Integer>></code></span>
<span style="background-color: rgb(255, 255, 255)">对文本进行分词后的词语偏移量，列表中每个元素是一个包含两个整数的列表：第一个整数表示词或标记在原始文本中的起始索引（是从0开始），第二个整数表示结束索引（不包括该索引处的字符）。</span>

&nbsp;




# 应用(bot)  API
Source: https://www.volcengine.com/docs/82379/1526787
 <span style="background-color: rgb(43, 43, 43)"><code> POST https://ark.cn-beijing.volces.com/api/v3/bots/chat/completions</code></span><span style="background-color: rgb(43, 43, 43)">   </span>[运行](https://api.volcengine.com/api-explorer/?action=BotsChatCompletions&data=%7B%7D&groupName=%E5%BA%94%E7%94%A8Bot%20API&query=%7B%7D&serviceCode=ark&version=2024-01-01)
<span style="background-color: rgb(255, 255, 255)">本文介绍方舟应用 API 的输入输出参数，供您使用接口时查阅字段含义。</span>

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="wSiJrOpz"><RenderMd content={` [ ](https://www.volcengine.com/docs/82379/1526787)[体验中心](https://console.volcengine.com/ark/region:ark+cn-beijing/application)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[模型列表](https://www.volcengine.com/docs/82379/1330310#%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E8%83%BD%E5%8A%9B)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1099320#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[获取Bot ID](https://www.volcengine.com/docs/82379/1267885)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[接口文档](https://www.volcengine.com/docs/82379/1526787)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[常见问题](https://www.volcengine.com/docs/82379/1359411)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="Cqg8POb3"><RenderMd content={`本接口支持 API Key 鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
> 如需使用 Access Key 来鉴权，推荐使用 SDK 的方式，具体请参见 [SDK概述](https://www.volcengine.com/docs/82379/1302007)。
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


<span id="#RxN8G2nH"></span>
## 请求参数 
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1526787#Qu59cel0)

<span id="#pjuiBZGA"></span>
### 请求体

* **model** `string` `必选`
   您需要调用的应用的 ID （Bot<span style="background-color: rgb(255, 255, 255)"> ID</span>），[获取 Bot ID](https://www.volcengine.com/docs/82379/1267885) 。
* <span style="background-color: rgb(32, 33, 35)"><strong>messages</strong></span><span style="background-color: rgb(32, 33, 35)">  </span><span style="background-color: rgba(238, 242, 245, 0.5)"><code>object[]</code></span><span style="background-color: rgb(32, 33, 35)"> </span>`必选`<span style="background-color: rgb(32, 33, 35)"> </span>
   到目前为止的对话组成的消息列表。不同模型支持不同类型的消息，如文本、图片等。


```mixin-react
return (<Tabs>
<Tabs.TabPane title="System message" key="LH6TIuAN"><RenderMd content={`\`object\`
系统消息，<span style="background-color: rgb(32, 33, 35)">开发人员提供的指令，模型应遵循这些指令。如模型扮演的角色或者目标等。</span>

* messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>\`必选\`
   发送消息的角色，此处应为<span style="background-color: rgb(var(--gray-100)/.5)"><code>system</code></span><span style="background-color: rgb(var(--gray-100)/.5)">。</span>
* messages.**content** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string / object[]</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>\`必选\`
   系统信息内容。


\`\`\`mixin-react
return (<Tabs>
<Tabs.TabPane title="纯文本消息内容" key="hfntJGS9Qc"><RenderMd content={\`\\`string\\`
纯文本的消息内容。
\`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="多模态消息内容" key="n9QNRdS3Eb"><RenderMd content={\`<span style="background-color: rgb(var(--gray-100)/.5)"><code>object[]</code></span>
视觉理解模型等多模态模型、部分大语言模型支持此类型。
**文本消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，内容文本输入。[视觉理解模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3)、部分大语言模型支持此类型消息。

* messages.content.**text** \\`string\\` \\`必选\\`
   文本消息内容部分。
* messages.content.**type** \\`string\\` \\`必选\\`
   文本消息类型，此次应为 \\`text\\`。

**图像消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，图像内容部分。[视觉理解模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3)支持此类型消息。

* messages.content.**image_url** \\`object\\` \\`必选\\`
      图片消息的内容部分。
   * messages.content.image_url.**url** \\`string\\` \\`必选\\`
      支持传入图片链接或图片的Base64编码，不同模型支持图片大小略有不同，具体请参见[使用说明](https://www.volcengine.com/docs/82379/1362931#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E)。
      * 传入图片URL：传入图片的可访问链接，推荐使用 TOS（火山引擎对象存储） 存储图片，并生成图片链接。
      * 传入Base64编码：请遵循格式\\`data:image/<图片格式>;base64,<Base64编码>\\`，可见[示例](https://www.volcengine.com/docs/82379/1362931#base64-%E7%BC%96%E7%A0%81%E8%BE%93%E5%85%A5)。
   * messages.content.image_url.**detail** \\`string\\`  \\`默认值 auto\\`
         <span style="background-color: rgb(255, 255, 255)">支持手动设置图片的质量，取值范围</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">：高细节模式，适用于需要理解图像细节信息的场景，如对图像的多个局部信息/特征提取、复杂/丰富细节的图像理解等场景，理解更全面。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">：低细节模式，适用于简单的图像分类/识别、整体内容理解/描述等场景，理解更快速。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">：默认模式，不同模型选择的模式略有不同，具体请参见</span>[理解图像的深度控制](https://www.volcengine.com/docs/82379/1362931#bf4d9224)<span style="background-color: rgb(255, 255, 255)">。</span>
* messages.content.**type** \\`string\\` \\`必选\\`
   图像消息类型，此次应为 \\`image_url\\`。
\`}></RenderMd></Tabs.TabPane></Tabs>);
 \`\`\`

&nbsp;
 
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="User message" key="U17siWJ7"><RenderMd content={`\`object\` 
<span style="background-color: rgb(32, 33, 35)">用户发送的消息，包含提示或附加上下文信息。</span>

* messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>\`必选\`
   发送消息的角色，此处应为\`user\`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>
* messages.**content** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string / object[]</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>\`必选\`
   用户信息内容。

 &nbsp;

\`\`\`mixin-react
return (<Tabs>
<Tabs.TabPane title="纯文本消费内容" key="y14glT6IQY"><RenderMd content={\`\\`string\\`
大语言模型支持此类型。
\`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="多模态消息内容" key="RizapJXctJ"><RenderMd content={\`<span style="background-color: rgb(var(--gray-100)/.5)"><code>object[]</code></span>
视觉理解模型等多模态模型、部分大语言模型支持此类型。
**文本消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，内容文本输入。[视觉理解模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3)、部分大语言模型支持此类型消息。

* messages.content.**text** \\`string\\` \\`必选\\`
   文本消息内容部分。
* messages.content.**type** \\`string\\` \\`必选\\`
   文本消息类型，此次应为 \\`text\\`。

**图像消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，图像内容部分。[视觉理解模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3)支持此类型消息。

* messages.content.**image_url** \\`object\\` \\`必选\\`
      图片消息的内容部分。
   * messages.content.image_url.**url** \\`string\\` \\`必选\\`
      支持传入图片链接或图片的Base64编码，不同模型支持图片大小略有不同，具体请参见[使用说明](https://www.volcengine.com/docs/82379/1362931#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E)。
      * 传入图片URL：传入图片的可访问链接，推荐使用 TOS（火山引擎对象存储） 存储图片，并生成图片链接。
      * 传入Base64编码：请遵循格式\\`data:image/<图片格式>;base64,<Base64编码>\\`，可见[示例](https://www.volcengine.com/docs/82379/1362931#base64-%E7%BC%96%E7%A0%81%E8%BE%93%E5%85%A5)。
   * messages.content.image_url.**detail** \\`string / null\\`  \\`默认值 auto\\`
         <span style="background-color: rgb(255, 255, 255)">支持手动设置图片的质量，取值范围</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">、</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>high</code></span><span style="background-color: rgb(255, 255, 255)">：高细节模式，适用于需要理解图像细节信息的场景，如对图像的多个局部信息/特征提取、复杂/丰富细节的图像理解等场景，理解更全面。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>low</code></span><span style="background-color: rgb(255, 255, 255)">：低细节模式，适用于简单的图像分类/识别、整体内容理解/描述等场景，理解更快速。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>auto</code></span><span style="background-color: rgb(255, 255, 255)">：默认模式，不同模型选择的模式略有不同，具体请参见</span>[理解图像的深度控制](https://www.volcengine.com/docs/82379/1362931#bf4d9224)<span style="background-color: rgb(255, 255, 255)">。</span>
* messages.content.**type** \\`string\\` \\`必选\\`
   图像消息类型，此次应为 \\`image_url\\`。
\`}></RenderMd></Tabs.TabPane></Tabs>);
 \`\`\`


* messages.**name** <span style="background-color: rgba(238, 242, 245, 0.5)"><code>string</code></span><span style="background-color: rgba(238, 242, 245, 0.5)"> </span>
   发送此消息的角色的姓名。用于区别同一个角色但是不同主体发送的消息。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Assistant message" key="e5k6349e"><RenderMd content={`\`object\`
<span style="background-color: rgb(32, 33, 35)">模型响应用户消息而回复的消息。</span>
:::tip
messages.**content**<span style="background-color: rgba(27, 31, 35, 0.05)"><strong> </strong></span><span style="background-color: rgb(255, 255, 255)">与 </span>messages.**tool_calls**<span style="background-color: rgba(27, 31, 35, 0.05)"><strong> </strong></span><span style="background-color: rgb(255, 255, 255)">字段二者至少填写其一。</span>

:::
* messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>\`必选\`
   发送消息的角色，此处应为\`assistant\`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>
* messages.**content** <span style="background-color: rgb(32, 33, 35)"><code>string / array</code></span><span style="background-color: rgb(32, 33, 35)"> </span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>
   模型回复的消息。
* messages.**tool_calls** \`object[]\`
   模型回复的工具调用信息。
   * messages.tool_calls**.function** \`object\` \`必选\`
      <span style="background-color: rgb(255, 255, 255)">模型调用工具对应的函数信息。</span>
      * messages.tool_calls**.**function.**name** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>\`必选\`
         <span style="background-color: rgb(255, 255, 255)">模型需要调用的函数名称。</span>
      * messages.tool_calls**.**function.<span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>\`必选\`
         <span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
   :::tip
   <span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>
   :::
   * messages.tool_calls**.id** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>\`必选\`
      <span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>
   * messages.tool_calls**.type** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>\`必选\`
      <span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Tool message" key="LzW66SZa"><RenderMd content={`\`object\`
模型调用工具的消息。

* messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>\`必选\`
   发送消息的角色，此处应为\`tool\`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>
* messages.**content** <span style="background-color: rgb(32, 33, 35)"><code>string / array</code></span><span style="background-color: rgb(32, 33, 35)"> </span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>\`必选\`
   工具返回的消息。
* messages.<span style="background-color: rgb(255, 255, 255)"><strong>tool_call_id </strong></span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span><span style="background-color: rgb(255, 255, 255)"> </span>\`必选\`
   <span style="background-color: rgb(255, 255, 255)">模型调用的工具的 ID。</span>
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


* **thinking** `object` `默认值 {"type":"enabled"}`

控制模型是否开启深度思考模式。默认开启深度思考模式，可以手动关闭。
> 支持此字段的模型以及使用示例请参见[文档](https://www.volcengine.com/docs/82379/1449737#%E5%85%B3%E9%97%AD%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83)。


属性

---


thinking.**type** `string`  `必选`
取值范围：`enabled`， `disabled`，`auto`。

* `enabled`：开启思考模式，模型一定先思考后回答。
* `disabled`：关闭思考模式，模型直接回答问题，不会进行思考。
* `auto`：自动思考模式，模型根据问题自主判断是否需要思考，简单题目直接回答。


* **stream** `boolean / null` `默认值 false`
   响应内容是否流式返回：
   * `false`：模型生成完所有内容后一次性返回结果。
   * `true`：按 SSE 协议逐块返回模型生成内容，并以一条 `data: [DONE] `消息结束。
* **stream_options** `object / null` `默认值 null`
   流式响应的选项。当 **stream** 为 `true` 时可设置 **stream_options** 字段。
   * stream_options.**include_usage** `boolean / null` `默认值 false`
      是否包含本次请求的 token 用量统计信息。
      * `false`：不返回 token 用量信息。
      * `true`：在 `data: [DONE]` 消息之前会返回一个额外的块，此块上的 **usage** 字段代表整个请求的 token 用量，**choices** 字段为空数组。所有其他块也将包含 **usage** 字段，但值为 `null`。
* **max_tokens** `integer / null` `默认值 4096`
   模型回复最大长度（单位 token），取值范围各个模型不同，详细见[模型列表](https://www.volcengine.com/docs/82379/1330310)。
   输入 token 和输出 token 的总长度还受模型的上下文长度限制。
* **stop** `string / string[] / null` `默认值 null`
   模型遇到 stop 字段所指定的字符串时将停止继续生成，这个词语本身不会输出。最多支持 4 个字符串。
   `["你好", "天气"]`
* **frequency_penalty** `float / null` `默认值 0`
   取值范围为 [\-2.0, 2.0]。
   频率惩罚系数。如果值为正，会根据新 token 在文本中的出现频率对其进行惩罚，从而降低模型逐字重复的可能性。
* **presence_penalty** `float / null` `默认值 0`
   取值范围为 [\-2.0, 2.0]。
   存在惩罚系数。如果值为正，会根据新 token 到目前为止是否出现在文本中对其进行惩罚，从而增加模型谈论新主题的可能性。
* **temperature** `float / null` `默认值 1`
   取值范围为 [0, 2]。
   采样温度。控制了生成文本时对每个候选词的概率分布进行平滑的程度。。当取值为 0 时模型仅考虑对数概率最大的一个 token。
   较高的值（如 0.8）会使输出更加随机，而较低的值（如 0.2）会使输出更加集中确定。
   通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。
* **top_p** `float / null` `默认值 0.7`
   取值范围为 [0, 1]。
   核采样概率阈值。模型会考虑概率质量在 top_p 内的 token 结果。当取值为 0 时模型仅考虑对数概率最大的一个 token。
   0.1 意味着只考虑概率质量最高的前 10% 的 token，取值越大生成的随机性越高，取值越低生成的确定性越高。通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。
* **logprobs** `boolean / null` `默认值 false`
   是否返回输出 tokens 的对数概率。
   * `false`：不返回对数概率信息。
   * `true`：返回消息内容中每个输出 token 的对数概率。
* **top_logprobs** `integer / null` `默认值 0`
   取值范围为 [0, 20]。
   指定每个输出 token 位置最有可能返回的 token 数量，每个 token 都有关联的对数概率。仅当 **logprobs**为`true` 时可以设置 **top_logprobs** 参数。
* **logit_bias** `map / null` `默认值 null`
   调整指定 token 在模型输出内容中出现的概率，使模型生成的内容更加符合特定的偏好。**logit_bias** 字段接受一个 map 值，其中每个键为词表中的 token ID（使用 tokenization 接口获取），每个值为该 token 的偏差值，取值范围为 [\-100, 100]。
   \-1 会减少选择的可能性，1 会增加选择的可能性；\-100 会完全禁止选择该 token，100 会导致仅可选择该 token。该参数的实际效果可能因模型而异。
   `{ "1234": -100}`
* **tools** `object[] / null` `默认值 null`
   模型可以调用的工具列表。目前仅函数作为工具被支持。用这个来提供模型可能为其生成 JSON 输入的函数列表。支持该字段的模型请参见[文档](https://www.volcengine.com/docs/82379/1330310#98fee2f1)。
   * tools.**type** `string` `必选`
      工具类型，当前仅支持 `function`。
   * tools.**function** `object` `必选`
      模型可以调用的类型为`function`的工具列表。
      * tools.function.**name** `string` `必选`
         调用的函数的名称。
      * tools.function.**description** `string` `必选`
         调用的函数的描述，大模型会使用它来判断是否调用这个函数。
      * tools.function.**parameters** `object` `必选`
         函数请求参数，以 JSON Schema 格式描述。具体格式请参考 [JSON Schema](https://json-schema.org/understanding-json-schema) 文档。
         ```JSON
         {
             "type": "object",
             "properties": {
                 "location": {
                     "type": "string",
                     "description": "城市，如：北京"
                 }
             },
             "required": ["location"]
         }
         ```
         
* **metadata** `object / null` `默认值 null`
   <span style="background-color: rgb(255, 255, 255)">额外参数。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>group_chat_config</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>必选</code></span>
      <span style="background-color: rgb(255, 255, 255)">运行时动态传入的角色配置。</span>
      * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)"><strong>characters</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>object[]</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
         <span style="background-color: rgb(255, 255, 255)">群聊角色列表。</span>
         * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.</span><span style="background-color: rgb(248, 248, 248)"><strong>name</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
            <span style="background-color: rgb(255, 255, 255)">群聊角色名称。</span>
         * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.</span><span style="background-color: rgb(248, 248, 248)"><strong>system_prompt</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
            <span style="background-color: rgb(255, 255, 255)">群聊角色设定，用于告知应用需要扮演的角色。</span>
         * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.</span><span style="background-color: rgb(248, 248, 248)"><strong>model_desc</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>object</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
            模型说明。
            * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.model_desc.</span><span style="background-color: rgb(248, 248, 248)"><strong>endpoint_id</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
               <span style="background-color: rgb(255, 255, 255)">您创建的 </span>[推理接入点](https://www.volcengine.com/docs/82379/1099522)<span style="background-color: rgb(255, 255, 255)">ID。</span>
      * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)"><strong>description</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> `默认值 null`
         <span style="background-color: rgb(255, 255, 255)">群聊场景描述，可设定群聊的主题、时间地点、事件场景、用户扮演的角色等信息。</span>
      * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)"><strong>user_name</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> `默认值 用户`
         <span style="background-color: rgb(255, 255, 255)">表示“我”所扮演的角色名称 ，默认值为“用户”。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>user_info</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> `默认值 null`
      联网的智能体可使用，如查询天气场景，前端可以直接通过该字段传地点信息给模型，方便查对应地点的天气。
      <span style="background-color: rgb(255, 255, 255)">传入的信息需满足条件：可以被反序列化成 json 的字符串，并需包含 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>city</code></span><span style="background-color: rgb(255, 255, 255)"> 和 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>district</code></span><span style="background-color: rgb(255, 255, 255)"> 两个字段。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>emit_intention_signal_extra</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> `默认值 "false"`
      <span style="background-color: rgb(255, 255, 255)">值是 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>"true"</code></span><span style="background-color: rgb(255, 255, 255)"> 时，会中途返回intention状态 </span><span style="background-color: rgba(27, 31, 35, 0.05)">"正在搜索"。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>target_character_name</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> `默认值 null`
      <span style="background-color: rgb(255, 255, 255)">群聊Bot对话时填写，指定本次要发言的角色名，必须是存在于</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>characters</code></span><span style="background-color: rgb(255, 255, 255)">里的角色。</span>

<span id="#Qu59cel0"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1526787#RxN8G2nH)


```mixin-react
return (<Tabs>
<Tabs.TabPane title="非流式调用返回" key="VG2t5Ndo"><RenderMd content={`* **id** \`string\`
   <span style="background-color: rgb(255, 255, 255)">本次请求的唯一标识。</span>
* **model** \`string\`
   <span style="background-color: rgb(255, 255, 255)">本次请求实际使用的模型名称和版本。</span>
   <span style="background-color: rgb(255, 255, 255)">doubao 1.5 代模型的模型名称格式为 doubao\-1\-5\-\*\*。如调用部署doubao\-1.5\-pro\-32k 250115模型的推理接入点，返回</span><span style="background-color: rgba(27, 31, 35, 0.05)">model</span><span style="background-color: rgb(255, 255, 255)">字段信息doubao\-1\-5\-pro\-32k\-250115。</span>
* **created** \`integer\`
   <span style="background-color: rgb(255, 255, 255)">本次请求创建时间的 Unix 时间戳（秒）。</span>
* <span style="background-color: rgb(255, 255, 255)"><strong>object</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>\`string\`
   <span style="background-color: rgb(255, 255, 255)">固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>chat.completion</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
* **choices** \`object[]\`
   <span style="background-color: rgb(255, 255, 255)">本次请求的模型输出内容。</span>
   * choices.**index** <span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
      <span style="background-color: rgb(255, 255, 255)">当前元素在 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><strong>choices</strong></span><span style="background-color: rgb(255, 255, 255)"> 列表的索引。</span>
   * choices.<span style="background-color: rgb(255, 255, 255)"><strong>finish_reason </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
      <span style="background-color: rgb(255, 255, 255)">模型停止生成 token 的原因。取值范围：</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>stop</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出自然结束，或因命中请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">stop</span><span style="background-color: rgb(255, 255, 255)"> 中指定的字段而被截断。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>length</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出因达到模型输出限制而被截断，有下面几种原因：</span>
         * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_token</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">回答内容的长度限制</span><span style="background-color: rgba(27, 31, 35, 0.05)">）</span><span style="background-color: rgb(255, 255, 255)">。</span>
         * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_completion_tokens</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">思维链内容+回答内容的长度限制）。</span>
         * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>context_window</code></span><span style="background-color: rgb(255, 255, 255)"> 限制（输入内容+思维链内容+回答内容的长度限制）。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>content_filter</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出被内容审核拦截。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>tool_calls</code></span><span style="background-color: rgb(255, 255, 255)">：模型调用了工具。</span>
   * choices.**message** \`object\`
      <span style="background-color: rgb(255, 255, 255)">模型输出的内容。</span>
      * choices.message.**role** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
         <span style="background-color: rgb(255, 255, 255)">内容输出的角色，此处固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>assistant</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
      * choices.message.**content** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
         <span style="background-color: rgb(255, 255, 255)">模型生成的消息内容。</span>
      * choices.message.<span style="background-color: rgb(255, 255, 255)"><strong>reasoning_content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string / null</code></span>
         <span style="background-color: rgb(255, 255, 255)">模型处理问题的思维链内容。</span>
         <span style="background-color: rgb(255, 255, 255)">仅深度推理模型支持返回此字段，深度推理模型请参见</span>[支持模型](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>
      * choices.message.<span style="background-color: rgb(255, 255, 255)"><strong>tool_calls </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
         <span style="background-color: rgb(255, 255, 255)">模型生成的工具调用。</span>
         * choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>i</strong></span>**d** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
            <span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>
         * choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
            <span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
         * choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>function </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object</code></span>
            <span style="background-color: rgb(255, 255, 255)">模型调用的函数。</span>
            * choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>name </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
               <span style="background-color: rgb(255, 255, 255)">模型调用的函数的名称。</span>
            * choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
               <span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
               <span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>
   * choices.<span style="background-color: rgb(255, 255, 255)"><strong>logprobs </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object / null</code></span>
      <span style="background-color: rgb(255, 255, 255)">当前内容的对数概率信息。</span>
      * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
         <span style="background-color: rgba(27, 31, 35, 0.05)">message</span><span style="background-color: rgb(255, 255, 255)">列表中每个 </span><span style="background-color: rgba(27, 31, 35, 0.05)">content</span><span style="background-color: rgb(255, 255, 255)"> 元素中的 token 对数概率信息。</span>
         * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
            <span style="background-color: rgb(255, 255, 255)">当前 token。</span>
         * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
            <span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>
         * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
            <span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>
         * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>top_logprobs </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
            <span style="background-color: rgb(255, 255, 255)">在当前 token 位置最有可能的标记及其对数概率的列表。在一些情况下，返回的数量可能比请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">top_logprobs</span><span style="background-color: rgb(255, 255, 255)"> 指定的数量要少。</span>
            * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
               <span style="background-color: rgb(255, 255, 255)">当前 token。</span>
            * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
               <span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>
            * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
               <span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>
   * choices.<span style="background-color: rgb(255, 255, 255)"><strong>moderation_hit_type </strong></span><span style="background-color: rgb(255, 255, 255)"><code>string / null</code></span>
      <span style="background-color: rgb(255, 255, 255)">模型输出文字含有敏感信息时，会返回模型输出文字命中的风险分类标签。</span>
      <span style="background-color: rgb(255, 255, 255)">返回值及含义：</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>severe_violation</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及严重违规。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>violence</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及激进行为。</span>
      <span style="background-color: rgb(255, 255, 255)">注意：当前只有</span>[视觉理解模型](https://www.volcengine.com/docs/82379/1362931#%E6%94%AF%E6%8C%81%E6%A8%A1%E5%9E%8B)<span style="background-color: rgb(255, 255, 255)">支持返回该字段，且只有在</span><span style="background-color: rgb(255, 255, 255)">方舟控制台</span>[接入点配置页面](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint/create?customModelId=)<span style="background-color: rgb(255, 255, 255)">或者 </span>[CreateEndpoint](https://www.volcengine.com/docs/82379/1262823)<span style="background-color: rgb(255, 255, 255)"> 接口中，将内容护栏方案（ModerationStrategy）设置为基础方案（Basic）时，才会返回风险分类标签。</span>
* **bot_usage** \`object\`
   <span style="background-color: rgb(255, 255, 255)">本次请求的 token 用量。</span>
   * bot_usage.<span style="background-color: rgb(255, 255, 255)"><strong>model_usage </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
      <span style="background-color: rgb(255, 255, 255)">本次请求不同 endpoint 的 token 消耗。</span>
      * bot_usage.<span style="background-color: rgb(255, 255, 255)">model_usage</span><span style="background-color: rgb(255, 255, 255)"><strong>.name</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
         调用的模型 ID。
      * bot_usage.<span style="background-color: rgb(255, 255, 255)">model_usage</span><span style="background-color: rgb(255, 255, 255)"><strong>.prompt_tokens</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
         <span style="background-color: rgb(255, 255, 255)">输入的 prompt token 数量，包含用户输入的提示词和调用插件返回的信息。</span>
      * bot_usage.<span style="background-color: rgb(255, 255, 255)">model_usage</span><span style="background-color: rgb(255, 255, 255)"><strong>.completion_tokens</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
         <span style="background-color: rgb(255, 255, 255)">模型生成的 token 数量。</span>
      * bot_usage.<span style="background-color: rgb(255, 255, 255)">model_usage</span><span style="background-color: rgb(255, 255, 255)"><strong>.total_tokens</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
         <span style="background-color: rgb(255, 255, 255)">本次请求消耗的总 token 数量（输入 + 输出）。</span>
   * <span style="background-color: rgb(255, 255, 255)"><strong>action_usage</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
      <span style="background-color: rgb(255, 255, 255)">本次请求插件用量信息。</span>
      * <span style="background-color: rgb(255, 255, 255)">action_usage.</span><span style="background-color: rgb(255, 255, 255)"><strong>action_name</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
         <span style="background-color: rgb(255, 255, 255)">插件分类名称，如 </span><span style="background-color: rgb(31, 31, 31)"><code>content_plugin</code></span><span style="background-color: rgb(255, 255, 255)">（内容插件）等。</span>
      * <span style="background-color: rgb(255, 255, 255)">action_usage.</span><span style="background-color: rgb(255, 255, 255)"><strong>count</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
         <span style="background-color: rgb(255, 255, 255)">本次请求某插件分类插件总调用次数。</span>
   * <span style="background-color: rgb(255, 255, 255)"><strong>action_details</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
      <span style="background-color: rgb(255, 255, 255)">本次请求插件调用详情。</span>
      * <span style="background-color: rgb(255, 255, 255)">action_details.</span><span style="background-color: rgb(255, 255, 255)"><strong>name</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
         <span style="background-color: rgb(255, 255, 255)">插件分类名称，如 </span><span style="background-color: rgb(31, 31, 31)"><code>content_plugin</code></span><span style="background-color: rgb(255, 255, 255)">（内容插件）等。</span>
      * <span style="background-color: rgb(255, 255, 255)">action_details.</span><span style="background-color: rgb(255, 255, 255)"><strong>count</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
         <span style="background-color: rgb(255, 255, 255)">本次请求某插件分类中插件调用次数。</span>
      * <span style="background-color: rgb(255, 255, 255)">action_details.</span><span style="background-color: rgb(255, 255, 255)"><strong>tool_details</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
         <span style="background-color: rgb(255, 255, 255)">某插件分类中插件调用详细信息。</span>
         * <span style="background-color: rgb(255, 255, 255)">action_details.tool_details.</span><span style="background-color: rgb(255, 255, 255)"><strong>name</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
            具体调用的工具名称。
         * <span style="background-color: rgb(255, 255, 255)">action_details.tool_details.</span><span style="background-color: rgb(255, 255, 255)"><strong>input</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
            <span style="background-color: rgb(255, 255, 255)">插件输入参数，调用插件的数据结构。</span>
         * <span style="background-color: rgb(255, 255, 255)">action_details.tool_details.</span><span style="background-color: rgb(255, 255, 255)"><strong>output</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
            <span style="background-color: rgb(255, 255, 255)">插件输出结果，调用插件返回的数据结构。</span>
         * <span style="background-color: rgb(255, 255, 255)">action_details.tool_details.</span><span style="background-color: rgb(255, 255, 255)"><strong>created_at</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
            <span style="background-color: rgb(255, 255, 255)">插件调用开始时间。</span>
         * <span style="background-color: rgb(255, 255, 255)">action_details.tool_details.</span><span style="background-color: rgb(255, 255, 255)"><strong>completed_at</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
            <span style="background-color: rgb(255, 255, 255)">插件调用结束时间。</span>
* **metadata** \`object / null\` 
   <span style="background-color: rgb(255, 255, 255)">额外参数。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>group_chat_config</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>必选</code></span>
      <span style="background-color: rgb(255, 255, 255)">运行时动态传入的角色配置。</span>
      * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)"><strong>characters</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>object[]</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
         <span style="background-color: rgb(255, 255, 255)">群聊角色列表。</span>
         * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.</span><span style="background-color: rgb(248, 248, 248)"><strong>name</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
            <span style="background-color: rgb(255, 255, 255)">群聊角色名称。</span>
         * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.</span><span style="background-color: rgb(248, 248, 248)"><strong>system_prompt</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
            <span style="background-color: rgb(255, 255, 255)">群聊角色设定，用于告知应用需要扮演的角色。</span>
         * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.</span><span style="background-color: rgb(248, 248, 248)"><strong>model_desc</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>object</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
            模型说明。
            * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.model_desc.</span><span style="background-color: rgb(248, 248, 248)"><strong>endpoint_id</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
               <span style="background-color: rgb(255, 255, 255)">您创建的</span>[推理接入点](https://www.volcengine.com/docs/82379/1099522)<span style="background-color: rgb(255, 255, 255)">ID。</span>
      * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)"><strong>description</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> \`默认值 null\`
         <span style="background-color: rgb(255, 255, 255)">群聊场景描述，可设定群聊的主题、时间地点、事件场景、用户扮演的角色等信息。</span>
      * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)"><strong>user_name</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> \`默认值 用户\`
         <span style="background-color: rgb(255, 255, 255)">表示“我”所扮演的角色名称 ，默认值为“用户”。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>user_info</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> \`默认值 null\`
      <span style="background-color: rgb(255, 255, 255)">可以被反序列化成 json 的字符串，需要包含 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>city</code></span><span style="background-color: rgb(255, 255, 255)"> 和 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>district</code></span><span style="background-color: rgb(255, 255, 255)"> 两个字段。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>emit_intention_signal_extra</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> \`默认值 "false"\`
      <span style="background-color: rgb(255, 255, 255)">值是 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>"true"</code></span><span style="background-color: rgb(255, 255, 255)"> 时，会中途返回intention状态 </span><span style="background-color: rgba(27, 31, 35, 0.05)">"正在搜索"。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>target_character_name</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> \`默认值 null\`
      <span style="background-color: rgb(255, 255, 255)">群聊Bot对话时填写，指定本次要发言的角色名，必须是存在于</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>characters</code></span><span style="background-color: rgb(255, 255, 255)">里的角色。</span>
* **references** \`object[]\`
   本次请求中应用调用了插件的信息。字段参考具体见各个插件的数据结构。
   * [联网插件](https://www.volcengine.com/docs/82379/1285209)
   * [知识库插件](https://www.volcengine.com/docs/82379/1285210)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="流式调用返回" key="NnNZPgLM"><RenderMd content={`* **id** \`string\`
   <span style="background-color: rgb(255, 255, 255)">本次请求的唯一标识。</span>
* **model** \`string\`
   <span style="background-color: rgb(255, 255, 255)">本次请求实际使用的模型名称和版本。</span>
   <span style="background-color: rgb(255, 255, 255)">doubao 1.5 代模型的模型名称格式为 doubao\-1\-5\-\*\*。如调用部署doubao\-1.5\-pro\-32k 250115模型的推理接入点，返回</span><span style="background-color: rgba(27, 31, 35, 0.05)">model</span><span style="background-color: rgb(255, 255, 255)">字段信息doubao\-1\-5\-pro\-32k\-250115。</span>
* **created** \`integer\`
   <span style="background-color: rgb(255, 255, 255)">本次请求创建时间的 Unix 时间戳（秒）。</span>
* <span style="background-color: rgb(255, 255, 255)"><strong>object</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>\`string\`
   <span style="background-color: rgb(255, 255, 255)">固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>chat.completion.chunk</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
* **choices** \`object[]\`
   <span style="background-color: rgb(255, 255, 255)">本次请求的模型输出内容。</span>
   * choices.**index** <span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
      <span style="background-color: rgb(255, 255, 255)">当前元素在 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><strong>choices</strong></span><span style="background-color: rgb(255, 255, 255)"> 列表的索引。</span>
   * choices.<span style="background-color: rgb(255, 255, 255)"><strong>finish_reason </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
      <span style="background-color: rgb(255, 255, 255)">模型停止生成 token 的原因。取值范围：</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>stop</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出自然结束，或因命中请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">stop</span><span style="background-color: rgb(255, 255, 255)"> 中指定的字段而被截断。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>length</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出因达到模型输出限制而被截断，有下面几种原因：</span>
         * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_token</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">回答内容的长度限制</span><span style="background-color: rgba(27, 31, 35, 0.05)">）</span><span style="background-color: rgb(255, 255, 255)">。</span>
         * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_completion_tokens</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">思维链内容+回答内容的长度限制）。</span>
         * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>context_window</code></span><span style="background-color: rgb(255, 255, 255)"> 限制（输入内容+思维链内容+回答内容的长度限制）。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>content_filter</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出被内容审核拦截。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>tool_calls</code></span><span style="background-color: rgb(255, 255, 255)">：模型调用了工具。</span>
   * choices.**delta** \`object\`
      <span style="background-color: rgb(255, 255, 255)">模型输出的增量内容。</span>
      * choices.delta.**role** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
         <span style="background-color: rgb(255, 255, 255)">内容输出的角色，此处固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>assistant</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
      * choices.delta.**content** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
         <span style="background-color: rgb(255, 255, 255)">模型生成的消息内容。</span>
      * choices.delta.<span style="background-color: rgb(255, 255, 255)"><strong>reasoning_content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string / null</code></span>
         <span style="background-color: rgb(255, 255, 255)">模型处理问题的思维链内容。</span>
         <span style="background-color: rgb(255, 255, 255)">仅深度推理模型支持返回此字段，深度推理模型请参见</span>[支持模型](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>
      * choices.delta.<span style="background-color: rgb(255, 255, 255)"><strong>tool_calls </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
         <span style="background-color: rgb(255, 255, 255)">模型调用的工具列表。</span>
         * choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>i</strong></span>**d** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
            <span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>
         * choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>index</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>interger</code></span>
            <span style="background-color: rgb(255, 255, 255)">当前元素在模型调用的工具列表的索引。</span>
         * choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
            <span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
         * choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>function </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object</code></span>
            <span style="background-color: rgb(255, 255, 255)">模型调用的函数。</span>
            * choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>name </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
               <span style="background-color: rgb(255, 255, 255)">模型调用的函数的名称。</span>
            * choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
               <span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
               <span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>
   * choices.<span style="background-color: rgb(255, 255, 255)"><strong>logprobs </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object / null</code></span>
      <span style="background-color: rgb(255, 255, 255)">当前内容的对数概率信息。</span>
      * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
         <span style="background-color: rgba(27, 31, 35, 0.05)">message</span><span style="background-color: rgb(255, 255, 255)">列表中每个 </span><span style="background-color: rgba(27, 31, 35, 0.05)">content</span><span style="background-color: rgb(255, 255, 255)"> 元素中的 token 对数概率信息。</span>
         * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
            <span style="background-color: rgb(255, 255, 255)">当前 token。</span>
         * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
            <span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>
         * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
            <span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>
         * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>top_logprobs </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
            <span style="background-color: rgb(255, 255, 255)">在当前 token 位置最有可能的标记及其对数概率的列表。在一些情况下，返回的数量可能比请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">top_logprobs</span><span style="background-color: rgb(255, 255, 255)"> 指定的数量要少。</span>
            * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
               <span style="background-color: rgb(255, 255, 255)">当前 token。</span>
            * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
               <span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>
            * choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
               <span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>
   * choices.<span style="background-color: rgb(255, 255, 255)"><strong>moderation_hit_type </strong></span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span><span style="background-color: rgb(32, 33, 35)"><code>/ null</code></span>
      <span style="background-color: rgb(255, 255, 255)">模型输出文字含有敏感信息时，会返回模型输出文字命中的风险分类标签。</span>
      <span style="background-color: rgb(255, 255, 255)">返回值及含义：</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>severe_violation</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及严重违规。</span>
      * <span style="background-color: rgba(27, 31, 35, 0.05)"><code>violence</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及激进行为。</span>
      <span style="background-color: rgb(255, 255, 255)">注意：当前只有</span>[视觉理解模型](https://www.volcengine.com/docs/82379/1362931#%E6%94%AF%E6%8C%81%E6%A8%A1%E5%9E%8B)<span style="background-color: rgb(255, 255, 255)">支持返回该字段，且只有在</span><span style="background-color: rgb(255, 255, 255)">方舟控制台</span>[接入点配置页面](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint/create?customModelId=)<span style="background-color: rgb(255, 255, 255)">或者 </span>[CreateEndpoint](https://www.volcengine.com/docs/82379/1262823)<span style="background-color: rgb(255, 255, 255)"> 接口中，将内容护栏方案（ModerationStrategy）设置为基础方案（Basic）时，才会返回风险分类标签。</span>
* **bot_usage** \`object\`
   <span style="background-color: rgb(255, 255, 255)">本次请求的 token 用量。</span>
   * bot_usage.<span style="background-color: rgb(255, 255, 255)"><strong>model_usage </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
      <span style="background-color: rgb(255, 255, 255)">本次请求不同 endpoint 的 token 消耗。</span>
      * bot_usage.<span style="background-color: rgb(255, 255, 255)">model_usage</span><span style="background-color: rgb(255, 255, 255)"><strong>.</strong></span><span style="background-color: rgb(255, 255, 255)">name </span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
         调用的模型 ID。
      * bot_usage.<span style="background-color: rgb(255, 255, 255)">model_usage</span><span style="background-color: rgb(255, 255, 255)"><strong>.</strong></span><span style="background-color: rgb(255, 255, 255)">prompt_tokens </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
         <span style="background-color: rgb(255, 255, 255)">输入的 prompt token 数量，包含用户输入的提示词和调用插件返回的信息。</span>
      * bot_usage.<span style="background-color: rgb(255, 255, 255)">model_usage</span><span style="background-color: rgb(255, 255, 255)"><strong>.</strong></span><span style="background-color: rgb(255, 255, 255)">completion_tokens </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
         <span style="background-color: rgb(255, 255, 255)">模型生成的 token 数量。</span>
      * bot_usage.<span style="background-color: rgb(255, 255, 255)">model_usage</span><span style="background-color: rgb(255, 255, 255)"><strong>.</strong></span><span style="background-color: rgb(255, 255, 255)">total_tokens </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
         <span style="background-color: rgb(255, 255, 255)">本次请求消耗的总 token 数量（输入 + 输出）。</span>
   * <span style="background-color: rgb(255, 255, 255)">action_usage </span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
      <span style="background-color: rgb(255, 255, 255)">本次请求插件用量信息。</span>
      * <span style="background-color: rgb(255, 255, 255)">action_usage.action_name </span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
         <span style="background-color: rgb(255, 255, 255)">插件分类名称，如 </span><span style="background-color: rgb(31, 31, 31)"><code>content_plugin</code></span><span style="background-color: rgb(255, 255, 255)">（内容插件）等。</span>
      * <span style="background-color: rgb(255, 255, 255)">action_usage.count </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
         <span style="background-color: rgb(255, 255, 255)">本次请求某插件分类插件总调用次数。</span>
   * <span style="background-color: rgb(255, 255, 255)">action_details </span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
      <span style="background-color: rgb(255, 255, 255)">本次请求插件调用详情。</span>
      * <span style="background-color: rgb(255, 255, 255)">action_details.name </span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
         <span style="background-color: rgb(255, 255, 255)">插件分类名称，如 </span><span style="background-color: rgb(31, 31, 31)"><code>content_plugin</code></span><span style="background-color: rgb(255, 255, 255)">（内容插件）等。</span>
      * <span style="background-color: rgb(255, 255, 255)">action_details.count </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
         <span style="background-color: rgb(255, 255, 255)">本次请求某插件分类中插件调用次数。</span>
      * <span style="background-color: rgb(255, 255, 255)">action_details.tool_details </span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
         <span style="background-color: rgb(255, 255, 255)">某插件分类中插件调用详细信息。</span>
         * <span style="background-color: rgb(255, 255, 255)">action_details.tool_details.name </span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
            具体调用的工具名称。
         * <span style="background-color: rgb(255, 255, 255)">action_details.tool_details.input </span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
            <span style="background-color: rgb(255, 255, 255)">插件输入参数，调用插件的数据结构。</span>
         * <span style="background-color: rgb(255, 255, 255)">action_details.tool_details.output </span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
            <span style="background-color: rgb(255, 255, 255)">插件输出结果，调用插件返回的数据结构。</span>
         * <span style="background-color: rgb(255, 255, 255)">action_details.tool_details.created_at </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
            <span style="background-color: rgb(255, 255, 255)">插件调用开始时间。</span>
         * <span style="background-color: rgb(255, 255, 255)">action_details.tool_details.completed_at </span><span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
            <span style="background-color: rgb(255, 255, 255)">插件调用结束时间。</span>
* **metadata** \`object / null\` 
   <span style="background-color: rgb(255, 255, 255)">额外参数。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>group_chat_config</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>必选</code></span>
      <span style="background-color: rgb(255, 255, 255)">运行时动态传入的角色配置。</span>
      * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)"><strong>characters</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>object[]</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
         <span style="background-color: rgb(255, 255, 255)">群聊角色列表。</span>
         * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.</span><span style="background-color: rgb(248, 248, 248)"><strong>name</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
            <span style="background-color: rgb(255, 255, 255)">群聊角色名称。</span>
         * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.</span><span style="background-color: rgb(248, 248, 248)"><strong>system_prompt</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
            <span style="background-color: rgb(255, 255, 255)">群聊角色设定，用于告知应用需要扮演的角色。</span>
         * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.</span><span style="background-color: rgb(248, 248, 248)"><strong>model_desc</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>object</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
            模型说明。
            * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)">characters.model_desc.</span><span style="background-color: rgb(248, 248, 248)"><strong>endpoint_id</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string</code></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>必选</code></span>
               <span style="background-color: rgb(255, 255, 255)">您创建的</span>[推理接入点](https://www.volcengine.com/docs/82379/1099522)<span style="background-color: rgb(255, 255, 255)">ID。</span>
      * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)"><strong>description</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> \`默认值 null\`
         <span style="background-color: rgb(255, 255, 255)">群聊场景描述，可设定群聊的主题、时间地点、事件场景、用户扮演的角色等信息。</span>
      * metadata**.**<span style="background-color: rgb(255, 255, 255)">group_chat_config.</span><span style="background-color: rgb(248, 248, 248)"><strong>user_name</strong></span><span style="background-color: rgb(248, 248, 248)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> \`默认值 用户\`
         <span style="background-color: rgb(255, 255, 255)">表示“我”所扮演的角色名称 ，默认值为“用户”。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>user_info</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> \`默认值 null\`
      <span style="background-color: rgb(255, 255, 255)">可以被反序列化成 json 的字符串，需要包含 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>city</code></span><span style="background-color: rgb(255, 255, 255)"> 和 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>district</code></span><span style="background-color: rgb(255, 255, 255)"> 两个字段。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>emit_intention_signal_extra</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> \`默认值 "false"\`
      <span style="background-color: rgb(255, 255, 255)">值是 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>"true"</code></span><span style="background-color: rgb(255, 255, 255)"> 时，会中途返回intention状态 </span><span style="background-color: rgba(27, 31, 35, 0.05)">"正在搜索"。</span>
   * metadata**.**<span style="background-color: rgb(255, 255, 255)"><strong>target_character_name</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(248, 248, 248)"><code>string / null</code></span> \`默认值 null\`
      <span style="background-color: rgb(255, 255, 255)">群聊Bot对话时填写，指定本次要发言的角色名，必须是存在于</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>characters</code></span><span style="background-color: rgb(255, 255, 255)">里的角色。</span>
* **references** \`object[]\`
   本次请求中应用调用了插件的信息。字段参考具体见各个插件的数据结构。
   * [联网插件](https://www.volcengine.com/docs/82379/1285209)
   * [知识库插件](https://www.volcengine.com/docs/82379/1285210)
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

&nbsp;




# 联网插件 数据结构
Source: https://www.volcengine.com/docs/82379/1285209


联网插件返回的数据结构如下：
<span id="searchdocument"></span>
## SearchDocument

| | | | | \
|参数名称 |类型 |\
| |<div style:"width=70px"></div> |描述 |\
| | |<div style:"width=200px"></div> |示例值 |
|---|---|---|---|
| | | | | \
|site_name |String |站点名 |抖音百科 |
| | | | | \
|summary |String |对该搜索结果的总结部分文本 |\- |
| | | | | \
|publish_time |String |发布时间 |\- |
| | | | | \
|title |String |标题 |\
| | |> 部分内容源的搜索结果含有该字段信息。 |\- |
| | | | | \
|url |String |引用链接 |\
| | |> 部分内容源的搜索结果含有该字段信息。 |\- |
| | | | | \
|logo_url |String |logo链接 |\
| | |> 部分内容源的搜索结果含有该字段信息。 |\- |
| | | | | \
|mobile_url |String |移动端引用链接 |\
| | |> 部分内容源的搜索结果含有该字段信息。 |\- |
| | | | | \
|cover_image |Object of[CoverImage](https://www.volcengine.com/docs/82379/1285209#coverimage) |封面图片 |\
| | |> 部分内容源的搜索结果含有该字段信息。 |\- |
| | | | | \
|extra |Object of [ExtraContent](https://www.volcengine.com/docs/82379/1285209#extracontent) |非通用字段 |\
| | |> 部分内容源的搜索结果含有该字段信息。 |\- |

<span id="coverimage"></span>
## CoverImage

| | | | | \
|参数名称 |类型 |描述 |\
| | |<div style:"width=200px"></div> |示例值 |
|---|---|---|---|
| | | | | \
|url |String |封面图链接 |\
| | |> 部分内容源的搜索结果含有该字段信息。 |\- |
| | | | | \
|width |Integer |宽度 |\- |
| | | | | \
|height |Integer |高度 |\- |

<span id="extracontent"></span>
## ExtraContent

| | | | | \
|参数名称 |类型 |描述 |\
| | |<div style:"width=200px"></div> |示例值 |
|---|---|---|---|
| | | | | \
|weather_card_data |Object of [WeatherCardData](https://www.volcengine.com/docs/82379/1285209#weathercarddata) |天气相关的额外信息 |\- |

<span id="weathercarddata"></span>
## WeatherCardData

| | | | | \
|参数名称 |类型 |描述 |\
| | |<div style:"width=200px"></div> |示例值 |
|---|---|---|---|
| | | | | \
|display |Object of [WeatherCardDataDisplay](https://www.volcengine.com/docs/82379/1285209#weathercarddatadisplay) |天气卡片展示相关信息 |\- |

<span id="weathercarddatadisplay"></span>
## WeatherCardDataDisplay

| | | | | \
|参数名称 |类型 |描述 |\
| | |<div style:"width=200px"></div> |示例值 |
|---|---|---|---|
| | | | | \
|aqi |object |当前时刻空气质量指数详细情况 |\- |
| | | | | \
|aqiForecast |object |7日空气质量指数预报 |\- |
| | | | | \
|aqiForecastHourly |object |7日每小时空气质量指数预报 |\- |
| | | | | \
|aqi_url |String |空气质量指数url |\- |
| | | | | \
|city |object |城市信息 |\- |
| | | | | \
|condition |object |当天天气情况 |\- |
| | | | | \
|condition_url |String |当天天气情况url |\- |
| | | | | \
|seven_forecast_data |object |近7日天气预报 |\- |




# 知识库插件 数据结构
Source: https://www.volcengine.com/docs/82379/1285210


知识库插件返回的数据结构如下：
<span id="knowledgebasechunk"></span>
## KnowledgeBaseChunk

| | | | | \
|参数名称 |类型 |描述 |示例值 |
|---|---|---|---|
| | | | | \
|collection_name |String |Collection 名字 |- |
| | | | | \
|project |String |Collection 所在的 project name |- |
| | | | | \
|doc_id |String |文档 id |- |
| | | | | \
|doc_name |String |文档名字 |- |
| | | | | \
|doc_type |String |文档类型 |- |
| | | | | \
|doc_title |String |文档标题 |- |
| | | | | \
|chunk_id |String |分块 id |- |
| | | | | \
|chunk_title |String |分块标题 |- |




# CreateBatchInferenceJob - 创建批量推理任务
Source: https://www.volcengine.com/docs/82379/1339603
创建批量推理任务





## 调试
<APILink link="https://api.volcengine.com/api-explorer/?action=CreateBatchInferenceJob&groupName=%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86%E4%BB%BB%E5%8A%A1%20API&serviceCode=ark&version=2024-01-01"></APILink>

## 请求参数

下表仅列出该接口特有的请求参数和部分公共参数。更多信息请见[公共参数](https://www.volcengine.com/docs/6369/67268)。



```mixin-react
const columns = [
  {
    width: '20%',
    title: '参数',
    dataIndex: 'Name',
    className: 'openapi-doc-parameter-table-name'
  },
  {
    width: 130,
    title: '类型',
    dataIndex: 'DataType',
    className: 'openapi-doc-parameter-table-type'
  },
  {
    width: 90,
    title: '是否必填',
    dataIndex: 'IsRequired',
    className: 'openapi-doc-parameter-table-required'
  },
  {
    width: '20%',
    title: '示例值',
    dataIndex: 'Example',
    className: 'openapi-doc-parameter-table-example'
  },
  {
    title: '描述',
    dataIndex: 'Description',
    className: 'openapi-doc-parameter-table-description'
  },
];

const data = [
  {
    rowKey: '->Action',
    Name: 'Action',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"CreateBatchInferenceJob"} />,
    Description: <RenderMd content={"要执行的操作，取值：CreateBatchInferenceJob。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Version',
    Name: 'Version',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"2024-01-01"} />,
    Description: <RenderMd content={"API的版本，取值：2024-01-01。"} />,
    children: [
    ]
  },
  {
    rowKey: '->ProjectName',
    Name: 'ProjectName',
    DataType: 'String',
    IsRequired: '否',
    Example: <RenderMd content={"my-project"} />,
    Description: <RenderMd content={"- 资源所属的项目名称，默认值为`default`。\n- 若资源不在默认项目中，需填写正确的项目名称，获取项目名称，请查看[文档](https://www.volcengine.com/docs/82379/1359411#%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E9%A1%B9%E7%9B%AE%E5%90%8D%E7%A7%B0%EF%BC%88project-name%EF%BC%89%EF%BC%9F)。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Name',
    Name: 'Name',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"my-batch-Inference-job"} />,
    Description: <RenderMd content={"批量推理任务名称"} />,
    children: [
    ]
  },
  {
    rowKey: '->Description',
    Name: 'Description',
    DataType: 'String',
    IsRequired: '否',
    Example: <RenderMd content={"my-batch-Inference-job"} />,
    Description: <RenderMd content={"批量推理任务描述"} />,
    children: [
    ]
  },
  {
    rowKey: '->ModelReference',
    Name: 'ModelReference',
    DataType: 'Object',
    IsRequired: '是',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务选择的模型。CustomModelId（定制模型）、FoundationModel（基础模型），两个参数需要指定一个。"} />,
    children: [
        {
          rowKey: '->ModelReference->CustomModelId',
          Name: 'CustomModelId',
          DataType: 'String',
          IsRequired: '否',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"定制模型的ID"} />,
          children: [
          ]
        },
        {
          rowKey: '->ModelReference->FoundationModel',
          Name: 'FoundationModel',
          DataType: 'Object',
          IsRequired: '否',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"基础模型"} />,
          children: [
            {
              rowKey: '->ModelReference->FoundationModel->Name',
              Name: 'Name',
              DataType: 'String',
              IsRequired: '是',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"基础模型名称。\n- 请注意模型名称为小写。\n- doubao 1.5 代模型的模型名称格式为 \"doubao-1-5-\\*\\*\"。\n举例： \"Doubao-1.5-pro-32k\" 模型Name字段为 \"doubao-1-5-pro-32k\"。"} />,
              children: [
              ]
            },
            {
              rowKey: '->ModelReference->FoundationModel->ModelVersion',
              Name: 'ModelVersion',
              DataType: 'String',
              IsRequired: '是',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"基础模型版本"} />,
              children: [
              ]
            },
          ]
        },
    ]
  },
  {
    rowKey: '->InputFileTosLocation',
    Name: 'InputFileTosLocation',
    DataType: 'Object',
    IsRequired: '是',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理输入的文件"} />,
    children: [
        {
          rowKey: '->InputFileTosLocation->ObjectKey',
          Name: 'ObjectKey',
          DataType: 'String',
          IsRequired: '是',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"TOS对象路径"} />,
          children: [
          ]
        },
        {
          rowKey: '->InputFileTosLocation->BucketName',
          Name: 'BucketName',
          DataType: 'String',
          IsRequired: '是',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"TOS桶名称"} />,
          children: [
          ]
        },
    ]
  },
  {
    rowKey: '->OutputDirTosLocation',
    Name: 'OutputDirTosLocation',
    DataType: 'Object',
    IsRequired: '是',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务输出结果的文件夹"} />,
    children: [
        {
          rowKey: '->OutputDirTosLocation->ObjectKey',
          Name: 'ObjectKey',
          DataType: 'String',
          IsRequired: '是',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"TOS对象路径"} />,
          children: [
          ]
        },
        {
          rowKey: '->OutputDirTosLocation->BucketName',
          Name: 'BucketName',
          DataType: 'String',
          IsRequired: '是',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"TOS桶名称"} />,
          children: [
          ]
        },
    ]
  },
  {
    rowKey: '->CompletionWindow',
    Name: 'CompletionWindow',
    DataType: 'String',
    IsRequired: '否',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务的最大等待时间"} />,
    children: [
    ]
  },
  {
    rowKey: '->Tags',
    Name: 'Tags',
    DataType: 'Array of Object',
    IsRequired: '否',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务绑定的标签"} />,
    children: [
        {
          rowKey: '->Tags->Key',
          Name: 'Key',
          DataType: 'String',
          IsRequired: '是',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"标签键"} />,
          children: [
          ]
        },
        {
          rowKey: '->Tags->Value',
          Name: 'Value',
          DataType: 'String',
          IsRequired: '是',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"标签值"} />,
          children: [
          ]
        },
    ]
  },
  {
    rowKey: '->DryRun',
    Name: 'DryRun',
    DataType: 'Boolean',
    IsRequired: '否',
    Example: <RenderMd content={"true"} />,
    Description: <RenderMd content={"是否仅对此请求进行预检。\n取值：\n- true：发送检查请求。 \n- false(默认)：发送正常请求。"} />,
    children: [
    ]
  },

];

return (<Table
  rowKey="rowKey"
  className="openapi-doc-parameter-table"
  columns={columns}
  data={data}
  border={ { cell: true, wrapper: true } }
  scroll={ { x: "auto" } }
  pagination={false}
/>);
```

## 返回参数


下表仅列出本接口特有的返回参数。更多信息请参见[返回结构](https://www.volcengine.com/docs/6369/80336)。


```mixin-react
const columns = [
  {
    width: '25%',
    title: '参数',
    dataIndex: 'Name',
    className: 'openapi-doc-parameter-table-name',
  },
  {
    width: 130,
    title: '类型',
    dataIndex: 'DataType',
    className: 'openapi-doc-parameter-table-type'
  },
  {
    width: '25%',
    title: '示例值',
    dataIndex: 'Example',
    className: 'openapi-doc-parameter-table-example'
  },
  {
    title: '描述',
    dataIndex: 'Description',
    className: 'openapi-doc-parameter-table-description'
  },
];

const data = [
  {
    rowKey: "->Id",
    Name: "Id",
    DataType: "String",
    Example: <RenderMd content={"bi-20240918****-r2***"} />,
    Description: <RenderMd content={"批量推理任务的Id"} />,
    children: [
    ]
  },
];

return (<Table
  rowKey="rowKey"
  className="openapi-doc-parameter-table"
  columns={columns}
  data={data}
  border={ { cell: true, wrapper: true } }
  scroll={ { x: "auto" } }
  pagination={false}
/>);
```

## 请求示例 
```text
POST /?Action=CreateBatchInferenceJob&Version=2024-01-01 HTTP/1.1
Host: open.volcengineapi.com
Content-Type: application/json; charset=UTF-8
X-Date: 20240514T132743Z
X-Content-Sha256: 287e874e******d653b44d21e
Authorization: HMAC-SHA256 Credential=Adfks******wekfwe/20240514/cn-beijing/ark/request, SignedHeaders=host;x-content-sha256;x-date, Signature=47a7d934ff7b37c03938******cd7b8278a40a1057690c401e92246a0e41085f

{
    "Name": "批量推理任务",
    "Description": "这是一个批量推理任务",
    "ModelReference": {
      "FoundationModel": {
        "Name": "doubao-pro-32k",
        "ModelVersion": "240615"
      }
    },
    "InputFileTosLocation": {
      "BucketName": "my-bucket-name",
      "ObjectKey": "batch-inference-job/dataset/my-job.jsonl"
    },
    "OutputDirTosLocation": {
      "ObjectKey": "batch-inference-job/output/",
      "BucketName": "my-bucket-name"
    },
    "ProjectName":"default",
    "CompletionWindow": "1d",
    "Tags": [
      {
        "Key": "test_key",
        "Value": "test_value"
      }
    ]
}
```
## 返回示例 
```json
{
  "ResponseMetadata": {
    "RequestId": "20240918194640ECB302768CB287CEDAC6",
    "Action": "CreateBatchInferenceJob",
    "Version": "2024-01-01",
    "Service": "ark",
    "Region": "cn-beijing"
  },
  "Result": {
    "Id": "bi-2024091****-****"
  }
}
```


## 错误码
您可访问[公共错误码](https://www.volcengine.com/docs/82379/1299023)，获取更多错误码信息。



<style>
.volc-md-viewer .arco-table-th {
	min-width: 100px;
}
.volc-md-viewer .openapi-doc-parameter-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errorcode {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errormessage {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:first-child .arco-table-cell {
  display: flex;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:nth-child(2) .arco-table-cell {
  word-break: normal;
}
</style>


# ListBatchInferenceJobs - 获取批量推理任务列表
Source: https://www.volcengine.com/docs/82379/1339606
获取批量推理任务列表





## 调试
<APILink link="https://api.volcengine.com/api-explorer/?action=ListBatchInferenceJobs&groupName=%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86%E4%BB%BB%E5%8A%A1%20API&serviceCode=ark&version=2024-01-01"></APILink>

## 请求参数

下表仅列出该接口特有的请求参数和部分公共参数。更多信息请见[公共参数](https://www.volcengine.com/docs/6369/67268)。



```mixin-react
const columns = [
  {
    width: '20%',
    title: '参数',
    dataIndex: 'Name',
    className: 'openapi-doc-parameter-table-name'
  },
  {
    width: 130,
    title: '类型',
    dataIndex: 'DataType',
    className: 'openapi-doc-parameter-table-type'
  },
  {
    width: 90,
    title: '是否必填',
    dataIndex: 'IsRequired',
    className: 'openapi-doc-parameter-table-required'
  },
  {
    width: '20%',
    title: '示例值',
    dataIndex: 'Example',
    className: 'openapi-doc-parameter-table-example'
  },
  {
    title: '描述',
    dataIndex: 'Description',
    className: 'openapi-doc-parameter-table-description'
  },
];

const data = [
  {
    rowKey: '->Action',
    Name: 'Action',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"ListBatchInferenceJobs"} />,
    Description: <RenderMd content={"要执行的操作，取值：ListBatchInferenceJobs。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Version',
    Name: 'Version',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"2024-01-01"} />,
    Description: <RenderMd content={"API的版本，取值：2024-01-01。"} />,
    children: [
    ]
  },
  {
    rowKey: '->ProjectName',
    Name: 'ProjectName',
    DataType: 'String',
    IsRequired: '否',
    Example: <RenderMd content={"default"} />,
    Description: <RenderMd content={"- 资源所属的项目名称，默认值为`default`。\n- 若资源不在默认项目中，需填写正确的项目名称，获取项目名称，请查看[文档](https://www.volcengine.com/docs/82379/1359411#%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E9%A1%B9%E7%9B%AE%E5%90%8D%E7%A7%B0%EF%BC%88project-name%EF%BC%89%EF%BC%9F)。"} />,
    children: [
    ]
  },
  {
    rowKey: '->PageNumber',
    Name: 'PageNumber',
    DataType: 'Integer',
    IsRequired: '否',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"分页查询时的起始页码，从 1 开始，默认为 1"} />,
    children: [
    ]
  },
  {
    rowKey: '->PageSize',
    Name: 'PageSize',
    DataType: 'Integer',
    IsRequired: '否',
    Example: <RenderMd content={"10"} />,
    Description: <RenderMd content={"分页查询时每页显示的记录数，取值： - 最小值：1 - 最大值：100 - 默认值：10"} />,
    children: [
    ]
  },
  {
    rowKey: '->SortOrder',
    Name: 'SortOrder',
    DataType: 'String',
    IsRequired: '否',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"指定排序顺序。 可指定值: - Asc： 升序排列 - Desc: 降序排列"} />,
    children: [
    ]
  },
  {
    rowKey: '->SortBy',
    Name: 'SortBy',
    DataType: 'String',
    IsRequired: '否',
    Example: <RenderMd content={"CreateTime"} />,
    Description: <RenderMd content={"指定排序指标。 可指定值: \\* CreateTime：创建时间 \\* UpdateTime：更新时间"} />,
    children: [
    ]
  },
  {
    rowKey: '->TagFilters',
    Name: 'TagFilters',
    DataType: 'Array of Object',
    IsRequired: '否',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"基于绑定的标签的筛选条件"} />,
    children: [
        {
          rowKey: '->TagFilters->Key',
          Name: 'Key',
          DataType: 'String',
          IsRequired: '是',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"标签键"} />,
          children: [
          ]
        },
        {
          rowKey: '->TagFilters->Values',
          Name: 'Values',
          DataType: 'Array of String',
          IsRequired: '否',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"标签值"} />,
          children: [
          ]
        },
    ]
  },
  {
    rowKey: '->Filter',
    Name: 'Filter',
    DataType: 'Object',
    IsRequired: '否',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"带查询批量推理任务的筛选条件"} />,
    children: [
        {
          rowKey: '->Filter->Ids',
          Name: 'Ids',
          DataType: 'Array of String',
          IsRequired: '否',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"指定批量推理任务的ID"} />,
          children: [
          ]
        },
        {
          rowKey: '->Filter->Name',
          Name: 'Name',
          DataType: 'String',
          IsRequired: '否',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"模糊搜索批量推理任务名称"} />,
          children: [
          ]
        },
        {
          rowKey: '->Filter->FoundationModels',
          Name: 'FoundationModels',
          DataType: 'Array of Object',
          IsRequired: '否',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"基础模型"} />,
          children: [
            {
              rowKey: '->Filter->FoundationModels->Name',
              Name: 'Name',
              DataType: 'String',
              IsRequired: '是',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"基础模型名称"} />,
              children: [
              ]
            },
            {
              rowKey: '->Filter->FoundationModels->ModelVersions',
              Name: 'ModelVersions',
              DataType: 'Array of String',
              IsRequired: '否',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"基础模型版本"} />,
              children: [
              ]
            },
          ]
        },
        {
          rowKey: '->Filter->CustomModelIds',
          Name: 'CustomModelIds',
          DataType: 'Array of String',
          IsRequired: '否',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务对应的定制模型ID"} />,
          children: [
          ]
        },
        {
          rowKey: '->Filter->Phases',
          Name: 'Phases',
          DataType: 'Array of String',
          IsRequired: '否',
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"指定批量推理任务的状态值"} />,
          children: [
          ]
        },
    ]
  },

];

return (<Table
  rowKey="rowKey"
  className="openapi-doc-parameter-table"
  columns={columns}
  data={data}
  border={ { cell: true, wrapper: true } }
  scroll={ { x: "auto" } }
  pagination={false}
/>);
```

## 返回参数


下表仅列出本接口特有的返回参数。更多信息请参见[返回结构](https://www.volcengine.com/docs/6369/80336)。


```mixin-react
const columns = [
  {
    width: '25%',
    title: '参数',
    dataIndex: 'Name',
    className: 'openapi-doc-parameter-table-name',
  },
  {
    width: 130,
    title: '类型',
    dataIndex: 'DataType',
    className: 'openapi-doc-parameter-table-type'
  },
  {
    width: '25%',
    title: '示例值',
    dataIndex: 'Example',
    className: 'openapi-doc-parameter-table-example'
  },
  {
    title: '描述',
    dataIndex: 'Description',
    className: 'openapi-doc-parameter-table-description'
  },
];

const data = [
  {
    rowKey: "->TotalCount",
    Name: "TotalCount",
    DataType: "Integer",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务数量"} />,
    children: [
    ]
  },
  {
    rowKey: "->PageNumber",
    Name: "PageNumber",
    DataType: "Integer",
    Example: <RenderMd content={"1"} />,
    Description: <RenderMd content={"分页查询时的起始页码，从 1 开始，默认为 1。"} />,
    children: [
    ]
  },
  {
    rowKey: "->PageSize",
    Name: "PageSize",
    DataType: "Integer",
    Example: <RenderMd content={"10"} />,
    Description: <RenderMd content={"分页查询时每页显示的记录数，取值： - 最小值：1 - 最大值：100 - 默认值：10"} />,
    children: [
    ]
  },
  {
    rowKey: "->Items",
    Name: "Items",
    DataType: "Array of Object",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务数组"} />,
    children: [
        {
          rowKey: "->Items->Id",
          Name: "Id",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务的ID"} />,
          children: [
          ]
        },
        {
          rowKey: "->Items->Name",
          Name: "Name",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务名称"} />,
          children: [
          ]
        },
        {
          rowKey: "->Items->Description",
          Name: "Description",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务描述"} />,
          children: [
          ]
        },
        {
          rowKey: "->Items->InputFileTosLocation",
          Name: "InputFileTosLocation",
          DataType: "Object",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务传入的文件的TOS地址"} />,
          children: [
            {
              rowKey: "->Items->InputFileTosLocation->ObjectKey",
              Name: "ObjectKey",
              DataType: 'String',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"TOS对象路径"} />,
              children: [
              ]
            },
            {
              rowKey: "->Items->InputFileTosLocation->BucketName",
              Name: "BucketName",
              DataType: 'String',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"TOS桶名称"} />,
              children: [
              ]
            },
          ]
        },
        {
          rowKey: "->Items->OutputDirTosLocation",
          Name: "OutputDirTosLocation",
          DataType: "Object",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务的结果输出的TOS地址"} />,
          children: [
            {
              rowKey: "->Items->OutputDirTosLocation->ObjectKey",
              Name: "ObjectKey",
              DataType: 'String',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"TOS对象路径"} />,
              children: [
              ]
            },
            {
              rowKey: "->Items->OutputDirTosLocation->BucketName",
              Name: "BucketName",
              DataType: 'String',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"TOS桶名称"} />,
              children: [
              ]
            },
          ]
        },
        {
          rowKey: "->Items->CompletionWindow",
          Name: "CompletionWindow",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务的最大等待时间"} />,
          children: [
          ]
        },
        {
          rowKey: "->Items->Status",
          Name: "Status",
          DataType: "Object",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务的状态元信息"} />,
          children: [
            {
              rowKey: "->Items->Status->PhaseTime",
              Name: "PhaseTime",
              DataType: 'String',
              Example: <RenderMd content={"\\-"} />,
              Description: <RenderMd content={"批量推理任务状态更新时间，RFC3339格式"} />,
              children: [
              ]
            },
            {
              rowKey: "->Items->Status->Message",
              Name: "Message",
              DataType: 'String',
              Example: <RenderMd content={"\\-"} />,
              Description: <RenderMd content={"批量推理任务状态信息"} />,
              children: [
              ]
            },
            {
              rowKey: "->Items->Status->Phase",
              Name: "Phase",
              DataType: 'String',
              Example: <RenderMd content={"Running"} />,
              Description: <RenderMd content={"批量推理任务的状态。\n- \"Queued\"：任务排队中，任务由于账号下并发任务数达到上限等原因需排队等候。\n- \"Initializing\"：任务初始化中。\n- \"Running\"：任务运行中。\n- \"Terminating\"：由于到期等系统原因或手动终止，任务当前处于取消中状态。\n- \"Terminated\"：任务已被终止。\n-  \"Completed\"：任务已完成，所有请求已经处理完毕，任务已完成。\n- \"Failed\"：输入文件校验失败或其他原因导致任务失败。"} />,
              children: [
              ]
            },
          ]
        },
        {
          rowKey: "->Items->ModelReference",
          Name: "ModelReference",
          DataType: "Object",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务选中的模型"} />,
          children: [
            {
              rowKey: "->Items->ModelReference->CustomModelId",
              Name: "CustomModelId",
              DataType: 'String',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"定制模型的ID"} />,
              children: [
              ]
            },
            {
              rowKey: "->Items->ModelReference->FoundationModel",
              Name: "FoundationModel",
              DataType: 'Object',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"基础模型"} />,
              children: [
                {
                  rowKey: "->Items->ModelReference->FoundationModel->Name",
                  Name: "Name",
                  DataType: "String",
                  Example: <RenderMd content={""} />,
                  Description: <RenderMd content={"基础模型名称。\n- 请注意模型名称为小写。\n- doubao 1.5 代模型的模型名称格式为 \"doubao-1-5-\\*\\*\"。\n举例： \"Doubao-1.5-pro-32k\" 模型Name字段为 \"doubao-1-5-pro-32k\"。"} />,
                  children: [
                  ]
                },
                {
                  rowKey: "->Items->ModelReference->FoundationModel->ModelVersion",
                  Name: "ModelVersion",
                  DataType: "String",
                  Example: <RenderMd content={""} />,
                  Description: <RenderMd content={"基础模型版本"} />,
                  children: [
                  ]
                },
              ]
            },
          ]
        },
        {
          rowKey: "->Items->RequestCounts",
          Name: "RequestCounts",
          DataType: "Object",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务的request数量"} />,
          children: [
            {
              rowKey: "->Items->RequestCounts->Total",
              Name: "Total",
              DataType: 'Long',
              Example: <RenderMd content={"\\-"} />,
              Description: <RenderMd content={"所有request数量"} />,
              children: [
              ]
            },
            {
              rowKey: "->Items->RequestCounts->Completed",
              Name: "Completed",
              DataType: 'Long',
              Example: <RenderMd content={"\\-"} />,
              Description: <RenderMd content={"完成的request数量"} />,
              children: [
              ]
            },
            {
              rowKey: "->Items->RequestCounts->Failed",
              Name: "Failed",
              DataType: 'Long',
              Example: <RenderMd content={"\\-"} />,
              Description: <RenderMd content={"失败的request数量"} />,
              children: [
              ]
            },
          ]
        },
        {
          rowKey: "->Items->Tags",
          Name: "Tags",
          DataType: "Array of Object",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务绑定的标签"} />,
          children: [
            {
              rowKey: "->Items->Tags->Key",
              Name: "Key",
              DataType: 'String',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"标签键"} />,
              children: [
              ]
            },
            {
              rowKey: "->Items->Tags->Value",
              Name: "Value",
              DataType: 'String',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"标签值"} />,
              children: [
              ]
            },
          ]
        },
        {
          rowKey: "->Items->CreateTime",
          Name: "CreateTime",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务创建时间，RFC3339格式"} />,
          children: [
          ]
        },
        {
          rowKey: "->Items->UpdateTime",
          Name: "UpdateTime",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务更新时间，RFC3339格式"} />,
          children: [
          ]
        },
        {
          rowKey: "->Items->ProjectName",
          Name: "ProjectName",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"项目名称"} />,
          children: [
          ]
        },
        {
          rowKey: "->Items->ExpireTime",
          Name: "ExpireTime",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"批量推理任务到期时间，RFC3339格式"} />,
          children: [
          ]
        },
    ]
  },
];

return (<Table
  rowKey="rowKey"
  className="openapi-doc-parameter-table"
  columns={columns}
  data={data}
  border={ { cell: true, wrapper: true } }
  scroll={ { x: "auto" } }
  pagination={false}
/>);
```

## 请求示例 
```text
{
  "ProjectName": "\\-",
  "PageNumber": 0,
  "PageSize": 10,
  "SortOrder": "\\-",
  "SortBy": "CreateTime",
  "TagFilters": [
    {
      "Key": "4e74qI",
      "Values": [
        "oEG"
      ]
    }
  ],
  "Filter": {
    "Ids": [
      "PhiQsNAH3Z"
    ],
    "Name": "Sy0pz",
    "FoundationModels": [
      {
        "Name": "jWyMB1c9ar",
        "ModelVersions": [
          "l"
        ]
      }
    ],
    "CustomModelIds": [
      "8iwBx"
    ],
    "Phases": [
      "f5yt"
    ]
  }
}
```
## 返回示例 
```json
{
    "ResponseMetadata": {
        "RequestId": "2024091819503335D2321703C1A3CCA381",
        "Action": "ListBatchInferenceJobs",
        "Version": "2024-01-01",
        "Service": "ark",
        "Region": "cn-beijing"
    },
    "Result": {
        "TotalCount": 1,
        "PageNumber": 1,
        "PageSize": 10,
        "Items": [
            {
                "Id": "bi-20240918194641-r2nwq",
                "Name": "批量推理任务",
                "Description": "这是一个批量推理任务",
                "InputFileTosLocation": {
                    "BucketName": "my-bucket-name",
                    "ObjectKey": "batch-inference-job/dataset/my-job.jsonl"
                },
                "OutputDirTosLocation": {
                    "BucketName": "my-bucket-name",
                    "ObjectKey": "batch-inference-job/output/"
                },
                "CompletionWindow": "1d",
                "Status": {
                    "Phase": "Completed",
                    "PhaseTime": "2024-09-18T11:50:00Z",
                    "Message": "批量推理任务已完成"
                },
                "ModelReference": {
                    "FoundationModel": {
                        "Name": "doubao-pro-32k",
                        "ModelVersion": "240615"
                    }
                },
                "RequestCounts": {
                    "Total": 2,
                    "Completed": 2,
                    "Failed": 0
                },
                "Tags": [
                    {
                        "Key": "sys:ark:createdBy",
                        "Value": "IAMUser/30805480/test@bytedance.com"
                    },
                    {
                        "Key": "test_key",
                        "Value": "test_value"
                    }
                ],
                "ProjectName": "default",
                "CreateTime": "2024-09-18T11:46:41Z",
                "UpdateTime": "2024-09-18T11:50:00Z",
                "ExpireTime": "2024-09-19T11:46:41Z"
            }
        ]
    }
}
```


## 错误码
您可访问[公共错误码](https://www.volcengine.com/docs/82379/1299023)，获取更多错误码信息。



<style>
.volc-md-viewer .arco-table-th {
	min-width: 100px;
}
.volc-md-viewer .openapi-doc-parameter-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errorcode {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errormessage {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:first-child .arco-table-cell {
  display: flex;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:nth-child(2) .arco-table-cell {
  word-break: normal;
}
</style>


# GetBatchInferenceJob - 获取批量推理任务
Source: https://www.volcengine.com/docs/82379/1339609
获取批量推理任务 





## 调试
<APILink link="https://api.volcengine.com/api-explorer/?action=GetBatchInferenceJob&groupName=%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86%E4%BB%BB%E5%8A%A1%20API&serviceCode=ark&version=2024-01-01"></APILink>

## 请求参数

下表仅列出该接口特有的请求参数和部分公共参数。更多信息请见[公共参数](https://www.volcengine.com/docs/6369/67268)。



```mixin-react
const columns = [
  {
    width: '20%',
    title: '参数',
    dataIndex: 'Name',
    className: 'openapi-doc-parameter-table-name'
  },
  {
    width: 130,
    title: '类型',
    dataIndex: 'DataType',
    className: 'openapi-doc-parameter-table-type'
  },
  {
    width: 90,
    title: '是否必填',
    dataIndex: 'IsRequired',
    className: 'openapi-doc-parameter-table-required'
  },
  {
    width: '20%',
    title: '示例值',
    dataIndex: 'Example',
    className: 'openapi-doc-parameter-table-example'
  },
  {
    title: '描述',
    dataIndex: 'Description',
    className: 'openapi-doc-parameter-table-description'
  },
];

const data = [
  {
    rowKey: '->Action',
    Name: 'Action',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"GetBatchInferenceJob"} />,
    Description: <RenderMd content={"要执行的操作，取值：GetBatchInferenceJob。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Version',
    Name: 'Version',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"2024-01-01"} />,
    Description: <RenderMd content={"API的版本，取值：2024-01-01。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Id',
    Name: 'Id',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务的ID"} />,
    children: [
    ]
  },

];

return (<Table
  rowKey="rowKey"
  className="openapi-doc-parameter-table"
  columns={columns}
  data={data}
  border={ { cell: true, wrapper: true } }
  scroll={ { x: "auto" } }
  pagination={false}
/>);
```

## 返回参数


下表仅列出本接口特有的返回参数。更多信息请参见[返回结构](https://www.volcengine.com/docs/6369/80336)。


```mixin-react
const columns = [
  {
    width: '25%',
    title: '参数',
    dataIndex: 'Name',
    className: 'openapi-doc-parameter-table-name',
  },
  {
    width: 130,
    title: '类型',
    dataIndex: 'DataType',
    className: 'openapi-doc-parameter-table-type'
  },
  {
    width: '25%',
    title: '示例值',
    dataIndex: 'Example',
    className: 'openapi-doc-parameter-table-example'
  },
  {
    title: '描述',
    dataIndex: 'Description',
    className: 'openapi-doc-parameter-table-description'
  },
];

const data = [
  {
    rowKey: "->Id",
    Name: "Id",
    DataType: "String",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务的ID"} />,
    children: [
    ]
  },
  {
    rowKey: "->Name",
    Name: "Name",
    DataType: "String",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务名称"} />,
    children: [
    ]
  },
  {
    rowKey: "->Description",
    Name: "Description",
    DataType: "String",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务描述"} />,
    children: [
    ]
  },
  {
    rowKey: "->InputFileTosLocation",
    Name: "InputFileTosLocation",
    DataType: "Object",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务传入的文件的TOS地址"} />,
    children: [
        {
          rowKey: "->InputFileTosLocation->ObjectKey",
          Name: "ObjectKey",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"TOS对象路径"} />,
          children: [
          ]
        },
        {
          rowKey: "->InputFileTosLocation->BucketName",
          Name: "BucketName",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"TOS桶名称"} />,
          children: [
          ]
        },
    ]
  },
  {
    rowKey: "->OutputDirTosLocation",
    Name: "OutputDirTosLocation",
    DataType: "Object",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务的结果输出的TOS地址"} />,
    children: [
        {
          rowKey: "->OutputDirTosLocation->ObjectKey",
          Name: "ObjectKey",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"TOS对象路径"} />,
          children: [
          ]
        },
        {
          rowKey: "->OutputDirTosLocation->BucketName",
          Name: "BucketName",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"TOS桶名称"} />,
          children: [
          ]
        },
    ]
  },
  {
    rowKey: "->ErrorFileTosLocation",
    Name: "ErrorFileTosLocation",
    DataType: "Object",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务输出的错误信息的TOS地址"} />,
    children: [
        {
          rowKey: "->ErrorFileTosLocation->ObjectKey",
          Name: "ObjectKey",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"TOS对象路径"} />,
          children: [
          ]
        },
        {
          rowKey: "->ErrorFileTosLocation->BucketName",
          Name: "BucketName",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"TOS桶名称"} />,
          children: [
          ]
        },
    ]
  },
  {
    rowKey: "->CompletionWindow",
    Name: "CompletionWindow",
    DataType: "String",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务的最大等待时间"} />,
    children: [
    ]
  },
  {
    rowKey: "->Status",
    Name: "Status",
    DataType: "Object",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务的状态元信息"} />,
    children: [
        {
          rowKey: "->Status->PhaseTime",
          Name: "PhaseTime",
          DataType: "String",
          Example: <RenderMd content={"\\-"} />,
          Description: <RenderMd content={"批量推理任务状态更新时间，RFC3339格式"} />,
          children: [
          ]
        },
        {
          rowKey: "->Status->Message",
          Name: "Message",
          DataType: "String",
          Example: <RenderMd content={"\\-"} />,
          Description: <RenderMd content={"批量推理任务状态信息"} />,
          children: [
          ]
        },
        {
          rowKey: "->Status->Phase",
          Name: "Phase",
          DataType: "String",
          Example: <RenderMd content={"Running"} />,
          Description: <RenderMd content={"批量推理任务的状态。\n- \"Queued\"：任务排队中，任务由于账号下并发任务数达到上限等原因需排队等候。\n- \"Initializing\"：任务初始化中。\n- \"Running\"：任务运行中。\n- \"Terminating\"：由于到期等系统原因或手动终止，任务当前处于取消中状态。\n- \"Terminated\"：任务已被终止。\n-  \"Completed\"：任务已完成，所有请求已经处理完毕，任务已完成。\n- \"Failed\"：输入文件校验失败或其他原因导致任务失败。"} />,
          children: [
          ]
        },
    ]
  },
  {
    rowKey: "->ModelReference",
    Name: "ModelReference",
    DataType: "Object",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务选中的模型"} />,
    children: [
        {
          rowKey: "->ModelReference->CustomModelId",
          Name: "CustomModelId",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"定制模型的ID"} />,
          children: [
          ]
        },
        {
          rowKey: "->ModelReference->FoundationModel",
          Name: "FoundationModel",
          DataType: "Object",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"基础模型"} />,
          children: [
            {
              rowKey: "->ModelReference->FoundationModel->Name",
              Name: "Name",
              DataType: 'String',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"基础模型名称。\n- 请注意模型名称为小写。\n- doubao 1.5 代模型的模型名称格式为 \"doubao-1-5-\\*\\*\"。\n举例： \"Doubao-1.5-pro-32k\" 模型Name字段为 \"doubao-1-5-pro-32k\"。"} />,
              children: [
              ]
            },
            {
              rowKey: "->ModelReference->FoundationModel->ModelVersion",
              Name: "ModelVersion",
              DataType: 'String',
              Example: <RenderMd content={""} />,
              Description: <RenderMd content={"基础模型版本"} />,
              children: [
              ]
            },
          ]
        },
    ]
  },
  {
    rowKey: "->RequestCounts",
    Name: "RequestCounts",
    DataType: "Object",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务的request数量"} />,
    children: [
        {
          rowKey: "->RequestCounts->Total",
          Name: "Total",
          DataType: "Long",
          Example: <RenderMd content={"\\-"} />,
          Description: <RenderMd content={"所有request数量"} />,
          children: [
          ]
        },
        {
          rowKey: "->RequestCounts->Completed",
          Name: "Completed",
          DataType: "Long",
          Example: <RenderMd content={"\\-"} />,
          Description: <RenderMd content={"完成的request数量"} />,
          children: [
          ]
        },
        {
          rowKey: "->RequestCounts->Failed",
          Name: "Failed",
          DataType: "Long",
          Example: <RenderMd content={"\\-"} />,
          Description: <RenderMd content={"失败的request数量"} />,
          children: [
          ]
        },
    ]
  },
  {
    rowKey: "->Tags",
    Name: "Tags",
    DataType: "Array of Object",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务绑定的标签"} />,
    children: [
        {
          rowKey: "->Tags->Key",
          Name: "Key",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"标签键"} />,
          children: [
          ]
        },
        {
          rowKey: "->Tags->Value",
          Name: "Value",
          DataType: "String",
          Example: <RenderMd content={""} />,
          Description: <RenderMd content={"标签值"} />,
          children: [
          ]
        },
    ]
  },
  {
    rowKey: "->ProjectName",
    Name: "ProjectName",
    DataType: "String",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"资源所属的项目名称"} />,
    children: [
    ]
  },
  {
    rowKey: "->CreateTime",
    Name: "CreateTime",
    DataType: "String",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务创建时间，RFC3339格式"} />,
    children: [
    ]
  },
  {
    rowKey: "->UpdateTime",
    Name: "UpdateTime",
    DataType: "String",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务更新时间，RFC3339格式"} />,
    children: [
    ]
  },
  {
    rowKey: "->ExpireTime",
    Name: "ExpireTime",
    DataType: "String",
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务到期时间，RFC3339格式"} />,
    children: [
    ]
  },
];

return (<Table
  rowKey="rowKey"
  className="openapi-doc-parameter-table"
  columns={columns}
  data={data}
  border={ { cell: true, wrapper: true } }
  scroll={ { x: "auto" } }
  pagination={false}
/>);
```

## 请求示例 
```text
{
    "Id": "7WtYtkPG9x"
}
```
## 返回示例 
```json
{
    "ResponseMetadata": {
        "RequestId": "2024091910512025A35A851624E4541879",
        "Action": "GetBatchInferenceJob",
        "Version": "2024-01-01",
        "Service": "ark",
        "Region": "cn-beijing"
    },
    "Result": {
        "Id": "bi-20240918194641-r2nwq",
        "Name": "批量推理任务",
        "Description": "这是一个批量推理任务",
        "InputFileTosLocation": {
            "BucketName": "my-bucket-name",
            "ObjectKey": "batch-inference-job/dataset/my-job.jsonl"
        },
        "OutputDirTosLocation": {
            "BucketName": "my-bucket-name",
            "ObjectKey": "batch-inference-job/output/"
        },
        "CompletionWindow": "1d",
        "Status": {
            "Phase": "Completed",
            "PhaseTime": "2024-09-18T11:50:00Z",
            "Message": "批量推理任务已完成"
        },
        "ModelReference": {
            "FoundationModel": {
                "Name": "doubao-pro-32k",
                "ModelVersion": "240615"
            }
        },
        "RequestCounts": {
            "Total": 2,
            "Completed": 2,
            "Failed": 0
        },
        "Tags": [
            {
                "Key": "sys:ark:createdBy",
                "Value": "IAMUser/30805480/test@bytedance.com"
            },
            {
                "Key": "test_key",
                "Value": "test_value"
            }
        ],
        "ProjectName": "default",
        "CreateTime": "2024-09-18T11:46:41Z",
        "UpdateTime": "2024-09-18T11:50:00Z",
        "ExpireTime": "2024-09-19T11:46:41Z"
    }
}
```


## 错误码
您可访问[公共错误码](https://www.volcengine.com/docs/82379/1299023)，获取更多错误码信息。



<style>
.volc-md-viewer .arco-table-th {
	min-width: 100px;
}
.volc-md-viewer .openapi-doc-parameter-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errorcode {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errormessage {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:first-child .arco-table-cell {
  display: flex;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:nth-child(2) .arco-table-cell {
  word-break: normal;
}
</style>


# UpdateBatchInferenceJob - 更新批量推理任务
Source: https://www.volcengine.com/docs/82379/1339610
更新批量推理任务1





## 调试
<APILink link="https://api.volcengine.com/api-explorer/?action=UpdateBatchInferenceJob&groupName=%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86%E4%BB%BB%E5%8A%A1%20API&serviceCode=ark&version=2024-01-01"></APILink>

## 请求参数

下表仅列出该接口特有的请求参数和部分公共参数。更多信息请见[公共参数](https://www.volcengine.com/docs/6369/67268)。



```mixin-react
const columns = [
  {
    width: '20%',
    title: '参数',
    dataIndex: 'Name',
    className: 'openapi-doc-parameter-table-name'
  },
  {
    width: 130,
    title: '类型',
    dataIndex: 'DataType',
    className: 'openapi-doc-parameter-table-type'
  },
  {
    width: 90,
    title: '是否必填',
    dataIndex: 'IsRequired',
    className: 'openapi-doc-parameter-table-required'
  },
  {
    width: '20%',
    title: '示例值',
    dataIndex: 'Example',
    className: 'openapi-doc-parameter-table-example'
  },
  {
    title: '描述',
    dataIndex: 'Description',
    className: 'openapi-doc-parameter-table-description'
  },
];

const data = [
  {
    rowKey: '->Action',
    Name: 'Action',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"UpdateBatchInferenceJob"} />,
    Description: <RenderMd content={"要执行的操作，取值：UpdateBatchInferenceJob。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Version',
    Name: 'Version',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"2024-01-01"} />,
    Description: <RenderMd content={"API的版本，取值：2024-01-01。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Name',
    Name: 'Name',
    DataType: 'String',
    IsRequired: '否',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务名称"} />,
    children: [
    ]
  },
  {
    rowKey: '->Description',
    Name: 'Description',
    DataType: 'String',
    IsRequired: '否',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量任务描述"} />,
    children: [
    ]
  },
  {
    rowKey: '->DryRun',
    Name: 'DryRun',
    DataType: 'Boolean',
    IsRequired: '否',
    Example: <RenderMd content={"true"} />,
    Description: <RenderMd content={"是否仅对此请求进行预检。取值： - true：发送检查请求。 - false(默认)：发送正常请求"} />,
    children: [
    ]
  },
  {
    rowKey: '->Id',
    Name: 'Id',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"\\-"} />,
    Description: <RenderMd content={"批量推理任务的ID"} />,
    children: [
    ]
  },

];

return (<Table
  rowKey="rowKey"
  className="openapi-doc-parameter-table"
  columns={columns}
  data={data}
  border={ { cell: true, wrapper: true } }
  scroll={ { x: "auto" } }
  pagination={false}
/>);
```

## 返回参数



本接口无特有的返回参数。更多信息请见[返回结构](https://www.volcengine.com/docs/6369/80336)。


## 请求示例 
```text
{
    "Id": "jTcq2HdZCY",
    "Name": "2izb27TqbM",
    "Description": "lup3fM4Mu5",
    "DryRun": true
}
```
## 返回示例 
```json
{
  "ResponseMetadata": {
    "RequestId": "20241101204820216194191074D4638D",
    "Action": "UpdateBatchInferenceJob",
    "Version": "2024-01-01",
    "Service": "ark",
    "Region": "cn-beijing"
  },
  "Result": {}
}
```


## 错误码
您可访问[公共错误码](https://www.volcengine.com/docs/82379/1299023)，获取更多错误码信息。



<style>
.volc-md-viewer .arco-table-th {
	min-width: 100px;
}
.volc-md-viewer .openapi-doc-parameter-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errorcode {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errormessage {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:first-child .arco-table-cell {
  display: flex;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:nth-child(2) .arco-table-cell {
  word-break: normal;
}
</style>


# DeleteBatchInferenceJob - 删除批量推理任务
Source: https://www.volcengine.com/docs/82379/1339613
删除批量推理任务





## 调试
<APILink link="https://api.volcengine.com/api-explorer/?action=DeleteBatchInferenceJob&groupName=%E7%AE%A1%E7%90%86%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86%E4%BB%BB%E5%8A%A1&serviceCode=ark&version=2024-01-01"></APILink>

## 请求参数

下表仅列出该接口特有的请求参数和部分公共参数。更多信息请见[公共参数](https://www.volcengine.com/docs/6369/67268)。



```mixin-react
const columns = [
  {
    width: '20%',
    title: '参数',
    dataIndex: 'Name',
    className: 'openapi-doc-parameter-table-name'
  },
  {
    width: 130,
    title: '类型',
    dataIndex: 'DataType',
    className: 'openapi-doc-parameter-table-type'
  },
  {
    width: 90,
    title: '是否必填',
    dataIndex: 'IsRequired',
    className: 'openapi-doc-parameter-table-required'
  },
  {
    width: '20%',
    title: '示例值',
    dataIndex: 'Example',
    className: 'openapi-doc-parameter-table-example'
  },
  {
    title: '描述',
    dataIndex: 'Description',
    className: 'openapi-doc-parameter-table-description'
  },
];

const data = [
  {
    rowKey: '->Action',
    Name: 'Action',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"DeleteBatchInferenceJob"} />,
    Description: <RenderMd content={"要执行的操作，取值：DeleteBatchInferenceJob。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Version',
    Name: 'Version',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"2024-01-01"} />,
    Description: <RenderMd content={"API的版本，取值：2024-01-01。"} />,
    children: [
    ]
  },
  {
    rowKey: '->DryRun',
    Name: 'DryRun',
    DataType: 'Boolean',
    IsRequired: '否',
    Example: <RenderMd content={"true"} />,
    Description: <RenderMd content={"是否仅对此请求进行预检。取值： - true：发送检查请求。 - false(默认)：发送正常请求"} />,
    children: [
    ]
  },
  {
    rowKey: '->Id',
    Name: 'Id',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"bi-20240**-7q**"} />,
    Description: <RenderMd content={"批量推理任务的ID"} />,
    children: [
    ]
  },

];

return (<Table
  rowKey="rowKey"
  className="openapi-doc-parameter-table"
  columns={columns}
  data={data}
  border={ { cell: true, wrapper: true } }
  scroll={ { x: "auto" } }
  pagination={false}
/>);
```

## 返回参数



本接口无特有的返回参数。更多信息请见[返回结构](https://www.volcengine.com/docs/6369/80336)。


## 请求示例 
```text
POST /?Action=DeleteBatchInferenceJob&Version=2024-01-01 HTTP/1.1
Host: ark.cn-beijing.volcengineapi.com
Content-Type: application/json; charset=UTF-8
X-Date: 20250115T094923Z
X-Content-Sha256: 287e874e******d653b44d21e
Authorization: HMAC-SHA256 Credential=Adfks******wekfwe/20250115/cn-beijing/ark/request, SignedHeaders=host;x-content-sha256;x-date, Signature=47a7d934ff7b37c03938******cd7b8278a40a1057690c401e92246a0e41085f

{
  "DryRun": true,
  "Id": "bi-20240**-7q**"
}
```
## 返回示例 
```json
{
  "ResponseMetadata": {
    "RequestId": "20250115174930217216139059A62D03",
    "Action": "DeleteBatchInferenceJob",
    "Version": "2024-01-01",
    "Service": "ark",
    "Region": "cn-beijing"
  },
  "Result": {}
}
```


## 错误码
您可访问[公共错误码](https://www.volcengine.com/docs/82379/1299023)，获取更多错误码信息。



<style>
.volc-md-viewer .arco-table-th {
	min-width: 100px;
}
.volc-md-viewer .openapi-doc-parameter-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errorcode {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errormessage {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:first-child .arco-table-cell {
  display: flex;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:nth-child(2) .arco-table-cell {
  word-break: normal;
}
</style>


# StopBatchInferenceJob - 停止批量推理任务
Source: https://www.volcengine.com/docs/82379/1339616
停止批量推理任务1





## 调试
<APILink link="https://api.volcengine.com/api-explorer/?action=StopBatchInferenceJob&groupName=%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86%E4%BB%BB%E5%8A%A1%20API&serviceCode=ark&version=2024-01-01"></APILink>

## 请求参数

下表仅列出该接口特有的请求参数和部分公共参数。更多信息请见[公共参数](https://www.volcengine.com/docs/6369/67268)。



```mixin-react
const columns = [
  {
    width: '20%',
    title: '参数',
    dataIndex: 'Name',
    className: 'openapi-doc-parameter-table-name'
  },
  {
    width: 130,
    title: '类型',
    dataIndex: 'DataType',
    className: 'openapi-doc-parameter-table-type'
  },
  {
    width: 90,
    title: '是否必填',
    dataIndex: 'IsRequired',
    className: 'openapi-doc-parameter-table-required'
  },
  {
    width: '20%',
    title: '示例值',
    dataIndex: 'Example',
    className: 'openapi-doc-parameter-table-example'
  },
  {
    title: '描述',
    dataIndex: 'Description',
    className: 'openapi-doc-parameter-table-description'
  },
];

const data = [
  {
    rowKey: '->Action',
    Name: 'Action',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"StopBatchInferenceJob"} />,
    Description: <RenderMd content={"要执行的操作，取值：StopBatchInferenceJob。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Version',
    Name: 'Version',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"2024-01-01"} />,
    Description: <RenderMd content={"API的版本，取值：2024-01-01。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Id',
    Name: 'Id',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"bi-202409181****-r2***"} />,
    Description: <RenderMd content={"批量推理任务的ID"} />,
    children: [
    ]
  },
  {
    rowKey: '->DryRun',
    Name: 'DryRun',
    DataType: 'Boolean',
    IsRequired: '否',
    Example: <RenderMd content={"false"} />,
    Description: <RenderMd content={"是否仅对此请求进行预检。<br>\n取值：\n- true：发送检查请求。\n- false(默认)：发送正常请求。"} />,
    children: [
    ]
  },

];

return (<Table
  rowKey="rowKey"
  className="openapi-doc-parameter-table"
  columns={columns}
  data={data}
  border={ { cell: true, wrapper: true } }
  scroll={ { x: "auto" } }
  pagination={false}
/>);
```

## 返回参数



本接口无特有的返回参数。更多信息请见[返回结构](https://www.volcengine.com/docs/6369/80336)。


## 请求示例 
```text
POST /?Action=StopBatchInferenceJob&Version=2024-01-01 HTTP/1.1
Host: ark.cn-beijing.volcengineapi.com
Content-Type: application/json; charset=UTF-8
X-Date: 20241101T132518Z
X-Content-Sha256: 287e874e******d653b44d21e
Authorization: HMAC-SHA256 Credential=Adfks******wekfwe/20241101/cn-beijing/ark/request, SignedHeaders=host;x-content-sha256;x-date, Signature=47a7d934ff7b37c03938******cd7b8278a40a1057690c401e92246a0e41085f

{
  "Id": "WT8B0KFw"
}
```
## 返回示例 
```json
{
  "ResponseMetadata": {
    "RequestId": "202411012125322342121442116F88A9",
    "Action": "StopBatchInferenceJob",
    "Version": "2024-01-01",
    "Service": "ark",
    "Region": "cn-beijing"
  },
  "Result": {}
}
```


## 错误码
您可访问[公共错误码](https://www.volcengine.com/docs/82379/1299023)，获取更多错误码信息。



<style>
.volc-md-viewer .arco-table-th {
	min-width: 100px;
}
.volc-md-viewer .openapi-doc-parameter-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errorcode {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errormessage {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:first-child .arco-table-cell {
  display: flex;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:nth-child(2) .arco-table-cell {
  word-break: normal;
}
</style>


# ResumeBatchInferenceJob - 重启批量推理任务
Source: https://www.volcengine.com/docs/82379/1433715
重启批量推理任务





## 调试
<APILink link="https://api.volcengine.com/api-explorer/?action=ResumeBatchInferenceJob&groupName=%E7%AE%A1%E7%90%86%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86%E4%BB%BB%E5%8A%A1&serviceCode=ark&version=2024-01-01"></APILink>

## 请求参数

下表仅列出该接口特有的请求参数和部分公共参数。更多信息请见[公共参数](https://www.volcengine.com/docs/6369/67268)。



```mixin-react
const columns = [
  {
    width: '20%',
    title: '参数',
    dataIndex: 'Name',
    className: 'openapi-doc-parameter-table-name'
  },
  {
    width: 130,
    title: '类型',
    dataIndex: 'DataType',
    className: 'openapi-doc-parameter-table-type'
  },
  {
    width: 90,
    title: '是否必填',
    dataIndex: 'IsRequired',
    className: 'openapi-doc-parameter-table-required'
  },
  {
    width: '20%',
    title: '示例值',
    dataIndex: 'Example',
    className: 'openapi-doc-parameter-table-example'
  },
  {
    title: '描述',
    dataIndex: 'Description',
    className: 'openapi-doc-parameter-table-description'
  },
];

const data = [
  {
    rowKey: '->Action',
    Name: 'Action',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"ResumeBatchInferenceJob"} />,
    Description: <RenderMd content={"要执行的操作，取值：ResumeBatchInferenceJob。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Version',
    Name: 'Version',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"2024-01-01"} />,
    Description: <RenderMd content={"API的版本，取值：2024-01-01。"} />,
    children: [
    ]
  },
  {
    rowKey: '->Id',
    Name: 'Id',
    DataType: 'String',
    IsRequired: '是',
    Example: <RenderMd content={"bi-2024**-**"} />,
    Description: <RenderMd content={"批量推理任务 id\n"} />,
    children: [
    ]
  },

];

return (<Table
  rowKey="rowKey"
  className="openapi-doc-parameter-table"
  columns={columns}
  data={data}
  border={ { cell: true, wrapper: true } }
  scroll={ { x: "auto" } }
  pagination={false}
/>);
```

## 返回参数


下表仅列出本接口特有的返回参数。更多信息请参见[返回结构](https://www.volcengine.com/docs/6369/80336)。


```mixin-react
const columns = [
  {
    width: '25%',
    title: '参数',
    dataIndex: 'Name',
    className: 'openapi-doc-parameter-table-name',
  },
  {
    width: 130,
    title: '类型',
    dataIndex: 'DataType',
    className: 'openapi-doc-parameter-table-type'
  },
  {
    width: '25%',
    title: '示例值',
    dataIndex: 'Example',
    className: 'openapi-doc-parameter-table-example'
  },
  {
    title: '描述',
    dataIndex: 'Description',
    className: 'openapi-doc-parameter-table-description'
  },
];

const data = [
  {
    rowKey: "->Id",
    Name: "Id",
    DataType: "String",
    Example: <RenderMd content={"bi-2024**-**"} />,
    Description: <RenderMd content={"批量推理任务 id"} />,
    children: [
    ]
  },
];

return (<Table
  rowKey="rowKey"
  className="openapi-doc-parameter-table"
  columns={columns}
  data={data}
  border={ { cell: true, wrapper: true } }
  scroll={ { x: "auto" } }
  pagination={false}
/>);
```

## 请求示例 
```text
POST /?Action=ResumeBatchInferenceJob&Version=2024-01-01&Id=bi-2024**-** HTTP/1.1
Host: ark.cn-beijing.volcengineapi.com
Content-Type: application/json; charset=UTF-8
X-Date: 20250115T094652Z
X-Content-Sha256: 287e874e******d653b44d21e
Authorization: HMAC-SHA256 Credential=Adfks******wekfwe/20250115/cn-beijing/ark/request, SignedHeaders=host;x-content-sha256;x-date, Signature=47a7d934ff7b37c03938******cd7b8278a40a1057690c401e92246a0e41085f

{}
```
## 返回示例 
```json
{
  "ResponseMetadata": {
    "RequestId": "202501151747141031441900110C4B1C",
    "Action": "ResumeBatchInferenceJob",
    "Version": "2024-01-01",
    "Service": "ark",
    "Region": "cn-beijing"
  },
  "Result": {
    "Id": "bi-2024**-**"
  }
}
```


## 错误码
您可访问[公共错误码](https://www.volcengine.com/docs/82379/1299023)，获取更多错误码信息。



<style>
.volc-md-viewer .arco-table-th {
	min-width: 100px;
}
.volc-md-viewer .openapi-doc-parameter-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errorcode {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-errormessage {
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-errorcode-table-description{
  min-width: 150px;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:first-child .arco-table-cell {
  display: flex;
}
.volc-md-viewer .openapi-doc-parameter-table .arco-table-tr>.arco-table-td:nth-child(2) .arco-table-cell {
  word-break: normal;
}
</style>


# 深度思考
Source: https://www.volcengine.com/docs/82379/1449737
您可以使用具备深度思考能力的模型，如 deepseek r1、doubao thinking 系列模型，来提升最终答案的准确性。模型在回答问题前，会对问题进行分析和拆解，并基于对问题的拆解回答问题，回答会更加全面和深入。当您向模型提问时，方舟返回模型回答问题前的问题思考逻辑（思维链内容），基于此可观察模型推导过程并使用这部分信息。

> * 查看 [对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)，检索 API 字段参数说明。
> * 查看[三方工具调用说明](https://www.volcengine.com/docs/82379/1463945)，了解第三方工具调用模型的支持情况。

<span id="5f0f3750"></span>
# 支持模型
当前支持深度思考的模型请参见 [深度思考](https://www.volcengine.com/docs/82379/1330310#898d064d)。
> 详细了解计费以及下面长度限制规格的关系，可以阅读 [附2-工作原理](https://www.volcengine.com/docs/82379/1449737#a3986ddb)。

<span id="2ce4ac9b"></span>
# 前提条件
* [获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) 。
   * 使用 Access Key 鉴权请参考[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
* [开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需 Model ID 。
   * 通过 Endpoint ID 调用模型服务请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。



<span id="18cf565a"></span>
# 快速开始
快速调用深度思考模型。
> 其中注意使用下面命令将API Key配置为环境变量`ARK_API_KEY`。
> `export ARK_API_KEY="<ARK_API_KEY>"`


```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="N8MZWGgTL8"><RenderMd content={`\`\`\`Shell
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer \$ARK_API_KEY" \\
  -d '{ 
    "model": "doubao-seed-1-6-250615",
    "messages": [
        {
            "role": "user",
            "content": "我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性"
        }
    ]
  }'
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="FIOrLxCR5A"><RenderMd content={`\`\`\`Python
import os
# 升级方舟 SDK 到最新版本 pip install -U 'volcengine-python-sdk[ark]'
from volcenginesdkarkruntime import Ark

client = Ark(
    # 从环境变量中读取您的方舟API Key
    api_key=os.environ.get("ARK_API_KEY"), 
    # 深度思考模型耗费时间会较长，请您设置较大的超时时间，避免超时，推荐30分钟以上
    timeout=1800,
    )
response = client.chat.completions.create(
    # 替换 <MODEL> 为Model ID
    model="deepseek-r1-250528",
    messages=[
        {"role": "user", "content": "我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性"}
    ]
)
# 当触发深度思考时，打印思维链内容
if hasattr(response.choices[0].message, 'reasoning_content'):
    print(response.choices[0].message.reasoning_content)
print(response.choices[0].message.content)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="xNPnoZjmch"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "os"
    "time"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
        //通过 os.Getenv 从环境变量中获取 ARK_API_KEY
        os.Getenv("ARK_API_KEY"),
        //深度思考模型耗费时间会较长，请您设置较大的超时时间，避免超时导致任务失败。推荐30分钟以上
        arkruntime.WithTimeout(30*time.Minute),
    )
    // 创建一个上下文，通常用于传递请求的上下文信息，如超时、取消等
    ctx := context.Background()
    // 构建聊天完成请求，设置请求的模型和消息内容
    req := model.ChatCompletionRequest{
        // 需要替换 <MODEL> 为模型的Model ID
        Model: "doubao-seed-1-6-250615",
        Messages: []*model.ChatCompletionMessage{
            {
                // 消息的角色为用户
                Role: model.ChatMessageRoleUser,
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性"),
                },
            },
        },
    }

    // 发送聊天完成请求，并将结果存储在 resp 中，将可能出现的错误存储在 err 中
    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
        // 若出现错误，打印错误信息并终止程序
        fmt.Printf("standard chat error: %v\\n", err)
        return
    }
    // 检查是否触发深度思考，触发则打印思维链内容
    if resp.Choices[0].Message.ReasoningContent != nil {
        fmt.Println(*resp.Choices[0].Message.ReasoningContent)
    }
    // 打印聊天完成请求的响应结果
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="OpenAI Python SDK" key="SnPxve6s2V"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

client = OpenAI(
    # 从环境变量中读取您的方舟API Key
    api_key=os.environ.get("ARK_API_KEY"), 
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 深度思考模型耗费时间会较长，建议您设置一个较长的超时时间，推荐为30分钟
    timeout=1800,
    )
response = client.chat.completions.create(
    # 替换 <MODEL> 为 Model ID
    model="doubao-seed-1-6-250615",
    messages=[
        {"role": "user", "content": "我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性"}
    ]
)
# 当触发深度思考时，打印思维链内容
if hasattr(response.choices[0].message, 'reasoning_content'):
    print(response.choices[0].message.reasoning_content)
print(response.choices[0].message.content)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="DqLCwkL8ku"><RenderMd content={`\`\`\`Java
package com.example;

import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;

import java.time.Duration;
import java.util.ArrayList;
import java.util.List;

/**
 * 这是一个示例类，展示了如何使用ArkService来完成聊天功能。
 */
public class ChatCompletionsExample {
    public static void main(String[] args) {
        // 从环境变量中获取API密钥
        String apiKey = System.getenv("ARK_API_KEY");
        // 创建ArkService实例
        ArkService arkService = ArkService.builder().apiKey(apiKey)
                .timeout(Duration.ofMinutes(30))// 深度思考模型耗费时间会较长，请您设置较大的超时时间，避免超时导致任务失败。推荐30分钟以上
                .build();
        // 初始化消息列表
        List<ChatMessage> chatMessages = new ArrayList<>();
        // 创建用户消息
        ChatMessage userMessage = ChatMessage.builder()
                .role(ChatMessageRole.USER) // 设置消息角色为用户
                .content("我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性") // 设置消息内容
                .build();
        // 将用户消息添加到消息列表
        chatMessages.add(userMessage);
        // 创建聊天完成请求
        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                .model("doubao-seed-1-6-250615")
                .messages(chatMessages) // 设置消息列表
                .build();
        // 发送聊天完成请求并打印响应
        try {
            // 获取响应并打印每个选择的消息内容
            arkService.createChatCompletion(chatCompletionRequest)
                    .getChoices()
                    .forEach(choice -> {                    
                        // 校验是否触发了深度思考，打印思维链内容
                        if (choice.getMessage().getReasoningContent() != null) {
                            System.out.println("推理内容: " + choice.getMessage().getReasoningContent());
                        }
                        // 打印消息内容
                        System.out.println("消息内容: " + choice.getMessage().getContent());
                    });
        } catch (Exception e) {
            System.out.println("请求失败: " + e.getMessage());
        } finally {
            // 关闭服务执行器
            arkService.shutdownExecutor();
        }
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="c92eb9dc"></span>
# 使用说明
详细 API 字段说明请参见 [对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。
<span id="219aa2c7"></span>
## 减少请求超时失败
您可以使用流式输出或者设置更长超时时间，来减少因为超时导致任务失败的情况。
:::tip
深度思考模型使用思维链输出内容，导致回复篇幅更长、速率更慢，所以极易因超时导致任务失败。尤其在非流式输出模式下，任务未完成时断开连接，未输出内容，又产生 token 用量费用。
:::
为避免任务超时的失败，有下面两种方式：

* 配置更大的超时时间。特别是非流式输出模型，超时时间`timeout`推荐设置30分钟以上，您可以观察任务超时触发概率，来进一步调节超时时间。此外，为避免网络中断，还请注意网络链路中的 TCP keep-alive 设置，确保网络连接的稳定性。
* 推荐使用流式输出。流式输出是一种高效且可靠的方式。您可参考示例代码 [流式输出](https://www.volcengine.com/docs/82379/1449737#4ad2b076)来实现流式调用。同时，建议您避免将应用的输出方式与方舟的输出方式绑定。例如，若您的应用原本处于非流式输出场景，您可先以流式输出方式获取完整内容，再一次性输出，这样既能避免任务超时失败，又能满足应用的输出需求。

> 使用方舟Go SDK时，不管是否使用流式输出，都请将超时时间设置为30分钟以上。

<span id="12afb6c0"></span>
## 使用批量推理获得更高吞吐
当您的业务需要处理大量的数据，且对于模型返回及时性要求不高，您可使用批量推理获取最低 10B token/天 的配额以及批量推理的成本降低。批量推理支持任务的方式以及类似 Chat 的接口调用方式，使用批量推理，详细说明请查看[批量推理](https://www.volcengine.com/docs/82379/1399517)。
<span id="ada69f7e"></span>
## 提示词优化建议
深度思考模型会自行分析和拆解问题（思维链），与普通模型相比，提示词侧重点有所不同。

* 提示词除了待解决问题，应该更多补充目标和场景等信息。如使用英语，用Python等语言要求；面向小学生、向领导汇报等阅读对象信息；完成论文写作、完成课题报告、撰写剧本等场景信息；体现我的专业性、获得领导赏识等目标信息。
* 减少或者避免对问题的拆解描述，如分步骤思考、使用示例等，这样会限制住模型的推理逻辑。
* 减少使用系统提示词，所有提示词信息直接通过用户提示词（`role: user`）来提问。
* 当碰到 deepseek r1 模型跳过思考过程，可以在你的提示词前添加下面的内容来输出思维链内容：

```Plain Text
任何输出都要有思考过程，输出内容必须以 "<think>\n\n嗯" 开头。仔细揣摩用户意图，在思考过程之后，提供逻辑清晰且内容完整的回答，可以使用Markdown格式优化信息呈现。\n\n
{你的问题}
```

<span id="7cf8f2eb"></span>
# 更多示例
<span id="a8bcbf39"></span>
## 单轮对话
见[快速开始](https://www.volcengine.com/docs/82379/1449737#18cf565a)。
<span id="774e488d"></span>
## 多轮对话
组合使用系统消息、模型消息以及用户消息，可以实现多轮对话，即根据一个主题进行多次对话。
:::tip
“reasoning_content”是模型的输出字段，不应作为输入。如果在输入的 messages 序列中包含此字段，API 将返回 400 错误。进行多轮对话时，应只保留 role 和 content 字段。可参考下例，删除`reasoning_content`字段内容，详细见[附2-工作原理](https://www.volcengine.com/docs/82379/1449737#a3986ddb)。
:::

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="Or4DxABn0V"><RenderMd content={`\`\`\`Shell
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer \$ARK_API_KEY" \\
  -d '{ 
    "model": "<MODEL>",
    "messages": [
        {"role": "user", "content": "深度思考模型与非深度思考模型区别"},
        {"role": "assistant", "content": "推理模型主要依靠逻辑、规则或概率等进行分析、推导和判断以得出结论或决策，非推理模型则是通过模式识别、统计分析或模拟等方式来实现数据描述、分类、聚类或生成等任务而不依赖显式逻辑推理。"},
        {"role": "user", "content": "我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性"}
    ]
  }'
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="fBDfOqW70k"><RenderMd content={`\`\`\`Python
import os
# 升级方舟 SDK 到最新版本 pip install -U 'volcengine-python-sdk[ark]'
from volcenginesdkarkruntime import Ark

client = Ark(
    # 从环境变量中读取您的方舟API Key
    api_key=os.environ.get("ARK_API_KEY"), 
    # 深度思考模型耗费时间会较长，建议您设置一个较长的超时时间，推荐为30分钟
    timeout=1800,
    )
response = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID
    model="<MODEL>",
    messages=[
        {"role": "user", "content": "研究深度思考模型与非深度思考模型区别"},
        {"role": "assistant", "content": "推理模型主要依靠逻辑、规则或概率等进行分析、推导和判断以得出结论或决策，非推理模型则是通过模式识别、统计分析或模拟等方式来实现数据描述、分类、聚类或生成等任务而不依赖显式逻辑推理。"},
        {"role": "user", "content": "我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性"},
    ],
)

if hasattr(response.choices[0].message, 'reasoning_content'):
    print(response.choices[0].message.reasoning_content)
print(response.choices[0].message.content)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="OpenAI Python SDK" key="M0YG4bisIb"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

client = OpenAI(
    # 从环境变量中读取您的方舟API Key
    api_key=os.environ.get("ARK_API_KEY"), 
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 深度思考模型耗费时间会较长，建议您设置一个较长的超时时间，推荐为30分钟
    timeout=1800,
    )
response = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID
    model="<MODEL>",
    messages=[
        {"role": "user", "content": "研究深度思考模型与非深度思考模型区别"},
        {"role": "assistant", "content": "推理模型主要依靠逻辑、规则或概率等进行分析、推导和判断以得出结论或决策，非推理模型则是通过模式识别、统计分析或模拟等方式来实现数据描述、分类、聚类或生成等任务而不依赖显式逻辑推理。"},
        {"role": "user", "content": "我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性"},
    ],
)

if hasattr(response.choices[0].message, 'reasoning_content'):
    print(response.choices[0].message.reasoning_content)
print(response.choices[0].message.content)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="ezsJfbKQ2Q"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "os"
    "time"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
        //通过 os.Getenv 从环境变量中获取 ARK_API_KEY
        os.Getenv("ARK_API_KEY"),
        //深度思考模型耗费时间会较长，请您设置较大的超时时间，避免超时导致任务失败。推荐30分钟以上
        arkruntime.WithTimeout(30*time.Minute),
    )
    // 创建一个上下文，通常用于传递请求的上下文信息，如超时、取消等
    ctx := context.Background()
    // 构建聊天完成请求，设置请求的模型和消息内容
    req := model.ChatCompletionRequest{
        // 需要替换 <MODEL> 为模型的Model ID
        Model: "<MODEL>",
        Messages: []*model.ChatCompletionMessage{
            {
                // 消息的角色为用户
                Role: model.ChatMessageRoleUser,
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("研究深度思考模型与非深度思考模型区别"),
                },
            },
            {
                // 消息的角色为模型
                Role: model.ChatMessageRoleAssistant,
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("推理模型主要依靠逻辑、规则或概率等进行分析、推导和判断以得出结论或决策，非推理模型则是通过模式识别、统计分析或模拟等方式来实现数据描述、分类、聚类或生成等任务而不依赖显式逻辑推理。"),
                },
            },
            {
                // 消息的角色为用户
                Role: model.ChatMessageRoleUser,
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性"),
                },
            },
        },
    }

    // 发送聊天完成请求，并将结果存储在 resp 中，将可能出现的错误存储在 err 中
    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
        // 若出现错误，打印错误信息并终止程序
        fmt.Printf("standard chat error: %v\\n", err)
        return
    }
    // 检查是否触发深度思考，触发则打印思维链内容
    if resp.Choices[0].Message.ReasoningContent != nil {
        fmt.Println(*resp.Choices[0].Message.ReasoningContent)
    }
    // 打印聊天完成请求的响应结果
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="S9KLrL4bIt"><RenderMd content={`\`\`\`Java
package com.example;

import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;

import java.time.Duration;
import java.util.Arrays;
import java.util.List;

/**
 * 这是一个示例类，展示了如何使用ArkService来完成聊天功能。
 */
public class ChatCompletionsExample {
    public static void main(String[] args) {
        // 从环境变量中获取API密钥
        String apiKey = System.getenv("ARK_API_KEY");
        // 创建ArkService实例
        ArkService arkService = ArkService.builder().apiKey(apiKey)
                .timeout(Duration.ofMinutes(30))// 深度思考模型耗费时间会较长，请您设置较大的超时时间，避免超时导致任务失败。推荐30分钟以上
                .build();
        // 多轮消息列表
        final List<ChatMessage> messages = Arrays.asList(
            ChatMessage.builder().role(ChatMessageRole.USER).content("研究深度思考模型与非深度思考模型区别").build(),
            ChatMessage.builder().role(ChatMessageRole.ASSISTANT).content("推理模型主要依靠逻辑、规则或概率等进行分析、推导和判断以得出结论或决策，非推理模型则是通过模式识别、统计分析或模拟等方式来实现数据描述、分类、聚类或生成等任务而不依赖显式逻辑推理。").build(),
            ChatMessage.builder().role(ChatMessageRole.USER).content("我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性").build()
        );
        // 创建聊天完成请求
        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                .model("<MODEL>")// 需要替换为模型的Model ID
                .messages(messages) // 设置消息列表
                .build();
        // 发送聊天完成请求并打印响应
        try {
            // 获取响应并打印每个选择的消息内容
            arkService.createChatCompletion(chatCompletionRequest)
                    .getChoices()
                    .forEach(choice -> {
                        // 进行空值检查后打印推理内容
                        if (choice.getMessage().getReasoningContent() != null) {
                            System.out.println("推理内容: " + choice.getMessage().getReasoningContent());
                        } else {
                            System.out.println("推理内容为空");
                        }
                        // 打印消息内容
                        System.out.println("消息内容: " + choice.getMessage().getContent());
                    });
        } catch (Exception e) {
            System.out.println("请求失败: " + e.getMessage());
        } finally {
            // 关闭服务执行器
            arkService.shutdownExecutor();
        }
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="4ad2b076"></span>
## 流式输出
随着大模型输出，动态输出内容。无需等待模型推理完毕，即可看到中间输出过程内容，可以改善用户的等待体验（一边输出一边看内容），效果如下所示。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="KDkZE8joOG"><RenderMd content={`\`\`\`Shell
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer \$ARK_API_KEY" \\
  -d '{ 
    "model": "<MODEL>",
    "messages": [
        {"role": "user", "content": "深度思考模型与非深度思考模型区别"}
    ],
    "stream": true
  }'
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="ak3PS9jFAM"><RenderMd content={`\`\`\`Python
import os
# 升级方舟 SDK 到最新版本 pip install -U 'volcengine-python-sdk[ark]'
from volcenginesdkarkruntime import Ark

client = Ark(
    # 从环境变量中读取您的方舟API Key
    api_key=os.environ.get("ARK_API_KEY"), 
    )
messages = [{"role": "user", "content": "深度思考模型与非深度思考模型的区别是什么"}]
response = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID
    model="<MODEL>",
    messages=messages,
    stream=True,
)
reasoning_content = ""
content = ""
with response: 
    for chunk in response:
        if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
            reasoning_content += chunk.choices[0].delta.reasoning_content
            print(chunk.choices[0].delta.reasoning_content, end="")
        else:
            content += chunk.choices[0].delta.content
            print(chunk.choices[0].delta.content, end="")
\`\`\`

:::tip
\`with completion \`：当 with 代码块内出现异常时，会自动调用对象的 __exit__() 方法进行清理工作。当设置了max_tokens 等中断条件时，可以避免socket层数据载满最终程序卡住。
:::
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="OpenAI Python SDK" key="jWGYNk2j8v"><RenderMd content={`\`\`\`Python
from openai import OpenAI
import os
client = OpenAI(
    # 从环境变量中读取您的方舟API Key
    api_key=os.environ.get("ARK_API_KEY"), 
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    )
messages = [{"role": "user", "content": "深度思考模型与非深度思考模型的区别是什么"}]
response = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID
    model="<MODEL>",
    messages=messages,
    stream=True,
)
reasoning_content = ""
content = ""
with response:
    for chunk in response:
        if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
            reasoning_content += chunk.choices[0].delta.reasoning_content
            print(chunk.choices[0].delta.reasoning_content, end="")
        else:
            content += chunk.choices[0].delta.content
            print(chunk.choices[0].delta.content, end="")
\`\`\`

:::tip
\`with completion \`：当 with 代码块内出现异常时，会自动调用对象的 __exit__() 方法进行清理工作。当设置了max_tokens 等中断条件时，可以避免socket层数据载满最终程序卡住。
:::
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="v7EjygGjXg"><RenderMd content={`:::warning
使用 Go SDK 调用模型进行流式输出时，请您同样配置较大的超时时间，来减少超时引起的失败。
:::
\`\`\`Go
package main

import (
    "context"
    "fmt"
    "io"
    "os"
    "time"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
        //通过 os.Getenv 从环境变量中获取 ARK_API_KEY
        os.Getenv("ARK_API_KEY"),
        //深度思考模型耗费时间会较长，请您设置较大的超时时间，避免超时导致任务失败。推荐30分钟以上
        arkruntime.WithTimeout(30*time.Minute),
    )
    // 创建一个上下文，通常用于传递请求的上下文信息，如超时、取消等
    ctx := context.Background()
    // 构建聊天完成请求，设置请求的模型和消息内容
    req := model.ChatCompletionRequest{
        // 需要替换 <MODEL> 为模型的Model ID
        Model: "<MODEL>",
        Messages: []*model.ChatCompletionMessage{
            {
                // 消息的角色为用户
                Role: model.ChatMessageRoleUser,
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性"),
                },
            },
        },
    }

    stream, err := client.CreateChatCompletionStream(ctx, req)
    if err != nil {
        fmt.Printf("stream chat error: %v\\n", err)
        return
    }
    defer stream.Close()

    for {
        recv, err := stream.Recv()
        if err == io.EOF {
            return
        }
        if err != nil {
            fmt.Printf("Stream chat error: %v\n", err)
            return
        }

        if len(recv.Choices) > 0 {
            // 输出 ReasoningContent
            if recv.Choices[0].Delta.ReasoningContent != nil {
                fmt.Print(*recv.Choices[0].Delta.ReasoningContent)
            }
            // 输出 Delta.Content
            fmt.Print(recv.Choices[0].Delta.Content)
        }
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="mIDjzlB6Cv"><RenderMd content={`\`\`\`Java
package com.example;

import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;
import java.util.ArrayList;
import java.util.List;

/**
 * 这是一个示例类，展示了如何使用ArkService来完成聊天功能。
 */
public class ChatCompletionsExample {
    public static void main(String[] args) {
        // 从环境变量中获取API密钥
        String apiKey = System.getenv("ARK_API_KEY");
        // 创建ArkService实例
        ArkService arkService = ArkService.builder().apiKey(apiKey)
                .build();
        // 初始化消息列表
        List<ChatMessage> chatMessages = new ArrayList<>();
        // 创建用户消息
        ChatMessage userMessage = ChatMessage.builder()
                .role(ChatMessageRole.USER) // 设置消息角色为用户
                .content("我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性") // 设置消息内容
                .build();
        // 将用户消息添加到消息列表
        chatMessages.add(userMessage);
        // 创建聊天完成请求
        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                .model("<MODEL>")// 需要替换为模型的Model ID
                .messages(chatMessages) // 设置消息列表
                .build();
        // 发送聊天完成请求并打印响应
        try {
            // 获取响应并打印每个选择的消息内容
            arkService.streamChatCompletion(chatCompletionRequest)
                    .doOnError(Throwable::printStackTrace)
                    .blockingForEach(choice -> {
                        if (choice.getChoices().size() > 0) {
                            ChatMessage message = choice.getChoices().get(0).getMessage();
                            // 判断是否触发深度思考，触发则打印模型输出的思维链内容
                            if (message.getReasoningContent()!= null &&!message.getReasoningContent().isEmpty()) {
                                System.out.print(message.getReasoningContent());
                            }
                            // 打印模型输出的回答内容
                            System.out.print(message.getContent());
                        }
                    });
        } catch (Exception e) {
            System.out.println("请求失败: " + e.getMessage());
        } finally {
            // 关闭服务执行器
            arkService.shutdownExecutor();
        }
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="65923378"></span>
## 开启联网能力
您可以使用方舟应用的联网插件，为`deepseek-r1-250528`模型附加上联网能力，让模型能够回答天气、时间等即时的知识问题。方法如下：

1. 获取应用ID：访问[DeepSeek-R1 联网搜索版应用](https://console.volcengine.com/ark/region:ark+cn-beijing/application/detail?id=bot-20250211130201-pll2f-nocode-preset)，快速创建联网应用。

> 内容源、返回结果数量等配置项您可根据需要灵活调整。

<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/fe32702d96394ef4855064c538db251d~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/fe32702d96394ef4855064c538db251d~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer>

2. 调用应用：通过应用ID，您即可让模型根据联网结果来分析问题。

> 开启联网能力需通过‘应用’调用，此时API路径会变为`/bots/chat/completions`，且请求参数需使用应用ID（Bot ID）而非模型ID（Model ID）。


```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="l8eUzA0ITK"><RenderMd content={`\`\`\`Shell
curl https://ark.cn-beijing.volces.com/api/v3/bots/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer \$ARK_API_KEY" \\
-d '{
    "model": "<BOT_ID>", 
    "messages": [  
        {
            "role": "user", "content": "今天北京天气如何"
        }
    ],
    "stream": true
}'
\`\`\`


`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="cvc9CSDdta"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中 
# 初始化Ark客户端，从环境变量中读取您的API Key
client = Ark(
    # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    api_key=os.environ.get("ARK_API_KEY"),
)

completion = client.bot_chat.completions.create(
    model="<BOT_ID>",  # 您当前的智能体的ID，注意此处与Chat API存在差异。
    messages=[
        {"role": "user", "content": "今天北京天气如何？"},
    ],
    stream=True,
)

for chunk in completion:
    if chunk.references:
        print(chunk.references)
    if not chunk.choices:
        continue
    if chunk.choices[0].delta.reasoning_content:
        print(chunk.choices[0].delta.reasoning_content, end="")  # 输出reasoning content
    elif chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
print()
\`\`\`


`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="FWqzyvrhu5"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "io"
    "os"
    "time"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    // 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
    // 初始化Ark客户端，从环境变量中读取您的API Key
    client := arkruntime.NewClientWithApiKey(
        // 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
        os.Getenv("ARK_API_KEY"),
        // 此为默认路径，您可根据业务所在地域进行配置
        //深度思考模型耗费时间会较长，请您设置较大的超时时间，避免超时导致任务失败。推荐30分钟以上
        arkruntime.WithTimeout(30*time.Minute),
    )

    ctx := context.Background()

    req := model.BotChatCompletionRequest{
        BotId: "<BOT_ID>", //您应用的ID，注意此处与Chat API存在差异。
        Messages: []*model.ChatCompletionMessage{
            {
                Role: model.ChatMessageRoleUser,
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("北京今天天气如何？"),
                },
            },
        },
    }
    stream, err := client.CreateBotChatCompletionStream(ctx, req)
    if err != nil {
        fmt.Printf("stream chat error: %v\n", err)
        return
    }
    defer stream.Close()

    for {
        recv, err := stream.Recv()
        if err == io.EOF {
            return
        }
        if err != nil {
            fmt.Printf("Stream chat error: %v\n", err)
            return
        }

        if len(recv.Choices) > 0 {
            fmt.Print(recv.Choices[0].Delta.Content)
            if recv.Choices[0].Delta.ReasoningContent != nil {
                fmt.Printf("%s", *recv.Choices[0].Delta.ReasoningContent) // 对于R1模型，输出reasoning content
            }
            if recv.References != nil {
                for _, ref := range recv.References {
                    fmt.Printf("reference url: %s\n", ref.Url)
                }
            }
        }
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="eYBfpkzPzT"><RenderMd content={`\`\`\`Java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.bot.completion.chat.BotChatCompletionRequest;
import com.volcengine.ark.runtime.model.bot.completion.chat.BotChatCompletionResult;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;

// 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
// 初始化Ark客户端，从环境变量中读取您的API Key
public class BotChatCompletionsExample {
    // 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    static String apiKey = System.getenv("ARK_API_KEY");
    // 此为默认路径，您可根据业务所在地域进行配置
    static ConnectionPool connectionPool = new ConnectionPool(5, 1, TimeUnit.SECONDS);
    static Dispatcher dispatcher = new Dispatcher();
    static ArkService service = ArkService.builder().dispatcher(dispatcher).connectionPool(connectionPool).apiKey(apiKey).build();

    public static void main(String[] args) {
        final List<ChatMessage> streamMessages = new ArrayList<>();
        final ChatMessage streamUserMessage = ChatMessage.builder().role(ChatMessageRole.USER).content("今天北京天气如何？").build();
        streamMessages.add(streamUserMessage);

        BotChatCompletionRequest streamChatCompletionRequest = BotChatCompletionRequest.builder()
                .botId("<BOT_ID>") //替换为您的应用ID
                .messages(streamMessages)
                .build();

        service.streamBotChatCompletion(streamChatCompletionRequest)
                .doOnError(Throwable::printStackTrace)
                .blockingForEach(
                        choice -> {
                            if (choice.getReferences() != null && !choice.getReferences().isEmpty()) {
                                choice.getReferences().forEach(ref -> System.out.println(ref.getUrl()));
                            }
                            if (!choice.getChoices().isEmpty()) {
                                if (choice.getChoices().get(0).getMessage().getReasoningContent() != null) {
                                    System.out.print(choice.getChoices().get(0).getMessage().getReasoningContent()); // 输出reasoning content
                                }
                                System.out.print(choice.getChoices().get(0).getMessage().getContent());
                            }
                        }
                );

        // shutdown service after all requests is finished
        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="0c455a85"></span>
## 图像理解
当您输入的信息包含图像信息，可以使用支持视觉理解的深度思考模型（如`doubao-1-5-thinking-pro-m-250415`）来处理图像信息，下面是一个简单示例代码。

* 更多具有深度思考+视觉理解能力的模型，可在 [模型列表](https://www.volcengine.com/docs/82379/1330310) 查询。
* 更多视觉理解相关的说明，请参见视觉理解教程的[使用说明](https://www.volcengine.com/docs/82379/1362931#09d30d63)。


```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="JjOQEaEpm6"><RenderMd content={`\`\`\`HTTP
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \\
 -H "Content-Type: application/json" \\
 -H "Authorization: Bearer \$ARK_API_KEY" \\
 -d '{
    "model": "doubao-1-5-thinking-pro-m-250415", 
    "messages": [
    {"role": "user", "content": [
        {
            "type": "image_url",
            "image_url": {
                "url": "https://ark-project.tos-cn-beijing.volces.com/images/view.jpeg"
            }
        },
        {
            "type":"text",
            "text": "这是哪里"
        }
    ]}
  ]
}'
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="eGU3RfSZcw"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
# 初始化Ark客户端，从环境变量中读取您的API Key
client = Ark(
    # 此为默认路径，您可根据业务所在地域进行配置
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    api_key=os.environ.get("ARK_API_KEY"),
)

response = client.chat.completions.create(
    # 可替换 Model ID 为其他 Model ID或创建的推理接入点 ID 
    model="doubao-1-5-thinking-pro-m-250415",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/images/view.jpeg"
                    },
                },
                {"type": "text", "text": "这是哪里？"},
            ],
        }
    ],
    
)

print(response.choices[0])
\`\`\`


`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="OpenAI Python SDK" key="lILczmrWZn"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
# 初始化Ark客户端，从环境变量中读取您的API Key
client = OpenAI(
    # 此为默认路径，您可根据业务所在地域进行配置
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    api_key=os.environ.get("ARK_API_KEY"),
)

response = client.chat.completions.create(
    # 指定您创建的方舟推理接入点 ID，此处已帮您修改为您的推理接入点 ID
    model="doubao-1-5-thinking-pro-m-250415",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/images/view.jpeg"
                    },
                },
                {"type": "text", "text": "这是哪里？"},
            ],
        }
    ],
)

print(response.choices[0])
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="GcUofYlXQA"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "os"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
)

func main() {
    // 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
    // 初始化Ark客户端，从环境变量中读取您的API Key
    client := arkruntime.NewClientWithApiKey(
       // 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
       os.Getenv("ARK_API_KEY"),
       // 此为默认路径，您可根据业务所在地域进行配置
       arkruntime.WithBaseUrl("https://ark.cn-beijing.volces.com/api/v3"),
    )
    ctx := context.Background()
    
    fmt.Println("----- image input -----")
    req := model.CreateChatCompletionRequest{
       // 替换Model ID，或指定您创建的方舟推理接入点 ID
       Model: "doubao-1-5-thinking-pro-m-250415",
       Messages: []*model.ChatCompletionMessage{
          {
             Role: model.ChatMessageRoleUser,
             Content: &model.ChatCompletionMessageContent{
                ListValue: []*model.ChatCompletionMessageContentPart{
                   {
                      Type: model.ChatCompletionMessageContentPartTypeImageURL,
                      ImageURL: &model.ChatMessageImageURL{
                         URL: "https://ark-project.tos-cn-beijing.volces.com/images/view.jpeg",
                      },
                   },
                   {
                      Type: model.ChatCompletionMessageContentPartTypeText,
                      Text: "这是哪里？",
                   },
                },
             },
          },
       },
    }

    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
       fmt.Printf("standard chat error: %v
", err)
       return
    }
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`


`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="i4IsDcOiyu"><RenderMd content={`\`\`\`Java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionContentPart;
import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;

// 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
// 初始化Ark客户端，从环境变量中读取您的API Key
public class ChatCompletionsVisionExample {
    // 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    static String apiKey = System.getenv("ARK_API_KEY");
    // 此为默认路径，您可根据业务所在地域进行配置
    static String baseUrl = "https://ark.cn-beijing.volces.com/api/v3";
    static ConnectionPool connectionPool = new ConnectionPool(5, 1, TimeUnit.SECONDS);
    static Dispatcher dispatcher = new Dispatcher();
    static ArkService service = ArkService.builder().dispatcher(dispatcher).connectionPool(connectionPool).baseUrl(baseUrl).apiKey(apiKey).build();

    public static void main(String[] args) {
        System.out.println("----- image input -----");
        final List<ChatMessage> messages = new ArrayList<>();
        final List<ChatCompletionContentPart> multiParts = new ArrayList<>();
        multiParts.add(ChatCompletionContentPart.builder().type("image_url").imageUrl(
              new ChatCompletionContentPart.ChatCompletionContentPartImageURL(
                  "https://ark-project.tos-cn-beijing.volces.com/images/view.jpeg"
              )
        ).build());
        multiParts.add(ChatCompletionContentPart.builder().type("text").text(
                "这是哪里？"
        ).build());

        final ChatMessage userMessage = ChatMessage.builder().role(ChatMessageRole.USER)
                .multiContent(multiParts).build();
        messages.add(userMessage);

        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                // 指定您创建的方舟推理接入点 ID，此处已帮您修改为您的推理接入点 ID
                .model("doubao-1-5-thinking-pro-m-250415")
                .messages(messages)
                .build();

        service.createChatCompletion(chatCompletionRequest).getChoices().forEach(choice -> System.out.println(choice.getMessage().getContent()));

        service.shutdownExecutor();
    }
}
\`\`\`


`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="0002"><span> 

<span id="fa3f44fa"></span>
## 关闭深度思考
部分深度思考能力的模型支持通过 **thinking** 字段控制是否关闭深度思考能力。

* `enabled`：默认强制开启，强制开启深度思考能力。
* `disabled`：强制关闭深度思考能力。
* `auto`：模型自行判断是否进行深度思考。

:::tip
支持该字段的模型：

* `doubao-seed-1-6-250615`
* `doubao-seed-1-6-flash-250615`
   * 不支持auto取值
* `doubao-1-5-thinking-vision-pro-250428`
* `doubao-1-5-ui-tars-250428`
* `doubao-1-5-thinking-pro-m-250428`
:::

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="LO6o3aVZv9"><RenderMd content={`\`\`\`Shell
curl --location "https://ark.cn-beijing.volces.com/api/v3/chat/completions" \\
--header "Authorization: Bearer \$ARK_API_KEY" \\
--header "Content-Type: application/json" \\
--data '{
 "model": "doubao-seed-1-6-250615",
     "messages": [
         {
             "role": "user",
             "content": [
                 {
                     "type":"text",
                     "text":"我要研究深度思考模型与非深度思考模型区别的课题，体现出我的专业性"
                 }
             ]
         }
     ],
     "thinking":{
         "type":"disabled"
     }
}'
\`\`\`


* **model**：请变更为实际调用的模型。
* **thinking.type**：字段可以取值范围。
   *  \`disabled\`：强制关闭深度思考能力，模型不输出思维链内容。
   * \`enabled\`：强制开启深度思考能力，模型强制输出思维链内容。
   * \`auto\`：模型自行判断是否需要进行深度思考。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="QuZwYGzfN0"><RenderMd content={`\`\`\`Python
import os
# 升级方舟 SDK 到最新版本 pip install -U 'volcengine-python-sdk[ark]'
from volcenginesdkarkruntime import Ark

client = Ark(
    # 从环境变量中读取您的方舟API Key
    api_key=os.environ.get("ARK_API_KEY"), 
    # 深度思考模型耗费时间会较长，请您设置较大的超时时间，避免超时，推荐30分钟以上
    timeout=1800,
    )
response = client.chat.completions.create(
    # 替换 <MODEL> 为您的Model ID
    model="doubao-seed-1-6-250615",
    messages=[
        {"role": "user", "content": "我要研究深度思考模型与非深度思考模型区别的课题，体现出我的专业性"}
    ],
     thinking={
         "type": "disabled", # 不使用深度思考能力
         # "type": "enabled", # 使用深度思考能力
         # "type": "auto", # 模型自行判断是否使用深度思考能力
     },
)

print(response)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="OpenAI Python SDK" key="i47EjniFe0"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

client = OpenAI(
    # 从环境变量中读取您的方舟API Key
    api_key=os.environ.get("ARK_API_KEY"),
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 深度思考模型耗费时间会较长，请您设置较大的超时时间，避免超时，推荐30分钟以上
    timeout=1800,
)
response = client.chat.completions.create(
    # 替换 <MODEL> 为您的Model ID
    model="doubao-seed-1-6-250615",
    messages=[
        {
            "role": "user",
            "content": "我要研究深度思考模型与非深度思考模型区别的课题，体现出我的专业性",
        }
    ],
    extra_body={
        "thinking": {
            "type": "disabled",  # 不使用深度思考能力
            # "type": "enabled", # 使用深度思考能力
            # "type": "auto", # 模型自行判断是否使用深度思考能力
        }
    },
)


print(response)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="pd86hKfEBt"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "os"
    "time"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
        //从环境变量中获取 ARK_API_KEY
        os.Getenv("ARK_API_KEY"),
        //深度思考模型耗费时间会较长，请您设置较大的超时时间，避免超时导致任务失败。推荐30分钟以上
        arkruntime.WithTimeout(30*time.Minute),
    )
    // 创建一个上下文，通常用于传递请求的上下文信息，如超时、取消等
    ctx := context.Background()
    // 构建聊天完成请求，设置请求的模型和消息内容
    req := model.CreateChatCompletionRequest{
        // 需要替换 <MODEL> 为您的 Model ID
        Model: "doubao-seed-1-6-250615",
        Messages: []*model.ChatCompletionMessage{
            {
                // 消息的角色为用户
                Role: model.ChatMessageRoleUser,
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性"),
                },
            },
        },
        Thinking: &model.Thinking{
            Type: model.ThinkingTypeDisabled, // 关闭深度思考能力
            // Type: model.ThinkingTypeEnabled, //开启深度思考能力
            // Type: model.ThinkingTypeAuto, //模型自行判断是否使用深度思考能力
        },
    }


    // 发送聊天完成请求，并将结果存储在 resp 中，将可能出现的错误存储在 err 中
    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
        // 若出现错误，打印错误信息并终止程序
        fmt.Printf("standard chat error: %v\\n", err)
        return
    }
    // 检查是否触发深度思考，触发则打印思维链内容
    if resp.Choices[0].Message.ReasoningContent != nil {
        fmt.Println(*resp.Choices[0].Message.ReasoningContent)
    }
    // 打印聊天完成请求的响应结果
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="mc3CcguAPL"><RenderMd content={`\`\`\`Java
package com.example;

import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;

import java.time.Duration;
import java.util.ArrayList;
import java.util.List;

/**
 * 这是一个示例类，展示了如何使用ArkService来完成聊天功能。
 */
public class ChatCompletionsExample {
    public static void main(String[] args) {
        // 从环境变量中获取API密钥
        String apiKey = System.getenv("ARK_API_KEY");
        // 创建ArkService实例
        ArkService arkService = ArkService.builder().apiKey(apiKey)
                .timeout(Duration.ofMinutes(30))// 深度思考模型耗费时间会较长，请您设置较大的超时时间，避免超时导致任务失败。推荐30分钟以上
                .build();
        // 初始化消息列表
        List<ChatMessage> chatMessages = new ArrayList<>();
        // 创建用户消息
        ChatMessage userMessage = ChatMessage.builder()
                .role(ChatMessageRole.USER) // 设置消息角色为用户
                .content("我要研究深度思考模型与非深度思考模型区别的课题，怎么体现我的专业性") // 设置消息内容
                .build();
        // 将用户消息添加到消息列表
        chatMessages.add(userMessage);
        // 创建聊天完成请求
        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                .model("doubao-seed-1-6-250615")
                .messages(chatMessages) // 设置消息列表
                .thinking(new ChatCompletionRequest.ChatCompletionRequestThinking("disabled"))
                .build();
        // 发送聊天完成请求并打印响应
        try {
            // 获取响应并打印每个选择的消息内容
            arkService.createChatCompletion(chatCompletionRequest)
                    .getChoices()
                    .forEach(choice -> {                    
                        // 校验是否触发了深度思考，打印思维链内容
                        if (choice.getMessage().getReasoningContent() != null) {
                            System.out.println("推理内容: " + choice.getMessage().getReasoningContent());
                        } else {
                            System.out.println("推理内容为空");
                        }
                        // 打印消息内容
                        System.out.println("消息内容: " + choice.getMessage().getContent());
                    });
        } catch (Exception e) {
            System.out.println("请求失败: " + e.getMessage());
        } finally {
            // 关闭服务执行器
            arkService.shutdownExecutor();
        }
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


<span id="0001"><span> 


<span id="31ecc4d7"></span>
## 设置模型输出长度限制
模型输出长度 = 思维链长度 + 回答长度
当您需要调整模型输出长度，如控制成本，思维链与回答不超过500字；或输出篇幅较长，如输出行业研究报告，可通过在请求时设置 **max_completion_tokens** 字段，来达成目标。

> * 支持配置模型输出长度限制的模型：`deepseek-r1-250528`，`doubao-seed-1-6-250615`， `doubao-seed-1-6-flash-250615`。
> * **max_tokens**（控制模型回答），**max_completion_tokens**（控制模型输出）不可同时设置，会直接报错。
> * 如设置了 **max_completion_tokens**，参数的**max_tokens** 默认值以及最大思维链限制将失效，最大输出以模型配置的 **max_completion_tokens** 值为准。
> * 如只需控制回答长度，可参考：[设置模型回答长度限制](https://www.volcengine.com/docs/82379/1399009#3821b26a)。


```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="TPATppOusu"><RenderMd content={`\`\`\`Bash
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer \$ARK_API_KEY" \\
  -d '{
    "model": "<MODEL>",
    "messages": [
        {
            "role": "user",
            "content": "你好"
        }
    ],
    "max_completion_tokens": 1024
  }'
\`\`\`


* \`<MODEL>\`：需要替换为Model ID，查询Model ID见 [模型列表](https://www.volcengine.com/docs/82379/1330310)。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="ecl3ypG45b"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark
# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
client = Ark(
    api_key=os.environ.get("ARK_API_KEY"),
)

completion = client.chat.completions.create(
    # 替换为您的推理接入点ID，创建方法见：https://www.volcengine.com/docs/82379/1399008
    model="<MODEL>",
    messages=[
        {"role": "system", "content": "你是 AI 人工智能助手"},
        {"role": "user", "content": "常见的十字花科植物有哪些？"},
    ],
    # 设置模型最大输出长度为 1024 token，按需调整
    max_completion_tokens = 1024,
)
print(completion.choices[0].message.content)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="l9ynSTmloz"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "io"
    "os"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
        os.Getenv("ARK_API_KEY"),
    )
    
    ctx := context.Background()

    fmt.Println("----- standard request -----")
    req := model.CreateChatCompletionRequest{
        // 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
       Model: "<MODEL>",
       Messages: []*model.ChatCompletionMessage{
          {
             Role: model.ChatMessageRoleSystem,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("你是AI人工智能助手"),
             },
          },
          {
             Role: model.ChatMessageRoleUser,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("常见的十字花科植物有哪些？"),
             },
          },
       },
       MaxCompletionTokens: volcengine.Int(1024), // 设置最大输出长度为 1024 token
    }

    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
       fmt.Printf("standard chat error: %v\n", err)
       return
    }
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="TnJoMdLlyR"><RenderMd content={`\`\`\`java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;
import java.util.ArrayList;
import java.util.List;

public class ChatCompletionsExample {
    public static void main(String[] args) {
        String apiKey = System.getenv("ARK_API_KEY");
        ArkService service = ArkService.builder().apiKey(apiKey).baseUrl("https://ark-cn-beijing.bytedance.net/api/v3").build();
        System.out.println("\n----- standard request -----");
        final List<ChatMessage> messages = new ArrayList<>();
        final ChatMessage systemMessage = ChatMessage.builder().role(ChatMessageRole.SYSTEM).content("你是豆包，是由字节跳动开发的 AI 人工智能助手").build();
        final ChatMessage userMessage = ChatMessage.builder().role(ChatMessageRole.USER).content("常见的十字花科植物有哪些？").build();
        messages.add(systemMessage);
        messages.add(userMessage);

        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                .model("<MODEL>")// 替换为您的推理接入点ID，创建方法见：https://www.volcengine.com/docs/82379/1399008// 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
                .messages(messages)
                .maxCompletionTokens(1024)// 设置最大输出长度为 1024 token
                .build();
        service.createChatCompletion(chatCompletionRequest).getChoices().forEach(choice -> System.out.println(choice.getMessage().getContent()));
        // shutdown service
        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="d86010f4"></span>
# 相关文档

* [对话（Chat API）](https://www.volcengine.com/docs/82379/1494384)：深度思考 API 参数说明，调用模型的深度思考能力，模型调用中出现错误，可参考深度思考 API 参数说明。

<span id="5f021d10"></span>
# 常见问题

* [并发 RPM 或者 TPM 额度明明有剩余为什么提示限流报错？](https://www.volcengine.com/docs/82379/1359411#91505308)


<span id="a3986ddb"></span>
# 附-工作原理
深度思考模型除了提问（Question）和回答（Answer）外，还会输出思维链内容（COT）。思维链内容展现的是模型处理问题的过程，包括将问题拆分为多个问题进行处理，生成多种回复综合得出更好回答等过程。但是这个内容不会被拼接到上下文中，如下图所示。
<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/101d39d6769941e3b9c6f8997551eca3~tplv-goo7wpa0wc-image.image" width="428px" /></div>

<span id="4adf109b"></span>
# 附-模型输入输出长度限制说明
<span id="90b705e2"></span>
## 旧版
在控制模型输入输出以及计费时会用到不同的概念，他们作用的内容会有所不同。其中，思维链和回答内容长度会作为输出长度进行计费，问题会作为输入长度进行计费。如下图所示。

输入&quot;,&quot;style&quot;:&quot;text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;&quot;,&quot;parent&quot;:&quot;XT9nsl0K&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;text&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;510&quot;,&quot;y&quot;:&quot;90&quot;,&quot;width&quot;:&quot;40&quot;,&quot;height&quot;:&quot;20&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;9pkDrdM3&quot;:{&quot;id&quot;:&quot;9pkDrdM3&quot;,&quot;value&quot;:&quot;output<br />输出&quot;,&quot;style&quot;:&quot;text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;&quot;,&quot;parent&quot;:&quot;XT9nsl0K&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;text&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;510&quot;,&quot;y&quot;:&quot;200&quot;,&quot;width&quot;:&quot;40&quot;,&quot;height&quot;:&quot;20&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;y6e6QRwL&quot;:{&quot;id&quot;:&quot;y6e6QRwL&quot;,&quot;value&quot;:&quot;最大思维链长度&quot;,&quot;style&quot;:&quot;text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;&quot;,&quot;parent&quot;:&quot;XT9nsl0K&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;text&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;220&quot;,&quot;y&quot;:&quot;240&quot;,&quot;width&quot;:&quot;100&quot;,&quot;height&quot;:&quot;20&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;wz2sXNpS&quot;:{&quot;id&quot;:&quot;wz2sXNpS&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;curved=1;endArrow=none;endFill=0;&quot;,&quot;parent&quot;:&quot;XT9nsl0K&quot;,&quot;source&quot;:&quot;YnbZeiXu&quot;,&quot;target&quot;:&quot;4jZCaV84&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;YnbZeiXu&quot;:{&quot;id&quot;:&quot;YnbZeiXu&quot;,&quot;value&quot;:&quot;最大输入长度&quot;,&quot;style&quot;:&quot;text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;&quot;,&quot;parent&quot;:&quot;XT9nsl0K&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;text&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;220&quot;,&quot;y&quot;:&quot;90&quot;,&quot;width&quot;:&quot;100&quot;,&quot;height&quot;:&quot;20&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;xJySjtje&quot;:{&quot;id&quot;:&quot;xJySjtje&quot;,&quot;value&quot;:&quot;max_tokens<br />回答的最大长度&quot;,&quot;style&quot;:&quot;text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;&quot;,&quot;parent&quot;:&quot;XT9nsl0K&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;text&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;220&quot;,&quot;y&quot;:&quot;170&quot;,&quot;width&quot;:&quot;100&quot;,&quot;height&quot;:&quot;20&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;YoRYK0PL&quot;:{&quot;id&quot;:&quot;YoRYK0PL&quot;,&quot;value&quot;:&quot;&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;endArrow=none;endFill=0;&quot;,&quot;parent&quot;:&quot;XT9nsl0K&quot;,&quot;source&quot;:&quot;3aw3lFxx&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;,&quot;-0-mxPoint&quot;:{&quot;x&quot;:&quot;560&quot;,&quot;y&quot;:&quot;100&quot;,&quot;as&quot;:&quot;targetPoint&quot;}}},&quot;TTI8zEEa&quot;:{&quot;id&quot;:&quot;TTI8zEEa&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=1;entryY=0.419;entryDx=0;entryDy=0;endArrow=none;endFill=0;entryPerimeter=0;curved=1;&quot;,&quot;parent&quot;:&quot;XT9nsl0K&quot;,&quot;source&quot;:&quot;3aw3lFxx&quot;,&quot;target&quot;:&quot;Va6Pz1Ee&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;3aw3lFxx&quot;:{&quot;id&quot;:&quot;3aw3lFxx&quot;,&quot;value&quot;:&quot;context window<br />最大上下文长度&quot;,&quot;style&quot;:&quot;text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;&quot;,&quot;parent&quot;:&quot;XT9nsl0K&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;text&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;600&quot;,&quot;y&quot;:&quot;90&quot;,&quot;width&quot;:&quot;100&quot;,&quot;height&quot;:&quot;20&quot;,&quot;as&quot;:&quot;geometry&quot;}}},&quot;mxCellList&quot;:[&quot;No9833eF&quot;,&quot;XT9nsl0K&quot;,&quot;Va6Pz1Ee&quot;,&quot;FiZj5lde&quot;,&quot;fzAN0dqs&quot;,&quot;9hDt9Nd2&quot;,&quot;b2OjP7KV&quot;,&quot;4jZCaV84&quot;,&quot;7UU7hDgF&quot;,&quot;fm4HoO5t&quot;,&quot;XcKTE6mN&quot;,&quot;9pkDrdM3&quot;,&quot;y6e6QRwL&quot;,&quot;wz2sXNpS&quot;,&quot;YnbZeiXu&quot;,&quot;xJySjtje&quot;,&quot;YoRYK0PL&quot;,&quot;TTI8zEEa&quot;,&quot;3aw3lFxx&quot;]},&quot;lastEditTime&quot;:0,&quot;snapshot&quot;:&quot;&quot;}" />

下面是各个对象的长度限制说明，触发后即停止输出，并返回停止原因为`length`（因为长度限制导致输出停止）：

| | | | | \
|对象 |关键参数 |说明 |可否配置 |
|---|---|---|---|
| | | | | \
|问题内容 |最大输入长度 |与回答共享配额，即未使用配额共享给回答内容 |不可配置 |
| | | | | \
|回答内容 |最大输入长度 |与问题共享配额，即输出长度不可超过 `最大输入长度-已输入的问题内容长度` |不可配置 |
|^^| | | | \
| |最大回答长度 |动态配置，输出长度不可超过**max_tokens** 参数的配置。 |\
| | |> [设置模型最大输出长度](https://www.volcengine.com/docs/82379/1399009#3821b26a) |可配置 |\
| | | | |
| | | | | \
|思维链内容 |最大思维链长度 |独占，不共享，即单次请求如有未使用的配额也不共享给问题及回答。 |不可配置 |

内容截断逻辑举例：模型A属性如下，最大上下文长度96k，最大输入长度64k，最大输出16k，思维链最大长度32k。

* 当用户输入的问题长度 56k，模型输出的思维链长度16k，模型输出的回答长度达到8k时，`问题长度+回答长度 = 56k+8k = 64k`，触发**最大输入长度**限制，模型将停止输出，返回停止原因（**finish_reason**）字段为`length`。
* 当用户输入的问题长度 22k，模型输出思维链长度16k，模型输出的回答长度达到16k时，触发**最大回答长度**限制，模型将停止输出，返回停止原因（**finish_reason**）字段为`length`。
* 当用户输入的问题长度 22k，模型输出的思维链长度32k时，触发**最大思维链长度**限制，模型将停止输出，返回停止原因（**finish_reason**）字段为`length`。




# 文本生成
Source: https://www.volcengine.com/docs/82379/1399009
语言大模型具备文本理解和文字对话的能力。如当您传入文本信息时，大模型可以理解信息，并结合这些信息进行回复。通过这篇教程，您可以学习到如何使用模型服务 API，来调用模型理解文本，生成文本内容，并可以基于此 API 构建或者扩展自己的应用或者自动化任务。
> 应用场景：见 [附1.应用场景](https://www.volcengine.com/docs/82379/1399009#4a486037)。

<span id="bc2d9138"></span>
# 前提条件
* [获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) 。
   * 使用 Access Key 鉴权请参考[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
* [开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需 Model ID 。
   * 通过 Endpoint ID 调用模型服务请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。



<span id="18cf565a"></span>
# 快速开始
支持文本生成的大模型当前支持在请求中传入图片链接，图片信息需要作为用户角色输入信息传给大模型，即`"role": "user"`，下面是简单的文本生成调用示例代码。
```Python
import os
# 通过 pip install volcengine-python-sdk[ark] 安装方舟SDK
from volcenginesdkarkruntime import Ark

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')
# 替换 <MODEL> 为模型的Model ID
model = "<MODEL>"

# 初始化Ark客户端
client = Ark(
    api_key = api_key,
)

# 创建一个对话请求
completion = client.chat.completions.create(
    model = model,
    messages = [
        {"role": "user", "content": "请将下面内容进行结构化处理：火山方舟是火山引擎推出的大模型服务平台，提供模型训练、推理、评测、精调等全方位功能与服务，并重点支撑大模型生态。 火山方舟通过稳定可靠的安全互信方案，保障模型提供方的模型安全与模型使用者的信息安全，加速大模型能力渗透到千行百业，助力模型提供方和使用者实现商业新增长。"},
    ],
)

print(completion.choices[0].message.content)
```

模型回复预览：
```Shell
**一、火山方舟的所属与定位**
火山方舟是火山引擎推出的大模型服务平台。

**二、火山方舟的功能与服务**
1. 提供全方位功能
   - 包括模型训练、推理、评测、精调等功能与服务。
2. 重点支撑
   - 重点支撑大模型生态。

**三、火山方舟的安全保障与作用**
1. 安全保障
   - 通过稳定可靠的安全互信方案，保障模型提供方的模型安全与模型使用者的信息安全。
2. 作用
   - 加速大模型能力渗透到千行百业，助力模型提供方和使用者实现商业新增长。
```

<span id="ad23177b"></span>
# 支持模型
当前支持文本生成的模型见[文本生成能力](https://www.volcengine.com/docs/82379/1330310#15a31773)。
选择的建议：

* 选择最新的模型：如果您首次选择模型，推荐您选择对应系列最新版本模型。如`doubao-seed-1-6-***`与`doubao-seed-1-6-flash-***`，在文本分类、内容创作等能力大幅提升。
* 选择对应领域的模型：如果您在角色扮演、工具调用等领域，推荐您选择对应领域加强的模型，可以在[模型列表](https://www.volcengine.com/docs/82379/1330310)查询。
   * 联网总结：模型版本中带`browsing`字段的模型，配合联网插件使用，在网页内容总结方面具有更好的效果，信息检索回答任务全面提升，回答更准确、更少冗余内容。
   * 工具调用：模型版本中带`functioncall`字段的模型，对任务解析与函数调用的能力进行了重点优化，在调用预定义函数、获取外部信息方面都有更好的效果。如您使用大模型时需要调用函数或者其他接口时可选该类模型。
   * 角色扮演：模型版本中带`character`字段的模型，针对性提高角色扮演与情感陪伴能力，具备更强的上下文感知与剧情推动能力，多轮对话、智能交互类场景可以选择该模型。
   * 长文本：模型名称中带`128k`、`256k`字段的模型，可以输入 20 万字（`128k`）、40 万字（`256k`）左右的上下文，您进行如文本分类与信息抽取、小说全文总结摘要等长文本分析场景可以选择该类模型。
   * 通用任务：应对通用任务，适合绝大部分场景，如果您业务不在前面所述特定领域，即可选择该类模型。

<span id="1b205112"></span>
# 计费说明
模型计费说明请参见[大语言模型](https://www.volcengine.com/docs/82379/1099320#大语言模型：)。
<span id="68d93947"></span>
# 编写提示词
提示词（Prompt）是输入给模型的信息，模型会根据提示词来进行推理，生成回复内容。正确设计和编写提示词，如提供说明、示例、好的规范等方法可以提高模型输出的质量和准确性。而进行提示词优化的工作也被称为提示词工程（Prompt Engineering）。
> 我们为您提供了如何编辑好的提示词的一些实践[Prompt 最佳实践](https://www.volcengine.com/docs/82379/1221660)，您可以基于实践来优化提示词，以获得更好的回复。

下面为您介绍如何使用 `chatcompletions` 接口，将提示词正确输入给模型。
在 [对话(Chat)-文本 API（文档下线中）](https://www.volcengine.com/docs/82379/1298454)中，您可以通过 `messages` 对象将信息传入给模型，其中`role`字段定义信息传入的角色，`content`承载消息内容。模型会结合传入的角色和信息来理解内容，并生成对应的回复。
<span id="3a9dc0f4"></span>
## 用户消息
最终用户传入给模型消息，此时 `role` 字段应设置为`user`，该类型消息往往是包含用户希望模型处理的具体任务或者处理的信息。
下面就是一个简单的用户消息，要求模型对文本进行结构化处理。
```Shell
messages = [
    {"role": "user", "content": "请将下面内容进行结构化处理：火山方舟是火山引擎推出的大模型服务平台，提供模型训练、推理、评测、精调等全方位功能与服务，并重点支撑大模型生态。 火山方舟通过稳定可靠的安全互信方案，保障模型提供方的模型安全与模型使用者的信息安全，加速大模型能力渗透到千行百业，助力模型提供方和使用者实现商业新增长。"}
]
```

<span id="d5b9bd6b"></span>
## 系统消息
用于指定模型扮演角色或交代背景信息，此时 `role` 字段应设置为`system`。如果设置系统消息，请放在`messages`列表的第一位。
下面是一个系统消息示例，模型会作为文本转化工具进行结构化处理。
```Shell
messages =[
    {"role": "system", "content": "你是一个文本转化器，能够将输入的文本进行结构化处理。你收到信息后，只返回结构化处理后的内容，不应该返回其他内容。"},
    {"role": "user", "content": "请将下面内容进行结构化处理：火山方舟是火山引擎推出的大模型服务平台，提供模型训练、推理、评测、精调等全方位功能与服务，并重点支撑大模型生态。 火山方舟通过稳定可靠的安全互信方案，保障模型提供方的模型安全与模型使用者的信息安全，加速大模型能力渗透到千行百业，助力模型提供方和使用者实现商业新增长。"},
]
```

<span id="e1f87540"></span>
## 模型消息
假定为模型返回的消息，此时`role`字段应设置为`assistant`。在多轮对话中，会需要传入历史的对话，而模型回复的消息就可以用模型消息表示。
```Shell
messages =[
    {"role": "system", "content": "你是个十进制计算器，只返回结算结果，不返回其他"},
    {"role": "user", "content": "一加一"},
    {"role": "assistant", "content": "2"},
    {"role": "user", "content": "再加一"},
]
```

<span id="2cbebf10"></span>
# 使用规格及建议

* 每个模型输出有几个关键的限制，各个模型详细的规格信息，请参见 [模型列表](https://www.volcengine.com/docs/82379/1330310)。
   * 最大上下文长度（Context Window）：即单次请求模型能处理的内容长度，包括输入的内容和模型输出的内容，单位 token ，超出最大上下文长度的内容会被截断处理，这会导致模型处理信息时丢失部分信息或者输出信息被截断。如碰到上下文限制导致的内容截断，可以选择支持更大最大上下文长度规格的模型，如`doubao-pro-128k`、`doubao-pro-256k`等模型名称中带`128k`、`256k`字段的模型。
   * 最大输出长度（Max Output Tokens）：即单次模型输出的内容的最大长度，内容过长会被截断。如果碰到这种情况，可以参考[Prefill Response模式最佳实践](https://www.volcengine.com/docs/82379/1359497)，实现多次回复，拼接出完整回复。
   * 每分钟处理内容量（TPM）：即账号下同模型（不区分版本）每分钟能处理的内容量限制，单位 token。如果默认 TPM 限制无法满足您的业务，您可以通过[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)联系我们提升配额。
      > 举例来说：一个主账号下，创建doubao-pro-32k a、b、c 3个版本的A、B 、C 3个推理接入点，某模型的 TPM 为80w。那么某分钟，A、B、C 3个节点处理内容量 A 20w token、B 50w token、C 20w token，就会在触发80w TPM限制，并产生报错。
   * 每秒钟处理请求数（QPS）：即账号下同模型（不区分版本）每秒钟能处理的请求数上限，与上面TPM类似。如果默认 QPS 限制无法满足您的业务，您可以通过[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)联系我们提升配额。

对于token用量，您可以使用接口[分词 API（文档下线中）](https://www.volcengine.com/docs/82379/1337112)来计算。
<span id="1d866118"></span>
# 示例
<span id="d86010f4"></span>
## 单轮对话
与模型进行一次交互，交互内容为单轮对话，模型根据系统消息和用户消息来返回内容。
> 因为是非流式输出，需要等待模型推理完所有内容，将内容一起返回给您，会有一定延时。


```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="roT0JttLyX"><RenderMd content={`\`\`\`Shell
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer \$ARK_API_KEY" \\
  -d '{
    "model": "<MODEL>",
    "messages": [
        {
            "role": "user",
            "content": "你好"
        }
    ]
  }'
\`\`\`


* 替换\`<MODEL>\`  为Model ID，查询Model ID见 [模型列表](https://www.volcengine.com/docs/82379/1330310)。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="z67AKto9G0"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark
# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
client = Ark(
    api_key=os.environ.get("ARK_API_KEY"),
)

completion = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
    model="<MODEL>",
    messages=[
        {"role": "system", "content": "你是 AI 人工智能助手"},
        {"role": "user", "content": "常见的十字花科植物有哪些？"},
    ],
)
print(completion.choices[0].message.content)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="ojYnJ1vxn2"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "io"
    "os"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
        os.Getenv("ARK_API_KEY"),
    )
    
    ctx := context.Background()

    fmt.Println("----- standard request -----")
    req := model.CreateChatCompletionRequest{
        // 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
       Model: "<MODEL>",
       Messages: []*model.ChatCompletionMessage{
          {
             Role: model.ChatMessageRoleSystem,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("你是豆包，是由字节跳动开发的 AI 人工智能助手"),
             },
          },
          {
             Role: model.ChatMessageRoleUser,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("常见的十字花科植物有哪些？"),
             },
          },
       },
    }

    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
       fmt.Printf("standard chat error: %v\n", err)
       return
    }
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="MpCcyGJxk8"><RenderMd content={`\`\`\`java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;
import java.util.ArrayList;
import java.util.List;

public class ChatCompletionsExample {
    public static void main(String[] args) {
        String apiKey = System.getenv("ARK_API_KEY");
        ArkService service = ArkService.builder().apiKey(apiKey).build();
        System.out.println("\n----- standard request -----");
        final List<ChatMessage> messages = new ArrayList<>();
        final ChatMessage systemMessage = ChatMessage.builder().role(ChatMessageRole.SYSTEM).content("你是豆包，是由字节跳动开发的 AI 人工智能助手").build();
        final ChatMessage userMessage = ChatMessage.builder().role(ChatMessageRole.USER).content("常见的十字花科植物有哪些？").build();
        messages.add(systemMessage);
        messages.add(userMessage);

        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                .model("<MODEL>")// 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
                .messages(messages)
                .build();
        service.createChatCompletion(chatCompletionRequest).getChoices().forEach(choice -> System.out.println(choice.getMessage().getContent()));
        // shutdown service
        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="f6222fec"></span>
## 多轮对话
组合使用系统消息、模型消息以及用户消息，可以实现多轮对话，即根据一个主题进行多次对话。
需要注意，`chat.completions`接口是无状态的，在每次请求时，将历史信息都放在`messages`中，并通过`role`字段设置，让模型了解之前不同角色的不同对话内容，以便进行主题相关的延续性对话。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="V5rG8yGVda"><RenderMd content={`\`\`\`Bash
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer \$ARK_API_KEY" \\
  -d '{
    "model": "<MODEL>",
    "messages": [
        {
            "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手。",
            "role": "system"
        },
        {
            "content": "花椰菜是什么？",
            "role": "user"
        },
        {
            "content": "花椰菜又称菜花、花菜，是一种常见的蔬菜。",
            "role": "assistant"
        },
        {
            "content": "再详细点。",
            "role": "user"
        }
    ]
  }'
\`\`\`


* 替换\`<MODEL>\`  为Model ID，查询Model ID见 [模型列表](https://www.volcengine.com/docs/82379/1330310)。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="ZJFQuS5k9c"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark
# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
client = Ark(api_key=os.environ.get("ARK_API_KEY"))
client = Ark(
    api_key=os.environ.get("ARK_API_KEY"),
)

completion = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
    model="<MODEL>",
    messages=[
            {
                "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手。",
                "role": "system",
            },
            {"content": "花椰菜是什么？", "role": "user"},
            {
                "content": "花椰菜又称菜花、花菜，是一种常见的蔬菜。",
                "role": "assistant",
            },
            {"content": "再详细点。", "role": "user"},
        ],
)
print(completion.choices[0].message.content)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="vhBQolxQ1X"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "io"
    "os"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
        os.Getenv("ARK_API_KEY"),
    )
    
    ctx := context.Background()

    fmt.Println("----- standard request -----")
    req := model.CreateChatCompletionRequest{
        // 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
       Model: "<MODEL>",
       Messages: []*model.ChatCompletionMessage{
            &model.ChatCompletionMessage{
                Role: "system",
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("你是豆包，是由字节跳动开发的 AI 人工智能助手。"),
                },
            },
            &model.ChatCompletionMessage{
                Role: "user",
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("花椰菜是什么？"),
                },
            },
            &model.ChatCompletionMessage{
                Role: "assistant",
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("花椰菜又称菜花、花菜，是一种常见的蔬菜。"),
                },
            },
            &model.ChatCompletionMessage{
                Role: "user",
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("再详细点。"),
                },
            },
        },
    }

    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
       fmt.Printf("standard chat error: %v\n", err)
       return
    }
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="iyCT9pWjFx"><RenderMd content={`\`\`\`java
package com.volcengine.sample;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.volcengine.ark.runtime.model.completion.chat.*;
import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest.*;
import com.volcengine.ark.runtime.service.ArkService;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;

public class Sample {
    static String apiKey = System.getenv("ARK_API_KEY");
    static ConnectionPool connectionPool = new ConnectionPool(5, 1, TimeUnit.SECONDS);
    static Dispatcher dispatcher = new Dispatcher();
    static ArkService service = ArkService.builder()
            .dispatcher(dispatcher)
            .connectionPool(connectionPool)
            .apiKey(apiKey)
            .build();

    public static void main(String[] args) throws JsonProcessingException {
        List<ChatMessage> messagesForReqList = new ArrayList<>();
        ChatMessage elementForMessagesForReqList0 = ChatMessage.builder()
                .role(ChatMessageRole.SYSTEM)
                .content("你是豆包，是由字节跳动开发的 AI 人工智能助手。")
                .build();
        ChatMessage elementForMessagesForReqList1 = ChatMessage.builder().role(ChatMessageRole.USER).content("花椰菜是什么？")
                .build();
        ChatMessage elementForMessagesForReqList2 = ChatMessage.builder()
                .role(ChatMessageRole.ASSISTANT)
                .content("花椰菜又称菜花、花菜，是一种常见的蔬菜。")
                .build();
        ChatMessage elementForMessagesForReqList3 = ChatMessage.builder().role(ChatMessageRole.USER).content("再详细点。")
                .build();
        messagesForReqList.add(elementForMessagesForReqList0);
        messagesForReqList.add(elementForMessagesForReqList1);
        messagesForReqList.add(elementForMessagesForReqList2);
        messagesForReqList.add(elementForMessagesForReqList3);

        ChatCompletionRequest req = ChatCompletionRequest.builder()
                .model("<MODEL>")// 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
                .messages(messagesForReqList)
                .build();
        service.createChatCompletion(req)
                .getChoices()
                .forEach(choice -> System.out.println(choice.getMessage().getContent()));
        // shutdown service after all requests is finished
        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


<span id="78d5cc11"></span>
## 流式输出
随着大模型输出，动态输出内容。无需等待模型推理完毕，即可看到中间输出过程内容，可以缓解用户等待体感（一边输出一边看内容），效果如下所示。
<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0b0ed47ec1b94b20a4f4966aa80130e6~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0b0ed47ec1b94b20a4f4966aa80130e6~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer>

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="W7uJnozJah"><RenderMd content={`\`\`\`Bash
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer \$ARK_API_KEY" \\
  -d '{
    "model": "<MODEL>",
    "messages": [
        {
            "role": "user",
            "content": "你好"
        }
    ],
    "stream": true
  }'
\`\`\`


* 替换\`<MODEL>\`  为Model ID，查询Model ID见 [模型列表](https://www.volcengine.com/docs/82379/1330310)。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="kItrShNfDB"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark
# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
client = Ark(
    api_key=os.environ.get("ARK_API_KEY"),
)

completion = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
    model="<MODEL>",
    messages=[
        {"role": "system", "content": "你是 AI 人工智能助手"},
        {"role": "user", "content": "常见的十字花科植物有哪些？"},
    ],
    stream=True,
)

with completion: # 确保在代码块执行完毕后自动关闭连接，避免链接泄露
    for chunk in completion:
        if chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
\`\`\`

:::tip
\`with completion \`：当 with 代码块内出现异常时，会自动调用对象的 __exit__() 方法进行清理工作。当设置了max_tokens 等中断条件时，可以避免socket层数据载满最终程序卡住。
:::
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="p5toSsoL86"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "io"
    "os"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
        os.Getenv("ARK_API_KEY"),
    )
    
    ctx := context.Background()

    fmt.Println("----- standard request -----")
    req := model.CreateChatCompletionRequest{
        // 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
       Model: "<MODEL>",
       Messages: []*model.ChatCompletionMessage{
          {
             Role: model.ChatMessageRoleSystem,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("你是豆包，是由字节跳动开发的 AI 人工智能助手"),
             },
          },
          {
             Role: model.ChatMessageRoleUser,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("常见的十字花科植物有哪些？"),
             },
          },
       },
       Stream: volcengine.Bool(true),
    }

    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
       fmt.Printf("standard chat error: %v\n", err)
       return
    }
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="TsxfGhKFHR"><RenderMd content={`\`\`\`java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;
import java.util.ArrayList;
import java.util.List;

public class ChatCompletionsExample {
    public static void main(String[] args) {
        String apiKey = System.getenv("ARK_API_KEY");
        ArkService service = ArkService.builder().apiKey(apiKey).build();
        System.out.println("\n----- standard request -----");
        final List<ChatMessage> messages = new ArrayList<>();
        final ChatMessage systemMessage = ChatMessage.builder().role(ChatMessageRole.SYSTEM).content("你是豆包，是由字节跳动开发的 AI 人工智能助手").build();
        final ChatMessage userMessage = ChatMessage.builder().role(ChatMessageRole.USER).content("常见的十字花科植物有哪些？").build();
        messages.add(systemMessage);
        messages.add(userMessage);

        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                .model("<MODEL>") 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
                .messages(messages)
                .stream(true)
                .build();
        service.createChatCompletion(chatCompletionRequest).getChoices().forEach(choice -> System.out.println(choice.getMessage().getContent()));
        // shutdown service
        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="0fa48070"></span>
## Function Calling
支持工具调用模型请参见 [支持范围](https://www.volcengine.com/docs/82379/1262342#8c325d45)，更详细的 Function Calling 使用教程请参见 [工具调用 Function Calling](https://www.volcengine.com/docs/82379/1262342)。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python SDK" key="ZAljBplNqT"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
client = Ark(
    api_key=os.environ.get("ARK_API_KEY"),
)

print("----- function call request -----")
completion = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
    model="<MODEL>",
    messages = [
        {"role": "user", "content": "北京今天天气如何？"},
    ],
    tools=[
        {
            "type": "function",
            "function": {
                "name": "get_current_weather",
                "description": "获取给定地点的天气",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "地点的位置信息，比如北京"
                        },
                        "unit": {
                            "type": "string",
                            "enum": [
                                "摄氏度",
                                "华氏度"
                            ]
                        }
                    },
                    "required": [
                        "location"
                    ]
                }
            }
        }
    ]
)
print(completion.choices[0])
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="LH75xHgqpp"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "os"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
       // 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
       os.Getenv("ARK_API_KEY"),
    )
    
    ctx := context.Background()

    fmt.Println("----- function call request -----")
    req := model.CreateChatCompletionRequest{
       // 替换 <Model> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
       Model: "<MODEL>",
       Messages: []*model.ChatCompletionMessage{
          {
             Role: model.ChatMessageRoleUser,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("北京今天天气如何？"),
             },
          },
       },
       Tools: []*model.Tool{
          {
             Type: model.ToolTypeFunction,
             Function: &model.FunctionDefinition{
                Name:        "get_current_weather",
                Description: "获取给定地点的天气",
                Parameters: map[string]interface{}{
                   "type": "object",
                   "properties": map[string]interface{}{
                      "location": map[string]interface{}{
                         "type":        "string",
                         "description": "地点的位置信息，比如北京",
                      },
                      "unit": map[string]interface{}{
                         "type": "string",
                         "enum": []string{"摄氏度", "华氏度"},
                      },
                   },
                   "required": []string{"location"},
                },
             },
          },
       },
    }

    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
       fmt.Printf("standard chat error: %v\n", err)
       return
    }

    s, _ := json.Marshal(resp)
    fmt.Println(string(s))

}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="lPiR2v61OH"><RenderMd content={`\`\`\`java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.completion.chat.*;
import com.volcengine.ark.runtime.service.ArkService;
import java.util.*;

public class FunctionCallChatCompletionsExample {
    public static void main(String[] args) {
        String apiKey = System.getenv("ARK_API_KEY");
        ArkService service = ArkService.builder().apiKey(apiKey).build();

        System.out.println("\n----- function call request -----");
        final List<ChatMessage> messages = new ArrayList<>();
        final ChatMessage userMessage = ChatMessage.builder().role(ChatMessageRole.USER).content("北京今天天气如何？").build();
        messages.add(userMessage);

        final List<ChatTool> tools = Arrays.asList(
                new ChatTool(
                        "function",
                        new ChatFunction.Builder()
                                .name("get_current_weather")
                                .description("获取给定地点的天气")
                                .parameters(new Weather(
                                        "object",
                                        new HashMap<String, Object>() {{
                                            put("location", new HashMap<String, String>() {{
                                                put("type", "string");
                                                put("description", "T地点的位置信息，比如北京");
                                            }});
                                            put("unit", new HashMap<String, Object>() {{
                                                put("type", "string");
                                                put("enum", Arrays.asList("摄氏度", "华氏度"));
                                            }});
                                        }},
                                        Collections.singletonList("location")
                                ))
                                .build()
                        )
        );

        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                .model("<MODEL>")    //替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
                .messages(messages)
                .tools(tools)
                .build();
        service.createChatCompletion(chatCompletionRequest).getChoices().forEach(System.out::println);

        // shutdown service
        service.shutdownExecutor();
    }

    public static class Weather {
        public String type;
        public Map<String, Object> properties;
        public List<String> required;

        public Weather(String type, Map<String, Object> properties, List<String> required) {
            this.type = type;
            this.properties = properties;
            this.required = required;
        }

        public String getType() {
            return type;
        }

        public void setType(String type) {
            this.type = type;
        }

        public Map<String, Object> getProperties() {
            return properties;
        }

        public void setProperties(Map<String, Object> properties) {
            this.properties = properties;
        }

        public List<String> getRequired() {
            return required;
        }

        public void setRequired(List<String> required) {
            this.required = required;
        }
    }

}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="9a18aa1f"></span>
## 异常处理
增加异常处理，帮助定位问题。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python SDK" key="FcudhkHI5t"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime._exceptions import ArkAPIError
from volcenginesdkarkruntime import Ark

client = Ark(
    api_key=os.environ.get("ARK_API_KEY"),
)

# Streaming:
print("----- streaming request -----")
try:
    stream = client.chat.completions.create(
        # 替换 <Model> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
        model="<MODEL>",
        messages=[
            {"role": "system", "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手"},
            {"role": "user", "content": "常见的十字花科植物有哪些？"},
        ],
        stream=True
    )
    for chunk in stream:
        if not chunk.choices:
            continue

        print(chunk.choices[0].delta.content, end="")
    print()
except ArkAPIError as e:
    print(e)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="B5UlAscEuA"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "errors"
    "fmt"
    "io"
    "os"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
        os.Getenv("ARK_API_KEY"),
    )
    ctx := context.Background()

    fmt.Println("----- streaming request -----")
    req := model.CreateChatCompletionRequest{
        // 替换 <Model> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
       Model: "<MODEL>",
       Messages: []*model.ChatCompletionMessage{
          {
             Role: model.ChatMessageRoleSystem,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("你是豆包，是由字节跳动开发的 AI 人工智能助手"),
             },
          },
          {
             Role: model.ChatMessageRoleUser,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("常见的十字花科植物有哪些？"),
             },
          },
       },
    }
    stream, err := client.CreateChatCompletionStream(ctx, req)
    if err != nil {
       apiErr := &model.APIError{}
       if errors.As(err, &apiErr) {
          fmt.Printf("stream chat error: %v\n", apiErr)
       }
       return
    }
    defer stream.Close()

    for {
       recv, err := stream.Recv()
       if err == io.EOF {
          return
       }
       if err != nil {
          apiErr := &model.APIError{}
          if errors.As(err, &apiErr) {
             fmt.Printf("stream chat error: %v\n", apiErr)
          }
          return
       }

       if len(recv.Choices) > 0 {
          fmt.Print(recv.Choices[0].Delta.Content)
       }
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="GJaCLZ4Xii"><RenderMd content={`\`\`\`java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.exception.ArkHttpException;
import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;

import java.util.ArrayList;
import java.util.List;


public class ChatCompletionsExample {
    public static void main(String[] args) {

        String apiKey = System.getenv("ARK_API_KEY");
        ArkService service = ArkService.builder().apiKey(apiKey).build();

        System.out.println("\n----- streaming request -----");
        final List<ChatMessage> streamMessages = new ArrayList<>();
        final ChatMessage streamSystemMessage = ChatMessage.builder().role(ChatMessageRole.SYSTEM).content("你是豆包，是由字节跳动开发的 AI 人工智能助手").build();
        final ChatMessage streamUserMessage = ChatMessage.builder().role(ChatMessageRole.USER).content("常见的十字花科植物有哪些？").build();
        streamMessages.add(streamSystemMessage);
        streamMessages.add(streamUserMessage);

        ChatCompletionRequest streamChatCompletionRequest = ChatCompletionRequest.builder()
                .model("<MODEL>") // 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
                .messages(streamMessages)
                .build();

        try {
            service.streamChatCompletion(streamChatCompletionRequest)
                    .doOnError(Throwable::printStackTrace)
                    .blockingForEach(
                            choice -> {
                                if (choice.getChoices().size() > 0) {
                                    System.out.print(choice.getChoices().get(0).getMessage().getContent());
                                }
                            }
                    );
        } catch (ArkHttpException e) {
            System.out.print(e.toString());
        }

        // shutdown service
        service.shutdownExecutor();
    }

}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="826f1d99"></span>
## Prefill Response模式
通过预填（Prefill）部分`Assistant` 角色的内容，来引导和控制模型的输出。输出的控制可以应用在多个方面：强制按照 JSON 或 XML 等特定格式输出；跳过已生成的内容，避免触发模型最大输出限制；控制大模型在角色扮演场景中保持同一角色。

> * 支持的模型：[Doubao-pro ［热门］](https://www.volcengine.com/docs/82379/1330310#00bbadc1)、[Doubao-lite](https://www.volcengine.com/docs/82379/1330310#5d9e965a) 0828版本及以后。
> * 更详细的场景使用说明，请参见[Prefill Response模式最佳实践](https://www.volcengine.com/docs/82379/1359497)。


```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python SDK" key="ytFqKND2Uq"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
client = Ark(
    api_key=os.environ.get("ARK_API_KEY"),
)
completion = client.chat.completions.create(
    # 替换 <Model> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
    model="<MODEL>",
    messages=[
        {"role": "user", "content": "你是一个计算器，请计算： 1 + 1 "},
        # 最后Role为Assistant，并补充部分内容，便于模型进行续写
        {"role": "assistant", "content": "="}
    ]
)
print(completion.choices[0].message.content)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="CwmlR1nbIx"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "io"
    "os"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
        os.Getenv("ARK_API_KEY"),
    )
    
    ctx := context.Background()

    fmt.Println("----- standard request -----")
    req := model.CreateChatCompletionRequest{
        // 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
       Model: "<MODEL>",
       Messages: []*model.ChatCompletionMessage{
            &model.ChatCompletionMessage{
                Role: "user",
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("你是一个计算器，请计算： 1 + 1"),
                },
            },
            &model.ChatCompletionMessage{
                Role: "assistant",
                Content: &model.ChatCompletionMessageContent{
                    StringValue: volcengine.String("="),
                },
            },
        },
    }

    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
       fmt.Printf("standard chat error: %v\n", err)
       return
    }
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="yOl34fAFpY"><RenderMd content={`\`\`\`java
package com.volcengine.sample;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.volcengine.ark.runtime.model.completion.chat.*;
import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest.*;
import com.volcengine.ark.runtime.service.ArkService;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;

public class Sample {
    static String apiKey = System.getenv("ARK_API_KEY");
    static ConnectionPool connectionPool = new ConnectionPool(5, 1, TimeUnit.SECONDS);
    static Dispatcher dispatcher = new Dispatcher();
    static ArkService service = ArkService.builder()
            .dispatcher(dispatcher)
            .connectionPool(connectionPool)
            .apiKey(apiKey)
            .build();

    public static void main(String[] args) throws JsonProcessingException {
        List<ChatMessage> messagesForReqList = new ArrayList<>();
        ChatMessage elementForMessagesForReqList1 = ChatMessage.builder()
                .role(ChatMessageRole.USER)
                .content("你是一个计算器，请计算： 1 + 1")
                .build();
        ChatMessage elementForMessagesForReqList2 = ChatMessage.builder()
                .role(ChatMessageRole.ASSISTANT)
                .content("=")
                .build();
        messagesForReqList.add(elementForMessagesForReqList1);
        messagesForReqList.add(elementForMessagesForReqList2);

        ChatCompletionRequest req = ChatCompletionRequest.builder()
                .model("<MODEL>")// 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
                .messages(messagesForReqList)
                .build();
        service.createChatCompletion(req)
                .getChoices()
                .forEach(choice -> System.out.println(choice.getMessage().getContent()));
        // shutdown service after all requests is finished
        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="09025857"></span>
## 对话加密
为了保证推理会话数据的传输安全，在默认的网络层加密方案基础上，为在线推理的会话数据提供了端到端应用层加密方案，更多能力介绍和原理信息请参见[推理会话数据应用层加密方案](https://www.volcengine.com/docs/82379/1389905)。
您可以通过增加一行代码免费使用本功能。

> * 仅支持Python SDK，需要保证 SDK 版本 `volcengine-python-sdk` `1.0.104`及以上，可以通过 `pip install 'volcengine-python-sdk[ark]' -U` 获得 SDK 的最新版本。
> * 仅支持豆包文本生成和深度思考模型。
> * 仅支持 `ChatCompletions` 中的单轮/多轮会话，支持流式/非流式，同步/异步接口。

示例代码如下
```Python
import os
from volcenginesdkarkruntime import Ark

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
client = Ark(
    api_key=os.environ.get("ARK_API_KEY"),
)

print("----- standard request -----")
completion = client.chat.completions.create(
    # 替换 <Model> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
    model="<MODEL>",
    messages = [
        {"role": "system", "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手"},
        {"role": "user", "content": "常见的十字花科植物有哪些？"},
    ],
    #按下述代码设置自定义header，免费开启推理会话应用层加密
    extra_headers={'x-is-encrypted': 'true'}
)
print(completion.choices[0].message.content)
```

<span id="3821b26a"></span>
## 设置模型回答长度限制
<span id="0001"><span> 


当您需要调整模型回答长度，如需控制成本，回答不超过500字；或回答篇幅较长，如翻译长文本，避免中途截断，可通过在请求时设置`max_tokens`字段，来达成目标。
> 控制模型输出长度（思维链+回答），请参见 [设置模型输出长度限制](https://www.volcengine.com/docs/82379/1449737#31ecc4d7)。


```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="Gci7tAxGBl"><RenderMd content={`\`\`\`Bash
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer \$ARK_API_KEY" \\
  -d '{
    "model": "<MODEL>",
    "messages": [
        {
            "role": "user",
            "content": "你好"
        }
    ],
    "max_tokens": 1024
  }'
\`\`\`


* 替换\`<MODEL>\`  为Model ID，查询Model ID见 [模型列表](https://www.volcengine.com/docs/82379/1330310)。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="X2gJbLOLzO"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark
# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
client = Ark(
    api_key=os.environ.get("ARK_API_KEY"),
)

completion = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
    model="<MODEL>",
    messages=[
        {"role": "system", "content": "你是 AI 人工智能助手"},
        {"role": "user", "content": "常见的十字花科植物有哪些？"},
    ],
    # 设置模型最大输出长度为 1024 token，您可以按需进行调整
    max_tokens=1024,
)
print(completion.choices[0].message.content)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="Zp8qG8WbQY"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "io"
    "os"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
        os.Getenv("ARK_API_KEY"),
    )
    
    ctx := context.Background()

    fmt.Println("----- standard request -----")
    req := model.CreateChatCompletionRequest{
        // 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
       Model: "<MODEL>",
       Messages: []*model.ChatCompletionMessage{
          {
             Role: model.ChatMessageRoleSystem,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("你是豆包，是由字节跳动开发的 AI 人工智能助手"),
             },
          },
          {
             Role: model.ChatMessageRoleUser,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("常见的十字花科植物有哪些？"),
             },
          },
       },
       MaxTokens: volcengine.Int(1024), // 设置最大输出长度为 1024 token
    }

    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
       fmt.Printf("standard chat error: %v\n", err)
       return
    }
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="MM3be3m3ec"><RenderMd content={`\`\`\`java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;
import java.util.ArrayList;
import java.util.List;

public class ChatCompletionsExample {
    public static void main(String[] args) {
        String apiKey = System.getenv("ARK_API_KEY");
        ArkService service = ArkService.builder().apiKey(apiKey).build();
        System.out.println("\n----- standard request -----");
        final List<ChatMessage> messages = new ArrayList<>();
        final ChatMessage systemMessage = ChatMessage.builder().role(ChatMessageRole.SYSTEM).content("你是豆包，是由字节跳动开发的 AI 人工智能助手").build();
        final ChatMessage userMessage = ChatMessage.builder().role(ChatMessageRole.USER).content("常见的十字花科植物有哪些？").build();
        messages.add(systemMessage);
        messages.add(userMessage);

        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                .model("<MODEL>")// 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
                .messages(messages)
                .maxTokens(1024)// 设置最大输出长度为 1024 token
                .build();
        service.createChatCompletion(chatCompletionRequest).getChoices().forEach(choice -> System.out.println(choice.getMessage().getContent()));
        // shutdown service
        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


<span id="0562cbf1"></span>
## 异步输出
当您的任务较为复杂或者多个任务并发等场景下，您可以使用Asyncio接口实现并发调用，提高程序的效率，优化体验。示例代码如下：

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python SDK" key="Qf4Y5nmTzg"><RenderMd content={`\`\`\`Python
import asyncio
import os
from volcenginesdkarkruntime import AsyncArk
# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
client = AsyncArk(
    api_key=os.environ.get("ARK_API_KEY"),
)

async def main() -> None:
    stream = await client.chat.completions.create(
        # 替换 <MODEL> 为模型的Model ID , 查询Model ID：https://www.volcengine.com/docs/82379/1330310
        model="<MODEL>",
        messages=[
            {"role": "system", "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手"},
            {"role": "user", "content": "常见的十字花科植物有哪些？"},
        ],
        stream=True
    )
    async for completion in stream:
        print(completion.choices[0].delta.content, end="")
    print()

asyncio.run(main())
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="e7543d57"></span>
## 批量推理
方舟为您提供批量推理的能力，当您有大批量数据处理任务，可以使用批量推理能力，以获得更大吞吐量和更低的成本。详细介绍和使用，请参见 [批量推理](https://www.volcengine.com/docs/82379/1399517)。
<span id="7196ca50"></span>
# 相关文档

* [对话（Chat） API](https://www.volcengine.com/docs/82379/1494384)：文本生成的API参数说明，调用模型的文本生成能力，可参考文本生成API参数说明。
* [常见问题](https://www.volcengine.com/docs/82379/1359411)-[在线推理](https://www.volcengine.com/docs/82379/1359411#aa45e6c0)：在线推理的常见问题，如果遇到错误，可以尝试在这里找解决方案。
* [Prefill Response模式最佳实践](https://www.volcengine.com/docs/82379/1359497)：提升多轮对话角色一致性，优化模型回复格式，缓解模型输出最大限制，可参考本解决方案。


<span id="4a486037"></span>
# 附1.应用场景
您可以在以下场景中使用模型的文本生成能力。

| | | | \
|场景 |场景细分 |描述 |
|---|---|---|
| | | | \
|内容创作 |文章生成 |自动生成文章、新闻、评论等实用文本，提高内容产出效率。 |
|^^| | | \
| |文本润色 |在新闻报道、博客文章创作中辅助作者进行创意构思和文本润色。 |
| | | | \
|智能交互 |智能客服 |在客服系统中生成自然流畅的回复，提升用户体验。 |
|^^| | | \
| |聊天机器人 |在线咨询、英语学习等领域，理解用户意图、按照要求并生成回复。 |
| | | | \
|个性化教学 |学科问题解答 |分析题目、考点说明、解题思路、解题结果。 |
|^^| | | \
| |语言学习 |按照要求，进行某些语种对话，帮助用户习惯目标语言日常交流。 |
| | | | \
|机器翻译 |自动翻译 |结合语音类模型，实现同声传译、日常字幕生成、文本语言翻译等等。 |
| | | | \
|工作处理 |数据处理 |根据读入的数据，根据任务要求进行处理，如读取研报、分析新闻、评价内容等。 |



# 视觉理解
Source: https://www.volcengine.com/docs/82379/1362931
部分大模型具备视觉理解能力，如当您传入图片或视频时，大模型可以理解图片或视频里的视觉信息，并结合这些信息完成如描述其中的物体等视觉相关任务。通过这篇教程，您可以学习到如何通过调用大模型 API 来识别传入图片和视频里的信息。

> * 查看[使用示例](https://www.volcengine.com/docs/82379/1362931#547c81e8)，了解常见调用方法。
> * 查看[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)，检索 API 字段参数说明。
> * 查看[视频理解](https://www.volcengine.com/docs/82379/1362931#3c06d308)示例，和[视频理解](https://www.volcengine.com/docs/82379/1362931#1aba7aee)使用说明。

<span id="31778cb5"></span>
# 支持模型
当前支持视觉理解的模型请参见[视觉理解](https://www.volcengine.com/docs/82379/1330310#ff5ef604)。
<span id="2ce4ac9b"></span>
# 前提条件
* [获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) 。
   * 使用 Access Key 鉴权请参考[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
* [开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需 Model ID 。
   * 通过 Endpoint ID 调用模型服务请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。



<span id="18cf565a"></span>
# 快速开始
支持视觉理解的大模型当前支持在请求中传入图片链接，图片信息需要作为用户角色输入信息传给大模型，即`"role": "user"`，下面是简单的视觉模型调用示例代码。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="图片理解" key="OkoUAdJM8k"><RenderMd content={`\`\`\`Python
import os
# 通过 pip install volcengine-python-sdk[ark] 安装方舟SDK
from volcenginesdkarkruntime import Ark

# 替换 <MODEL> 为模型的Model ID
model="<MODEL>"

# 初始化Ark客户端，从环境变量中读取您的API Key
client = Ark(
    api_key=os.getenv('ARK_API_KEY'),
    )

# 创建一个对话请求
response = client.chat.completions.create(
    # 指定您部署了视觉理解大模型的推理接入点ID
    model = model,
    messages = [
        {
            # 指定消息的角色为用户
            "role": "user",  
            "content": [   
                # 图片信息，希望模型理解的图片
                {"type": "image_url", "image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"},},
                # 文本消息，希望模型根据图片信息回答的问题
                {"type": "text", "text": "支持输入是图片的模型系列是哪个？"}, 
            ],
        }
    ],
)

print(response.choices[0].message.content)
\`\`\`

模型回复预览：
\`\`\`Shell
根据表格中的信息，支持输入是图片的模型系列是 **Doubao-1.5-vision**。
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="视频理解" key="HMWx9aN0Ec"><RenderMd content={`\`\`\`Python
import os
# 通过 pip install volcengine-python-sdk[ark] 安装方舟SDK
from volcenginesdkarkruntime import Ark

# 替换 <MODEL> 为模型的Model ID
model="<MODEL>"

# 初始化Ark客户端，从环境变量中读取您的API Key
client = Ark(
    api_key=os.getenv('ARK_API_KEY'),
    )

# 创建一个对话请求
response = client.chat.completions.create(
    # 指定您部署了视觉理解大模型的推理接入点ID
    model = model,
    messages = [
        {
            # 指定消息的角色为用户
            "role": "user",  
            "content": [   
                {
                    "type": "video_url",
                    "video_url": {
                        # 您可以替换链接为您的实际视频链接
                        "url":  "https://ark-project.tos-cn-beijing.volces.com/doc_video/ark_vlm_video_input.mp4",
                    }
                },
            ],
        }
    ],
)

print(response.choices[0].message.content)
\`\`\`

模型回复预览
\`\`\`JSON
视频里展示了一座著名的钟楼，钟楼的外观是典型的哥特式建筑风格，钟面清晰可见。钟楼的右侧是一条繁忙的桥梁，桥上有许多车辆在行驶，包括红色的双层巴士。背景中可以看到城市的天际线，高楼大厦林立，天空中有一些云彩，整体氛围显得宁静而繁忙。视频右下角有“AI生成”的字样，表明这是由人工智能生成的图像。
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="09d30d63"></span>
# 使用说明
:::tip
处理完图片/视频后，图片/视频会从方舟服务器删除。方舟不会保留您提交的图片、视频以及文本信息等用户数据来训练模型。
:::
<span id="df962800"></span>
## 图片理解
<span id="4be57c22"></span>
### 图片传入方式
图片 URL 或图片 Base64 编码。用图片 URL 方式时，需确保图片 URL 可被访问。
:::tip
如果您希望获得更低的时延和成本，可以使用TOS（火山引擎对象存储）存储图片并生成访问链接。方舟与TOS网络打通，可使用内网通信，具备好处：

* 高速访问图片速度，降低模型回复的时延。
* 降低公网访问图片产生的高昂流量成本。
:::
视觉理解接口 [对话(Chat) API](https://www.volcengine.com/docs/82379/1494384) 是无状态的，如果您需要模型多次理解同一张图片，则每次请求时都需要传入该图片信息。
<span id="6412ed90"></span>
### 图片像素说明
方舟在处理图片前会先行进行图片尺寸判断，如果图片超出下面的限制，会直接报错。

* 新版模型（`doubao-1-5-vision-pro-32k-250115`及以后版本 ），传入图片满足下面条件（单位 px）：
   * 宽 > 14 且 高>14。
   * 宽*高范围： [196, 3600万]。
* 旧版模型：（` doubao-vision-pro-32k-241028`、`doubao-vision-lite-32k-241025` ），传入图片满足下面条件（单位 px）：
   * 宽和高长度范围：`[10, 6000]`。
   * 宽/高范围：`[1/100,100]`。

:::tip
在模型处理图片信息前，方舟会做压缩图片等预处理。您也可根据业务需求，自行压缩或裁剪图片，可减少图片传入时报错，降低 token 消耗以及降低 TTFT（首个 token 响应时间）。推荐减少的单张图片像素（`宽×高`）至下面范围内。

* 新版模型：`detail:low`模式下，104万（1024×1024） px；`detail:high`模式下，401万（2048×1960） px。
* 旧版模型：`detail:low`模式下，80万（896×896） px；`detail:high`模式下，320万（1792×1792） px。

其中`detail:low`、`detail:high`，指低/高精度理解图像，具体说明请参见[理解图像的深度控制](https://www.volcengine.com/docs/82379/1362931#bf4d9224)。
压缩图片示例代码，请参见应用案例：[最佳实践-上传本地图片进行分析](https://www.volcengine.com/docs/82379/1362931#f6bc4e62)。
:::
<span id="8c5c16c8"></span>
### 图片数量说明
单次请求传入图片数量受限于模型最大上下文长度（模型最大上下文长度见[视觉理解能力](https://www.volcengine.com/docs/82379/1330310#ff5ef604)模型）。当输入信息过长，譬如上下文长度 32k 的模型，传入 25 张图片，触发了模型上下文长度限制，信息会被截断后处理。
> 举例说明：

> * 当图片分辨率高，使用模型上下文窗口限制为 32k，每个图片转为 1312 个 token ，单轮可传入的图片数量为 `32000 ÷ 1312 = 24  `张。
> * 当图片分辨率小，使用模型上下文窗口限制为 32k，每个图片转为 256 个 token，单轮可传入的数量为 `32000 ÷ 256 = 125` 张。

:::tip
模型对图片理解以及内容回复的质量，受到同时处理图片信息量的影响。单次请求过多的图片张数会导致模型回复质量下滑，以及超出模型上下文限制，为了更好的回复质量，建议您合理控制传入图片的数量。
:::
<span id="7e6d3851"></span>
### 图片文件容量
单张图片小于 10 MB。
使用 base64 编码，请求中请求体大小不可超过 64 MB。
<span id="2d46b64d"></span>
### 图文传入顺序
提示词支持图片和文字混排，但图文顺序可能对模型的输出效果产生影响。在提示词构成为多张图片+1段文字，建议将文字放在提示词最后。
<span id="f9ea084e"></span>
### token 用量说明
token 用量，根据图片宽高像素计算可得。图片转化 token 的公式为：
```Plain Text
min(图片宽 * 图片高÷784, 单图 token 限制)
```

新版模型（`doubao-1-5-vision-pro-32k-250115`及以后版本）支持对图像有更精细理解：

* `detail:high`模式下，单图 token 限制升至 5120 token。
* `detail:low`模式下，单图 token 限制 1312 token。

旧版模型（ `doubao-vision-pro-32k-241028`、`doubao-vision-lite-32k-241025`） ：

* `detail:high`模式、`detail:low`模式，单图 token 限制均为 1312 token。

图片尺寸为 `1280 px × 720 px`，即宽为 1280 px，高为 720 px，传入模型图片 token 限制为 1312，则理解这张图消耗的 token 为`1280×720÷784=1176`，因为小于 1312，消耗 token 数为 1176 。
图片尺寸为 `1920 px × 1080 px`，即宽为 1920 px，高为 1080 px，传入模型图片 token 限制为 1312，则理解这张图消耗的 token 为`1920×1080÷784=2645`，因为大于 1312，消耗 token 数为 1312 。这时会压缩 token，即图片的细节会丢失部分，譬如字体很小的图片，模型可能就无法准确识别文字内容。
<span id="5f46bf24"></span>
### 图片格式说明
支持的图片格式如下表，注意文件后缀匹配图片格式，即图片文件扩展名（URL传入时）、图片格式声明（Base64 编码传入时）需与图片实际信息一致。

   
   | | | | \
   |**图片格式** |**文件扩展名** |**内容格式** **Content Type** |\
   | | | |\
   | | |> * [上传图片至对象存储时设置](https://www.volcengine.com/docs/6349/145523#%E8%AE%BE%E7%BD%AE%E6%96%87%E4%BB%B6%E5%85%83%E6%95%B0%E6%8D%AE)。 |\
   | | |> * 传入图片 Base64 编码时使用：[Base64 编码输入](https://www.volcengine.com/docs/82379/1362931#f6222fec)。 |\
   | | |> * 图片格式指定需使用小写 |
   |---|---|---|
   | | | | \
   |JPEG |.jpg, .jpeg |`image/jpeg` |
   | | | | \
   |PNG |.png |`image/png` |
   | | | | \
   |GIF |.gif |`image/gif` |
   | | | | \
   |WEBP |.webp |`image/webp` |
   | | | | \
   |BMP |.bmp |`image/bmp` |
   | | | | \
   |TIFF |.tiff, .tif |`image/tiff` |
   | | | | \
   |ICO |.ico |`image/x-icon` |
   | | | | \
   |DIB |.dib |`image/bmp` |
   | | | | \
   |ICNS |.icns |`image/icns` |
   | | | | \
   |SGI |.sgi |`image/sgi` |
   | | | | \
   |JPEG2000 |.j2c, .j2k, .jp2, .jpc, .jpf, .jpx |`image/jp2` |
   | | | | \
   |HEIC |\
   | |.heic |`image/heic` |\
   | | |> doubao-1.5-vision-pro及以后视觉理解能力模型支持 |
   | | | | \
   |HEIF |\
   | |.heif |`image/heif` |\
   | | |> doubao-1.5-vision-pro及以后视觉理解能力模型支持 |


:::tip
TIFF、 SGI、ICNS、JPEG2000 几种格式图片，需要保证和元数据对齐，如在对象存储中正确设置文件元数据，否则会解析失败。详细见 [使用视觉理解模型时，报错InvalidParameter？](https://www.volcengine.com/docs/82379/1359411#effccb14)
:::
<span id="8c9039b9"></span>
### API 参数字段说明
以下字段视觉理解暂不支持。

* 不支持设置频率惩罚系数，无 **frequency_penalty** 字段。
* 不支持设置存在惩罚系数，**presence_penalty** 字段。
* 不支持为单个请求生成多个返回，无 **n** 字段。

<span id="1aba7aee"></span>
## 视频理解
对视频按固定间隔抽取画面后，交由模型进行理解。
<span id="ea7689ca"></span>
### 视频格式说明

   
   | | | | \
   |**视频格式** |**文件扩展名** |**内容格式** **Content Type** |\
   | | | |\
   | | |> * [上传视频至对象存储时设置](https://www.volcengine.com/docs/6349/145523#%E8%AE%BE%E7%BD%AE%E6%96%87%E4%BB%B6%E5%85%83%E6%95%B0%E6%8D%AE)。 |\
   | | |> * 传入 Base64 编码时使用：[Base64 编码输入](https://www.volcengine.com/docs/82379/1362931#f6222fec)。 |\
   | | |> * 视频格式需小写 |
   |---|---|---|
   | | | | \
   |MP4 |.mp4 |`video/mp4` |
   | | | | \
   |AVI |.avi |`video/avi` |
   | | | | \
   |MOV |.mov |`video/quicktime` |


<span id="2a26390a"></span>
### 视频文件容量
单视频文件需在 50MB 以内。
<span id="0a667af0"></span>
### 不支持音频理解
暂不支持对视频文件中的音频信息进行理解。
<span id="04fcbe54"></span>
### 用量说明
单视频 token 用量范围在 [10k, 80k] ，单次请求视频最大 token 量还受模型的最大上下文窗口以及最大输入长度（当启用深度推理模式）限制，超出则请调整传入视频数量或视频长度。
方舟根据帧图像（某个时刻的视频画面，此处特指输入给模型的帧图像）张数（视频时长 * **fps** ），对帧图像进行压缩，以平衡对于视频的理解精度和 token 用量。帧图像会被等比例压缩至 [128 token, 640 token] ，对应像素范围在 [10万 像素, 50万像素]。

* 如`fps`过高或视频长度过长，需要处理的帧图像数量超出 640 帧（80×1024 token ÷ 128 token / 帧 = 640 帧），则按帧图像 128 token  `视频时长/640` 时间间隔均匀抽取 640帧。此时与请求中的配置不符，建议评估输出效果，按需调整视频时长或 **fps** 字段配置。
* 如`fps`过小或视频长度过短，需要处理的帧图像数量不足16帧（10×1024 token ÷ 640 token / 帧 = 16 帧），则按帧图像 640 token  `视频时长/16` 时间间隔均匀抽取 16帧。

<span id="547c81e8"></span>
# 使用示例
<span id="d86010f4"></span>
## 多图像输入
API 可以支持接受和处理多个图像输入，这些图像可以通过图片可访问 URL 或图片转为 Base64 编码后输入，模型将结合所有传入的图像中的信息来回答问题。
```Python
import os
# 通过 pip install volcengine-python-sdk[ark] 安装方舟SDK
from volcenginesdkarkruntime import Ark

# 从环境变量中获取API Key
client = Ark(
    api_key=os.getenv('ARK_API_KEY'),
    )

response = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID
    model="<MODEL>",
    messages=[
        {
            "role": "user",
            "content": [                
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"}},
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_2.png"}},
                {"type": "text", "text": "支持输入是图片的模型系列是哪个？同时，豆包应用场景有哪些？"},
            ],
        }
    ],
)

print(response.choices[0])
```

<span id="f6222fec"></span>
## Base64 编码输入
如果你要传入的图片/视频在本地，你可以将这个其转化为 Base64 编码，然后提交给大模型。下面是一个简单的示例代码。
:::warning
传入 Base64 编码格式时，请遵循以下规则：

* 传入的是图片：
   * 格式遵循`data:image/<图片格式>;base64,<Base64编码>`，其中，
      * 图片格式：`jpeg`、`png`、`gif`等，支持的图片格式详细见[图片格式说明](https://www.volcengine.com/docs/82379/1362931#5f46bf24)。
      * Base64 编码：图片的 Base64 编码。
* 传入的是视频：
   * 格式遵循`data:video/<视频格式>;base64,<Base64编码>`，其中，
      * 视频格式：`MP4`、`AVI`等，支持的视频格式详细见[视频格式说明](https://www.volcengine.com/docs/82379/1362931#ea7689ca)。
      * Base64 编码：视频的 Base64 编码。
:::

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="tY8jhpyJ2G"><RenderMd content={`\`\`\`Shell
BASE64_IMAGE=$(base64 < path_to_your_image.jpeg) && curl http://ark.cn-beijing.volces.com/api/v3/chat/completions \\
   -H "Content-Type: application/json"  \\
   -H "Authorization: Bearer $ARK_API_KEY"  \\
   -d @- <<EOF
   {
    "model": "doubao-seed-1-6-250615",
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "image_url",
            "image_url": {
              "url": "data:image/jpeg;base64,$BASE64_IMAGE"
            }
          },
          {
            "type": "text",
            "text": "图里有什么"
          }
        ]
      }
    ],
    "max_tokens": 300
  }
EOF
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python" key="BLMqfxLah7"><RenderMd content={`\`\`\`Python
import base64
import os
# 通过 pip install volcengine-python-sdk[ark] 安装方舟SDK
from volcenginesdkarkruntime import Ark

# 初始化一个Client对象，从环境变量中获取API Key
client = Ark(
    api_key=os.getenv('ARK_API_KEY'),
    )

# 定义方法将指定路径图片转为Base64编码
def encode_image(image_path):
  with open(image_path, "rb") as image_file:
    return base64.b64encode(image_file.read()).decode('utf-8')

# 需要传给大模型的图片
image_path = "path_to_your_image.jpg"

# 将图片转为Base64编码
base64_image = encode_image(image_path)

response = client.chat.completions.create(
  # 替换 <MODEL> 为模型的Model ID
  model="<MODEL>",
  messages=[
    {
      "role": "user",
      "content": [
        {
          "type": "image_url",
          "image_url": {
          # 需要注意：传入Base64编码前需要增加前缀 data:image/{图片格式};base64,{Base64编码}：
          # PNG图片："url":  f"data:image/png;base64,{base64_image}"
          # JPEG图片："url":  f"data:image/jpeg;base64,{base64_image}"
          # WEBP图片："url":  f"data:image/webp;base64,{base64_image}"
            "url":  f"data:image/<IMAGE_FORMAT>;base64,{base64_image}"
          },         
        },
        {
          "type": "text",
          "text": "图里有什么",
        },
      ],
    }
  ],
)

print(response.choices[0])
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java" key="yWF6CYODCM"><RenderMd content={`\`\`\`Java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.completion.chat.*;
import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionContentPart.*;
import com.volcengine.ark.runtime.service.ArkService;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.Base64;
import java.io.IOException; 


public class Sample {
 static String apiKey = System.getenv("ARK_API_KEY");

 static ConnectionPool connectionPool = new ConnectionPool(5, 1, TimeUnit.SECONDS);
 static Dispatcher dispatcher = new Dispatcher();
 static ArkService service =
 ArkService.builder()
 .dispatcher(dispatcher)
 .connectionPool(connectionPool)
 .apiKey(apiKey)
 .build();

 // Base64编码方法
 private static String encodeImage(String imagePath) throws IOException {
 byte[] imageBytes = Files.readAllBytes(Path.of(imagePath));
 return Base64.getEncoder().encodeToString(imageBytes);
 }

 public static void main(String[] args) throws Exception {

 List<ChatMessage> messagesForReqList = new ArrayList<>();

 // 本地图片路径（替换为实际路径）
 String imagePath = "/Users/bytedance/workspace/ark_vlm_bp/image/image.jpeg";

 // 生成Base64数据URL
 String base64Data = "data:image/jpeg;base64," + encodeImage(imagePath);

 // 构建消息内容（修复内容部分构建方式）
 List<ChatCompletionContentPart> contentParts = new ArrayList<>();

 // 图片部分使用builder模式
 contentParts.add(ChatCompletionContentPart.builder()
 .type("image_url")
 .imageUrl(new ChatCompletionContentPartImageURL(base64Data))
 .build());

 // 文本部分使用builder模式
 contentParts.add(ChatCompletionContentPart.builder()
 .type("text")
 .text("图里有什么")
 .build());

 // 创建消息
 messagesForReqList.add(ChatMessage.builder()
 .role(ChatMessageRole.USER)
 .multiContent(contentParts)
 .build());

 ChatCompletionRequest req =
 ChatCompletionRequest.builder()
 .model("doubao-1-5-vision-pro-32k-250115")
 .messages(messagesForReqList)
 .build();

 service.createChatCompletion(req)
 .getChoices()
 .forEach(choice -> System.out.println(choice.getMessage().getContent()));
 // shutdown service after all requests is finished
 service.shutdownExecutor();
 }
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go" key="mAvq2uUFE6"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "encoding/base64"
    "fmt"
    "os"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
)

func main() {
    // 读取本地图片文件
    imageBytes, err := os.ReadFile("path_to_your_image.jpeg") // 替换为实际图片路径
    if err != nil {
        fmt.Printf("读取图片失败: %v\n", err)
        return
    }
    base64Image := base64.StdEncoding.EncodeToString(imageBytes)

    client := arkruntime.NewClientWithApiKey(
        os.Getenv("ARK_API_KEY"),
        )
    ctx := context.Background()
    req := model.CreateChatCompletionRequest{
        Model: "doubao-seed-1-6-250615",
        Messages: []*model.ChatCompletionMessage{
            {
                Role: "user",
                Content: &model.ChatCompletionMessageContent{
                    ListValue: []*model.ChatCompletionMessageContentPart{
                        {
                            Type: "image_url",
                            ImageURL: &model.ChatMessageImageURL{
                                URL: fmt.Sprintf("data:image/jpeg;base64,%s", base64Image),
                            },
                        },
                        {
                            Type: "text",
                            Text: "图片主要讲了什么?",
                        },
                    },
                },
            },
        },
    }

    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
        fmt.Printf("standard chat error: %v\n", err)
        return
    }
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


<span id="bf4d9224"></span>
## 控制图片理解的精细度
控制图片理解的精细度（指对画面的精细）： **image_pixel_limit 、detail** 字段，2个字段若同时配置，则生效逻辑如下：

* 生效优先级：**image_pixel_limit** 高于 **detail** 字段，即同时配置 **detail** 与 **image_pixel_limit** 字段时，生效 **image_pixel_limit** 字段配置**。**
* 缺省时逻辑：**image_pixel_limit** 字段的 **min_pixels** / **max_pixels** 字段未设置，则使用 **detail** （默认值为`low`）设置配置的值对应的**min_pixels** 值 `3136` **** / **max_pixels** 值`1048576`。

下面分别介绍如何通过 **detail** 、 **image_pixel_limit** 控制视觉理解的精度。
<span id="885d96dc"></span>
### 通过 detail 字段（图片理解）
你可以通过`detail`参数来控制模型理解图片的精细度，以及返回速度，计费公式请参见[token 用量说明](https://www.volcengine.com/docs/82379/1362931#f9ea084e)。

* `low`：“低分辨率”模式，处理速度会提高，适合图片本身细节较少或者只需要模型理解图片大致信息或者对速度有要求的场景。此时 **min_pixels** 取值`3136`、**max_pixels** 取值`1048576`，超出此像素范围且小于3600w px的图片（超出3600w px 会直接报错）将会等比例缩放至范围内。
* `high`：“高分辨率”模式，这代表模型会理解图片更多的细节，但是处理图片速度会降低，适合需要模型理解图像细节，图像细节丰富，需要关注图片细节的场景。此时 **min_pixels** 取值`3136`、**max_pixels** 取值`4014080`，超出此像素范围且小于3600w px的图片（超出3600w px 会直接报错）的图片将会等比例缩放至范围内。
* `auto`：采用“低分辨率”模式。
> * 新版模型（`doubao-1-5-vision-pro-32k-250115`及以后版本）：采用`low`模式。
> * 旧版模型（`doubao-vision-pro-32k-241028`、`doubao-vision-lite-32k-241025`）：根据图片分辨率，自行选择模式。

```Python
import os
# 可通过 pip install volcengine-python-sdk[ark] 安装方舟SDK 
from volcenginesdkarkruntime import Ark

# 初始化一个Client对象，从环境变量中获取API Key
client = Ark(
    api_key=os.getenv('ARK_API_KEY'),
    )

# 调用 Ark 客户端的 chat.completions.create 方法创建聊天补全请求
response = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID
    model="<MODEL>",
    messages=[
        {
            # 消息角色为用户
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    # 第一张图片链接及细节设置为 high
                    "image_url": {
                        # 您可以替换图片链接为您的实际图片链接
                        "url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png",
                        "detail": "high"
                    }
                },
                # 文本类型的消息内容，询问图片里有什么
                {"type": "text", "text": "图片里有什么？"},
            ],
        }
    ],
)

print(response.choices[0])
```

<span id="d2b576dd"></span>
### **通过 image_pixel_limit 结构体**
控制传入给方舟的图像像素大小范围，如果不在此范围，则会等比例放大或者缩小至该范围内，后传给模型进行理解。您可以通过 **image_pixel_limit** 结构体，精细控制模型可理解的图片像素多少。
对应结构体如下：
```Bash
"image_pixel_limit": {
            "max_pixels": 3014080,   # 图片最大像素
            "min_pixels": 3136       # 图片最小像素
}
```

示例代码如下：
```Python
import os
# 可通过 pip install volcengine-python-sdk[ark] 安装方舟SDK 
from volcenginesdkarkruntime import Ark

# 初始化一个Client对象，从环境变量中获取API Key
client = Ark(
    api_key=os.getenv('ARK_API_KEY'),
    )

# 调用 Ark 客户端的 chat.completions.create 方法创建聊天补全请求
response = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID
    model="<MODEL>",
    messages=[
        {
            # 消息角色为用户
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    # 第一张图片链接及细节设置为 high
                    "image_url": {
                        # 您可以替换图片链接为您的实际图片链接
                        "url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png",
                        "image_pixel_limit": {
                            "max_pixels": 3014080,
                            "min_pixels": 3136,
                        },
                    }
                },
                # 文本类型的消息内容，询问图片里有什么
                {"type": "text", "text": "图片里有什么？"},
            ],
        }
    ],
)

print(response.choices[0])
```

<span id="3c06d308"></span>
## 控制视频理解的精细度
> 当前支持视频理解的模型见[视觉理解能力](https://www.volcengine.com/docs/82379/1330310#ff5ef604)，简单示例见 [快速开始](https://www.volcengine.com/docs/82379/1362931#18cf565a)

您可通过 **fps** 字段，控制从视频中抽取图像的频率，默认为1，即每秒从视频中抽取一帧图像，输入给模型进行视觉理解。 可通过 **fps** 字段，控制模型对于视频中图像变化的敏感度。

* 当视频画面变化剧烈或需关注画面变化，如计算视频中角色动作次数，可调高 **fps** 设置（最高 `5`），防止抽帧频率低导致误判。
* 当视频画面变化不频繁或无需关注画面变化，如画面中人数，可调低 **fps** （最低`0.2`），可提升处理速度，节省 token 用量。

示例代码如下：
```Python
import os
# 可通过 pip install volcengine-python-sdk[ark] 安装方舟SDK 
from volcenginesdkarkruntime import Ark

# 初始化一个Client对象，从环境变量中获取API Key
client = Ark(
    api_key=os.getenv('ARK_API_KEY'),
    )

# 调用 Ark 客户端的 chat.completions.create 方法创建聊天补全请求
response = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID
    model="<MODEL>",
    messages=[
        {
            # 消息角色为用户
            "role": "user",
            "content": [
                {
                    "type": "video_url",
                    # 第一张图片链接及细节设置为 high
                    "video_url": {
                        # 您可以替换图片链接为您的实际图片链接
                        "url":  "https://ark-project.tos-cn-beijing.volces.com/doc_video/ark_vlm_video_input.mp4",
                        "fps": 2, # 每秒截取2帧画面，用于视频理解
                    }
                },
                # 文本类型的消息内容，询问图片里有什么
                {"type": "text", "text": "视频里有什么？"},
            ],
        }
    ],
)

print(response.choices[0])
```

<span id="26737fa8"></span>
## 使用BotChatCompletions接口
您可调用配置视觉理解模型的bot，同时配置支持的插件（联网、文件解析等），增强模型能力，如拍照查，根据图片绘制表格、开发前端代码等任务。

* 配置应用请参见：
   * [1.1 创建模型推理接入点](https://www.volcengine.com/docs/82379/1267885#_1-1-创建模型推理接入点)。
   * [2. 零代码智能体创建](https://www.volcengine.com/docs/82379/1267885#_2-零代码智能体创建)。

示例代码如下：
```python
import os
from volcenginesdkarkruntime import Ark

client = Ark(
    api_key=os.environ.get("ARK_API_KEY"),
)

print("----- standard request -----")
completion = client.bot_chat.completions.create(
    model="<YOUR_BOT_ID>",
    messages = [
        {
            "role": "user",  # 指定消息的角色为用户
            "content": [  # 消息内容列表    
                {
                    "type": "image_url",  # 图片消息
                    # 图片的URL，需要大模型进行理解的图片链接
                    "image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"}
                },
                {"type": "text", "text": "支持输入是图片的模型系列是哪个？"},  # 文本消息
            ],
        }
    ],
)
print(completion.choices[0].message.content)
print(completion.references)
```

<span id="474e4601"></span>
## 图文混排
支持灵活地传入提示词和图片信息的方式，您可以任意调整传图图片和文本的顺序，以及在`system message`或者`User message`传入图文信息。模型会根据顺序返回处理信息的结果，示例如下。
> 提示词支持图片和文字混排输入给模型，但图文顺序可能对模型的输出效果产生影响，特别是在图片较多且只有一段文字的情况下，建议拼接时将文字放在图片之后。

```Python
import os
# 安装&升级SDK https://www.volcengine.com/docs/82379/1541595
from volcenginesdkarkruntime import Ark

# 初始化Ark客户端，从环境变量中读取您的API Key
client = Ark(
    api_key=os.getenv('ARK_API_KEY'),
    )
# 创建一个对话请求
response = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID
    model="<MODEL>",
        messages=[
        {
            "role": "system",
            "content": [
                {"type": "text", "text": "下面人物是目标人物"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/target.png"
                    },
                },
                {"type": "text", "text": "请确认下面图片中是否含有目标人物"},
            ],
        },
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "图片1中是否含有目标人物"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/scene_01.png"
                    },
                },
                {"type": "text", "text": "图片2中是否含有目标人物"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/scene_02.png"
                    },
                },
                
            ],
        },
    ],
)

print(response.choices[0].message.content)
```

:::warning
图文混排场景，图片与文本顺序会影响模型输出效果，如果输入结果与预期不符，可以尝试更换图文和文本的顺序。
:::
<span id="5fdeb294"></span>
## 视觉定位（Visual Grounding）
请参见教程 [视觉定位 Grounding](https://www.volcengine.com/docs/82379/1616136)。
<span id="52afa2e1"></span>
## GUI任务处理
请参见教程 [GUI 任务处理](https://www.volcengine.com/docs/82379/1584296)。
<span id="41d02620"></span>
# 最佳实践-深度思考模式
doubao-1-5-vision-pro-250328 模型，支持使用以下System Prompt，开启深度思考模型，并获得最佳效果。
```Plain Text
You should first think about the reasoning process in the mind and then provide the user with the answer. The reasoning process is enclosed within <think> </think> tags, i.e. <think> reasoning process here </think>here answer
```

下面是简单回复示例。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="模型回复说明" key="UrLa9WVvly"><RenderMd content={`通过System Prompt开启思考模型时，思考内容不会通过response中的reasoning_content字段输出。思考内容与回答内容，均通过response中的content字段输出。
例如：
\`\`\`Plain Text
<think>
思考内容
</think>
回答内容
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="模型回复示例" key="qseMJu5cUY"><RenderMd content={`\`\`\`Plain Text
<think>
好，现在用户需要详细描述四张图片并分类。先看第一张：广阔草原，远景山脉森林，中景草地颜色渐变，近景小黑点（可能动物或人）。自然景观，侧重地形植被——判断为自然风景类。

第二张：猴子特写，手持食物，周围绿叶红花。主体动物与植物互动，环境有蓝天。虽有植物但主体是动物行为——动物类。

第三张：松鼠在树枝，啃食东西，茂密树叶。主体野生动物栖息状态，自然环境但聚焦动物——动物类。

第四张：狗在砖墙，建筑遗迹背景。动物（狗）与人工建筑（砖墙）结合，但主体是动物状态？但砖墙属人文元素。不过分类可能看主体：若动物为主则动物类，若强调建筑与动物互动？但通常第四张狗是主体，砖墙背景。但再检查：

分类逻辑：自然风景（无动物主体，纯景观）、动物（主体动物）、人文？但第四张砖墙是人造结构，但图片主体是狗。看示例分类：比如第一张纯风景，后三张主体动物。但第四张狗在古迹？不过用户给的例子可能分自然风景、动物。检查第四张描述：狗躺砖墙，砖墙是背景，主体动物。所以分类：

图1：自然风景（草原山脉）

图2、3、4：动物（猴子、松鼠、狗）

描述时详细刻画元素：图1的色彩层次（黄绿草地、深绿森林、山脉轮廓），图2猴子动作（手持食物、树叶花朵衬托），图3松鼠姿态（树枝位置、啃食细节），图4狗的表情（放松）与砖墙质感（古老）。
</think>
### 图片1：草原山脉景观  
**描述**：画面展现开阔的自然景观。前景是大片**黄绿渐变的草地**，中景有几处小黑点（可能是动物或行人），中远景是**起伏的山脉**，山坡覆盖着茂密的**深绿色森林**，与浅绿色草坡形成层次。天空清澈，点缀几缕白云。整体氛围宁静，展现了**草原、森林、山脉**的自然壮美。  
**分类**：**自然风景类**（无动物主体，以地形、植被、天空构成纯自然景观）。

### 图片2：猴子进食  
**描述**：主体是一只**猴子**，坐在木质结构上，双手捧食物（可能是水果）。猴子毛发呈灰褐色，面部细节清晰。周围有**绿色树叶**和**鲜艳的红色花朵**（如三角梅），背景是淡蓝色天空。画面聚焦动物行为，通过植物衬托自然生境。  
**分类**：**动物类**（主体为野生动物，展现其觅食行为）。

### 图片3：松鼠栖息  
**描述**：一只**松鼠**倒挂在树枝上，啃食手中的食物。松鼠毛色棕黑相间，尾巴蓬松。背景是**茂密的绿叶**，树干纹理粗糙，光线明亮。画面捕捉动物的动态瞬间，突出其与树木（栖息地）的关系。  
**分类**：**动物类**（主体为野生动物，展现其栖息习性）。

### 图片4：犬类休憩  
**描述**：一只**黑白相间的狗**趴在**古老的砖墙**上，砖墙由红褐色石块堆砌，表面斑驳（可能是历史遗迹）。狗神态放松，张嘴露舌，背景简洁。画面结合**动物**与**人造建筑**，但主体是动物的状态。  
**分类**：**动物类**（尽管背景含人文元素，核心主体是动物）。


### 总结分类  
- **自然风景**：图1（纯自然地貌，无动物主体）。  
- **动物类**：图2（猴子）、图3（松鼠）、图4（狗）——均以动物为视觉焦点，展现其行为或状态。  

（若严格区分“动物 vs. 动物+人文”，图4可商榷，但通常摄影分类中“动物类”允许背景含环境元素，除非建筑占绝对主导。此组图中动物仍是图4的视觉中心。）
\`\`\`


`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="f6bc4e62"></span>
# 最佳实践-上传本地图片进行分析
下面介绍具体场景的应用案例，包括数据处理以及模型调用等端到端的案例。
处理图片通常会与网络存储结合起来使用，下面介绍如何结合对象存储 TOS，来实现完整的图片处理流程。
<span id="d21eccfc"></span>
## 代码流程
完整流程会分成以下步骤：

1. 压缩图片。分辨率会影响 token 消耗数量，可以通过图片压缩，来节省网络、存储以及模型分析成本。
2. 将压缩后的图片上传至对象存储 TOS，并为图片生成预签名 URL。

> 其中调用TOS需要使用Access Key，获取Access Key 请参见[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。


3. 调用视觉理解大模型分析图片。

<span id="d4b9b207"></span>
## 示例代码

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python" key="Jxt3brK2PC"><RenderMd content={`1. 安装依赖。
   \`\`\`Shell
   pip install -r requirements.txt
   \`\`\`

   \`requirements.txt\`文本内容如下：
   \`\`\`Shell
   Pillow
   volcengine-python-sdk[ark]
   tos
   \`\`\`

2. 示例代码。
   \`\`\`Python
   import os
   import tos
   from PIL import Image
   from tos import HttpMethodType
   from volcenginesdkarkruntime import Ark
   
   # 从环境变量获取 Access Key/API Key信息
   ak = os.getenv('VOLC_ACCESSKEY')
   sk = os.getenv('VOLC_SECRETKEY')
   api_key = os.getenv('ARK_API_KEY')
   # 配置视觉理解模型的 Model ID
   model_id = '<MODEL>'
   
   # 压缩前图片
   original_file = "original_image.jpeg"
   # 压缩后图片存放路径
   compressed_file = "compressed_image.jpeg"
   # 压缩的目标图片大小，300KB
   target_size = 300 * 1024
   
   # endpoint 和 region 填写Bucket 所在区域对应的Endpoint。
   # 以华北2(北京)为例，region 填写 cn-beijing。
   # 公网域名endpoint 填写 tos-cn-beijing.volces.com
   endpoint, region = "tos-cn-beijing.volces.com", "cn-beijing"
   # 对象桶名称
   bucket_name = "demo-bucket-test"
   # 对象名称，例如 images 下的 compressed_image.jpeg 文件，则填写为 images/compressed_image.jpeg
   object_key = "images/compressed_image.jpeg"
   
   def compress_image(input_path, output_path):
       img = Image.open(input_path)
       current_size = os.path.getsize(input_path)
   
       # 粗略的估计压缩质量，也可以从常量开始，逐步减小压缩质量，直到文件大小小于目标大小
       image_quality = int(float(target_size / current_size) * 100)
       img.save(output_path, optimize=True, quality=int(float(target_size / current_size) * 100))
   
       # 如果压缩后文件大小仍然大于目标大小，则继续压缩
       # 压缩质量递减，直到文件大小小于目标大小
       while os.path.getsize(output_path) > target_size:
           img = Image.open(output_path)
           image_quality -= 10
           if image_quality <= 0:
               break
           img.save(output_path, optimize=True, quality=image_quality)
       return image_quality
   
   def upload_tos(filename, tos_endpoint, tos_region, tos_bucket_name, tos_object_key):
       # 创建 TosClientV2 对象，对桶和对象的操作都通过 TosClientV2 实现
       tos_client, inner_tos_client = tos.TosClientV2(ak, sk, tos_endpoint, tos_region), tos.TosClientV2(ak, sk,
                                                                                                         tos_endpoint,
                                                                                                         tos_region)
       try:
           # 将本地文件上传到目标桶中, filename为本地压缩后图片的完整路径
           tos_client.put_object_from_file(tos_bucket_name, tos_object_key, filename)
           # 获取上传后预签名的 url
           return inner_tos_client.pre_signed_url(HttpMethodType.Http_Method_Get, tos_bucket_name, tos_object_key)
       except Exception as e:
           if isinstance(e, tos.exceptions.TosClientError):
               # 操作失败，捕获客户端异常，一般情况为非法请求参数或网络异常
               print('fail with client error, message:{}, cause: {}'.format(e.message, e.cause))
           elif isinstance(e, tos.exceptions.TosServerError):
               # 操作失败，捕获服务端异常，可从返回信息中获取详细错误信息
               print('fail with server error, code: {}'.format(e.code))
               # request id 可定位具体问题，强烈建议日志中保存
               print('error with request id: {}'.format(e.request_id))
               print('error with message: {}'.format(e.message))
               print('error with http code: {}'.format(e.status_code))
           else:
               print('fail with unknown error: {}'.format(e))
           raise e
   
   
   if __name__ == "__main__":
       print("----- 压缩图片 -----")
       quality = compress_image(original_file, compressed_file)
       print("Compressed Image Quality: {}".format(quality))
   
       print("----- 上传至TOS -----")
       pre_signed_url_output = upload_tos(compressed_file, endpoint, region, bucket_name, object_key)
       print("Pre-signed TOS URL: {}".format(pre_signed_url_output.signed_url))
   
       print("----- 传入图片调用视觉理解模型 -----")
       client = Ark(api_key=api_key)
   
       # 图片输入:
       response = client.chat.completions.create(
           # 配置推理接入点
           model=model_id,
           messages=[
               {
                   "role": "user",
                   "content": [                    
                       {
                           "type": "image_url",
                           "image_url": {
                               "url": pre_signed_url_output.signed_url
                           }
                       },
                       {"type": "text", "text": "Which is the most secure payment app according to Americans?"},
                   ],
               }
           ],
       )
   
       print(response.choices[0])
   \`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go" key="mqACQQqiWS"><RenderMd content={`1. 安装GO SDK。
   * TOS GO SDK 安装请参见[文档](https://www.volcengine.com/docs/6349/93476)。
   * ARK JAVA SDK 安装请参见[文档](https://www.volcengine.com/docs/82379/1541595)。
2. 示例代码如下。

\`\`\`Go
package main

import (
    "context"
    "fmt"
    "image"
    "image/jpeg"
    "os"

    "github.com/volcengine/ve-tos-golang-sdk/v2/tos"
    "github.com/volcengine/ve-tos-golang-sdk/v2/tos/enum"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
)

const (
    targetSize          = int64(300 * 1024)       // 300KB
    originalImageFile   = "original_image.jpeg"   // 压缩前图片路径
    compressedImageFile = "compressed_image.jpeg" // 压缩后图片存放路径
    ep_id = "ep-****-***"  //配置你部署了视觉理解模型的推理接入点 Endpoint ID
    ep_id = "<MODEL>"  //配置视觉理解模型的 Model ID
    // Bucket 对应的 Endpoint，以华北2（北京）为例
    // 公网域名地址：https://tos-cn-beijing.volces.com
    endpoint, region = "https://tos-cn-beijing.volces.com", "cn-beijing"
    // 填写 对象存储BucketName
    bucketName = "*** Provide your bucket name ***"
    // 将文件上传到 images 目录下的 compressed_image.jpeg 文件
    objectKey = "images/compressed_image.jpeg"
)

var (
    accessKey = os.Getenv("VOLC_ACCESSKEY")
    secretKey = os.Getenv("VOLC_SECRETKEY")
    apiKey    = os.Getenv("ARK_API_KEY")
)

func compressImage(inputPath, outputPath string, targetSize int64) (int, error) {
    file, err := os.Open(inputPath)
    if err != nil {
       return -1, err
    }
    defer file.Close()

    img, _, err := image.Decode(file)
    if err != nil {
       return -1, err
    }

    outputFile, err := os.Create(outputPath)
    if err != nil {
       return -1, err
    }
    defer outputFile.Close()

    originalImageInfo, err := file.Stat()
    if err != nil {
       return -1, err
    }
    quality := int(float64(targetSize) / float64(originalImageInfo.Size()) * 100)

    for {
       err = jpeg.Encode(outputFile, img, &jpeg.Options{Quality: quality})
       if err != nil {
          return -1, err
       }

       info, err := outputFile.Stat()
       if err != nil {
          return -1, err
       }

       if info.Size() <= targetSize {
          break
       }

       quality -= 10
       if quality <= 0 {
          return -1, fmt.Errorf("无法压缩到目标大小")
       }

       outputFile.Close()
       outputFile, err = os.Create(outputPath)
       if err != nil {
          return -1, err
       }
    }

    return quality, nil
}
func uploadTos(ctx context.Context, endpoint, region, bucketName, objectKey, filePath string) (*tos.PreSignedURLOutput, error) {
    // 初始化客户端
    client, err := tos.NewClientV2(endpoint, tos.WithRegion(region), tos.WithCredentials(tos.NewStaticCredentials(accessKey, secretKey)))
    if err != nil {
       return nil, err
    }

    // 将压缩后的图片上传到tos
    output, err := client.PutObjectFromFile(ctx, &tos.PutObjectFromFileInput{
       PutObjectBasicInput: tos.PutObjectBasicInput{
          Bucket: bucketName,
          Key:    objectKey,
       },
       FilePath: filePath,
    })
    if err != nil {
       return nil, err
    }
    fmt.Println("PutObjectV2 Request ID:", output.RequestID)

    // 获取预签名下载链接
    innerClient, err := tos.NewClientV2(endpoint, tos.WithRegion(region), tos.WithCredentials(tos.NewStaticCredentials(accessKey, secretKey)))
    if err != nil {
       return nil, err
    }
    return innerClient.PreSignedURL(&tos.PreSignedURLInput{
       HTTPMethod: enum.HttpMethodGet,
       Bucket:     bucketName,
       Key:        objectKey,
    })
}

func main() {
    ctx := context.Background()

    fmt.Println("----- Compress Image -----")
    quality, err := compressImage(originalImageFile, compressedImageFile, targetSize)
    if err != nil {
       panic(err)
    }

    fmt.Println("Compressed Image Quality:", quality)

    fmt.Println("----- Upload Image To TOS -----")
    preSignedUrl, err := uploadTos(ctx, endpoint, region, bucketName, objectKey, compressedImageFile)
    if err != nil {
       return
    }
    fmt.Println("PreSignedUrl:", preSignedUrl.SignedUrl)

    fmt.Println("----- Image Input Chat -----")
    client := arkruntime.NewClientWithApiKey(apiKey)
    req := model.ChatCompletionRequest{
       Model: ep_id,
       Messages: []*model.ChatCompletionMessage{
          {
             Role: model.ChatMessageRoleUser,
             Content: &model.ChatCompletionMessageContent{
                ListValue: []*model.ChatCompletionMessageContentPart{                   
                   {
                      Type: model.ChatCompletionMessageContentPartTypeImageURL,
                      ImageURL: &model.ChatMessageImageURL{
                         URL: preSignedUrl.SignedUrl,
                      },
                   },
                   {
                      Type: model.ChatCompletionMessageContentPartTypeText,
                      Text: "Which is the most secure payment app according to Americans?",
                   },
                },
             },
          },
       },
    }

    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
       fmt.Printf("standard chat error: %v\n", err)
       return
    }
    fmt.Println(*resp.Choices[0].Message.Content.StringValue)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java" key="ltrWHXWWBD"><RenderMd content={`1. 安装Java SDK。
   * TOS JAVA SDK 安装请参见[文档](https://www.volcengine.com/docs/6349/93481)。
   * ARK JAVA SDK 安装请参见[文档](https://www.volcengine.com/docs/82379/1541595)。
2. 示例代码如下。

\`\`\`Java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionContentPart;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;
import com.volcengine.tos.TOSV2;
import com.volcengine.tos.TOSV2ClientBuilder;
import com.volcengine.tos.TosClientException;
import com.volcengine.tos.TosServerException;
import com.volcengine.tos.comm.HttpMethod;
import com.volcengine.tos.model.object.PreSignedURLInput;
import com.volcengine.tos.model.object.PreSignedURLOutput;
import com.volcengine.tos.model.object.PutObjectInput;
import com.volcengine.tos.model.object.PutObjectOutput;
import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;

import javax.imageio.ImageIO;
import javax.imageio.ImageWriteParam;
import javax.imageio.ImageWriter;
import javax.imageio.stream.ImageOutputStream;
import java.awt.image.BufferedImage;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.OutputStream;
import java.util.ArrayList;
import java.util.List;

public class VLMChatExample {

    private static final String TOS_ENDPOINT = "https://tos-cn-beijing.volces.com";
    private static final String REGION = "cn-beijing";
    private static final String ARK_API_KEY = System.getenv("ARK_API_KEY");
    private static final String VOLC_ACCESSKEY = System.getenv("VOLC_ACCESSKEY");
    private static final String VOLC_SECRETKEY = System.getenv("VOLC_SECRETKEY");
    private static final long TOS_EXPIRE_TIME = 3600;

    public static void compressImage(String inputImagePath, String outputImagePath, long targetSizeInBytes) throws IOException {
        File inputFile = new File(inputImagePath);
        BufferedImage img = ImageIO.read(inputFile);
        float quality = targetSizeInBytes * 1.0f / inputFile.length();
        try (ImageOutputStream ios = ImageIO.createImageOutputStream(new File(outputImagePath))) {
            ImageWriter writer = ImageIO.getImageWritersByFormatName("jpeg").next();
            ImageWriteParam param = writer.getDefaultWriteParam();
            param.setCompressionMode(ImageWriteParam.MODE_EXPLICIT);
            param.setCompressionQuality(quality);
            writer.setOutput(ios);
            writer.write(null, new javax.imageio.IIOImage(img, null, null), param);
            writer.dispose();
        }
    }

    public static void uploadImageToTOS(String filePath, String bucketName, String objectKey) throws Throwable {

        TOSV2 tos = new TOSV2ClientBuilder().build(REGION, TOS_ENDPOINT, VOLC_ACCESSKEY, VOLC_SECRETKEY);

        // step 1. 上传本地图片到tos
        File file = new File(filePath);
        try (FileInputStream inputStream = new FileInputStream(file)) {
            PutObjectInput putObjectInput = new PutObjectInput().setBucket(bucketName)
                    .setKey(objectKey).setContent(inputStream).setContentLength(file.length());
            PutObjectOutput output = tos.putObject(putObjectInput);
            System.out.println("putObject succeed, object's etag is " + output.getEtag());
            System.out.println("putObject succeed, object's crc64 is " + output.getHashCrc64ecma());
        } catch (IOException e) {
            System.out.println("putObject read file failed");
            e.printStackTrace();
            throw e;
        } catch (TosClientException e) {
            // 操作失败，捕获客户端异常，一般情况是请求参数错误，此时请求并未发送
            System.out.println("putObject failed");
            System.out.println("Message: " + e.getMessage());
            if (e.getCause() != null) {
                e.getCause().printStackTrace();
            }
            throw e;
        } catch (TosServerException e) {
            // 操作失败，捕获服务端异常，可以获取到从服务端返回的详细错误信息
            System.out.println("putObject failed");
            System.out.println("StatusCode: " + e.getStatusCode());
            System.out.println("Code: " + e.getCode());
            System.out.println("Message: " + e.getMessage());
            System.out.println("RequestID: " + e.getRequestID());
            throw e;
        } catch (Throwable t) {
            // 作为兜底捕获其他异常，一般不会执行到这里
            System.out.println("putObject failed");
            System.out.println("unexpected exception, message: " + t.getMessage());
            throw t;
        }
    }

    public static String getPreSignedURL(String bucketName, String objectKey) throws Throwable {

        TOSV2 tos = new TOSV2ClientBuilder().build(REGION, TOS_ENDPOINT, VOLC_ACCESSKEY, VOLC_SECRETKEY);

        // 生成预签名链接
        try {
            PreSignedURLInput input = new PreSignedURLInput().setBucket(bucketName).setKey(objectKey)
                    .setHttpMethod(HttpMethod.GET).setExpires(TOS_EXPIRE_TIME);
            PreSignedURLOutput output = tos.preSignedURL(input);
            System.out.println("preSignedURL succeed, the signed url is " + output.getSignedUrl());
            System.out.println("preSignedURL succeed, the signed header is " + output.getSignedHeader());
            return output.getSignedUrl();
        } catch (TosClientException e) {
            // 操作失败，捕获客户端异常，一般情况是请求参数错误，此时请求并未发送
            System.out.println("preSignedURL failed");
            System.out.println("Message: " + e.getMessage());
            if (e.getCause() != null) {
                e.getCause().printStackTrace();
            }
            throw e;
        } catch (Throwable t) {
            // 作为兜底捕获其他异常，一般不会执行到这里
            System.out.println("preSignedURL failed");
            System.out.println("unexpected exception, message: " + t.getMessage());
            throw t;
        }
    }

    public static void main(String[] args) throws Throwable {
        String filePath = "/your/path/to/your/image.jpeg";
        String compressedPath = "/your/path/to/compress/image.jpeg";
        String tosBucket = "{your bucket name}";
        // 您上传图片至存储桶的路径及名称，例如上传文件至tos的 images 下并命名为 compressed_image.jpeg 文件，则填写为 images/compressed_image.jpeg
        String objectKey = "{your object key}";
        // 1. 压缩图片
        try {
            compressImage(filePath, compressedPath, 300 * 1024);
        } catch (IOException e) {
            System.out.println("compressImage failed");
            e.printStackTrace();
            throw e;
        }
        // 2. 上传TOS
        try {
            uploadImageToTOS(compressedPath, tosBucket, objectKey);
        } catch (Throwable t) {
            System.out.println("uploadImageToTOS failed");
            t.printStackTrace();
            throw t;
        }
        // 3. 生成预签名链接
        String preSignedURL = "";
        try {
            preSignedURL = getPreSignedURL(tosBucket, objectKey);
        } catch (Throwable t) {
            System.out.println("getPreSignedURL failed");
            t.printStackTrace();
            throw t;
        }

        // 4. 调用大模型Chat
        ArkService service = new ArkService(ARK_API_KEY);

        System.out.println("----- image input -----");
        final List<ChatMessage> messages = new ArrayList<>();
        final List<ChatCompletionContentPart> multiParts = new ArrayList<>();
        multiParts.add(ChatCompletionContentPart.builder().type("image_url").imageUrl(
                new ChatCompletionContentPart.ChatCompletionContentPartImageURL(preSignedURL)
        ).build());
        multiParts.add(ChatCompletionContentPart.builder().type("text").text(
                "Which is the most secure payment app according to Americans?"
        ).build());
        final ChatMessage userMessage = ChatMessage.builder().role(ChatMessageRole.USER)
                .multiContent(multiParts).build();
        messages.add(userMessage);

        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                .model("{your ark model endpoint id}")
                .messages(messages)
                .build();

        service.createChatCompletion(chatCompletionRequest).getChoices().forEach(choice -> System.out.println(choice.getMessage().getContent()));
        // shutdown service
        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


<span id="54612bc0"></span>
# 相关文档

* [对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)：视觉理解 API 参数说明，调用模型的视觉理解能力，模型调用中出现错误，可参考视觉理解 API 参数说明。

<span id="b867b8aa"></span>
# 常见问题
[使用视觉理解模型时，报错InvalidParameter？](https://www.volcengine.com/docs/82379/1359411#effccb14)



# 视觉定位 Grounding
Source: https://www.volcengine.com/docs/82379/1616136
视觉定位（Visual Grounding，后简称 Grounding）是根据对自然语言的任务要求，在图片中找到对应的目标，并返回目标的坐标，需要模型具备视觉理解以及自然语言理解的能力。
和目标检测最大的区别在于，输入多了自然语言信息，在对物体进行定位时需要理解自然语言的信息。使用上更加灵活交互更加自然。

| || || \
|输入 | |输出 | |
|---|---|---|---|
| | | | | \
|原始图片 |提示词 |模型输出坐标 |按坐标绘图 |
| | | | | \
|![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/f9a8b28c25ac4d86979de8f52e73def6~tplv-goo7wpa0wc-image.image =1024x) |\
| |框出中间狼卡通形象的头部的位置，输出 bounding box 的坐标 |`<bbox>175 98 791 476</bbox>` |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/114267ea04e7424a8dc2e168c55b2ae8~tplv-goo7wpa0wc-image.image =1024x) |\
| | | | |


<span id="90aef7dd"></span>
# 支持模型
请参见[视觉理解能力](https://www.volcengine.com/docs/82379/1330310#ff5ef604)。
<span id="ea901635"></span>
# 前提条件
* [获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) 。
   * 使用 Access Key 鉴权请参考[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
* [开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需 Model ID 。
   * 通过 Endpoint ID 调用模型服务请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。



<span id="750b19d5"></span>
# 使用流程
:::tip
您可以在飞书[多维表格](https://bytedance.larkoffice.com/base/extension/replit_30ee7a1d654ae3e6?)中进行 Grounding 测试、体验和使用，适合快速体验、简单场景，无需编码。
:::
下面将基于示例代码，详细介绍grounding的使用流程。
<span id="cb799c3b"></span>
## 1. 环境准备与参数配置
首先导入必要的库，设置模型ID、图片路径和提示词等参数，并从环境变量中读取API密钥。
```Python
import os
import base64
import cv2
from volcenginesdkarkruntime import Ark

# 配置参数
DEFAULT_MODEL = "<MODEL>"  # 替换为实际的模型ID
IMAGE_PATH = "./ark_demo_img.png"
PROMPT = "框出中间狼卡通形象的头部的位置，输出 bounding box 的坐标"
BBOX_TAG_START = "<bbox>"
BBOX_TAG_END = "</bbox>"

# 读取API密钥
api_key = os.getenv("ARK_API_KEY")

# 创建Ark客户端
client = Ark(
    api_key=api_key,
)
```


<span id="c6651960"></span>
## 2. 图片读取与Base64编码
读取本地图片文件，并将其转换为Base64字符串格式，以便通过API传输。
```Python
with open(IMAGE_PATH, "rb") as f:
    base64_image = base64.b64encode(f.read()).decode('utf-8')
```


<span id="10dc2486"></span>
## 3. 调用API生成边界框
将Base64编码的图片和文本提示词作为多模态输入，发送给grounding模型获取预测结果。
```Python
response = client.chat.completions.create(
    model=DEFAULT_MODEL,
    messages=[{
        "role": "user",
        "content": [{
            "type": "image_url",  # 图片输入
            "image_url": {"url": f"data:image/png;base64,{base64_image}"}
        }, {
            "type": "text",  # 文本提示
            "text": PROMPT
        }]
    }]
)
bbox_content = response.choices[0].message.content
```


<span id="cbfeb48d"></span>
## 4. 解析模型返回的边界框坐标
从模型返回的结果中提取边界框坐标，并验证其格式是否符合预期。
坐标格式为 `<bbox>x_min y_min x_max y_max</bbox>`，其中(`x_min`, `y_min`)为方框左上角的坐标，(`x_max`, `y_max` )为方框右下角的坐标。
```Python
# 检查结果格式是否正确
if not (bbox_content.startswith(BBOX_TAG_START) and bbox_content.endswith(BBOX_TAG_END)):
    print("错误：边界框格式不正确，缺少标签包裹")
    exit(1)

# 解析坐标值
try:
    coords_str = bbox_content[len(BBOX_TAG_START):-len(BBOX_TAG_END)]
    coords = list(map(int, coords_str.split()))
    if len(coords) != 4:  # 验证坐标数量(xmin, ymin, xmax, ymax)
        raise ValueError("坐标数量不正确，需要4个数值")
    x_min, y_min, x_max, y_max = coords
except ValueError as e:
    print(f"坐标解析失败: {str(e)}")
    exit(1)
```

<span id="7de20f90"></span>
## 5. 在原图上绘制边界框并保存
转化坐标，`x_min`, `y_min`, `x_max`, `y_max`取值范围是 **0-1000**，是 **归一化到 1000*1000 的比例坐标**，即图片宽高分别等分为1000后，图片左上角为原点绘制坐标系，对应点的坐标位置，原理如下图所示。
<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e247476bb66b4b4f945b48318c18ee9b~tplv-goo7wpa0wc-image.image" width="200px" /></div>

根据图像实际尺寸缩放边界框坐标，将模型输出的相对坐标映射到绝对坐标，需进行计算，例如左上角坐标横轴绝对值是 `x=x_min/1000*w`，w 是图片的实际宽度。
```Python
# 读取原图
image = cv2.imread(IMAGE_PATH)

# 获取图像尺寸并缩放坐标(模型输出范围为0-1000)
h, w = image.shape[:2]
x_min_real = int(x_min * w / 1000)
y_min_real = int(y_min * h / 1000)
x_max_real = int(x_max * w / 1000)
y_max_real = int(y_max * h / 1000)

# 绘制红色边界框
cv2.rectangle(image, (x_min_real, y_min_real), (x_max_real, y_max_real), (0, 0, 255), 3)

# 保存结果图片
output_path = os.path.splitext(IMAGE_PATH)[0] + "_with_bboxes.png"
cv2.imwrite(output_path, image)
print(f"成功保存标注图片: {output_path}")
```

<span id="4c0fb035"></span>
## 结果预览
配置并运行该示例代码，在代码路径下生成绘制后的图片预览。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/114267ea04e7424a8dc2e168c55b2ae8~tplv-goo7wpa0wc-image.image =163x)
<span id="93a6289f"></span>
# 提示词说明
<span id="4211ce22"></span>
## 使用限制

* 不建议将坐标结果（ bounding box 坐标）放在 json 中。
* 不建议指定 bounding box 的输出结构。

<span id="aa6f318c"></span>
## 典型场景

| | | | | | \
|场景 |场景说明 |触发条件 |提示词 |效果图 |
|---|---|---|---|---|
| | | | | | \
|带属性物体检测 |需要定位图像中符合自然语言描述的特定属性的对象 |prompt里需包含关键词： |\
| | |`<bbox>x1 y1 x2 y2</bbox> 框` |`帮我框选森林里的着火范围，以<bbox>x1 y1 x2 y2</bbox>的形式表示` |\
| | | | |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e8140cc3d68240fcaab0a92be13101bd~tplv-goo7wpa0wc-image.image =1151x) |\
| | | | | |
| | | | | | \
|多目标检测 |需要同时检测多个预定义类别的对象 |prompt里需包含关键词： |\
| | |` [{"category": category, "bbox": "<bbox>x1 y1 x2 y2</bbox>"}, {"category": category, "bbox": "<bbox>x1 y1 x2 y2</bbox>"}] ` |请检测图像中所有属于 "plate（盘子）、photo（照片）、kid（小孩）、cup（杯子）" 类别的物体。对于每个物体，请提供其类别和边界框，格式为：`[{"category": category, "bbox": "<bbox>x1 y1 x2 y2</bbox>"}, {"category": category, "bbox": "<bbox>x1 y1 x2 y2</bbox>"}]` |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/f768fcf0037a4baf80b2d4157898d8a2~tplv-goo7wpa0wc-image.image =1280x) |\
| | | | | |
| | | | | | \
|根据图像信息定位目标 |根据目标的图像信息在另一张图中进行定位 |prompt里需包含关键词： |\
| | |`<bbox>x1 y1 x2 y2</bbox>` |`请根据第一张图的主要目标，识别第二张图中类似的目标，对于每个物体提供其边界框，格式为：<bbox>x1 y1 x2 y2</bbox>` |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/8ca3750ecfd540f285703e11f3c9edf9~tplv-goo7wpa0wc-image.image =1024x) |
| | | | | | \
|计算物体数量 |需要统计特定对象的数量 |prompt里需包含关键词： |\
| | |`<point>x y</point> 点` |\
| | | |`定位画面中水面上的所有人，输出 point，格式<point>x1 y1</point>，并计数水面中有多少人？` |\
| | | | |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2392404be5034344b31fc99b9e637dac~tplv-goo7wpa0wc-image.image =1151x) |\
| | | | | |
| | | | | | \
|识别图像文本 |需要提取图像中的文字内容及位置 |prompt里需包含关键词： |\
| | |`<text>text</text><polygon>x1 y1, x2 y2, x3 y3, x4 y4</polygon> ` |标注图中的文字，格式为`<text>text</text><polygon>x1 y1, x2 y2, x3 y3, x4 y4</polygon>` |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7ef81d129cb34b5a8e3e1c8cc5d67f7e~tplv-goo7wpa0wc-image.image =1280x) |\
| | | | | |
| | | | | | \
|3D物体检测 |检测图像中的3D立体格式的物体 |prompt里需包含关键词： |\
| | |`图像相机的详细参数以及<3dbbox>x_center y_center z_center x_size y_size z_size pitch yaw roll</3dbbox>` |`以下是该图像的详细相机参数。相机内参：焦距f_x=5545.08, f_y=5545.08。主点坐标位于图像中心附近，因此当图像宽度为4284，高度为5712时，c_x=2142.00且c_y=2856.00。这里我们不考虑畸变参数。因此，内参矩阵K = [[1460.00, 0, 2142.00], [0, 1460.00, 2856.00], [0, 0, 1]]。相机坐标系：X 轴向右，Y 轴向下，Z 轴向前。原点为相机位置。我们将相机坐标系作为世界坐标系，即相机外参矩阵为[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]]。请按照以下格式输出每个3D框：<3dbbox>x_center y_center z_center x_size y_size z_size pitch yaw roll</3dbbox> 注意：(1) x_center, y_center, z_center：目标中心在相机坐标系中沿着XYZ轴的位置，单位为米。(2) x_size, y_size, z_size：当旋转角为零时，目标沿XYZ轴的尺寸，单位为米。(3) pitch, yaw, roll：分别为围绕XYZ轴的欧拉角。这里的每个角度值被归一化到（-1,1），需要乘以180转换到实际的角度。在这幅图中检测杯子，并以3D边界框格式展示结果。检测图像中的杯子，并以 3D框形式显示结果` |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b8c5fa94a87c4977874c345630e0179e~tplv-goo7wpa0wc-image.image =1280x) |

<span id="14cdebb9"></span>
## 


# GUI 任务处理
Source: https://www.volcengine.com/docs/82379/1584296
本教程指导你使用具备GUI任务处理能力模型，在计算机、移动设备等真实 GUI 环境中完成自动化任务（如界面点击、模式设置等）。模型支持图文结合的多轮交互，精准解析 GUI 操作指令并生成可执行的动作逻辑。 
<span id="1b67c619"></span>
# 支持的模型
见[GUI 任务处理能力](https://www.volcengine.com/docs/82379/1330310#71fe225f)。
<span id="65e813e0"></span>
# API文档
见文档：[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384#RxN8G2nH)。
<span id="ee2c320d"></span>
# 前提条件
* [获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) 。
   * 使用 Access Key 鉴权请参考[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
* [开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需 Model ID 。
   * 通过 Endpoint ID 调用模型服务请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。




<span id="ea8acb31"></span>
# 快速开始

> * 下面示例代码不适用于`doubao-1-5-ui-tars-250328`，`doubao-1-5-ui-tars-250328`模型用户推荐升级至`doubao-1-5-ui-tars-250428`，具备深度思考能力，能更好处理问题。
> * 如确定使用 `doubao-1-5-ui-tars-250328`，使用说明，请查看[示例代码](https://www.volcengine.com/docs/82379/1536429#c274b383)。

以“将图像设置为Palette - Based模式”任务为例，演示单轮 GUI 任务流程。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ae7d606574e24c7a98a4eb9b934e2757~tplv-goo7wpa0wc-image.image =689x)
正式开始前需安装对应的SDK。
```Bash
pip install pillow numpy matplotlib
pip install volcengine-python-sdk[ark]
```

<span id="2bd4e181"></span>
## 步骤1：配置 API 与工具函数
```Python
import os
# 通过 pip install volcengine-python-sdk[ark] 安装方舟SDK
from volcenginesdkarkruntime import Ark
import base64

# 初始化Ark客户端，从环境变量中读取您的API Key
client = Ark(
    api_key=os.getenv('ARK_API_KEY'),
    )

# 图片转 Base64 工具函数
def encode_image(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')
```

<span id="c85d406b"></span>
## 步骤2：构造对话消息（系统提示 + 图片）
其中 prompt 提示词模板见 [系统提示设计](https://www.volcengine.com/docs/82379/1584296#be30d2ab)。
```Python
from prompt import COMPUTER_USE_DOUBAO
# 系统提示模板（指定任务与语言）
instruction = "Could you help me set the image to Palette-Based?"
language = "Chinese"
system_prompt = COMPUTER_USE_DOUBAO.format(instruction=instruction, language=language)

# 编码目标截图
image_path = "image.png"
image_format = image_path.split('.')[-1]  # 提取图片格式（如png）
base64_image = encode_image(image_path)

# 构造messages（用户角色，包含文本提示和图片）
messages = [
    {
        "role": "user",
        "content": system_prompt
    },
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/{image_format};base64,{base64_image}"
                }
            }
        ]
    }
]
```

<span id="69d721cd"></span>
## 步骤3：调用模型推理
```Python
def inference(messages):
    response = client.chat.completions.create(
        # 按需替换 model id
        model="doubao-1-5-ui-tars-250428",
        messages=messages,
        temperature=0.0,  # 固定温度保证输出稳定
        stream=True       # 流式获取响应（可选）
    )
    # 流式响应拼接
    full_response = ""
    for chunk in response:
        if chunk.choices[0].delta.content:
            full_response += chunk.choices[0].delta.content
    return full_response

response = inference(messages)
print(response)
```

模型会返回GUI 任务处理的思考过程和动作指令如下：
```Plain Text
1. 首先分析当前界面：屏幕上显示GIMP的Preferences窗口，遮挡了主界面操作。要设置图像为Palette - Based，需先关闭Preferences窗口，再通过Image菜单操作。
2. 下一步逻辑：关闭Preferences窗口，点击其右上角的关闭按钮（×），以便后续访问Image菜单。
3. 目标元素：Preferences窗口右上角的关闭按钮，位置在窗口右上角，呈×形状。

Action: click(point='<point>450 416</point>')
```

<span id="697b77a8"></span>
## 步骤4：解析动作指令
模型返回的坐标为相对坐标，即将图片宽高归一化至1000后，对应点的坐标。要将这些值按照图像实际宽高进行比例换算，公式如下：
```Plain Text
X绝对坐标 = X相对坐标/1000 × 图像宽度 
Y绝对坐标 = Y相对坐标/1000 × 图像高度 
```

示例代码
```Python
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import re

image = Image.open(image_path)
original_width, original_height = image.size
# 解析坐标（示例：提取action中的坐标）
match = re.search(r'<point>(\d+)\s+(\d+)</point>', response)
if match:
    x = int(int(match.group(1))/1000*original_width)  # 提取第一个数字并转为绝对坐标
    y = int(int(match.group(2))/1000*original_height)  # 提取第二个数字并转为绝对坐标
    action_point = (x, y)    # 生成整数元组
else:
    raise ValueError(f"Failed to parse coordinates from response. Raw response: {response}")

print(action_point)  # 应输出类似(450, 416)的整数元组
# 在原图上标记动作位置
image = Image.open(image_path)
draw = ImageDraw.Draw(image)
draw.ellipse((action_point[0]-5, action_point[1]-5, action_point[0]+5, action_point[1]+5), fill="red")


# 展示标记后的图片
plt.imshow(image)
plt.axis("off")
plt.show()
```

<span id="9896cd57"></span>
# 使用说明
<span id="be30d2ab"></span>
## 系统提示设计
使用 [系统提示模板](https://www.volcengine.com/docs/82379/1536429#00d8bbfd)明确任务（`Instruction`）和语言（`Language`），请勿更改其中内容，避免影响模型输出效果。
将提示词模板复制至 prompt.py 并存放在主脚本目录下：

* 通过`import  COMPUTER_USE_DOUBAO from prompt`导入。
* 通过`system_prompt = COMPUTER_USE_DOUBAO.format(instruction=instruction, language=language)`方式使用提示词模板及传入提示词配置。

具体使用示例见[步骤2：构造对话消息（系统提示 + 图片）](https://www.volcengine.com/docs/82379/1584296#c85d406b)。
<span id="7a07477f"></span>
## 多轮对话管理
多轮任务最多保留最近5张截图（含当前）和历史响应，`messages`结构示例（以8轮为例）： 
```Python
messages = [
    # 第1轮：系统提示
    {"role": "user", "content": "初始系统提示"},
    # 第1轮响应
    {"role": "assistant", "content": "第1轮模型输出"},
    # 第2轮响应
    {"role": "assistant", "content": "第2轮模型输出"},
    # 第3轮响应
    {"role": "assistant", "content": "第3轮模型输出"},
    # 第4轮：用户上传第4轮截图
    {"role": "user", "content": [{"type": "image_url", "image_url": "..."}]},
    # 第4轮响应
    {"role": "assistant", "content": "第4轮模型输出"},
    # ... 最多保留5轮截图对应的消息 ...
    # 第7轮：用户上传第4轮截图
    {"role": "user", "content": [{"type": "image_url", "image_url": "..."}]},
    # 第7轮响应
    {"role": "assistant", "content": "第7轮模型输出"},
    # 第8轮：用户上传第N张截图
    {"role": "user", "content": [{"type": "image_url", "image_url": "..."}]},
]
```

示例代码
```Python
import os
# 通过 pip install volcengine-python-sdk[ark] 安装方舟SDK
from volcenginesdkarkruntime import Ark
import base64
from prompt import COMPUTER_USE_DOUBAO

# 初始化Ark客户端，从环境变量中读取您的API Key
client = Ark(
    api_key=os.getenv('ARK_API_KEY'),
    )

# 图片转 Base64 工具函数
def encode_image(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')

instruction = "Could you help me set the image to Palette-Based?"
language = "Chinese"
system_prompt = COMPUTER_USE_DOUBAO.format(instruction=instruction, language=language)

image_4turn_path = "samples/image_4_turn.png"
image_5turn_path = "samples/image_5_turn.png"
image_6turn_path = "samples/image_6_turn.png"
image_7turn_path = "samples/image_7_turn.png"
image_8turn_path = "samples/image_8_turn.png"

base64_image_4turn = encode_image(image_4turn_path)
base64_image_5turn = encode_image(image_5turn_path)
base64_image_6turn = encode_image(image_6turn_path)
base64_image_7turn = encode_image(image_7turn_path)
base64_image_8turn = encode_image(image_8turn_path)
image_format = image_path.split('.')[-1]
assert image_format in ['jpg', 'jpeg', 'png', 'webp']

messages = [
    {
        "role": "user",
        "content": system_prompt
    },
    {
        "role": "assistant",
        "content": "Thought: 我看到屏幕上弹出了一个颜色配置文件转换的对话框，要继续操作的话得先处理掉它。对话框右下角有个\"Convert\"按钮，我需要点击它来确认这个转换操作。\nAction: click(point='<point>607 647</point>')"
    },
    {
        "role": "assistant",
        "content": "Thought: 看到这张复古电视机的照片，我需要把它设置成基于调色板的方式。让我先点击顶部菜单栏的\"Tools\"选项，这样就能找到相关的颜色设置选项了。\nAction: click(point='<point>220 71</point>')"
    },
    {
        "role": "assistant",
        "content": "Thought: 刚才点开了Tools菜单，但发现这不是正确的路径。要设置图片为基于调色板的方式，我需要先关闭当前打开的Tools菜单，然后重新寻找正确的颜色设置选项。让我点击一下Tools按钮把它关掉。\nAction: click(point='<point>220 71</point>')"
    },
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/{image_format};base64,{base64_image_4turn}"
                }
            }
        ]
    },
    {
        "role": "assistant",
        "content": "Thought: 刚才在Tools菜单里没找到想要的选项，让我换个思路。我注意到顶部菜单栏有个\"Colors\"选项，这应该就是处理颜色设置的地方。我需要点击它来继续寻找将图片设置为基于调色板方式的选项。\nAction: click(point='<point>192 71</point>')"
    },
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/{image_format};base64,{base64_image_5turn}"
                }
            }
        ]
    },
    {
        "role": "assistant",
        "content": "Thought: 我在Colors菜单里仔细浏览了一遍，发现这里并没有直接设置调色板的选项。看来得换个思路了 - 先把这个菜单关掉，然后去Edit菜单看看，那里应该能找到更多关于图像处理的选项。毕竟要实现基于调色板的设置，可能需要通过其他路径来实现。\nAction: click(point='<point>192 71</point>')"
    },
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/{image_format};base64,{base64_image_6turn}"
                }
            }
        ]
    },
    {
        "role": "assistant",
        "content": "Thought: 我在Colors菜单里没找到想要的选项，让我换个思路。我注意到顶部菜单栏有个\"Edit\"选项，这应该就是处理颜色设置的地方。我需要点击它来继续寻找将图片设置为基于调色板方式的选项。\nAction: click(point='<point>65 71</point>')"
    },
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/{image_format};base64,{base64_image_7turn}"
                }
            }
        ]
    },
    {
        "role": "assistant",
        "content": "Thought: 我在Edit菜单里发现了Preferences选项，这正是我需要的。通过这个选项，我应该能找到调整图片颜色模式的设置。让我点击它进入设置界面，这样就能把图片转换成基于调色板的方式了。\nAction: click(point='<point>96 602</point>')"
    },
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/{image_format};base64,{base64_image_8turn}"
                }
            }
        ]
    }
]

response = inference(messages)
print(response)
```


<span id="a54aac62"></span>
## 响应解析与执行
模型输出的`Action`包含GUI操作类型（如`click`/`type`）和坐标，需： 

* 用正则或工具类（如[parse_action_to_structure_output](https://github.com/bytedance/UI-TARS/blob/main/codes/ui_tars/action_parser.py)）提取坐标。 
* 转换 相对坐标 → 绝对像素坐标（需已知截图原始分辨率）。 
* 调用自动化工具（如PyAutoGUI）执行操作： 

```Python
import pyautogui
from ui_tars.action_parser import parse_action_to_structure_output, parsing_response_to_pyautogui_code

# 解析模型输出为坐标字典
parsed_dict = parse_action_to_structure_output(response, image_width, image_height, model_type="doubao")
# 转换为PyAutoGUI可执行代码
py_code = parsing_response_to_pyautogui_code(parsed_dict, image_height, image_width)
print(py_code)  # 输出：pyautogui.click(x=450, y=417)
```

<span id="612dbea7"></span>
## **环境一致性**

* 截图分辨率与实际操作界面一致（模型输出坐标基于输入图像尺寸）。若GUI界面分辨率与截图不一致，需按比例转换坐标（如截图分辨率1920×1080，实际界面2560×1440，则坐标×(2560/1920)）。
* 建议使用固定窗口布局（如最大化窗口）避免元素位置偏移。

<span id="bef6afe5"></span>
## 其他说明

* **多轮上下文管理**：最多保留5张截图（含当前），避免上下文过长导致混淆。 
* **系统提示精准性**：明确任务目标（如“点击右上角关闭按钮”）和操作环境（如“Windows系统资源管理器”）。 
* **动作验证**：通过可视化标记（如红色圆点）确认解析的坐标是否在目标控件上，避免误操作。 
* **模型推理随机性**：**temperature** 请设置为 `0` ，**top_p** 请设置为 `0.7`，无随机性的推理参数，以提高模型输出准确性。

<span id="b355e37f"></span>
# 附 Action 说明
下面是模型可能返回的 action 值及对应值的含义。
<span id="eb3ff1d1"></span>
## 电脑 GUI 任务处理场景

| | | | | \
|Action名称 |动作类型 |参数 |输出示例 |
|---|---|---|---|
| | | | | \
|click |鼠标左键单击 |start_box |`click(start_box='<bbox>859 950 859 950</bbox>')` |
| | | | | \
|left_double |鼠标左键双击 |start_box |`left_double(start_box='<bbox>859 950 859 950</bbox>')` |
| | | | | \
|right_single |鼠标右键单击 |start_box |`right_single(start_box='<bbox>859 950 859 950</bbox>')` |
| | | | | \
|drag |拖拽 |start_box |\
| | |end_box |`drag(start_box='<bbox>768 150 768 150</bbox>', end_box='<bbox>79 150 79 150</bbox>')` |
| | | | | \
|hotkey |热键 |key |`hotkey(key='ctrl a')` |
| | | | | \
|type |键盘输入 |content |`type(content='北京天气怎么样')` |
| | | | | \
|scroll |滚动屏幕 |start_box |\
| | |direction |`scroll(direction='up', start_box='<bbox>850 869 850 869</bbox>')` |
| | | | | \
|wait |等待 | |`wait()` |
| | | | | \
|finished |完成 |content |`finished(content='todo.txt已打开')` |

<span id="8b70c950"></span>
## 手机 GUI 任务处理场景

| | | | | \
|Action 名称 |动作类型 |参数 |输出示例 |
|---|---|---|---|
| | | | | \
|click |点击 |point |`JSON<br>click(point='<point>x1 y1</point>')<br>` |
| | | | | \
|long_press |长按 |point |`JSON<br>long_press(point='<point>x1 y1</point>')<br>` |
| | | | | \
|type |输入 |content |`JSON<br>type(content='文本内容\\n')<br>` |
| | | | | \
|scroll |滚动 |point、direction |`JSON<br>scroll(point='<point>x1 y1</point>', direction='down')<br>` |
| | | | | \
|open_app |打开应用 |app_name |`JSON<br>open_app(app_name='微信')<br>` |
| | | | | \
|drag |拖拽 |start_point、end_point |`JSON<br>drag(start_point='<point>x1 y1</point>', end_point='<point>x2 y2</point>')<br>` |
| | | | | \
|press_home |返回主屏幕 |无 |`JSON<br>press_home()<br>` |
| | | | | \
|press_back |返回 |无 |`JSON<br>press_back()<br>` |
| | | | | \
|finished |完成 |content |`JSON<br>finished(content='操作完成信息')<br>` |




# 视频生成
Source: https://www.volcengine.com/docs/82379/1366799
视频生成模型具备出色的语义理解能力，可根据用户输入的文本、图片等内容，快速生成优质的视频片段。通过这篇教程您可以学习到如何通过调用视频生成模型 API 来生成视频。
<span id="2c6a9e64"></span>
## 快速开始
您可以通过下面代码快速体验文生视频能力。
:::tip
* 视频生成为异步接口，您需要先创建视频生成任务，再通过视频生成任务的 ID 去查询视频生成结果。
* 视频生成过程耗时较长，查询结果时请您耐心等待。
:::


```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python" key="D1RwhEl5ig"><RenderMd content={`\`\`\`Python
import os
import time  
# 通过 pip install 'volcengine-python-sdk[ark]' 安装方舟SDK
from volcenginesdkarkruntime import Ark

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
# 初始化Ark客户端，从环境变量中读取您的API Key
client = Ark(
    # 此为默认路径，您可根据业务所在地域进行配置
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    api_key=os.environ.get("ARK_API_KEY"),
)

if __name__ == "__main__":
    print("----- create request -----")
    create_result = client.content_generation.tasks.create(
        # 替换 <Model> 为模型的Model ID
        model="<Model>",
        content=[
            {
                # 文本提示词
                "type": "text",
                "text": "戴着帽子的老爷爷面带微笑往前走"
            },
        ]
    )
    print(create_result)

    # 轮询查询部分
    print("----- polling task status -----")
    task_id = create_result.id
    while True:
        get_result = client.content_generation.tasks.get(task_id=task_id)
        status = get_result.status
        if status == "succeeded":
            print("----- task succeeded -----")
            print(get_result)
            break
        elif status == "failed":
            print("----- task failed -----")
            print(f"Error: {get_result.error}")
            break
        else:
            print(f"Current status: {status}, Retrying after 10 seconds...")
            time.sleep(10)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java" key="zyILXb1P3Z"><RenderMd content={`\`\`\`Java
package com.volcengine.ark.runtime;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;
import com.volcengine.ark.runtime.model.content.generation.CreateContentGenerationTaskRequest;
import com.volcengine.ark.runtime.model.content.generation.CreateContentGenerationTaskRequest.Content;
import com.volcengine.ark.runtime.model.content.generation.CreateContentGenerationTaskResult;
import com.volcengine.ark.runtime.model.content.generation.GetContentGenerationTaskRequest;
import com.volcengine.ark.runtime.model.content.generation.GetContentGenerationTaskResponse;
import com.volcengine.ark.runtime.service.ArkService;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;

public class ContentGenerationTaskExample {
    // 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
    // 初始化Ark客户端，从环境变量中读取您的API Key
    static String apiKey = System.getenv("ARK_API_KEY");
    static ConnectionPool connectionPool = new ConnectionPool(5, 1, TimeUnit.SECONDS);
    static Dispatcher dispatcher = new Dispatcher();
    static ArkService service = ArkService.builder()
           .dispatcher(dispatcher)
           .connectionPool(connectionPool)
           .apiKey(apiKey)
           .build();
    public static void main(String[] args) {
        // 替换为您的 Model ID
        String model = "<Model>";

        System.out.println("----- create request -----");
        List<Content> contents = new ArrayList<>();
        contents.add(Content.builder()
                .type("text")
                .text("戴着帽子的老爷爷面带微笑往前走")
                .build());
        
        // 创建视频生成任务
        CreateContentGenerationTaskRequest createRequest = CreateContentGenerationTaskRequest.builder()
                .model(model)
                .content(contents)
                .build();

        CreateContentGenerationTaskResult createResult = service.createContentGenerationTask(createRequest);
        System.out.println(createResult);

        // 获取任务详情
        String taskId = createResult.getId();
        GetContentGenerationTaskRequest getRequest = GetContentGenerationTaskRequest.builder()
                .taskId(taskId)
                .build();
        
        // 轮询查询部分
        System.out.println("----- polling task status -----");
        while (true) {
            try {
                GetContentGenerationTaskResponse getResponse = service.getContentGenerationTask(getRequest);
                String status = getResponse.getStatus();
                if ("succeeded".equalsIgnoreCase(status)) {
                    System.out.println("----- task succeeded -----");
                    System.out.println(getResponse);
                    break;
                } else if ("failed".equalsIgnoreCase(status)) {
                    System.out.println("----- task failed -----");
                    System.out.println("Error: " + getResponse.getStatus());
                    break;
                } else {
                    System.out.printf("Current status: %s, Retrying in 10 seconds...", status);
                    TimeUnit.SECONDS.sleep(10);
                }
            } catch (InterruptedException ie) {
                Thread.currentThread().interrupt();
                System.err.println("Polling interrupted");
                break;
            }
        }
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go" key="fOLOh4FWkB"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "os"
    "time"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    // 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
    // 初始化Ark客户端，从环境变量中读取您的API Key
    client := arkruntime.NewClientWithApiKey(
            // 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
            os.Getenv("ARK_API_KEY"),
    )
    ctx := context.Background()

    // 替换为你的 Model ID
    modelEp := "<Model>"

    // 创建任务
    fmt.Println("----- create request -----")
    createReq := model.CreateContentGenerationTaskRequest{
        Model: modelEp,
        Content: []*model.CreateContentGenerationContentItem{
            {
                Type: model.ContentGenerationContentItemTypeText,
                Text: volcengine.String("戴着帽子的老爷爷面带微笑往前走"),
            },
        },
    }
    createResp, err := client.CreateContentGenerationTask(ctx, createReq)
    if err != nil {
        fmt.Printf("create content generation error: %v", err)
        return
    }
    taskID := createResp.ID
    fmt.Printf("Task Created with ID: %s", taskID)

    // 轮询查询部分
    fmt.Println("----- polling task status -----")
    for {
        getReq := model.GetContentGenerationTaskRequest{ID: taskID}
        getResp, err := client.GetContentGenerationTask(ctx, getReq)
        if err != nil {
            fmt.Printf("get content generation task error: %v", err)
            return
        }

        status := getResp.Status
        if status == "succeeded" {
            fmt.Println("----- task succeeded -----")
            fmt.Printf("Task ID: %s", getResp.ID)
            fmt.Printf("Model: %s", getResp.Model)
            fmt.Printf("Video URL: %s", getResp.Content.VideoURL)
            fmt.Printf("Completion Tokens: %d", getResp.Usage.CompletionTokens)
            fmt.Printf("Created At: %d, Updated At: %d", getResp.CreatedAt, getResp.UpdatedAt)
            return
        } else if status == "failed" {
            fmt.Println("----- task failed -----")
            if getResp.Error != nil {
                fmt.Printf("Error Code: %s, Message: %s", getResp.Error.Code, getResp.Error.Message)
            }
            return
        } else {
            fmt.Printf("Current status: %s, Retrying in 10 seconds...", status)
            time.Sleep(10 * time.Second)
        }
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


模型回复预览：
```Shell
# 视频生成过程中
----- create request -----
Task Created with ID: cgt-2025xxxx-xxxx
----- polling task status -----
Current status: queued, Retrying in 10 seconds...
Current status: running, Retrying in 10 seconds...

# 视频生成后
----- task succeeded -----
ContentGenerationTask(id='cgt-2025xxxx-xxxx', model='doubao-xxxx', status='succeeded', error=None, content=Content(video_url='https://xxxx'), usage=Usage(completion_tokens=103818, total_tokens=103818), created_at=1746606910, updated_at=1746606932)
```

<span id="5b7f9f24"></span>
## 
<span id="e7b4c498"></span>
## 支持模型

| | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |**模型 ID（Model ID）** |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**输出视频格式** |\
| | | | |<div style="width:120px"></div> |**RPM 限流** |\
| | | | | |> 创建视频生成任务时，每分钟发送的请求数 |\
| | | | | | |\
| | | | | |<div style="width:100px"></div> |**并发数限制** |**免费额度** |\
| | | | | | | |（token） |**定价** |\
| | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | \
|[doubao-seedance-1.0-pro](https://www.volcengine.com/docs/82379/1587798) |250528`强烈推荐` |doubao-seedance-1-0-pro-250528 |文生视频 |\
| | | |图生视频-基于首帧 |分辨率：480p，720p，1080p |\
| | | | |帧率：24 fps |\
| | | | |时长：5 秒，10秒 |600 |10 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |
| | | | | | | | | | \
|[doubao-seedance-1.0-lite](https://www.volcengine.com/docs/82379/1553576) |250428 `推荐` |doubao-seedance-1-0-lite-t2v-250428 |文生视频 |分辨率：720p，480p，1080p |\
| | | | |帧率：24 fps |\
| | | | |时长：5 秒，10秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |
|^^| | | | | | | | | \
| |250428`推荐` |doubao-seedance-1-0-lite-i2v-250428 |图生视频-基于首帧或首尾帧 |\
| | | |> 首尾帧不支持1080p |分辨率：720p，480p，1080p |\
| | | | |帧率：24 fps |\
| | | | |时长：5 秒，10秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |
| | | | | | | | | | \
|[wan2.1-14b](https://www.volcengine.com/docs/82379/1556464) |t2v-250225 |wan2-1-14b-t2v-250225 |文生视频 |分辨率：720p，480p |\
| | | | |帧率：16 fps |\
| | | | |时长：5 秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |\
| | | | | | | | | |
|^^| | | | | | | | | \
| |i2v-250225 |wan2-1-14b-i2v-250225 |图生视频-基于首帧 |分辨率：720p，480p |\
| | | | |帧率：16 fps |\
| | | | |时长：5 秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |\
| | | | | | | | | |
|^^| | | | | | | | | \
| |flf2v-250417 |wan2-1-14b-flf2v-250417 |图生视频-基于首尾帧 |分辨率：720p |\
| | | | |帧率：16 fps |\
| | | | |时长：5 秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |\
| | | | | | | | | |
| | | | | | | | | | \
|doubao-seaweed |241128 |doubao-seaweed-241128 |文生视频 |\
| | | |图生视频-基于首帧 |分辨率：720p，480p |\
| | | | |帧率：24 fps |\
| | | | |时长： |\
| | | | | |\
| | | | |* 文生视频：5 秒/10秒 |\
| | | | |* 图生视频：5 秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |


<span id="d1b0ff92"></span>
## API 参数说明
视频生成的 API 接口详细介绍请参见 [视频生成 API](https://www.volcengine.com/docs/82379/1520758)。
<span id="a57e57b6"></span>
### 模型文本命令比较
在文本提示词后追加--[parameters]，控制视频输出的规格，包括宽高比、帧率、分辨率等。使用不同的模型，可能对应支持不同的参数与取值，详见下表。

| | | | | | | | | \
| |doubao-seedance-1-0-pro |\
| |文生视频（t2v）和图生视频（i2v） |\
| |<div style="width:150px"></div> |doubao-seedance-1-0-lite-t2v |\
| | |文生视频 |\
| | |<div style="width:150px"></div> |doubao-seedance-1-0-lite-i2v |\
| | | |图生视频-基于首帧或首尾帧 |\
| | | |<div style="width:150px"></div> |doubao-seaweed |\
| | | | |文生视频（t2v）和图生视频（i2v） |\
| | | | |<div style="width:150px"></div> |wan2-1-14b-t2v |\
| | | | | |文生视频 |\
| | | | | |<div style="width:150px"></div> |wan2-1-14b-i2v |\
| | | | | | |图生视频 |\
| | | | | | |<div style="width:150px"></div> |wan2-1-14b-flf2v |\
| | | | | | | |首尾帧图生视频 |\
| | | | | | | |<div style="width:150px"></div> |
|---|---|---|---|---|---|---|---|
| | | | | | | | | \
|resolution  |\
|分辨率 |* 480p |\
| |* 720p |\
| |*  1080p |* 480p |\
| | |* 720p |\
| | |*  1080p |* 480p |\
| | | |* 720p |\
| | | |*  1080p |\
| | | | |\
| | | |> 首尾帧不支持1080p |* 480p(仅i2v支持) |\
| | | | |* 720p |* 480p |\
| | | | | |* 720p |* 480p |\
| | | | | | |* 720p |720p |
| | | | | | | | | \
|ratio |\
|宽高比 |**t2v** |\
| |480p档位：不同视频宽高比对应的分辨率如下： |\
| | |\
| |* `16:9`：864×480 |\
| |* `4:3`：736×544 |\
| |* `1:1`：640×640 |\
| |* `3:4`：544×736 |\
| |* `9:16`：480×864 |\
| |* `21:9`：960×416 |\
| | |\
| |720p档位，不同视频宽高比对应的分辨率如下： |\
| | |\
| |* `16:9`：1248×704 |\
| |* `4:3`：1120×832 |\
| |* `1:1`：960×960 |\
| |* `3:4`：832×1120 |\
| |* `9:16`：704×1248 |\
| |* `21:9`：1504×640 |\
| | |\
| |1080p档位，不同视频宽高比对应的分辨率如下： |\
| | |\
| |* `16:9`：1920×1088 |\
| |* `4:3`：1664×1248 |\
| |* `1:1`：1440×1440 |\
| |* `3:4`：1248×1664 |\
| |* `9:16`：1088×1920 |\
| |* `21:9`：2176×928 |\
| | |\
| |**i2v** |\
| |`adaptive`：根据所上传图片的比例，自动选择最合适的宽高比。所选的比例档位与t2v的比例枚举值一致。 |480p档位：不同视频宽高比对应的分辨率如下： |\
| | | |\
| | |* `16:9`：864×480 |\
| | |* `4:3`：736×544 |\
| | |* `1:1`：640×640 |\
| | |* `3:4`：544×736 |\
| | |* `9:16`：480×864 |\
| | |* `21:9`：960×416 |\
| | | |\
| | |720p档位，不同视频宽高比对应的分辨率如下： |\
| | | |\
| | |* `16:9`：1248×704 |\
| | |* `4:3`：1120×832 |\
| | |* `1:1`：960×960 |\
| | |* `3:4`：832×1120 |\
| | |* `9:16`：704×1248 |\
| | |* `21:9`：1504×640 |\
| | | |\
| | | 1080p档位，不同视频宽高比对应的分辨率如下： |\
| | | |\
| | |* `16:9`：1920×1088 |\
| | |* `4:3`：1664×1248 |\
| | |* `1:1`：1440×1440 |\
| | |* `3:4`：1248×1664 |\
| | |* `9:16`：1088×1920 |\
| | |* `21:9`：2176×928 |`adaptive`，根据所上传图片的比例，自动选择最合适的宽高比。 |\
| | | |所选的比例档位与seedance t2v的比例枚举值一致。 |480p档位(仅i2v支持)，不同视频宽高比对应的分辨率如下： |\
| | | | | |\
| | | | |* `16:9`：848×480  |\
| | | | |* `4:3`：640×480  |\
| | | | |* `1:1`：480×480  |\
| | | | |* `3:4`：480×640  |\
| | | | |* `9:16`：480×848  |\
| | | | |* `21:9`：1120×480  |\
| | | | |* `9:21`：480×1120  |\
| | | | | |\
| | | | |720p档位，不同视频宽高比对应的分辨率如下：  |\
| | | | | |\
| | | | |* `16:9`：1280×720  |\
| | | | |* `4:3`：960×720  |\
| | | | |* `1:1`：720×720  |\
| | | | |* `3:4`：720×960  |\
| | | | |* `9:16`：720×1280  |\
| | | | |* `21:9`：1280×544  |\
| | | | |* `9:21`：544×1280 |\
| | | | | |\
| | | | |> 注：`21:9`和`9:21`宽高比下，为防止显存溢出，短边被设置为544p |480P档位：不同视频宽高比对应的分辨率如下：  |\
| | | | | | |\
| | | | | |* `16:9`：832×480  |\
| | | | | |* `9:16`：480×832  |\
| | | | | | |\
| | | | | |720P档位：不同视频宽高比对应的分辨率如下：  |\
| | | | | | |\
| | | | | |* `16:9`：1280×720  |\
| | | | | |* `9:16`：720×1280 |`keep_ratio`， |\
| | | | | | |即所生成视频的宽高比与所上传图片的宽高比保持一致。 |`keep_ratio`， |\
| | | | | | | |即所生成视频的宽高比与所上传图片的宽高比保持一致。 |
| | | | | | | | | \
|duration  |\
|生成视频时长（秒） |* 5 |\
| |* 10 |* 5 |\
| | |* 10 |* 5 |\
| | | |* 10 |* 5 |\
| | | | |* 10：仅t2v支持 |5 |5 |5 |
| | | | | | | | | \
|fps  |\
|帧率 |24 |24 |24 |24 |16 |16 |16 |
| | | | | | | | | \
|watermark  |\
|是否包含水印 |✅ |✅ |✅ |✅ |✅ |✅ |✅ |
| | | | | | | | | \
|seed  |\
| 种子整数 |✅ |✅ |✅ |✅ |✅ |✅ |✅ |
| | | | | | | | | \
|camerafixed |\
|是否固定摄像头 |✅ |✅ |✅ |❌ |❌ |❌ |❌ |


<span id="f5531933"></span>
## 前提条件

* 您已有方舟 API Key，作为模型推理服务调用鉴权使用。如无，请参考[1.获取 API Key](https://www.volcengine.com/docs/82379/1399008#10d67aef)。

* [获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) 。
   * 使用 Access Key 鉴权请参考[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
* [开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需 Model ID 。
   * 通过 Endpoint ID 调用模型服务请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。




<span id="9dc301c3"></span>
## 使用限制

* 任务数据（如任务状态、视频URL等）仅保留24小时，超时后会被自动清除。请您务必及时保存生成的视频。 
* 不同模型的限制值不同，详见[视频生成能力](https://www.volcengine.com/docs/82379/1330310#56cc9564)。
   * RPM 限流：单个主账号下，创建视频任务时，该模型版本的 RPM （Request Per Minute）限流若超过该限制，创建视频生成任务时会报错。
   * 并发数限制：单个主账号下，每个模型版本的最大请求并发数量。若超过该限制，后续提交的请求将排队等待。

<span id="1b7439df"></span>
## 使用说明及建议

* 用简洁准确的自然语言写出你想要的效果。
* 如果有较为明确的效果预期，建议先用生图模型生成符合预期的图片，再用图生视频进行视频片段的生成
* 文生视频会有较大的结果随机性，可以用于激发创作灵感
* 图生视频时请尽量上传高清高质量的图片，上传图片的质量对图生视频影响较大。
* 当生成的视频不符合预期时，建议修改提示词，将抽象描述换成具象描述，并注意删除不重要的部分，将重要内容前置。
* 更多提示词的使用技巧请参见 [Seedance 提示词指南](https://www.volcengine.com/docs/82379/1587797)。

<span id="0c66686f"></span>
## 使用示例
<span id="fded0dfc"></span>
### 设置生成视频格式
通过在文本提示词后追加`--[parameters]`的方式，可控制视频输出的规格，包括宽高比、帧率、分辨率等。
```Shell
// 指定生成视频的宽高比为16:9，时长为 5 秒，帧率为 24 fps，分辨率为720p，包含水印，不固定摄像头
一位身穿绿色亮片礼服的女性站在粉红色背景前，周围飘落着五彩斑斓的彩纸 --rt 16:9 --dur 5 --fps 24 --rs 720p --wm true --cf false
```

<span id="19d393e1"></span>
### 文生视频

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python" key="YFtcTQj2jj"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
# 初始化Ark客户端，从环境变量中读取您的API Key

client = Ark(
    # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    api_key=os.environ.get("ARK_API_KEY"),
)

print("----- create request -----")
# 创建视频生成任务
create_result = client.content_generation.tasks.create(
     # 替换 <Model> 为模型的Model ID
    model="<Model>", 
    content=[
        {
            # 文本提示词与参数组合
            "type": "text",
            "text": "一位身穿绿色亮片礼服的女性站在粉红色背景前，周围飘落着五彩斑斓的彩纸 --wm true --dur 5"
        }
    ]
)
print(create_result)


print("----- get request -----")
# 获取任务详情
get_result = client.content_generation.tasks.get(task_id=create_result.id)
print(get_result)


print("----- list request -----")
# 列出符合特定条件的任务
list_result = client.content_generation.tasks.list(
    page_num=1,
    page_size=10,
    status="queued",  # 按状态筛选, e.g succeeded, failed, running, cancelled
    # model="<YOUR_MODEL_EP>, # 按 ep 筛选
    # task_ids=["test-id-1", "test-id-2"] # 按 task_id 筛选
)
print(list_result)


print("----- delete request -----")
# 通过任务 id 删除任务
try:
    client.content_generation.tasks.delete(task_id=create_result.id)
    print(create_result.id)
except Exception as e:
    print(f"failed to delete task: {e}")
\`\`\`


`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java" key="yTipEVgAHK"><RenderMd content={`\`\`\`Java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.content.generation.DeleteContentGenerationTaskResponse;
import com.volcengine.ark.runtime.model.content.generation.*;
import com.volcengine.ark.runtime.model.content.generation.CreateContentGenerationTaskRequest.Content;
import com.volcengine.ark.runtime.service.ArkService;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;


public class ContentGenerationTaskExample {
    // 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
    // 初始化Ark客户端，从环境变量中读取您的API Key
    static String apiKey = System.getenv("ARK_API_KEY");
    static ConnectionPool connectionPool = new ConnectionPool(5, 1, TimeUnit.SECONDS);
    static Dispatcher dispatcher = new Dispatcher();
    static ArkService service = ArkService.builder()
           .dispatcher(dispatcher)
           .connectionPool(connectionPool)
           .apiKey(apiKey)
           .build();
    public static void main(String[] args) {
         //替换为您的 Model ID
        String model = "<Model>"; 

        System.out.println("----- CREATE Task Request -----");
        List<Content> contents = new ArrayList<>();

        // 文本提示词与参数组合
        contents.add(Content.builder()
                .type("text")
                .text("一位身穿绿色亮片礼服的女性站在粉红色背景前，周围飘落着五彩斑斓的彩纸 --wm true --dur 5")
                .build());
        
        // 创建视频生成任务
        CreateContentGenerationTaskRequest createRequest = CreateContentGenerationTaskRequest.builder()
                .model(model)
                .content(contents)
                .build();
 
        CreateContentGenerationTaskResult createResult = service.createContentGenerationTask(createRequest);
        System.out.println(createResult);

        System.out.println("----- GET Task Request -----");
        
        // 获取任务详情
        GetContentGenerationTaskRequest getRequest = GetContentGenerationTaskRequest.builder()
                .taskId(createResult.getId())
                .build();

        GetContentGenerationTaskResponse getResult = service.getContentGenerationTask(getRequest);
        System.out.println(getResult);

        System.out.println("----- LIST Task Request -----");
        
        // 列出符合特定条件的任务
        ListContentGenerationTasksRequest listRequest = ListContentGenerationTasksRequest.builder()
                .pageNum(1)
                .pageSize(10)
                .status(TaskStatus.RUNNING)
                .addTaskId(createResult.getId()) //  按 task_id 筛选
                //  如果您需要按多个 task_id 进行筛选
                // .taskIds(Arrays.asList("test-id-1", "test-id-2"))
                .model(model)
                .build();

        ListContentGenerationTasksResponse listResponse = service.listContentGenerationTasks(listRequest);
        System.out.println(listResponse);

        System.out.println("----- DELETE Task Request -----");
        
        // 通过任务 id 删除任务
        DeleteContentGenerationTaskRequest deleteRequest = DeleteContentGenerationTaskRequest.builder()
                .taskId(getResult.getId())
                .build();

        try {
            DeleteContentGenerationTaskResponse deleteResult = service.deleteContentGenerationTask(deleteRequest);
            System.out.println(deleteResult);
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }

        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go" key="dunqw92qil"><RenderMd content={`\`\`\`Go
package main

import (
        "context"
        "fmt"
        "github.com/volcengine/volcengine-go-sdk/volcengine"
        "os"

        "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
        "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
)

func main() {
        // 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
        // 初始化Ark客户端，从环境变量中读取您的API Key
        client := arkruntime.NewClientWithApiKey(
                // 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
                os.Getenv("ARK_API_KEY"),
        )
        ctx := context.Background()
         //替换为您的 Model ID
        modelEp := "<Model>" 
        fmt.Println("----- create content generation task -----")
        // 创建视频生成任务
        createReq := model.CreateContentGenerationTaskRequest{
                Model: modelEp,
                Content: []*model.CreateContentGenerationContentItem{
                        {
                                // 文本提示词与参数组合
                                Type: model.ContentGenerationContentItemTypeText,
                                Text: volcengine.String("一位身穿绿色亮片礼服的女性站在粉红色背景前，周围飘落着五彩斑斓的彩纸 --wm true --dur 5"),
                        },
                },
        }

        createResponse, err := client.CreateContentGenerationTask(ctx, createReq)
        if err != nil {
                fmt.Printf("create content generation error: %v", err)
                return
        }
        fmt.Printf("Task Created with ID: %s", createResponse.ID)

        fmt.Println("----- get content generation task -----")
        // 获取任务详情
        taskID := createResponse.ID

        getRequest := model.GetContentGenerationTaskRequest{ID: taskID}

        getResponse, err := client.GetContentGenerationTask(ctx, getRequest)
        if err != nil {
                fmt.Printf("get content generation task error: %v", err)
                return
        }

        fmt.Printf("Task ID: %s", getResponse.ID)
        fmt.Printf("Model: %s", getResponse.Model)
        fmt.Printf("Status: %s", getResponse.Status)
        fmt.Printf("Video URL: %s", getResponse.Content.VideoURL)
        fmt.Printf("Completion Tokens: %d", getResponse.Usage.CompletionTokens)
        fmt.Printf("Created At: %d", getResponse.CreatedAt)
        fmt.Printf("Updated At: %d", getResponse.UpdatedAt)
        if getResponse.Error != nil {
                fmt.Printf("Error Code: %s", getResponse.Error.Code)
                fmt.Printf("Error Message: %s", getResponse.Error.Message)
        }

        fmt.Println("----- list content generation task -----")
        
        // 列出符合特定条件的任务
        listRequest := model.ListContentGenerationTasksRequest{
                PageNum:  volcengine.Int(1),
                PageSize: volcengine.Int(10),
                Filter: &model.ListContentGenerationTasksFilter{
                        Status: volcengine.String(model.StatusSucceeded),
                        //TaskIDs: volcengine.StringSlice([]string{"cgt-example-1", "cgt-example-2"}),
                        //Model:   volcengine.String(modelEp),
                },
        }

        listResponse, err := client.ListContentGenerationTasks(ctx, listRequest)
        if err != nil {
                fmt.Printf("failed to list content generation tasks: %v", err)
        }

        fmt.Printf("ListContentGenerationTasks returned %v results", listResponse.Total)

        fmt.Println("----- delete content generation task -----")
        
        // 通过任务 id 删除任务
        deleteRequest := model.DeleteContentGenerationTaskRequest{ID: taskID}

        err = client.DeleteContentGenerationTask(ctx, deleteRequest)
        if err != nil {
                fmt.Printf("delete content generation task error: %v", err)
        } else {
                fmt.Println("successfully deleted task id: ", taskID)
        }

}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="979b2d28"></span>
### 图生视频-基于首帧

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python" key="dAdayzXTrF"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
# 初始化Ark客户端，从环境变量中读取您的API Key

client = Ark(
    # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    api_key=os.environ.get("ARK_API_KEY"),
)

print("----- create request -----")
# 创建视频生成任务
create_result = client.content_generation.tasks.create(
    # 替换 <Model> 为模型的Model ID
    model="<Model>", 
    content=[
        {
            # 文本提示词与参数组合
            "type": "text",
            "text": "女孩抱着狐狸，女孩睁开眼，温柔地看向镜头，狐狸友善地抱着，镜头缓缓拉出，女孩的头发被风吹动 --wm true --dur 5"
        },
        {
            # 图片URL
            "type": "image_url",
            "image_url": {
                "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/i2v_foxrgirl.png"
            }
        }
    ]
)
print(create_result)


print("----- get request -----")
# 获取任务详情
get_result = client.content_generation.tasks.get(task_id=create_result.id)
print(get_result)


print("----- list request -----")
# 列出符合特定条件的任务
list_result = client.content_generation.tasks.list(
    page_num=1,
    page_size=10,
    status="queued",  # 按状态筛选, e.g succeeded, failed, running, cancelled
    # model="<YOUR_MODEL_EP>", # 按 ep 筛选
    # task_ids=["test-id-1", "test-id-2"] # 按 task_id 筛选
)
print(list_result)


print("----- delete request -----")
# 通过任务 id 删除任务
try:
    client.content_generation.tasks.delete(task_id=create_result.id)
    print(create_result.id)
except Exception as e:
    print(f"failed to delete task: {e}")
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java" key="GFyqZNivpT"><RenderMd content={`\`\`\`Java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.content.generation.DeleteContentGenerationTaskResponse;
import com.volcengine.ark.runtime.model.content.generation.*;
import com.volcengine.ark.runtime.model.content.generation.CreateContentGenerationTaskRequest.Content;
import com.volcengine.ark.runtime.service.ArkService;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;


public class ContentGenerationTaskExample {
    // 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
    // 初始化Ark客户端，从环境变量中读取您的API Key
    static String apiKey = System.getenv("ARK_API_KEY");
    static ConnectionPool connectionPool = new ConnectionPool(5, 1, TimeUnit.SECONDS);
    static Dispatcher dispatcher = new Dispatcher();
    static ArkService service = ArkService.builder()
           .dispatcher(dispatcher)
           .connectionPool(connectionPool)
           .apiKey(apiKey)
           .build();
    public static void main(String[] args) {
          //替换为您的 Model ID
        String model = "<Model>"; 
        
        System.out.println("----- CREATE Task Request -----");
        List<Content> contents = new ArrayList<>();

        // 文本提示词与参数组合
        contents.add(Content.builder()
                .type("text")
                .text("女孩抱着狐狸，女孩睁开眼，温柔地看向镜头，狐狸友善地抱着，镜头缓缓拉出，女孩的头发被风吹动 --wm true --dur 5")
                .build());

        // 图片URL
        contents.add(Content.builder()
                .type("image_url")
                .imageUrl(CreateContentGenerationTaskRequest.ImageUrl.builder()
                        .url("https://ark-project.tos-cn-beijing.volces.com/doc_image/i2v_foxrgirl.png")
                        .build())
                .build());
        
        // 创建视频生成任务
        CreateContentGenerationTaskRequest createRequest = CreateContentGenerationTaskRequest.builder()
                .model(model)
                .content(contents)
                .build();
 
        CreateContentGenerationTaskResult createResult = service.createContentGenerationTask(createRequest);
        System.out.println(createResult);

        System.out.println("----- GET Task Request -----");
        
        // 获取任务详情
        GetContentGenerationTaskRequest getRequest = GetContentGenerationTaskRequest.builder()
                .taskId(createResult.getId())
                .build();

        GetContentGenerationTaskResponse getResult = service.getContentGenerationTask(getRequest);
        System.out.println(getResult);

        System.out.println("----- LIST Task Request -----");
        
        // 列出符合特定条件的任务
        ListContentGenerationTasksRequest listRequest = ListContentGenerationTasksRequest.builder()
                .pageNum(1)
                .pageSize(10)
                .status(TaskStatus.RUNNING)
                .addTaskId(createResult.getId()) //  按 task_id 筛选
                //  如果您需要按多个 task_id 进行筛选
                // .taskIds(Arrays.asList("test-id-1", "test-id-2"))
                .model(model)
                .build();

        ListContentGenerationTasksResponse listResponse = service.listContentGenerationTasks(listRequest);
        System.out.println(listResponse);

        System.out.println("----- DELETE Task Request -----");
        
        // 通过任务 id 删除任务
        DeleteContentGenerationTaskRequest deleteRequest = DeleteContentGenerationTaskRequest.builder()
                .taskId(getResult.getId())
                .build();

        try {
            DeleteContentGenerationTaskResponse deleteResult = service.deleteContentGenerationTask(deleteRequest);
            System.out.println(deleteResult);
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }

        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go" key="ZePqhns7y0"><RenderMd content={`
\`\`\`Go
package main

import (
        "context"
        "fmt"
        "github.com/volcengine/volcengine-go-sdk/volcengine"
        "os"

        "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
        "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
)

func main() {
        // 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
        // 初始化Ark客户端，从环境变量中读取您的API Key
        client := arkruntime.NewClientWithApiKey(
                // 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
                os.Getenv("ARK_API_KEY"),
        )
        ctx := context.Background()
        //替换为您的 Model ID
        modelEp := "<Model>" 

        fmt.Println("----- create content generation task -----")
        // 创建视频生成任务
        createReq := model.CreateContentGenerationTaskRequest{
                Model: modelEp,
                Content: []*model.CreateContentGenerationContentItem{
                        {
                                // 文本提示词与参数组合
                                Type: model.ContentGenerationContentItemTypeText,
                                Text: volcengine.String("女孩抱着狐狸，女孩睁开眼，温柔地看向镜头，狐狸友善地抱着，镜头缓缓拉出，女孩的头发被风吹动 --wm true --dur 5"),
                        },
                        {
                                // 图片URL
                                Type: model.ContentGenerationContentItemTypeImage,
                                ImageURL: &model.ImageURL{
                                        URL: "https://ark-project.tos-cn-beijing.volces.com/doc_image/i2v_foxrgirl.png", 
                                },
                        },
                },
        }

        createResponse, err := client.CreateContentGenerationTask(ctx, createReq)
        if err != nil {
                fmt.Printf("create content generation error: %v", err)
                return
        }
        fmt.Printf("Task Created with ID: %s", createResponse.ID)

        fmt.Println("----- get content generation task -----")
        // 获取任务详情
        taskID := createResponse.ID

        getRequest := model.GetContentGenerationTaskRequest{ID: taskID}

        getResponse, err := client.GetContentGenerationTask(ctx, getRequest)
        if err != nil {
                fmt.Printf("get content generation task error: %v", err)
                return
        }

        fmt.Printf("Task ID: %s", getResponse.ID)
        fmt.Printf("Model: %s", getResponse.Model)
        fmt.Printf("Status: %s", getResponse.Status)
        fmt.Printf("Video URL: %s", getResponse.Content.VideoURL)
        fmt.Printf("Completion Tokens: %d", getResponse.Usage.CompletionTokens)
        fmt.Printf("Created At: %d", getResponse.CreatedAt)
        fmt.Printf("Updated At: %d", getResponse.UpdatedAt)
        if getResponse.Error != nil {
                fmt.Printf("Error Code: %s", getResponse.Error.Code)
                fmt.Printf("Error Message: %s", getResponse.Error.Message)
        }

        fmt.Println("----- list content generation task -----")
        
        // 列出符合特定条件的任务
        listRequest := model.ListContentGenerationTasksRequest{
                PageNum:  volcengine.Int(1),
                PageSize: volcengine.Int(10),
                Filter: &model.ListContentGenerationTasksFilter{
                        Status: volcengine.String(model.StatusSucceeded),
                        //TaskIDs: volcengine.StringSlice([]string{"cgt-example-1", "cgt-example-2"}),
                        //Model:   volcengine.String(modelEp),
                },
        }

        listResponse, err := client.ListContentGenerationTasks(ctx, listRequest)
        if err != nil {
                fmt.Printf("failed to list content generation tasks: %v", err)
        }

        fmt.Printf("ListContentGenerationTasks returned %v results", listResponse.Total)

        fmt.Println("----- delete content generation task -----")
        
        // 通过任务 id 删除任务
        deleteRequest := model.DeleteContentGenerationTaskRequest{ID: taskID}

        err = client.DeleteContentGenerationTask(ctx, deleteRequest)
        if err != nil {
                fmt.Printf("delete content generation task error: %v", err)
        } else {
                fmt.Println("successfully deleted task id: ", taskID)
        }

}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="0d55ca07"></span>
### 图生视频-基于首尾帧


```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python" key="bukFdSpLyj"><RenderMd content={`
\`\`\`Python
import os
from volcenginesdkarkruntime import Ark

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
# 初始化Ark客户端，从环境变量中读取您的API Key

client = Ark(
    # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    api_key=os.environ.get("ARK_API_KEY"),
)

print("----- create request -----")
# 创建视频生成任务
create_result = client.content_generation.tasks.create(
    # 设置模型ID
    model="wan2-1-14b-flf2v-250417", 
    content=[
        {
            # 文本提示词与参数组合
            "type": "text",
            "text": "CG动画风格，一只蓝色的小鸟从地面起飞，煽动翅膀。小鸟羽毛细腻，胸前有独特的花纹，背景是蓝天白云，阳光明媚。镜跟随小鸟向上移动，展现出小鸟飞翔的姿态和天空的广阔。近景，仰视视角。--rs 720p  --dur 5"
        },
        {
            # 首帧图片URL
            "type": "image_url",
            "image_url": {
                "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/wan_input_first_frame.png"
            },
            "role": "first_frame"
        },
        {
            # 尾帧图片URL
            "type": "image_url",
            "image_url": {
                "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/wan_input_last_frame.png"
            },
            "role": "last_frame"
        }
    ]
)
print(create_result)


print("----- get request -----")
# 获取任务详情
get_result = client.content_generation.tasks.get(task_id=create_result.id)
print(get_result)


print("----- list request -----")
# 列出符合特定条件的任务
list_result = client.content_generation.tasks.list(
    page_num=1,
    page_size=10,
    status="queued",  # 按状态筛选, e.g succeeded, failed, running, cancelled
    # model="<YOUR_MODEL_EP>", # 按 ep 筛选
    # task_ids=["test-id-1", "test-id-2"] # 按 task_id 筛选
)
print(list_result)


print("----- delete request -----")
# 通过任务 id 删除任务
try:
    client.content_generation.tasks.delete(task_id=create_result.id)
    print(create_result.id)
except Exception as e:
    print(f"failed to delete task: {e}")
\`\`\`


`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java" key="ezIC1aYZ42"><RenderMd content={`
\`\`\`Java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.content.generation.DeleteContentGenerationTaskResponse;
import com.volcengine.ark.runtime.model.content.generation.*;
import com.volcengine.ark.runtime.model.content.generation.CreateContentGenerationTaskRequest.Content;
import com.volcengine.ark.runtime.service.ArkService;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;


public class ContentGenerationTaskExample {
    // 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
    // 初始化Ark客户端，从环境变量中读取您的API Key
    static String apiKey = System.getenv("ARK_API_KEY");
    static ConnectionPool connectionPool = new ConnectionPool(5, 1, TimeUnit.SECONDS);
    static Dispatcher dispatcher = new Dispatcher();
    static ArkService service = ArkService.builder()
           .dispatcher(dispatcher)
           .connectionPool(connectionPool)
           .apiKey(apiKey)
           .build();
    public static void main(String[] args) {
        //替换为您的 Model ID
        String model = "wan2-1-14b-flf2v-250417"; 
        
        System.out.println("----- CREATE Task Request -----");
        List<Content> contents = new ArrayList<>();

        // 添加文本提示词与参数组合
        contents.add(Content.builder()
                .type("text")
                .text("CG动画风格，一只蓝色的小鸟从地面起飞，煽动翅膀。小鸟羽毛细腻，胸前有独特的花纹，背景是蓝天白云，阳光明媚。镜跟随小鸟向上移动，展现出小鸟飞翔的姿态和天空的广阔。近景，仰视视角。--rs 720p  --dur 5")
                .build());

        // 添加首帧图片URL
        contents.add(Content.builder()
                .type("image_url")
                .imageUrl(CreateContentGenerationTaskRequest.ImageUrl.builder()
                        .url("https://ark-project.tos-cn-beijing.volces.com/doc_image/wan_input_first_frame.png")
                        .build())
                .role("first_frame")
                .build());

        // 添加尾帧图片URL
        contents.add(Content.builder()
                .type("image_url")
                .imageUrl(CreateContentGenerationTaskRequest.ImageUrl.builder()
                        .url("https://ark-project.tos-cn-beijing.volces.com/doc_image/wan_input_last_frame.png")
                        .build())
                .role("last_frame")
                .build());
        
        // 创建视频生成任务
        CreateContentGenerationTaskRequest createRequest = CreateContentGenerationTaskRequest.builder()
                .model(model)
                .content(contents)
                .build();
 
        CreateContentGenerationTaskResult createResult = service.createContentGenerationTask(createRequest);
        System.out.println(createResult);

        System.out.println("----- GET Task Request -----");
        
        // 获取任务详情
        GetContentGenerationTaskRequest getRequest = GetContentGenerationTaskRequest.builder()
                .taskId(createResult.getId())
                .build();

        GetContentGenerationTaskResponse getResult = service.getContentGenerationTask(getRequest);
        System.out.println(getResult);

        System.out.println("----- LIST Task Request -----");
        
        // 列出符合特定条件的任务
        ListContentGenerationTasksRequest listRequest = ListContentGenerationTasksRequest.builder()
                .pageNum(1)
                .pageSize(10)
                .status(TaskStatus.RUNNING)
                .addTaskId(createResult.getId()) //  按 task_id 筛选
                //  如果您需要按多个 task_id 进行筛选
                // .taskIds(Arrays.asList("test-id-1", "test-id-2"))
                .model(model)
                .build();

        ListContentGenerationTasksResponse listResponse = service.listContentGenerationTasks(listRequest);
        System.out.println(listResponse);

        System.out.println("----- DELETE Task Request -----");
        
        // 通过任务 id 删除任务
        DeleteContentGenerationTaskRequest deleteRequest = DeleteContentGenerationTaskRequest.builder()
                .taskId(getResult.getId())
                .build();

        try {
            DeleteContentGenerationTaskResponse deleteResult = service.deleteContentGenerationTask(deleteRequest);
            System.out.println(deleteResult);
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }

        service.shutdownExecutor();
    }
}
\`\`\`


`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go" key="qWIVc7tvC1"><RenderMd content={`
\`\`\`Go
package main

import (
        "context"
        "fmt"
        "github.com/volcengine/volcengine-go-sdk/volcengine"
        "os"

        "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
        "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
)

func main() {
        // 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
        // 初始化Ark客户端，从环境变量中读取您的API Key
        client := arkruntime.NewClientWithApiKey(
                // 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
                os.Getenv("ARK_API_KEY"),
        )
        ctx := context.Background()
        // 设置模型ID
        modelEp := "wan2-1-14b-flf2v-250417" 

        fmt.Println("----- create content generation task -----")
        // 创建视频生成任务
        createReq := model.CreateContentGenerationTaskRequest{
                Model: modelEp,
                Content: []*model.CreateContentGenerationContentItem{
                        {
                                // 文本提示词与参数组合
                                Type: model.ContentGenerationContentItemTypeText,
                                Text: volcengine.String("CG动画风格，一只蓝色的小鸟从地面起飞，煽动翅膀。小鸟羽毛细腻，胸前有独特的花纹，背景是蓝天白云，阳光明媚。镜跟随小鸟向上移动，展现出小鸟飞翔的姿态和天空的广阔。近景，仰视视角。--rs 720p  --dur 5"),
                        },
                        {
                                // 首帧图片URL
                                Type: model.ContentGenerationContentItemTypeImageURL,
                                ImageURL: &model.ImageURL{
                                        URL: "https://ark-project.tos-cn-beijing.volces.com/doc_image/wan_input_first_frame.png",
                                },
                                Role: volcengine.String("first_frame"),
                        },
                        {
                                // 尾帧图片URL
                                Type: model.ContentGenerationContentItemTypeImageURL,
                                ImageURL: &model.ImageURL{
                                        URL: "https://ark-project.tos-cn-beijing.volces.com/doc_image/wan_input_last_frame.png",
                                },
                                Role: volcengine.String("last_frame"),
                        },
                },
        }

        createResponse, err := client.CreateContentGenerationTask(ctx, createReq)
        if err != nil {
                fmt.Printf("create content generation error: %v", err)
                return
        }
        fmt.Printf("Task Created with ID: %s", createResponse.ID)

        fmt.Println("----- get content generation task -----")
        // 获取任务详情
        taskID := createResponse.ID

        getRequest := model.GetContentGenerationTaskRequest{ID: taskID}

        getResponse, err := client.GetContentGenerationTask(ctx, getRequest)
        if err != nil {
                fmt.Printf("get content generation task error: %v", err)
                return
        }

        fmt.Printf("Task ID: %s", getResponse.ID)
        fmt.Printf("Model: %s", getResponse.Model)
        fmt.Printf("Status: %s", getResponse.Status)
        fmt.Printf("Video URL: %s", getResponse.Content.VideoURL)
        fmt.Printf("Completion Tokens: %d", getResponse.Usage.CompletionTokens)
        fmt.Printf("Created At: %d", getResponse.CreatedAt)
        fmt.Printf("Updated At: %d", getResponse.UpdatedAt)
        if getResponse.Error != nil {
                fmt.Printf("Error Code: %s", getResponse.Error.Code)
                fmt.Printf("Error Message: %s", getResponse.Error.Message)
        }

        fmt.Println("----- list content generation task -----")
        
        // 列出符合特定条件的任务
        listRequest := model.ListContentGenerationTasksRequest{
                PageNum:  volcengine.Int(1),
                PageSize: volcengine.Int(10),
                Filter: &model.ListContentGenerationTasksFilter{
                        Status: volcengine.String(model.StatusSucceeded),
                        //TaskIDs: volcengine.StringSlice([]string{"cgt-example-1", "cgt-example-2"}),
                        //Model:   volcengine.String(modelEp),
                },
        }

        listResponse, err := client.ListContentGenerationTasks(ctx, listRequest)
        if err != nil {
                fmt.Printf("failed to list content generation tasks: %v", err)
        }

        fmt.Printf("ListContentGenerationTasks returned %v results", listResponse.Total)

        fmt.Println("----- delete content generation task -----")
        
        // 通过任务 id 删除任务
        deleteRequest := model.DeleteContentGenerationTaskRequest{ID: taskID}

        err = client.DeleteContentGenerationTask(ctx, deleteRequest)
        if err != nil {
                fmt.Printf("delete content generation task error: %v", err)
        } else {
                fmt.Println("successfully deleted task id: ", taskID)
        }
}
\`\`\`


`}></RenderMd></Tabs.TabPane></Tabs>);
 ```




# 图片生成
Source: https://www.volcengine.com/docs/82379/1548482
图片生成模型具备出色的语义理解能力，可根据用户输入的文本内容，快速生成优质的图片。通过这篇教程您可以学习到如何通过调用图片生成模型 API 来生成图片。
<span id="88612aa1"></span>
## 前提条件

* 您已有方舟 API Key，作为模型推理服务调用鉴权使用。如无，请参考[1.获取 API Key](https://www.volcengine.com/docs/82379/1399008#10d67aef)。
* 在[开通管理页](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)开通所需模型的服务。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需模型的ID（Model ID），后续调用模型服务时需使用。

<span id="386b6ea2"></span>
## 快速开始
您可以通过下面代码快速体验文生图片能力。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python" key="B9JXzaTl2o"><RenderMd content={`\`\`\`Python
import os
# 通过 pip install 'volcengine-python-sdk[ark]' 安装方舟SDK
from volcenginesdkarkruntime import Ark

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
# 初始化Ark客户端，从环境变量中读取您的API Key
client = Ark(
    # 此为默认路径，您可根据业务所在地域进行配置
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    api_key=os.environ.get("ARK_API_KEY"),
)

imagesResponse = client.images.generate(
    model="doubaoseedream-3-0-t2i-250415",
    prompt="鱼眼镜头，一只猫咪的头部，画面呈现出猫咪的五官因为拍摄方式扭曲的效果。"
)

print(imagesResponse.data[0].url)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java" key="w7D1u14JVx"><RenderMd content={`\`\`\`Java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.content.generation.*;
import com.volcengine.ark.runtime.model.images.generation.GenerateImagesRequest;
import com.volcengine.ark.runtime.model.images.generation.ImagesResponse;
import com.volcengine.ark.runtime.service.ArkService;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;

public class ImageGenerationsExample {
    public static void main(String[] args) {
        String apiKey = System.getenv("ARK_API_KEY");
        ConnectionPool connectionPool = new ConnectionPool(5, 1, TimeUnit.SECONDS);
        Dispatcher dispatcher = new Dispatcher();
        ArkService service = ArkService.builder().dispatcher(dispatcher).connectionPool(connectionPool).apiKey(apiKey).build();

        GenerateImagesRequest generateRequest = GenerateImagesRequest.builder()
                .model("doubao-seedream-3-0-t2i-250415")
                .prompt("鱼眼镜头，一只猫咪的头部，画面呈现出猫咪的五官因为拍摄方式扭曲的效果。")
                .build();

        ImagesResponse imagesResponse = service.generateImages(generateRequest);
        System.out.println(imagesResponse.getData().get(0).getUrl());

        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go" key="kZKbWKzCm6"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "fmt"
    "os"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
)

func main() {
    client := arkruntime.NewClientWithApiKey(os.Getenv("ARK_API_KEY"))
    ctx := context.Background()

    generateReq := model.GenerateImagesRequest{
       Model:  "doubao-seedream-3-0-t2i-250415",
       Prompt: "鱼眼镜头，一只猫咪的头部，画面呈现出猫咪的五官因为拍摄方式扭曲的效果。",
    }

    imagesResponse, err := client.GenerateImages(ctx, generateReq)
    if err != nil {
       fmt.Printf("generate images error: %v\n", err)
       return
    }

    fmt.Printf("%s\n", *imagesResponse.Data[0].Url)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="OpenAI" key="zkXk696C9u"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

# 请确保您已将 API Key 存储在环境变量 ARK_API_KEY 中
# 初始化Ark客户端，从环境变量中读取您的API Key
client = OpenAI(
    # 此为默认路径，您可根据业务所在地域进行配置
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 从环境变量中获取您的 API Key。此为默认方式，您可根据需要进行修改
    api_key=os.environ.get("ARK_API_KEY"),
)

response = client.images.generate(
    # 指定您创建的方舟推理接入点 ID，此处已帮您修改为您的推理接入点 ID
    model="doubao-seedream-3-0-t2i-250415",
    prompt="鱼眼镜头，一只猫咪的头部，画面呈现出猫咪的五官因为拍摄方式扭曲的效果。",
    size="1024x1024",
    response_format="url"        
)

print(response.data[0].url)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="faba9b74"></span>
## 支持模型
<span id="2fb07e2a"></span>
### doubao-seedream
文档：[图片生成API](https://www.volcengine.com/docs/82379/1541523)

| | | | | | | \
|**模型名称** |**版本** |**模型 ID（Model ID）** |**模型领域** |**限流 IPM** |\
| | | | |**每分钟生成图片上限（img / min）** |**定价** |\
| | | | | |**（元/张）** |
|---|---|---|---|---|---|
| | | | | | | \
|doubao-seedream-3.0-t2i |250415 |doubao-seedream-3-0-t2i-250415 |文生图 |500 |0.259 |

<span id="17630dce"></span>
## 应用场景

| | | \
|场景 |描述 |
|---|---|
| | | \
|广告设计 |快速生成多样化的广告素材，根据产品特点和目标受众，定制创意海报、宣传图片，节省设计时间与成本。 |
| | | \
|游戏开发 |辅助创建游戏场景、角色形象和道具，通过输入关键词，生成高分辨率、风格统一的美术资源，加速游戏开发进程。 |
| | | \
|电商平台 |为商品自动生成多角度、多场景展示图，模拟商品在不同环境下的使用效果，增强用户购物体验，提升商品吸引力。 |
| | | \
|教育领域 |生成教学所需的插图、示意图，将抽象知识转化为可视化图像，辅助教师讲解复杂概念，帮助学生更好地理解知识。 |
| | | \
|影视制作 |协助完成概念图绘制、特效场景设计，快速生成虚拟角色和奇幻场景的参考图，为影视创作提供灵感和视觉基础。 |




# 同声传译
Source: https://www.volcengine.com/docs/82379/1433754
同声传译大模型服务接收待翻译内容的语音输入，经智能处理与分析，实时精准翻译，输出对应目标语言文本或语音。在会议、媒体活动等场景中，突破语言障碍，帮助您以及您的用户顺畅进行跨国交流、信息传递与知识共享。
:::tip
此为邀测能力，如需使用，提交[测试申请工单](https://console.volcengine.com/auth/login?redirectURI=%2Fworkorder%2Fcreate%3Fstep%3D2%26SubProductID%3DP00001166)。
:::


<span id="3dae0736"></span>
# 应用场景

| | | | \
|场景 |场景细分 |描述 |
|---|---|---|
| | | | \
|国际会议 |政治会议 |各国领导人峰会或国际组织会议中，大模型接入系统，翻译多国领导人发言，处理多语种多口音，保障沟通。 |
|^^| | | \
| |商务会议 |跨国商务谈判、行业研讨会里，大模型助力参会者理解内容，精准翻译商务术语，推动交流合作。 |
|^^| | | \
| |学术会议 |国际学术研讨、讲座场景下，大模型准确翻译专业术语，借助数据学习，传播学术成果。 |
| | | | \
|法庭审判 |涉外法庭 |涉外国当事人或文件的庭审中，大模型准确翻译证词等信息，适应法庭环境与法律术语。 |
| | | | \
|媒体活动 |新闻发布会 |企业、政府国际新闻发布时，大模型实时翻译，贴合表述习惯，方便媒体报道。 |
|^^| | | \
| |影视传媒 |国际电影节、纪录片活动中，大模型分析影片文化背景与情感，贴合情境翻译，优化观影体验。 |

<span id="37377baa"></span>
# 支持模型
当前支持同声传译的模型请参见 [同声传译能力](https://www.volcengine.com/docs/82379/1330310#cb87a288)。
<span id="d540c6f6"></span>
# 工作机制
您可以使用Websocket接口来调用同声传译模型服务，来实现音频即时输入和原文&译文的即时输出。下面是工作时的客户端、服务端交互机制。



完整信息交互分为几个阶段：

1. 建立连接和 Session 配置：
   1. 服务端与客户端建立连接。
   2. 并按照配置创建 Session 。
   3. 更新Session配置。
2. Session内数据交互，包括2部分
   1. 音频数据发送给服务端。
   2. 音频数据转为原文以及译文后返回客户端。
3. 结束 Session 并关闭连接：
   1. 客户端发送停止信号。
   2. 服务端将过程中的数据处理完毕，发送信号结束交互过程。

<span id="aaf45f14"></span>
# 接口说明
同传的接口说明请参见[同声传译 API](https://www.volcengine.com/docs/82379/1394617)。
<span id="70056a39"></span>
# 使用说明
<span id="095be31d"></span>
## **超时断连机制**

* 单连接最大连接时长为 2 小时，超时将会强制断连。
* 单连接静默持续时长 0.5 小时，超时将会强制断连。 

<span id="76aaee3a"></span>
## **限流机制**

* 主账号下同时在线连接数：10。
* 客户端每次发送的音频数据不大于10KB ，超过大于10 KB 的音频数据将会跳过，不会处理。
* 每分钟单连接提交`input_audio.commit`事件的数量Commit Per Minute (CPM) Per Connection上限为 700 次，账号下每个连接独立限制，互不影响。
* 每分钟单连接可使用的output tokens量（TPM Per Connection）上限为1200，账号下每个连接独立限制，互不影响。

<span id="52269492"></span>
## **语音数据切换语种**
如果您希望在连接 Session 中更换目标语言与源语言的语种，暂不建议直接更新 Session 配置（调用`session.update `），建议静默4秒或以上时间（即这段时间不发送音频数据给方舟），再更新 Session 配置。
> 如跨国电话会议，不同发言人可能使用不同的语种，此时可能会需要在连接 Session 中切换语种。

<span id="04b0f0c8"></span>
# 使用示例
下面通过一个 demo 为您介绍如何通过 WebSocket API 实现同声传译。
demo实现了，将一个音频文件（MP3 格式）转为流式音频，实现和服务端进行通信，实现音频的实时翻译和转录。
<span id="181e9804"></span>
## 前提条件
* [获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) 。
   * 使用 Access Key 鉴权请参考[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
* [开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需 Model ID 。
   * 通过 Endpoint ID 调用模型服务请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。




* 安装开源视频处理工具 FFmpeg，具体请参见[官方网站](https://www.ffmpeg.org/download.html)。

> 示例中使用FFmpeg来处理音频文件，将音频文件转化为音频元数据。

<span id="f6d0d705"></span>
## Node.js
<span id="2b9522c1"></span>
### 工程文件
<Attachment link="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/61df65a4db24419193b0442d26f2fc7e~tplv-goo7wpa0wc-image.image" name="ark_clasi_nodejs_beta.zip" ></Attachment>
代码的流程如下，具体的实现参见工程代码中的注释。

1. 初始化配置。
2. 读取音频文件。
3. 建立 WebSocket 连接。
4. 处理 WebSocket 事件。
5. 发送音频结束信号。

<span id="2cff570e"></span>
### 1.准备环境

1. 安装开源视频处理工具 FFmpeg，具体请参见[官方网站](https://www.ffmpeg.org/download.html)。

> 示例中使用了FFmpeg来处理音频文件，将音频文件转化为音频元数据。


2. 参考[Node.js官方文档](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)安装 Node.js。

> 为了方便安装和管理，我们采用官方推荐的nvm（node.js的版本管理器）安装Node.js与依赖包。


3. 下载工程文件，运行终端，进入工程文件目录，运行下面代码安装 Node.js 依赖包。

```Shell
npm install
```

<span id="844f18b2"></span>
### 2.配置代码
配置index.js脚本文件中下面部分
```JavaScript
...
// 调用同传模型，配置参数
new SimultaneousInterpretation({
    model: "<Model>",//替换 <Model> 为模型的 Model ID
    audioFilePath: path.resolve(__dirname, "input/demo.mp3"),//设置音频文件路径
    ffmpegFilePath: path.resolve(__dirname, "output/demo_mp3_ffmpeg.pcm"),//设置pcm文件保存的路径
    translationFilePath: path.resolve(
        __dirname,
        "output/demo_mp3_translation.txt"
    ),//设置翻译脚本保存的文件
    transcriptionFilePath: path.resolve(
        __dirname,
        "output/demo_mp3_transcription.txt"
    ),//设置源语言脚本保存的文件
    sourceLanguage: "zh", // 设置源语言为中文
    targetLanguage: "en", // 设置目标语言为英文
    glossaryList: [
        {
            // 替换为您的翻译术语库，模型翻译时会参考下面的对照关系
            input_audio_transcription: "大模型",
            input_audio_translation: "LLM",
        },
    ],
}).run();
```

<span id="1916dc04"></span>
### 3.运行脚本
运行终端，进入工程文件目录，运行下面命令，执行脚本。
```Shell
export ARK_API_KEY=<YOUR_ARK_API_KEY>
npm run start
```

<span id="6d20301c"></span>
## Java
<span id="fbf325c4"></span>
### 工程文件
<Attachment link="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/927cf4acbf334e969dfdfc46f4f5d93f~tplv-goo7wpa0wc-image.image" name="ark_clasi_java_beta.zip" ></Attachment>
代码的流程如下，具体的实现参见工程代码中的注释。

1. 初始化WebSocket客户端。
2. 连接建立。
3. 发送音频数据。
4. 接收服务器消息。
5. 音频传输完成。
6. 连接关闭。

<span id="0d4131dc"></span>
### 1.准备环境

1. 安装开源视频处理工具 FFmpeg，具体请参见[官方网站](https://www.ffmpeg.org/download.html)。

> 示例中使用了FFmpeg来处理音频文件，将音频文件转化为音频元数据。


2. 参考[Java](https://www.volcengine.com/docs/82379/1399008#0009f01e)准备 Java 开发环境。
3. 下载工程文件，运行终端，进入工程文件目录，运行下面命令清理以及安装依赖项。

```Shell
mvn clean install
```

<span id="7c47fef7"></span>
### 2.配置代码
 您需要对项目中的`SimultaneousInterpretationMain.java`文件进行配置：

* `private static final String model = "<Model>";`：替换为模型的Model ID，需配置同声传译模型。
* `private static final String filePath = "./input/demo.mp3";`：配置您的输入音频。
* `private static final String transcriptionFilePath = "./output/transcription.txt";`：音频转录文本的保存路径。
* `private static final String translationFilePath = "./output/translation.txt";`：音频翻译文本的保存路径。
* `"source_language", "zh",`：替换为您的音频文件的语种。
* `"target_language", "en",`：替换为您希望音频翻译成的语种。
*  替换您的翻译术语库，模型翻译时会参考下面的对照关系，如模型翻译时会将“大模型”翻译为“LLM”。

```Python
"input_audio_transcription", "大模型",
"input_audio_translation", "LLM"
```

<span id="a80fcabe"></span>
### 3.编译与运行

1. 打开终端，进入项目文件根目录，执行下面命令来运行 Java 代码。

```Shell
export ARK_API_KEY=<YOUR_ARK_API_KEY>
mvn exec:java -Dexec.mainClass="com.example.SimultaneousInterpretationMain"
```

<span id="db9acdec"></span>
## Python
<span id="732d98d4"></span>
### 工程文件
<Attachment link="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/499ccd3035b948d5a0dde587239d9097~tplv-goo7wpa0wc-image.image" name="ark_clasi_python_beta.zip" ></Attachment>
代码的流程如下，具体的实现参见工程代码中的注释。

* 建立 WebSocket 连接。
* 接收服务端返回的数据。
* 处理关闭连接事件以及异常事件。

<span id="cd54c1cc"></span>
### 1.准备环境

1. 安装开源视频处理工具 FFmpeg，具体请参见[官方网站](https://www.ffmpeg.org/download.html)。

> 示例中使用了FFmpeg来处理音频文件，将音频文件转化为音频元数据。


2. 参考[Python 安装](https://www.volcengine.com/docs/82379/1399008#ac6d94e2)，配置 Python 环境。
3. 安装 Python 依赖包，下载上面工程文件，解压后，并在终端中执行下面命令。

```Python
pip install -r requirements.txt
```

<span id="1aa164eb"></span>
### 2.配置代码
下面是 Python 示例代码。您需要进行下面配置：

* `file_path = "./input/demo.mp3"`：配置为您的输入音频。
* `<Model>`：替换为模型的Model ID，需配置同声传译模型。
* `transcription_file_path = "output/transcription.txt"`：音频转录文本的保存路径。
* `translation_file_path = "output/translation.txt"`：音频翻译文本的保存路径。
* ` "source_language": "zh"`：替换为您的音频文件的语种。
* `"target_language": "en"`：替换为您希望音频翻译成的语种。
*  替换您的翻译术语库，模型翻译时会参考下面的对照关系，如模型翻译时会将“大模型”翻译为“LLM”。

```Python
"input_audio_transcription": "大模型",
"input_audio_translation": "LLM",
```

<span id="6b34c37b"></span>
### 3.运行脚本
在终端中运行下面命令，运行 Python 脚本。
```Shell
export ARK_API_KEY=<YOUR_ARK_API_KEY>
python demo.py
```

正常运行，您会在终端回显中看到转录文本以及翻译文本，在输出目录会生成转录文件和翻译文件。





# 结构化输出
Source: https://www.volcengine.com/docs/82379/1568221
当您需要模型像程序一样输出标准格式（这里主要指 JSON 格式）而不是自然语言，方便工具进行标准化处理或展示时，可以使用格式化输出能力。
要启用该能力，需在请求时配置 **response_format** 对象，来指定模型输出 JSON 格式，甚至通过定义 JSON 结构，进一步定义模型输出哪些字段信息。
与通过提示词控制模型输出 JSON 格式的方法（不推荐）相比，使用结构化输出能力有以下好处：

* 输出更可靠：输出结构始终符合预期数据类型，包括结构中字段层级、名称、类型、顺序等，不必担心丢失必要的字段或生成幻觉的枚举值等，
* 使用更加简单：使用 API 字段来定义，提示词可更加简单，无需在提示词中反复强调或使用强烈措辞。

<span id="3aae5325"></span>
# 支持的模型
请参见[结构化输出](https://www.volcengine.com/docs/82379/1330310#5414cb1d)。
<span id="bbefb0e1"></span>
# API 文档
结构化输出 API 字段说明见[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384)。
<span id="87d19412"></span>
# 快速开始

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="h5E4z8eduW"><RenderMd content={`\`\`\`Bash
curl --location "https://ark.cn-beijing.volces.com/api/v3/chat/completions" \\
--header "Authorization: Bearer $ARK_API_KEY" \\
--header "Content-Type: application/json" \\
--data '{
  "model": "doubao-seed-1-6-250615",
  "messages": [
    {
      "role": "system",
      "content": "你是一位数学辅导老师。"
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "使用中文解题: 8x + 9 = 32 and x + y = 1"
        }
      ]
    }
  ],
  "response_format": {
    "type": "json_schema",
    "json_schema": {
      "name": "math_reasoning",
      "schema": {
        "type": "object",
        "properties": {
          "steps": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "explanation": {
                  "type": "string"
                },
                "output": {
                  "type": "string"
                }
              },
              "required": [
                "explanation",
                "output"
              ],
              "additionalProperties": false
            }
          },
          "final_answer": {
            "type": "string"
          }
        },
        "required": [
          "steps",
          "final_answer"
        ],
        "additionalProperties": false
      },
      "strict": true
    }
  },
  "thinking": {
    "type": "disabled"
  }
}'
\`\`\`

  其中，您可以通过 **thinking** 字段控制模型是否深度思考能力。

   * \`"disabled"\`：不使用深度思考能力。
   * \`"enabled"\`：强制使用深度思考能力。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python SDK" key="QegIIsGlKv"><RenderMd content={`\`\`\`Python
from volcenginesdkarkruntime import Ark
import os
from pydantic import BaseModel  # 用于定义响应解析模型

# 初始化方舟SDK客户端
client = Ark(
    # 从环境变量获取方舟API Key（需提前设置环境变量）
    api_key=os.environ.get("ARK_API_KEY"),
)

# 定义分步解析模型（对应业务场景的结构化响应）
class Step(BaseModel):
    explanation: str  # 步骤说明
    output: str       # 步骤计算结果

# 定义最终响应模型（包含分步过程和最终答案）
class MathResponse(BaseModel):
    steps: list[Step]       # 解题步骤列表
    final_answer: str       # 最终答案

# 调用方舟模型生成响应（自动解析为指定模型）
completion = client.beta.chat.completions.parse(
    model="doubao-seed-1-6-250615",  # 具体模型需替换为实际可用模型
    messages=[
        {"role": "system", "content": "你是一位数学辅导老师，需详细展示解题步骤"},
        {"role": "user", "content": "用中文解方程组：8x + 9 = 32 和 x + y = 1"}
    ],
    response_format=MathResponse,  # 指定响应解析模型
    extra_body={
         "thinking": {
             "type": "disabled" # 不使用深度思考能力
             # "type": "enabled" # 使用深度思考能力
         }
     }
)

# 提取解析后的结构化响应
resp = completion.choices[0].message.parsed

# 打印格式化的JSON结果
print(resp.model_dump_json(indent=2))
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="OpenAI Python SDK" key="leXZIkHG4j"><RenderMd content={`\`\`\`Python
from openai import OpenAI
import os
from pydantic import BaseModel

client = OpenAI(
    # 从环境变量中获取方舟 API Key
    api_key=os.environ.get("ARK_API_KEY"),
    base_url = "https://ark.cn-beijing.volces.com/api/v3",
)

class Step(BaseModel):
    explanation: str
    output: str
class MathResponse(BaseModel):
    steps: list[Step]
    final_answer: str
    
completion = client.beta.chat.completions.parse(
    model = "doubao-seed-1-6-250615",  # 替换为您需要使用的模型
    messages = [
        {"role": "system", "content": "你是一位数学辅导老师。"},
        {"role": "user", "content": "使用中文解题: 8x + 9 = 32 and x + y = 1"},
    ],
    response_format=MathResponse,
    extra_body={
         "thinking": {
             "type": "disabled" # 不使用深度思考能力
             # "type": "enabled" # 使用深度思考能力
         }
     }
)
resp = completion.choices[0].message.parsed
# 打印 JSON 格式结果
print(resp.model_dump_json(indent=2))
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go SDK" key="sey1ruMazd"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "os"
    "github.com/invopop/jsonschema" // required go1.18+
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

// 定义分步解析模型（对应业务场景的结构化响应）
type Step struct {
    Explanation string \`json:"explanation" jsonschema_description:"步骤说明"\`
    Output      string \`json:"output" jsonschema_description:"步骤计算结果"\`
}

// 定义最终响应模型（包含分步过程和最终答案）
type MathResponse struct {
    Steps       []Step \`json:"steps" jsonschema_description:"解题步骤列表"\`
    FinalAnswer string \`json:"final_answer" jsonschema_description:"最终答案"\`
}

// 复用原有 Schema 生成函数（已优化返回类型）
func GenerateSchema[T any]() *jsonschema.Schema { // <-- 优化返回类型为具体 Schema 类型
    reflector := jsonschema.Reflector{
        AllowAdditionalProperties: false,
        DoNotReference:            true,
    }
    return reflector.Reflect(new(T)) // 使用 new(T) 避免空值问题
}

// 生成数学响应的 JSON Schema
var MathResponseSchema = GenerateSchema[MathResponse]()

func main() {
    client := arkruntime.NewClientWithApiKey(
        os.Getenv("ARK_API_KEY"),
        )
    ctx := context.Background()

    // 构造请求消息（包含 system 和 user 角色）
    messages := []*model.ChatCompletionMessage{
        {
            Role: model.ChatMessageRoleSystem,
            Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("你是一位数学辅导老师，需详细展示解题步骤"),
            },
        },
        {
            Role: model.ChatMessageRoleUser,
            Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("用中文解方程组：8x + 9 = 32 和 x + y = 1"),
            },
        },
    }

    // 配置响应格式（使用 MathResponse 的 Schema）
    schemaParam := model.ResponseFormatJSONSchemaJSONSchemaParam{
        Name:        "math_response", // 对应 Python 中的响应名称
        Description: "数学题解答的结构化响应",
        Schema:      MathResponseSchema,
        Strict:      true,
    }

    // 构造请求（包含 thinking 配置）
    req := model.CreateChatCompletionRequest{
        Model:    "doubao-seed-1-6-250615", // 需替换为实际可用模型
        Messages: messages,
        ResponseFormat: &model.ResponseFormat{
            Type:       model.ResponseFormatJSONSchema,
            JSONSchema: &schemaParam,
        },
        Thinking: &model.Thinking{
            // Type: model.ThinkingTypeDisabled, // 关闭深度思考能力
            Type: model.ThinkingTypeEnabled, //开启深度思考能力
        },
    }


    // 调用 API
    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
        fmt.Printf("structured output chat error: %v\\n", err)
        return
    }


    // 解析结构化响应（关键差异：Go 需要手动反序列化）
    var mathResp MathResponse
    err = json.Unmarshal([]byte(*resp.Choices[0].Message.Content.StringValue), &mathResp)
    if err != nil {
        panic(err.Error())
    }


    // 打印格式化结果（使用 json.MarshalIndent 实现缩进）
    prettyJSON, _ := json.MarshalIndent(mathResp, "", "  ")
    fmt.Println(string(prettyJSON))
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java SDK" key="DLYn8gQPPT"><RenderMd content={`\`\`\`Java
package com.example;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest.ChatCompletionRequestResponseFormat;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.model.completion.chat.ResponseFormatJSONSchemaJSONSchemaParam;
import com.volcengine.ark.runtime.service.ArkService;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;

public class ChatCompletionsStructuredOutputsExamplev4 {
    static String apiKey = System.getenv("ARK_API_KEY");
    static ArkService service = ArkService.builder()
            .connectionPool(new ConnectionPool(5, 1, TimeUnit.SECONDS))
            .dispatcher(new Dispatcher())
            .apiKey(apiKey)
            .build();

    public static void main(String[] args) throws JsonProcessingException {
        ObjectMapper mapper = new ObjectMapper();

        // 构造消息列表（包含 system 和 user 角色）
        List<ChatMessage> messages = new ArrayList<>();
        messages.add(ChatMessage.builder()
                .role(ChatMessageRole.SYSTEM)
                .content("你是一位数学辅导老师，需详细展示解题步骤")
                .build());
        messages.add(ChatMessage.builder()
                .role(ChatMessageRole.USER)
                .content("用中文解方程组：8x + 9 = 32 和 x + y = 1")
                .build());

        // 生成 JSON Schema
        String schemaJson = "{\\n" +
                "  \\"type\\": \\"object\\",\\n" +
                "  \\"properties\\": {\\n" +
                "    \\"steps\\": {\\n" +
                "      \\"type\\": \\"array\\",\\n" +
                "      \\"items\\": {\\n" +
                "        \\"$ref\\": \\"#/definitions/Step\\"\\n" +
                "      }\\n" +
                "    },\\n" +
                "    \\"finalAnswer\\": {\\n" +
                "      \\"type\\": \\"string\\"\\n" +
                "    }\\n" +
                "  },\\n" +
                "  \\"definitions\\": {\\n" +
                "    \\"Step\\": {\\n" +
                "      \\"type\\": \\"object\\",\\n" +
                "      \\"properties\\": {\\n" +
                "        \\"explanation\\": {\\n" +
                "          \\"type\\": \\"string\\"\\n" +
                "        },\\n" +
                "        \\"output\\": {\\n" +
                "          \\"type\\": \\"string\\"\\n" +
                "        }\\n" +
                "      }\\n" +
                "    }\\n" +
                "  }\\n" +
                "}";
        JsonNode schemaNode = mapper.readTree(schemaJson);

        // 配置响应格式
        ChatCompletionRequestResponseFormat responseFormat = new ChatCompletionRequestResponseFormat(
                "json_schema",
                new ResponseFormatJSONSchemaJSONSchemaParam(
                        "math_response",
                        "数学题解答的结构化响应",
                        schemaNode,
                        true
                )
        );

        // 构造请求（包含 thinking 配置）
        ChatCompletionRequest request = ChatCompletionRequest.builder()
                .model("doubao-seed-1-6-250615") // 替换为实际使用模型
                .messages(messages)
                .responseFormat(responseFormat)
                .thinking(new ChatCompletionRequest.ChatCompletionRequestThinking("disabled")) // 关闭模型深度思考能力
                .build();

        // 调用 API 并解析响应
        var response = service.createChatCompletion(request);
        if (!response.getChoices().isEmpty()) {
            String content = String.valueOf(response.getChoices().get(0).getMessage().getContent());
            JsonNode jsonNode = mapper.readTree(content);
            // 打印格式化结果
            System.out.println(mapper.writerWithDefaultPrettyPrinter().writeValueAsString(jsonNode));
        }

        service.shutdownExecutor();
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

返回预览
```JSON
{
  "steps": [
    {
      "explanation": "解第一个方程8x + 9 = 32，先将等式两边同时减去9，得到8x = 32 - 9",
      "output": "8x = 23"
    },
    {
      "explanation": "然后等式两边同时除以8，求出x的值",
      "output": "x = 23/8"
    },
    {
      "explanation": "将x = 23/8代入第二个方程x + y = 1，求解y，即y = 1 - x",
      "output": "y = 1 - 23/8"
    },
    {
      "explanation": "计算1 - 23/8，通分后得到(8 - 23)/8",
      "output": "y = -15/8"
    }
  ],
  "final_answer": "x = 23/8，y = -15/8"
}
```

<span id="3e3c187a"></span>
# 模式对比：**`json_schema`** 与 `json_object`
格式化输出可以选择不同类型（**type**），包括 `json_schema`、`json_object` 、`text`。除 `text` 是让模型使用自然语言进行回复，`json_schema`  和 `json_object` 均是控制生成 JSON 格式回答，同时 `json_schema` 是 `json_object` 的演进版本，以下是他们的异同点。
> 当前 `json_schema` 功能还在beta 测试中，请谨慎评估后再在生产环境使用。


| | | | \
|结构化输出 |`json_schema`  |`json_object` |
|---|---|---|
| | | | \
|生成 JSON 回复 |是 |是 |
| | | | \
|可定义 JSON 结构 |是 |否 |\
| | |仅保障回复是合法 JSON |
| | | | \
|是否推荐 |是 |否 |
| | | | \
|支持的模型 |* doubao-seed-1-6-250615 |\
| |* doubao-seed-1-6-flash-250615 |\
| |* doubao-seed-1-6-thinking-250615 |\
| |* doubao-1-5-thinking-pro-250415 |\
| |* doubao-1-5-thinking-vision-pro-250428 |\
| |* deepseek-r1-250528 |* doubao-seed-1-6-250615 |\
| | |* doubao-seed-1-6-flash-250615 |\
| | |* doubao-seed-1-6-thinking-250615 |\
| | |* doubao-1-5-thinking-pro-250415 |\
| | |* doubao-1-5-thinking-vision-pro-250428 |\
| | |* doubao-1-5-vision-pro-250328 |\
| | |* deepseek-r1-250528 |
| | | | \
|严格模式 |\
|> 严格按照定义的结构生成回复。 |支持 |\
| |通过设置 **strict** 为 `true` 生效。 |\
| | |\
| |* 遵循语法[附1. JSON Schema 语法支持说明](https://www.volcengine.com/docs/82379/1568221#07ec5656)，若有不支持的结构会显示报错。 |不涉及 |
| | | | \
|配置方式 |..., |\
| |"response_format": {  |\
| |  "type": "json_schema",  |\
| |  "json_schema"{ |\
| |    "name":"my_schema", |\
| |    "strict": true,  |\
| |    "schema": {...} |\
| |  } |\
| |}, |\
| |... | ..., |\
| | |"response_format": {  |\
| | |  "type": "json_object" |\
| | |}, |\
| | |... |

<span id="7683a597"></span>
# 推荐使用步骤
<span id="8d92bc51"></span>
## 1.定义结构
您需要在 **schema** 字段中定义好模型生成的回复的 JSON 结构，可以参考[快速开始](https://www.volcengine.com/docs/82379/1568221#87d19412)的示例。

* 当您需要模型严格按照结构输出时，需配置 **strict** 字段为 `true`。方舟支持的关键字可见[附1. JSON Schema 语法支持说明](https://www.volcengine.com/docs/82379/1568221#07ec5656)，如果有明显不支持的定义，方舟会显示报错。
* 当您配置 **strict** 字段为 `false` 或者未配置 **strict** 字段，方舟会生成合法 JSON 结构的内容，同时尽可能参考您的定义的结构，不会对语法校验及报错。
* 请注意同级字段的先后顺序，模型输出将根据 **schema** 字段定义的字段顺序数据。

:::tip
为了帮助您获得更好的生成质量，JSON Schema 和提示词设计强烈建议阅读 [附2. JSON Schema 定义建议 ](https://www.volcengine.com/docs/82379/1568221#3267c790)、[附3. Prompt 建议](https://www.volcengine.com/docs/82379/1568221#05849c36)。
:::
<span id="9915283f"></span>
## 2.API 中进行配置JSON Schema
在 API 中指定结构化输出的模式
```JSON
...,
"response_format": { 
  "type": "json_schema", 
  "json_schema"{
    "name":"my_schema",
    "strict": true, 
    "schema": {...}
  }
},
...
```

完整示例代码见 [快速开始](https://www.volcengine.com/docs/82379/1568221#87d19412)。
:::tip
请勿与 **frequency_penalty**，**presence_penalty** 等采样参数共同使用，可能会导致模型输出异常。
:::
<span id="adf6252e"></span>
## 3. 处理错误案例
模型输出结构仍然可能包含错误，可能因为输出长度限制、任务复杂度、格式不清晰等。可以尝试调整指令，或将任务进行拆分为更简单子任务。您可以使用方舟的提示词优化工具来帮您优化模型提示词，详细见 [PromptPilot 概述](https://www.volcengine.com/docs/82379/1399495)。
<span id="07ec5656"></span>
# 附1. JSON Schema 语法支持说明
:::tip
* 按关键字的作用域分类，JSON Schema 有效关键字全集 https://json-schema.org/understanding-json-schema/keywords
* 下面支持的关键字代表方舟已支持关键字对应的输出格式约束语义。
* 方舟会忽略 JSON Schema 规范中没有格式约束语义的关键字。
* 使用明确不支持的关键字，方舟会显式报错。
* 请勿与 **frequency_penalty**，**presence_penalty** 等采样参数共同使用，可能会导致模型输出异常。
:::
<span id="cdc803ee"></span>
## Schema 层面公共关键字

* [type](https://www.learnjsonschema.com/2020-12/validation/type/)
   * integer
   * number
   * string
   * boolean
   * null
   * array
   * object
* [$ref](https://www.learnjsonschema.com/2020-12/core/ref/)
   * 只支持 `#` 开头的本地相对引用
* [$defs](https://www.learnjsonschema.com/2020-12/core/defs/)
* [const](https://www.learnjsonschema.com/2020-12/validation/const/)
* [enum](https://www.learnjsonschema.com/2020-12/validation/enum/)
* [anyOf](https://www.learnjsonschema.com/2020-12/applicator/anyof/)
* [oneOf](https://www.learnjsonschema.com/2020-12/applicator/oneof/)
   * 不严格保证 exactly one 语义
* [allOf](https://www.learnjsonschema.com/2020-12/applicator/allof/)
   * 不严格保证 all 语义

<span id="d2f98d7f"></span>
## type 相关的关键字

* "type": "integer"
   * [minimum](https://www.learnjsonschema.com/2020-12/validation/minimum/)
   * [maximum](https://www.learnjsonschema.com/2020-12/validation/maximum/)
   * [exclusiveMinimum](https://www.learnjsonschema.com/2020-12/validation/exclusiveminimum/)
   * [exclusiveMaximum](https://www.learnjsonschema.com/2020-12/validation/exclusivemaximum/)

> 以上无法 100% 保证区间语义。


* "type": "array"
   * [prefixItems](https://www.learnjsonschema.com/2020-12/applicator/prefixitems/)
   * [items](https://www.learnjsonschema.com/2020-12/applicator/items/)
   * [unevaluatedItems](https://www.learnjsonschema.com/2020-12/unevaluated/unevaluateditems/)
* "type": "object"
   * [properties](https://www.learnjsonschema.com/2020-12/applicator/properties/)
   * [required](https://www.learnjsonschema.com/2020-12/validation/required/)
   * [additionalProperties](https://www.learnjsonschema.com/2020-12/applicator/additionalproperties/)
   * [unevaluatedProperties](https://www.learnjsonschema.com/2020-12/unevaluated/unevaluatedproperties/)

<span id="3267c790"></span>
# 附2. JSON Schema 定义建议 
<span id="4eb8bb6c"></span>
### 字段命名与描述
字段命名含糊/无描述，导致模型难以判断含义。使用清晰有意义的英文名（如 user_name），并配合 `description` 详细说明字段用途。
错误示例
```JSON
{
  "type": "object",
  "properties": {
    "v1": {
      "type": "string"
    }
  }
}
```

改进后示例
```JSON
{
  "type": "object",
  "properties": {
    "user_name": {
      "type": "string",
      "description": "用户的姓名"
    }
  }
}
```


<span id="b5dffb5a"></span>
### 字段类型与结构设计
<span id="0a305a7e"></span>
#### 避免冗余嵌套与不必要复杂化
不过度使用 $ref，结构尽可能一次性展开。无意义的嵌套会增加模型生成难度，提高出错概率。
错误示例
```JSON
{
  "type": "object",
  "properties": {
    "date": {
      "type": "object",
      "properties": {
        "value": {
          "type": "string",
          "description": "日期"
        }
      }
    }
  }
}
```

改进后示例
```JSON
{
  "type": "object",
  "properties": {
    "date": {
      "type": "string",
      "description": "日期，格式为 YYYY-MM-DD"
    }
  }
}
```

<span id="28d8a165"></span>
#### 字段类型要明确、例子需补充
错误示例
```JSON
{
  "score": {
    "type": "string"
  }
}
```

改进后示例
```JSON
{
  "score": {
    "type": "integer",
    "description": "成绩，0到100的整数"
  }
}
```

> 说明：类型应尽量贴合实际业务。对于数字、布尔值等不能简单用 string 替代。

<span id="7da8f5ac"></span>
### 字段取值与约束设计
明确枚举值与格式
错误示例
```JSON
{
  "status": {
    "type": "string"
  }
}
```

改进后示例
```JSON
{
  "status": {
    "type": "string",
    "description": "处理状态，可为：pending、success 或 failed",
    "enum": ["pending", "success", "failed"]
  }
}
```

<span id="064bc324"></span>
### 结构层级与必填项
所有需要的结构明确 required，这样模型会始终输出所有必需字段，格式更规范。
推荐使用 required 时，始终加上`"additionalProperties": false`。
错误示例
```JSON
{
  "type": "object",
  "properties": {
    "steps": { "type": "array", "items": { "type": "string" } },
    "final_answer": { "type": "string" }
  }
  // 没有 required
}
```

改进后示例
```JSON
{
  "type": "object",
  "properties": {
    "steps": { "type": "array", "items": { "type": "string" } },
    "final_answer": { "type": "string" }
  },
  "required": ["steps", "final_answer"],
  "additionalProperties": false
}
```


<span id="04cb2281"></span>
### 业务语义简明清楚，避免歧义
错误示例
```JSON
{
  "type": "object",
  "properties": {
    "id": { "type": "string", "description": "用户或订单编号" }
  }
}
```

改进后示例
```JSON
{
  "type": "object",
  "properties": {
    "user_id": { "type": "string", "description": "用户编号" },
    "order_id": { "type": "string", "description": "订单编号" }
  }
}
```

<span id="7d13f9fd"></span>
## 使用工具评估和优化

* 为防止 JSON 模式与编程语言类型定义不一致，推荐使用语言原生的工具支持，如 Python 可使用 [Pydantic](https://docs.pydantic.dev/latest/)，TypeScript 可使用 [Zod](https://zod.dev/)。
* 可使用方舟工具来优化/评估模型提示词，详细见 [PromptPilot 概述](https://www.volcengine.com/docs/82379/1399495)。

<span id="05849c36"></span>
# 附3. Prompt 建议
<span id="0ca58701"></span>
### 指明任务目标，简洁表达意图

* 只需直接描述实际希望模型完成的任务即可，无须再过多强调“请用 JSON 输出”、“请用如下格式输出”等。
* 不必在 prompt 中重复 schema 结构的信息，避免造成矛盾或冗余。

错误示例
```Plain Text
请用如下 JSON 格式输出，并包含字段 steps、final_answer：8x + 9 = 32，x+y=1。
```

改进后示例
```Plain Text
请求解：8x + 9 = 32，x + y = 1。
```

<span id="92eb1341"></span>
### 结合结构化信息写业务内容，而不是格式引导

* 关注“内容本身”，而非“输出形式”。
* 业务描述越具体，LLM 更易给出符合 schema 的内容。

错误示例
```Plain Text
请输出一个包含 steps 和 final_answer 字段的 JSON。
```

改进后示例
```Plain Text
请一步步推理解答：8x + 9 = 32, x+y=1，并写出最终答案。
```




# 文本向量化
Source: https://www.volcengine.com/docs/82379/1583857
您可以使用文本向量化模型服务，将文本转化为表达文本语义的向量，并通过计算向量计算出文本之间语义差距。在检索、个性化推荐、智能对话等场景进行文本的分类、聚类、检索、生成等自然语言处理任务。
<span id="9b003f66"></span>
# 应用场景

| | | | \
|领域 |细分场景 |描述 |
|---|---|---|
| | | | \
|信息检索与搜索 |搜索引擎优化 |将查询和文档转化为向量，让搜索引擎依据向量语义理解用户意图，返回更相关结果。 |
|^^| | | \
| |企业内部搜索 |在企业知识库、文档库中，基于向量模型快速准确检索员工相关文档。 |
| | | | \
|内容推荐系统 |个性化推荐 |分析用户行为数据并向量化，计算用户兴趣与内容相似度，为用户推荐可能感兴趣的内容。 |
|^^| | | \
| |热点发现 |对大量文本内容向量化后，用聚类算法发现热点话题或流行趋势，为内容创作者提供参考。 |
| | | | \
|自然语言处理 |文本分类 |将文本数据输入向量模型得到向量表示，用于新闻分类、情感分析等。 |
|^^| | | \
| |命名实体识别 |先将文本向量化，再用实体识别模型处理向量，提取关键实体信息用于知识图谱构建等。 |
|^^| | | \
| |机器翻译 |将源语言和目标语言的文本向量化，更好地捕捉语义对应关系，提高翻译准确性和流畅性。 |
| | | | \
|问答系统 |问题理解与答案匹配 |理解用户问题并向量化，与知识库中的问题进行向量匹配，找到最相关答案。 |
|^^| | | \
| |知识图谱问答 |结合知识图谱和文本向量化技术，在知识图谱中高效查询和推理，为用户提供准确答案。 |
| | | | \
|文本生成与辅助写作 |文本生成 |作为文本生成模型的输入特征，依据给定主题或关键词的向量表示，生成符合逻辑和语境的文本。 |
|^^| | | \
| |辅助写作 |对大量优秀文本向量化学习，根据用户输入推荐词汇、短语或句子，提高写作质量和效率。 |
| | | | \
|社交网络与舆情分析 |用户画像与社交关系分析 |对用户发布的内容、评论等行为数据向量化处理，构建用户画像和社交关系网络，支持社交网络个性化推荐等运营。 |
|^^| | | \
| |舆情监测与分析 |对社交媒体等渠道的大量文本数据向量化，快速识别热点话题和公众情绪变化趋势，为决策提供依据。 |

<span id="05b89101"></span>
# 支持模型
当前支持文本向量化的模型请参见[文本向量化能力](https://www.volcengine.com/docs/82379/1330310#5fa3ded4)。
<span id="45ec2386"></span>
# 前提条件
* [获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) 。
   * 使用 Access Key 鉴权请参考[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
* [开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需 Model ID 。
   * 通过 Endpoint ID 调用模型服务请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。



<span id="ec7da6e5"></span>
# 快速开始
<span id="170e47e2"></span>
## **文本字符串转换向量**
通过调用`doubao-embedding-text-240715`模型，将输入的文本字符串转换为向量表示，并输出向量维度和前10维数值。
:::warning
为获得更好性能，建议文本数量总token不超过4096，或者文本条数不超过4。
:::
```Python
import os
from volcenginesdkarkruntime import Ark
# 初始化客户端
client = Ark(
    # 从环境变量中读取您的方舟API Key
    api_key=os.environ.get("ARK_API_KEY"),
    base_url="https://ark.cn-beijing.volces.com/api/v3"
)
response = client.embeddings.create(
    model="doubao-embedding-text-240715",
    input="Function Calling 是一种将大模型与外部工具和 API 相连的关键功能",
    encoding_format="float"  
)
# 打印结果
print(f"向量维度: {len(response.data[0].embedding)}")
print(f"前10维向量: {response.data[0].embedding[:10]}")
```

<span id="9c64c8e6"></span>
## **输入文本文件逐行转换**
向量化模型可以基于您上传的文档生成嵌入向量。此处以`embedding_text.txt`作为示例文件，您可以通过代码对文本文件逐行转化成向量。
<Attachment link="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c86250420bb943a4a6d48dae3759c488~tplv-goo7wpa0wc-image.image" name="embedding_text.txt" ></Attachment>
```Python
import os
from volcenginesdkarkruntime import Ark
client = Ark(
    # 从环境变量中读取您的方舟API Key
    api_key=os.environ.get("ARK_API_KEY"),
    base_url="https://ark.cn-beijing.volces.com/api/v3"
)
# 从文件读取文本并生成向量
with open("embedding_text.txt", "r", encoding="utf-8") as f:
    # 按行分割文本（每行作为一个独立输入）
    texts = [line.strip() for line in f if line.strip()]
    
    response = client.embeddings.create(
        model="doubao-embedding-text-240715",
        input=texts,
        encoding_format="float"
    )
# 打印结果
print(f"处理文本数量: {len(response.data)}")
print(f"首个文本向量维度: {len(response.data[0].embedding)}")
```

<span id="c936d261"></span>
# 相关技术
通过上述示例完成基础向量生成后，您可以基于使用场景对向量进行更深层次的处理与分析，常用的功能包括相似度计算与维度优化。
<span id="a376507a"></span>
## 相似度计算

* Doubao-embedding向量间相似度得分可以使用[余弦相似度](https://baike.baidu.com/item/%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6/17509249)作为计算方式，余弦相似度计算拆分为下面两步：
   * 第一步: 请求doubao-embedding接口得到embedding，将embedding向量L2_norm处理;
   * 第二步: 对norm处理后的向量进行点积计算得到余弦相似度;

<span id="0342c3e2"></span>
## 向量降维
向量化是通过向量来表征文本、图像等非结构化数据的过程，让计算机能明白语言、图像等的含义。其中标注词义的维度是描述向量化后向量中数字的个数。在文本向量化场景，每个维度对应文本的一个特征。

* **维度更多**：以更多独立特征标注词语来捕捉语义细节，提升表征精度。但会导致数据量膨胀，带来更高的存储成本（内存/磁盘占用）和计算开销（相似度计算、模型推理耗时）。
* **维度更低**：以更少特征标注词语，可能损失部分细节。但数据量缩减，存储效率与计算速度会提升，资源消耗以及成本更低。

下列模型支持多种维度，您可通过向量降维，选择合适的维度来向量化文本，平衡“语义精度”、”计算速度“与“资源成本”三者成本。

| | | | \
|**模型 ID（Model ID）** |\
|<div style="width:200px"></div> |**支持维度** |\
| | |**备注** |
|---|---|---|
| | | | \
|doubao-embedding-large-text-250515 |2048  |\
| |> 支持2048、1024、512、256 降维使用 |需要L2归一化后使用 |\
| | |:::tip |\
| | |**L2归一化** 是将向量中每个元素除以该向量的L2范数（即各元素平方和的平方根），使归一化后的向量长度为1，从而消除不同特征间的量纲差异并保留相对大小关系。 |\
| | |::: |
| | | | \
|doubao-embedding-large-text-240915 |4096  |\
| |> 支持2048、512, 1024 降维使用 |无 |
| | | | \
|doubao-embedding-text-240715 |2560  |\
| |> 支持 512, 1024, 2048 降维使用 |无 |
| | | | \
|doubao-embedding-text-240515 |2048  |\
| |> 支持 512, 1024 降维使用 |无 |

<span id="ecd587f9"></span>
## 示例代码

* 推荐用法：常规降维方式以`doubao-embedding-text-240715`模型为例，最高维度2560可以压缩到512, 1024, 2048维度存储检索，维度越高越接近最高维度效果。
   * 如何降维度&计算相似度？
      1. 降维度: 将embedding接口获取的向量直接截取前dim维度;
      2. 计算相似度: 对截取后的embedding做余弦相似度计算;

```Python
# 降维 + L2_norm
def sliced_norm_l2(vec: List[float], dim=2560) -> List[float]:
    # dim 取值 512,1024,2048
    norm = float(np.linalg.norm(vec[ :dim]))
    return [v / norm for v in vec[ :dim]]
    
# 余弦相似度计算
query_doc_relevance_score_2560d = np.matmul(
    sliced_norm_l2(embeddings[0], 2560), #查询向量
    sliced_norm_l2(embeddings[1], 2560)  #文档向量
)
```


* 针对`doubao-embedding-large-text-250515`模型，需要降维后L2归一化使用。模型支持多种嵌入维度：[2048、1024、512、256] ，即使在较低维度下性能下降也较小。
   * 如何降维度&计算相似度？
      1. 降维度: 将embedding接口获取的向量直接截取前dim维度;
      2. 归一化：使用 L2 归一化统一向量长度，确保余弦相似度计算准确。
      3. 计算相似度: 对截取后的embedding做余弦相似度计算;

```Python
def encode(
    client, inputs: List[str], is_query: bool = False, mrl_dim: Optional[int] = None
):
    # 处理查询文本（添加指令模板优化检索性能）
    if is_query:
        inputs = [f"Instruct: Given a web search query...\nQuery: {i}" for i in inputs]  
    # 调用API获取原始向量（未归一化）
    resp = client.embeddings.create(
        model="doubao-embedding-large-text-250515",
        input=inputs,
        encoding_format="float",
    )
    # 转换为张量并降维（截取前mrl_dim维度）
    embedding = torch.tensor([d.embedding for d in resp.data], dtype=torch.bfloat16)
    if mrl_dim is not None:
        assert mrl_dim in [256, 512, 1024, 2048], "仅支持256/512/1024/2048维"
        embedding = embedding[:, :mrl_dim]  
    # 必须执行归一化：L2归一化后才能计算余弦相似度
    embedding = torch.nn.functional.normalize(embedding, dim=1, p=2).float().numpy()
    return embedding
```

<span id="76b99436"></span>
# 最佳实践
<span id="5a7129af"></span>
## 场景概述 
下列程序实现了将查询文本和资料库文本向量匹配的功能。我们以`embedding_text.txt`的多行文本作为资料库，通过调用Doubao-embedding模型生成文本向量。当程序接收到用户的查询文本时，将其向量化并通过余弦相似度匹配资料库的向量，最终返回最相关的前3条文本及对应相似度分数。
<span id="46ee6f41"></span>
## 第一步：客户端初始化
导入所需的库包，并设置 API Key，为后续的数据处理和分析做准备。
```Python
import os
# 导入火山引擎大模型SDK
from volcenginesdkarkruntime import Ark
# 初始化客户端
client = Ark(
    api_key=os.environ.get("ARK_API_KEY"),
    base_url="https://ark.cn-beijing.volces.com/api/v3"
)
```

<span id="4b020211"></span>
## 第二步：从文件读取文本并生成向量
读取包含文本的`embedding_text.txt`文件，调用文本向量模型 API 逐行生成文本对应的向量，并将文本和向量保存为 JSON 文件。
<Attachment link="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c86250420bb943a4a6d48dae3759c488~tplv-goo7wpa0wc-image.image" name="embedding_text.txt" ></Attachment>
```Python
def generate_and_save_embeddings(file_path="embedding_text.txt", output_path="embeddings.json"):
    with open(file_path, "r", encoding="utf-8") as f:
        texts = [line.strip() for line in f if line.strip()]
    # 调用向量化API
    response = client.embeddings.create(
        model="doubao-embedding-text-240715",
        input=texts,
        encoding_format="float"
    )
    # 构建结果并保存
    results = [{"text": text, "embedding": data.embedding} 
              for text, data in zip(texts, response.data)]
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f)
    
    print(f"已生成并保存 {len(results)} 条向量至 {output_path}")
    return results
```

<span id="19ce35bd"></span>
## 第三步：加载预计算的向量数据
从 JSON 文件加载预计算的文本向量数据，为后续的相似度计算做准备。
```Python
def load_embeddings(file_path="embeddings.json"):
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)
```

<span id="bf561877"></span>
## 第四步：定义计算余弦相似度函数和搜索相似文本函数
利用余弦相似度来度量文本之间的相似性，实现了一个基于内容的文本搜索功能。
用户可以通过输入查询文本，检索与该查询文本最相关的文本。
```Python
# 定义计算余弦相似度函数
def cosine_similarity(a, b):
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
    
# 定义search_similar_text 函数：搜索与查询文本最相似的前N条文本
def search_similar_text(query_text, embeddings, top_n=3):
    # 生成查询文本的向量
    query_response = client.embeddings.create(
        model="doubao-embedding-text-240715",
        input=[query_text],
        encoding_format="float"
    )
    query_embedding = query_response.data[0].embedding
    # 计算相似度
    for item in embeddings:
        item["similarity"] = cosine_similarity(item["embedding"], query_embedding)
    # 排序并返回结果
    sorted_results = sorted(embeddings, key=lambda x: x["similarity"], reverse=True)
    return sorted_results[:top_n]
```

<span id="07ba3072"></span>
## 第五步：测试搜索功能
测试搜索功能，调用 `search_similar_text` 函数查询与`query`变量相关的文本，并返回与该查询文本最相关的前 3 条文本及其相似度分数。
```Python
# 示例：生成向量并搜索
if __name__ == "__main__":
    # 生成或加载向量
    try:
        embeddings = load_embeddings()
        print(f"已加载 {len(embeddings)} 条预计算向量")
    except FileNotFoundError:
        print("未找到预计算向量，将从文件生成...")
        embeddings = generate_and_save_embeddings()
    
    # 执行搜索（示例查询：上下文缓存机制）
    query = "上下文缓存（Context API）是方舟提供的一个高效的缓存机制，旨在为您优化生成式AI在不同交互场景下的性能和成本。"
    results = search_similar_text(query, embeddings, top_n=3)
    
    # 打印结果
    print(f"\n搜索查询: '{query}'")
    for i, result in enumerate(results, 1):
        print(f"\nTop {i} (相似度: {result['similarity']:.4f}):")
        print(f"{result['text'][:200]}...")  # 显示前200个字符
```

<span id="ee0ae119"></span>
## 结果示例
运行上述程序后，结果将展示与查询文本相似度最高的前3条文本内容，并分别标注其相似度分数。
```Plain Text
已加载 7 条预计算向量
搜索查询: '上下文缓存（Context API）是方舟提供的一个高效的缓存机制，旨在为您优化生成式AI在不同交互场景下的性能和成本。'
Top 1 (相似度: 0.9085):
上下文缓存（Context API）通过缓存数据优化AI性能与成本...
Top 2 (相似度: 0.7384):
文本生成可理解文本并进行对话回复...
Top 3 (相似度: 0.7201):
批量推理适用于大计算量非即时任务，享高配额与低价...
```




# 图像向量化
Source: https://www.volcengine.com/docs/82379/1409291
Doubao-embedding-vision 是一款由字节跳动研发的图像向量化模型，支持文本、图片及视频混合输入的向量化技术。该模型能够将不同类型的数据（文本、图片、视频）转换成向量表示，适用于文搜图、图搜图、图文混合搜索等场景。
通过 Doubao-embedding-vision 模型，用户可以实现多模态数据的统一向量化，便于处理和分析跨模态数据，以实现更高效的信息检索和数据分析。
<span id="6b9f8dec"></span>
# 应用场景
您可以在以下场景中使用模型的图文向量化能力。

| | | | | \
|**场景** |**细分场景** |**业务需求场景** |场景举例 |
|---|---|---|---|
| | | | | \
|批量数据向量化处理 |\- |需要对大量数据进行离线处理以转换为向量表示时，使用多模态向量化模型进行批量请求处理。 |批量处理电子商务平台上的商品图片，将其转换为向量表示以便于相似性匹配。 |
| | | | | \
|文本描述检索 |文搜图 |在图库场景中，用户侧重以文本描述来检索符合描述的图片。 |用户输入“蓝色海景”，系统根据描述搜索并展示相关蓝色海景图片。 |
|^^| | | | \
| |文搜文 |用于在知识库中进行文本描述检索，找到相关文档或知识库内容。 |用户输入“如何重置密码”，系统检索知识库中包含密码重置方法的文档。 |
| | | | | \
|图片特征检索 |图搜图 |图片检索相似物体。通过用户提供的图片，在不同场景下检索同一类物体，例如用于商品图搜索。 |用户上传一张椅子图片，系统返回相似款式的椅子商品图片。 |
|^^| | | | \
| |图文搜图 |图片特征的侧重提取，结合文本检索。电商搜索应用中，用户可以通过微调商品颜色等特征以提高检索结果精度。 |用户在搜索中指定产品颜色为“深蓝色”，系统根据颜色特征筛选商品图片。 |\
| | | |  |\
| | | | |
|^^| | | | \
| |图文搜图文 |多模态知识库搜索。用户提供图片及问题描述，在多模态知识库场景中搜索符合需求的内容。 |用户上传一个手机截图并描述“无法连接网络”，系统搜索相关网络连接故障解决方案。 |

<span id="4094f1a7"></span>
# 支持模型
当前支持图像向量化的模型请参见[图像向量化能力](https://www.volcengine.com/docs/82379/1330310#ee5ec35c)。
:::warning
不同版本的模型支持能力稍有区别：

* **doubao-embedding-vision-250615 及后续版本** 支持不限数量的视频、文本和图片混合输入。
* **历史版本** 模型仅支持最多 1文本 和 1图片 输入。
:::
<span id="5ebd2031"></span>
# 前提条件
* [获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) 。
   * 使用 Access Key 鉴权请参考[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
* [开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需 Model ID 。
   * 通过 Endpoint ID 调用模型服务请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。



<span id="72b74810"></span>
# 快速开始
图像向量模型支持接受和处理图像输入并转换为向量，这些图像可以通过可访问 URL 或转为 Base64 编码后输入，下面是简单的调用示例代码。
**视频、图、文混合输入**
> 仅 doubao-embedding-vision-250615及后续版本支持视频输入。

```Plain Text
curl https://ark.cn-beijing.volces.com/api/v3/embeddings/multimodal \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer ea764f0f-3b60-45b3-****-************" \
  -d '{
    "model": "doubao-embedding-vision-250615",
    "encoding_format": "float",
    "input": [
        {
            "type": "video_url",
            "video_url": {
                "url": "https://ark-project.tos-cn-beijing.volces.com/doc_video/ark_vlm_video_input.mp4"
            }
        },
        {
            "type": "image_url",
            "image_url": {
                "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/tower.png"
            }
        },
        {
            "type": "text",
            "text": "视频和图片里有什么"
        }
    ]
}'
```

**图文输入**
```Python
curl https://ark.cn-beijing.volces.com/api/v3/embeddings/multimodal  \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer ea764f0f-3b60-45b3-****-************" \
  -d '{
    "model": "doubao-embedding-vision-250328",
    "input": [
        {
            "type":"text",
            "text":"天很蓝，海很深"
        },
        {    
            "type":"image_url",
            "image_url":{
                "url":"https://ark-project.tos-cn-beijing.volces.com/images/view.jpeg"
            }
        }
      ]
}'
```

模型回复预览：
```Shell
{
    "id": "021718067849899d92fcbe0865fdffdde********************",
    "created": 171806****,
    "object": "list",
    "model": "doubao-embedding-***-******",
    "data": [
        {
            "object": "embedding",
            "embedding": [[0.62109375,-0.69140625,...,0.38671875]
        }
    ],
    "usage": {
        "prompt_tokens": 1340,
        "total_tokens": 1340,
        "prompt_tokens_details": {
            "text_tokens": 1312,
            "image_tokens": 28
        }
    }
}
```

<span id="c3270481"></span>
# 使用说明
:::tip
推荐使用方舟推出的图像向量化模型在处理完图像后，图像会从方舟服务器删除。方舟不会保留您提交的视频、图片以及文本信息等用户数据来训练模型。
:::
<span id="b29419f1"></span>
## 图片输入
<span id="0b5a74f9"></span>
### 图片传入方式
图片 URL 或图片 Base64 编码。用图片 URL 方式时，需确保图片 URL 可被访问。
<span id="77ea1f43"></span>
### 图片像素说明
模型能够支持尺寸更加灵活的图片，传入图片满足下面条件：

* 图片宽高长度（单位 px）：大于 14。

图片像素（宽＊高，单位 px）：小于 3600w。
<span id="5b3a1797"></span>
### 图片数量说明
单次请求最多传入图片数量为` 1 `张。
<span id="b2c67343"></span>
### token 用量说明
模型理解图片，会将图片转化为 token ，再进行推理计算。token 用量，根据图片宽高像素计算可得。图片转化 token 的公式为：
```Plain Text
min(图片宽 * 图片高/784, 单图 token 限制)
```

图片尺寸为 1280 px ＊ 720 px，即宽为 1280 px，高为 720 px，传入模型图片 token 限制为 1312，则理解这张图消耗的 token 为`1280＊720/784=1176`，因为小于 1312，消耗 token 数为 1176 。
图片尺寸为 1920 px ＊ 1080 px，即宽为 1920 px，高为 1080 px，传入模型图片 token 限制为 1312，则理解这张图消耗的 token 为`1920＊1080/784=2645`，因为大于 1312，消耗 token 数为 1312 。这时会压缩 token，即图片的细节会丢失部分，譬如字体很小的图片，模型可能就无法准确识别文字内容。
<span id="ebec26bf"></span>
### 图片格式说明
支持的图片格式如下表，需注意文件后缀和图片格式需要匹配，即图片文件扩展名（URL 传入）、编码中图片格式声明（Base64 编码传入）需要与图片实际信息一致。

   
   | | | | \
   |**图片格式** |**文件扩展名** |**内容格式** **Content Type** |\
   | | | |\
   | | |> * [上传图片至对象存储时设置](https://www.volcengine.com/docs/6349/145523#%E8%AE%BE%E7%BD%AE%E6%96%87%E4%BB%B6%E5%85%83%E6%95%B0%E6%8D%AE)。 |\
   | | |> * 传入图片 Base64 编码时使用：[Base64 编码输入](https://www.volcengine.com/docs/82379/1362931#f6222fec)。 |
   |---|---|---|
   | | | | \
   |JPEG |.jpg, .jpeg |`image/jpeg` |
   | | | | \
   |PNG |.apng, .png |`image/png` |
   | | | | \
   |GIF |.gif |`image/gif` |
   | | | | \
   |WEBP |.webp |`image/webp` |
   | | | | \
   |BMP |.bmp |`image/bmp` |
   | | | | \
   |TIFF |.tiff, .tif |`image/tiff` |
   | | | | \
   |ICO |.ico |`image/x-icon` |
   | | | | \
   |DIB |.dib |`image/bmp` |
   | | | | \
   |ICNS |.icns |`image/icns` |
   | | | | \
   |SGI |.sgi |`image/sgi` |
   | | | | \
   |JPEG2000 |.j2c, .j2k, .jp2, .jpc, .jpf, .jpx |`image/jp2` |


:::tip
TIFF、 SGI、ICNS、JPEG2000 几种格式图片，需要保证和元数据对齐如在对象存储中正确设置文件元数据，否则会解析失败。
:::
<span id="2b1050ae"></span>
## 视频输入
对视频按固定间隔抽取画面后，交由模型进行理解。
<span id="6a68e01e"></span>
### 视频格式说明

   
   | | | | \
   |**视频格式** |**文件扩展名** |**内容格式** **Content Type** |\
   | | | |\
   | | |> * [上传视频至对象存储时设置](https://www.volcengine.com/docs/6349/145523#%E8%AE%BE%E7%BD%AE%E6%96%87%E4%BB%B6%E5%85%83%E6%95%B0%E6%8D%AE)。 |\
   | | |> * 传入 Base64 编码时使用：[Base64 编码输入](https://www.volcengine.com/docs/82379/1362931#f6222fec)。 |\
   | | |> * 视频格式需小写 |
   |---|---|---|
   | | | | \
   |MP4 |.mp4 |`video/mp4` |
   | | | | \
   |AVI |.avi |`video/avi` |
   | | | | \
   |MOV |.mov |`video/quicktime` |


<span id="5c528e47"></span>
### 视频文件容量
单视频文件需在 50MB 以内。
<span id="1afe05bb"></span>
### 不支持音频理解
暂不支持对视频文件中的音频信息进行理解。
<span id="6cf6a782"></span>
### 用量说明
单视频 token 用量范围在[10k, 80k] ，单次请求视频最大 token 量还受模型的最大上下文窗口以及最大输入长度（当启用深度推理模式）限制，超出则请调整传入视频数量或视频长度。
方舟根据帧图像（某个时刻的视频画面，此处特指输入给模型的帧图像）张数（视频时长 * **fps** ），对帧图像进行压缩，以平衡对于视频的理解精度和 token 用量。帧图像会被等比例压缩至 [128 token, 640 token] ，对应像素范围在 [10万 像素, 50万像素]。
如`fps`过高或视频长度过长，需要处理的帧图像数量超出 640 帧（80×1024 token ÷ 128 token / 帧 = 640 帧），则按帧图像 128 token  `视频时长/640` 时间间隔均匀抽取 640帧。此时与请求中的配置不符，建议评估输出效果，按需调整视频时长或 **fps** 字段配置。
如`fps`过小或视频长度过短，需要处理的帧图像数量不足16帧（10×1024 token ÷ 640 token / 帧 = 16 帧），则按帧图像 640 token  `视频时长/16` 时间间隔均匀抽取 16帧。
<span id="e657bbfc"></span>
# 相关技术
<span id="49c2f920"></span>
## 相似度计算

* Doubao-embedding向量间相似度得分可以使用[余弦相似度](https://baike.baidu.com/item/%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6/17509249)作为计算方式，余弦相似度计算拆分为下面两步：
   * 第一步: 请求doubao-embedding接口得到embedding，将embedding向量L2_norm处理;
   * 第二步: 对norm处理后的向量进行点积计算得到余弦相似度;

<span id="e6bce9a8"></span>
## 向量降维
:::tip
* `doubao-embedding-vision-250615`及后续版本支持通过 **dimensions** 参数直接设定维度，请参见[图像向量化 API](https://www.volcengine.com/docs/82379/1523520#RxN8G2nH)。
* 历史版本可以参考本章节进行向量降维。
:::
向量化是通过向量来表征文本、图像等非结构化数据的过程，让计算机能理解语言、图像等的含义。其中，向量维度是描述向量化后向量中元素的个数（标注词义/图像特征的维度）。在图文向量化场景，每个维度对应文本的一个特征或者是对应图像的像素、色彩等视觉特征。  

* **维度更多**：以更多独立特征标注内容（文本的语义细节、图像的纹理特征），提升表征精度。但会导致数据量膨胀，带来更高的存储成本（内存/磁盘占用）和计算开销（相似度计算、模型推理耗时）。  
* **维度更低**：以更少特征标注内容，可能损失部分细节（文本的细微语义差异、图像的边缘像素信息）。但数据量缩减，存储效率与计算速度会提升，资源消耗及成本更低。  

向量降维功能的核心目标是减轻用户存储向量和检索向量的压力，通过压缩向量维度降低存储成本与计算开销。您可通过向量降维，选择合适的维度来向量化文本/图像，平衡“语义/视觉精度”“计算速度”与“资源成本”三者关系。
<span id="f6066125"></span>
## 示例代码

* `doubao-embedding-vision-241215`向量维度3072维，不支持降维使用
* `doubao-embedding-vision-250328`模型支持最高维度2048可以压缩到1024维度存储检索，维度越高越接近最高维度效果。
   * 如何降维度&计算相似度？
      1. 降维度: 将embedding接口获取的向量直接截取前dim维度;
      2. 计算相似度: 对截取后的embedding做余弦相似度计算;

```Python
# 降维+ L2_norm
def sliced_norm_l2(vec: List[float], dim=2048) -> List[float]:
    # dim 为1024
    norm = float(np.linalg.norm(vec[ :dim]))
    return [v / norm for v in vec[ :dim]]
    
# 余弦相似度计算
query_doc_relevance_score_2048d = np.matmul(
    sliced_norm_l2(embeddings[0], 2048), #查询向量
    sliced_norm_l2(embeddings[1], 2048)  #文档向量
)
```

<span id="6e808876"></span>
## Base64 编码输入
如果你要传入的视频/图片在本地，你可以将这个视频/图片转化为 Base64 编码，然后提交给大模型。下面是一个简单的转换示例代码。
:::warning
传入 Base64 编码格式时，请遵循以下规则：

* 传入的是图片：
   * 格式遵循`data:image/<图片格式>;base64,<Base64编码>`，其中，
      * 图片格式：`jpeg`、`png`、`gif`等，支持的图片格式详细见[图片格式说明](https://www.volcengine.com/docs/82379/1409291#ebec26bf)。
      * Base64 编码：图片的 Base64 编码。
* 转入的是视频：
   * 格式遵循`data:video/<视频格式>;base64,<Base64编码>`，其中，
      * 视频格式：`MP4`、`AVI`等，支持的视频格式详细见[视频格式说明](https://www.volcengine.com/docs/82379/1409291#6a68e01e)。
      * Base64 编码：视频的 Base64 编码。
:::
```Python
# 定义方法将指定路径图片转为Base64编码
def encode_image(image_path):
  with open(image_path, "rb") as image_file:
    return base64.b64encode(image_file.read()).decode('utf-8')

# 需要传给大模型的图片
image_path = "path_to_your_image.jpg"
# 将图片转为Base64编码
base64_image = encode_image(image_path)
```

转换后，图片的url格式参考如下：
```Python
    {
        "type": "image_url",
        "image_url": {
            "url":  f"data:image/<IMAGE_FORMAT>;base64,{base64_image}"
        }
    },
```

<span id="07f423de"></span>
# 最佳实践：多模态相似度匹配示例
<span id="83b84a47"></span>
## 场景概述
下述程序展示如何通过文本描述检索图片库中的相关素材。
程序读取包含 5 张水果图片 URL 的列表，调用 Doubao-embedding-vision 模型为每张图片生成向量表示。当用户输入查询文本 "香蕉" 时，程序将其转换为向量，并通过余弦相似度与图片向量库匹配，并输出最相似图片和相似度分数。该流程实现了基于语义的 "以文搜图" 功能，辅助用户从图片库中快速定位目标内容，适用于电商商品检索、媒体素材管理等场景。

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2000);">

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/8a24e352e2bf4d139e7c88f956ede96d~tplv-goo7wpa0wc-image.image =1536x)
<div style="text-align: center">Fruit1.jpg</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2000);margin-left: 16px;">

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/f52f28ec7c714f6891eab4854f0f1fad~tplv-goo7wpa0wc-image.image =1536x)
<div style="text-align: center">Fruit2.jpg</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2000);margin-left: 16px;">

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0daea3ea0ab24d2096e583212921fbf3~tplv-goo7wpa0wc-image.image =1536x)
<div style="text-align: center">Fruit3.jpg</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2000);margin-left: 16px;">

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5534103c2e4740cd926c95808c191c59~tplv-goo7wpa0wc-image.image =1536x)
<div style="text-align: center">Fruit4.jpg</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2000);margin-left: 16px;">

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7ba9bbd9ebbb4db59e2b62bd7f0c6e31~tplv-goo7wpa0wc-image.image =1536x)
<div style="text-align: center">Fruit5.jpg</div>



</div>
</div>

<span id="af524e73"></span>
## 第一步：导入库包
导入所需的库包，并设置 API Key，为后续的数据处理和分析做准备。
```Python
import os
import numpy as np
from volcenginesdkarkruntime import Ark
from sklearn.metrics.pairwise import cosine_similarity
```

<span id="17c97b74"></span>
## 第二步：获取向量
定义一个函数将单个文本或图片转换为向量表示。支持两种输入类型：文本和图片 URL。调用`doubao-embedding-vision-241215`模型获取float格式向量，再转换为numpy数组并展平为一维向量。
```Python
def get_embedding(input_data, input_type="text"):
    """调用火山引擎API获取单个文本或图片的向量表示"""
    client = Ark(api_key=os.environ.get("ARK_API_KEY"))
    if input_type == "text":
        input_item = {"type": "text", "text": input_data}
    elif input_type == "image_url":
        input_item = {"type": "image_url", "image_url": {"url": input_data}}
    else:
        raise ValueError("输入类型仅支持'text'或'image_url'")
    
    try:
        resp = client.multimodal_embeddings.create(
            model="doubao-embedding-vision-241215",
            encoding_format="float",
            input=[input_item]
        )
        if hasattr(resp, 'data') and isinstance(resp.data, dict) and 'embedding' in resp.data:
            embedding = resp.data['embedding']
            # 确保向量是numpy数组并展平为一维
            embedding = np.array(embedding).flatten()
            return embedding
        else:
            raise ValueError("API响应格式不符合预期，无法获取嵌入向量")
    except Exception as e:
        print(f" 获取向量失败，输入类型: {input_type}, 错误: {str(e)}")
        raise
```

<span id="677c14b2"></span>
## 第三步：生成向量库
批量处理图片 URL 列表，生成对应的向量表示，并构建向量库。
```Python
def generate_image_embeddings(image_urls):
    """批量生成图片向量并构建向量库"""
    print(f"[1/3] 开始生成 {len(image_urls)} 张图片的向量...")
    embeddings = []
    for i, url in enumerate(image_urls):
        try:
            embedding = get_embedding(url, "image_url")
            embeddings.append({
                "image_url": url,
                "embedding": embedding
            })
            print(f" [{i+1}/{len(image_urls)}] 成功: {url}")
        except Exception as e:
            print(f" [{i+1}/{len(image_urls)}] 失败: {url} - {str(e)}")
            continue
    if not embeddings:
        raise ValueError("所有图片向量生成失败")    
    print(f"[2/3] 完成: {len(embeddings)} 个有效向量")
    return embeddings
```

<span id="6a719441"></span>
## 第四步：图片相似度计算
利用余弦相似度来度量文本与图片之间的相似性，实现了一个基于内容的图片搜索功能。用户可以通过输入文本描述，检索与该描述最相关的图片。
```Python
def search_similar_images(query_embedding, embeddings, top_n=1, query_type="文本"):
    """搜索与查询向量最相似的图片"""
    print(f"\n[3/3] 开始搜索与{query_type}最相似的图片...")
    results = []
    # 确保查询向量是numpy数组且维度正确
    query_vec = np.array(query_embedding).reshape(1, -1)
    for item in embeddings:
        # 确保向量是numpy数组并调整为二维数组用于相似度计算
        item_vec = np.array(item["embedding"]).reshape(1, -1)
        
        similarity = cosine_similarity(query_vec, item_vec)[0][0]
        results.append({
            "image_url": item["image_url"],
            "similarity": similarity
        })
    
    results.sort(key=lambda x: x["similarity"], reverse=True)
    print(f" - 相似度计算完成，共 {len(results)} 个结果")
    return results[:top_n]
```

<span id="47064fe6"></span>
## 第五步：示例用法
测试搜索功能，调用`generate_image_embeddings`函数生成图片向量库，使用文本查询搜索相似图片，并返回最相似的结果。示例代码如下：
```Python
if __name__ == "__main__":
    image_urls = [
        "https://ark-project.tos-cn-beijing.volces.com/doc_image/Fruit1.jpg",
        "https://ark-project.tos-cn-beijing.volces.com/doc_image/Fruit2.jpg",
        "https://ark-project.tos-cn-beijing.volces.com/doc_image/Fruit3.jpg",
        "https://ark-project.tos-cn-beijing.volces.com/doc_image/Fruit4.jpg",
        "https://ark-project.tos-cn-beijing.volces.com/doc_image/Fruit5.jpg"
    ]
    query_text = "香蕉"
  
    try:
        # 生成图片向量
        image_embs = generate_image_embeddings(image_urls)        
        # 生成文本向量
        text_emb = get_embedding(query_text, "text")
        print(f"文本向量维度: {len(text_emb)}")        
        # 搜索相似图片
        similar_images = search_similar_images(text_emb, image_embs)
        print(f"最相似图片: {similar_images[0]['image_url']}")
        print(f"相似度分数: {similar_images[0]['similarity']:.4f}")
        
    except Exception as e:
        print(f"程序失败: {e}")
```

<span id="64cab73f"></span>
## 运行结果示例

* 开始生成 5 张图片的向量，依次对 5 个图片 URL发起请求，均返回 “成功”，表明 API 调用正常且图片链接可访问、格式合规。
* 完成处理，生成 5 个有效向量，文本向量维度为 3072，与模型输出维度一致，向量数量与输入图片数量匹配，无数据丢失。
* 开始相似度匹配，对文本向量与 5 个图片向量进行相似度计算，最终返回最相似图片为 Fruit2.jpg，表明两者在特征空间中具有较强相关性。

```Plain Text
[1/3] 开始生成 5 张图片的向量...
 (1/5)成功: https://ark-project.tos-cn-beijing.volces.com/doc_image/Fruit1.jpg
 (2/5)成功: https://ark-project.tos-cn-beijing.volces.com/doc_image/Fruit2.jpg
 (3/5)成功: https://ark-project.tos-cn-beijing.volces.com/doc_image/Fruit3.jpg
 (4/5)成功: https://ark-project.tos-cn-beijing.volces.com/doc_image/Fruit4.jpg
 (5/5)成功: https://ark-project.tos-cn-beijing.volces.com/doc_image/Fruit5.jpg
[2/3] 完成: 5 个有效向量
文本向量维度: 3072

[3/3] 开始搜索与文本最相似的图片...
 - 相似度计算完成，共 5 个结果
最相似图片: https://ark-project.tos-cn-beijing.volces.com/doc_image/Fruit2.jpg
相似度分数: 0.6462
```

<span id="00b99fb2"></span>
# 附：向量批量处理的解决方案
以下代码针对API仅支持单次传入一张图片的限制，通过异步并发与批量分组策略实现图片向量化的高效批量处理：利用`asyncio`创建异步任务，将图片按指定批次分组后并发调用API，采用“**全组失败回滚**”模式确保每组任务一致性，支持失败重试并隔离保存成功与失败结果（含向量详情、错误信息及输入URL）。
```Python
import asyncio
from volcenginesdkarkruntime import AsyncArk
from pathlib import Path
import os

class MultimodalEmbedder:
    """多模态向量化批量处理工具（全组失败模式）"""
    def __init__(self, api_key: str, model: str = "doubao-embedding-vision-241215", 
                 batch_size: int = 10, retries: int = 2):
        self.api_key = api_key
        self.model = model
        self.batch_size = batch_size
        self.retries = retries
        
    async def process(self, items_list):
        """异步处理图文数据列表"""
        async with AsyncArk(max_retries=self.retries) as client:
            # 创建并启动所有任务
            tasks = [
                asyncio.create_task(client.multimodal_embeddings.create(model=self.model, input=items))
                for items in items_list
            ]         
            try:
                # 等待所有任务完成，任一失败则立即抛出异常
                return await asyncio.gather(*tasks)
            except Exception:
                # 取消所有未完成的任务
                for task in tasks:
                    if not task.done():
                        task.cancel()
                # 重新抛出原始异常
                raise
    
    def save_results(self, results, output_dir: str = "embedding_results"):
        """保存向量化结果到文本文件"""
        Path(output_dir).mkdir(exist_ok=True)
        
        with open(f"{output_dir}/success.txt", "w", encoding="utf-8") as f:
            f.write("===== 向量化结果 =====\n")
            for idx, result in enumerate(results, 1):
                f.write(f"结果 #{idx}\nID: {result.id}\n")
                f.write(f"创建时间: {result.created}\n")
                f.write(f"模型: {self.model}\n")
                embedding = result.data.get("embedding", [])
                f.write(f"向量长度: {len(embedding)}\n")
                f.write(f"部分向量值: {embedding[:20]}...\n\n")
                
        print(f"结果已保存到 {output_dir}/success.txt")

if __name__ == "__main__":
    ARK_API_KEY = os.environ.get("ARK_API_KEY")
    if not ARK_API_KEY:
        print("未找到环境变量 ARK_API_KEY，请手动输入")
        ARK_API_KEY = input("API密钥: ").strip()
        if not ARK_API_KEY:
            raise ValueError("API密钥不能为空")
    
    embedder = MultimodalEmbedder(
        api_key=ARK_API_KEY,
        batch_size=10,
        retries=2
    )
    
    sample_data = [
        [
            {"type": "text", "text": "天很蓝，海很深"},
            {"type": "image_url", "image_url": {"url": "https://example.com/image1.jpg"}}
        ],
        [
            {"type": "text", "text": "阳光明媚的沙滩"},
            {"type": "image_url", "image_url": {"url": "https://example.com/image2.jpg"}}
        ]
    ]
    
    try:
        # 执行向量化处理
        results = asyncio.run(embedder.process(sample_data))
        # 保存结果（仅在全部成功时）
        embedder.save_results(results)
        print(f"全部成功: {len(results)}")
    except Exception as e:
        print(f"处理失败: {str(e)}")
```

<span id="3473635e"></span>
## 


# 批量推理
Source: https://www.volcengine.com/docs/82379/1399517
本文帮助您了解如何通过 API 使用批量推理。相比在线推理，显著提升处理吞吐量并降低使用成本，非常适合无需即时响应的任务。

* **更低成本**：输入输出单价为在线推理 50% ，且受益于透明前缀缓存，命中缓存的输入单价可进一步降低 60%。
* **更高配额**：默认 100亿 token/天，且支持工单申请提额；受益于更灵活的调度策略，高峰期仍可获得可观的任务处理速率。
* **场景灵活**：除了提供批量推理任务（Batch Job）来处理静态存储数据，方舟提供类在线推理的方式（Batch Chat）处理动态数据。
* **改造简单**：Batch Chat 接口参数与 Chat 接口一致，只需关注**超时时间**（方舟 SDK 已为您实现重试退避机制）及**并发策略**（详细见[使用说明](https://www.volcengine.com/docs/82379/1399517#41b49ce6)），即可快速切换至批量推理，无需修改业务逻辑。

:::tip
为充分发挥批量推理高配额优势，使用 Batch Chat 时，建议保持高并发推压，如创建大量（如10万个）线程或者协程并发请求，并配置较大超时时间，保障任务的完成率，[示例代码](https://www.volcengine.com/docs/82379/1399517#01826852)供参考。 
:::

> * 如您希望通过控制台操作，请参见文档 [批量推理](https://www.volcengine.com/docs/82379/1305505)。
> * 如您希望直接查看API文档，请参见 [批量(Chat) API](https://www.volcengine.com/docs/82379/1528783)、[批量(Job) API](https://www.volcengine.com/docs/82379/1339371)。

<span id="3a37679b"></span>
# 支持的模型
当前批量推理功能支持 [深度思考能力](https://www.volcengine.com/docs/82379/1330310#898d064d)、[文本生成能力](https://www.volcengine.com/docs/82379/1330310#15a31773)、[视觉理解能力](https://www.volcengine.com/docs/82379/1330310#ff5ef604)的模型及基于基础模型精调后的模型（精调后模型支持情况请以[批量推理控制台](https://console.volcengine.com/ark/region:ark+cn-beijing/batchInference/create)可选模型为准）。
> 方舟会开放更多模型，如您近期有其他模型批量推理的需求，请提交[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)onCall与我们沟通。

<span id="ce44a46d"></span>
# 计费说明
详细费用说明请参见[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。
<span id="5662bf05"></span>
# 选择调用方式
方舟提供了2种批量推理方式，您可根据自己的业务场景选择合适的调用方式。

| | | | \
|方式 |Batch Job（创建批量推理任务） |\
| |<div style="width:300px"></div> |Batch Chat（调用批量推理接入点） |\
| | |<div style="width:300px"></div> |
|---|---|---|
| | | | \
|工作方式 |使用 `JSONL` 文件存储要处理的请求，上传至火山引擎对象存储（TOS） 上。通过[CreateBatchInferenceJob - 创建批量推理任务](https://www.volcengine.com/docs/82379/1339603)创建批量任务，等待所有请求完成后将存储结果返回到TOS中。 |\
| |> 支持控制台操作，访问[批量推理](https://console.volcengine.com/ark/region:ark+cn-beijing/batchInference)。 |调用接口将处理任务推送给平台后，一段时间后（时间长短受资源影响），方舟平台会返回结果。 |
| | | | \
|应用场景 |* 数据已静态存储在火山引擎或其他云厂商的对象存储、HDFS、ES中。 |\
| |* 数据量大，每天处理数据量可超过 100 B token 。 |\
| |* 多模态模型批量推理，对网络带宽压力大。 |* 可处理非静态存储的数据，数据的整理改造复杂。 |\
| | |* 调用模型的上下游都是在线链路。 |\
| | |* 完整业务链路中调用模型其中一环，单独改造成本高。 |
| | | | \
|核心流程 |1. 上传或分片上传数据到对象存储 |\
| |2. 创建批量推理任务 |\
| |3. 查询批量推理任务状态 |\
| |4. 从对象存储中读取推理结果 |1. 创建批量推理接入点 |\
| | |2. 使用Batch Chat接口进行批量推理 |\
| | | |\
| | |> 根据业务配置超时（大于30分钟）与并发数 |
| | | | \
|优势 |* 数据处理规模或网络带宽上限更高。 |\
| |* 托管了所有请求的资源调度，支持灵活任务调度，吞吐可达最优。 |\
| |* 依赖批量推理更灵活的任务调度，即使是高峰期，您仍然可享受一定的处理效率。 |\
| |* 支持透明前缀缓存能力，命中缓存的 token 会有更低折扣。 |* 小改造成本，您的工程在使用在线推理接口的基础上进行小的调整，即可切换到批量推理。 |\
| | |* 依赖批量推理更灵活的任务调度，即使是高峰期，您仍然可享受一定的处理效率。 |\
| | |* 支持透明前缀缓存能力，命中缓存的 token 会有更低折扣。 |
| | | | \
|劣势 |存在工程改造量，可能涉及数据上传、分片、切分目录等环节改造。 |* 高峰期间会收到较多`ServerOverloaded` 报错 |\
| | | |\
| | |> 需应用重试退避策略（使用方舟 SDK 在在超时范围内自动处理）。 |\
| | | |\
| | | |\
| | |* 每日吞吐由平台资源限制与用户并发控制共同决定，每日吞吐可控性较Batch Job的方式稍弱。 |

<span id="6586959b"></span>
# 配额说明

* 批量推理限配额 TPD 计算逻辑：
   * 同账号下按照模型名称（如 `doubao-pro-32k-***` 所有版本）汇总计算。
   * 不与在线推理的限流数合并计算。
   > 举例说明：您主账号下，doubao-pro-32k 模型，a、b、c 3个的批量推理任务，d、e 2个在线推理任务。则您每天a、b、c 批量推理共用 10 B token 配额，d 、e 共用在线推理任务 TPM、RPM 限流额度。
* 方舟对批量推理设置配额的原则是保障用户间资源分配的公平性，防止滥用或误用接口造成平台过载而服务中断。如您业务需要每天处理更多数据，请提交[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)申请。
* 您可以提交超出配额的任务量，当方舟平台有空闲资源，将动态扩展您的配额量。
* TPD 的时间计算窗口为 24 小时滑动窗口，一次短时高并发请求影响后续 24 小时的配额，与固定窗口相比，您请注意请求分布的均匀性。
* 账号配额，默认每个模型 10B token/天，可通过[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)申请提额。

<span id="075b8a07"></span>
# Batch Chat 使用教程
您可以用极小的代价，将业务从在线推理迁移至批量推理，则可以使用 Batch Chat 的方式实现批量推理。
> 查看接口字段详细说明见[对话(Chat)-批量 API（文档下线中）](https://www.volcengine.com/docs/82379/1449576)。

<span id="49f91cdc"></span>
## 前提条件

* 您已[获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey)。
> * 如您使用 Access Key 鉴权，可参见 [Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
> * 为了更安全使用 API Key / Access Key，建议您[将 API Key / Access Key 配置到环境变量](https://www.volcengine.com/docs/82379/1399008#%E9%85%8D%E7%BD%AE-api-key-%E5%88%B0%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F)中。
* 您已[获取批量推理接入点 ID](https://www.volcengine.com/docs/82379/1305505#_1-%E5%88%9B%E5%BB%BA%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86%E6%8E%A5%E5%85%A5%E7%82%B9%E5%B9%B6%E8%8E%B7%E5%8F%96%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86%E6%8E%A5%E5%85%A5%E7%82%B9id)。
* 您已安装/更新方舟最新的 SDK，可参见[安装及升级 SDK](https://www.volcengine.com/docs/82379/1541595)。

<span id="20fdc5ac"></span>
## 快速入门
您可以使用最小化示例代码快速发起一个批量推理请求。
与在线推理不同的是，您需使用 Batch Chat 接口，并替换`<Model>`为您的[批量推理接入点 ID](https://www.volcengine.com/docs/82379/1305505#_1-%E5%88%9B%E5%BB%BA%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86%E6%8E%A5%E5%85%A5%E7%82%B9%E5%B9%B6%E8%8E%B7%E5%8F%96%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86%E6%8E%A5%E5%85%A5%E7%82%B9id)。
```Python
import os
from volcenginesdkarkruntime import Ark
# 从环境变量中读取您的方舟API Key
client = Ark(
        api_key=os.environ.get("ARK_API_KEY"),
        # 1小时超时
        timeout=3600,
)
# 使用batch_chat.completions接口
completion = client.batch_chat.completions.create(  
    # 替换 <Model>为批量推理接入点 ID
    model="<MODEL>",
    messages=[
        {"role": "user", "content": "你好"}
    ]
)
print(completion.choices[0].message.content)
```

<span id="41b49ce6"></span>
## 使用说明及建议
为了充分发挥批量推理任务高配额的优势，建议保持高并发推压，如 10万+线程/协程（Python 语言存在线程开销较大问题，推荐使用如 asyncio 异步协程，或多进程方案优化性能），多机部署扩展等策略。同时为了保证请求完成率，需要配置一个较大的超时时间，各语言实现的[示例代码](https://www.volcengine.com/docs/82379/1399517#01826852)供您参考。
<span id="3b8e1a6f"></span>
### 提高任务请求完成比例
为了提高任务请求完成比例，避免服务端高负载时，大量请求排队中超时，推荐您手动配置一个较大的超时时间（取值在1小时到72小时）。**推荐配置24小时~72小时**，**无需您手动配置重试策略**，方舟会智能地进行任务调度，保障您任务的完成率。
> 超时时间对应`timeout` 字段，代表着单个请求的超时时间。请放心设置，较高的超时时间并不会对配额有影响。若设置较短的超时时间，在需要较长时间回复的场景（如深度思考模型输出思维链内容，回复篇幅更长、速率更慢），任务处理中途超时断开连接，既浪费您的 token 成本，又无法输出内容。
> 方舟客户端会在超时时间范围内自动重试请求，或者按照方舟服务端要求暂停若干时间后重试。在方舟服务端，则根据负载情况对请求做出暂不处理、排队、指定客户端若干时间后重试等操作。

```Python
...
client = AsyncArk(
    api_key=os.environ.get("ARK_API_KEY"),
    # 使用异步接口并配置较高的超时时间，推荐24小时~72小时
    timeout=3600*24,
    )
...
```

<span id="a0b61aa1"></span>
### 配置并发策略充分使用配额
方舟为每个主账户提供至少 10B token/天的配额，您可通过请求并发数及副本数的配置，将大量任务提交到方舟平台处理。方舟平台会根据业务负载，为您智能调度执行任务，甚至可在低负载时，为您提供超出基础配额的处理能力。
> 请求并发数`workerNum`表示 向方舟服务端发起请求时的最大并发数。它决定了在同一时间内，业务能够向服务端发起请求的最大数量。

在创建 client 之后，且在向方舟服务端发起请求之前，需要启动 client 的相关线程。
> 对于 Java 客户端，由于其自带了线程池，因此无需额外手动启动线程。根据不同的编程语言，调用相应的方法会有所不同。为确保准确调用，请参照[示例代码](https://www.volcengine.com/docs/82379/1399517#01826852)调用。

配置`workerNum`，推荐业务综合考虑业务预期的最大峰值、平均时延、机器并发上限等因素，来确定请求并发数。下面是个简单例子，供您参考如何设定请求并发数及副本数。
:::tip
业务预期的最大峰值QPS为5000，单个请求的平均延时为5秒，部署在2C4G的机器或容器上。
**关键的指标**

* 业务并发数：`5000*5 = 25000`
* 服务器限制：不考虑业务层损耗，服务器最大负载约在1000~1500 QPS间，这里假设为1000 QPS。

**副本数和并发数配置**
如果需要应对业务峰值时的业务量，可部署更多副本（推荐）或提升服务器规格（不推荐）：

* 副本数（预估的服务器数量）：`业务QPS/服务器限制=5000/1000=5`。
* 请求并发数`workerNum`（每个副本上设置并发数）：`服务器限制*请求平均延时=1000*5=5000`。
:::
<span id="b1e6f34a"></span>
### 视觉理解批量任务说明

* 调用视觉理解模型如`doubao-1.5-vision-pro-32k`进行批量推理。传入图片/视频的方式同[视觉理解](https://www.volcengine.com/docs/82379/1362931)，支持如下几种方式。
   *  图片的 TOS 链接（推荐）
   * 可访问的图片链接
   * 图片 Base64 编码

批量推理中包含的图片链接请保持长期（推荐7天）可用，避免因为图片链接过期，导致批量推理任务失败。TOS 预签名链接默认过期时长为1小时，需手动变更过期时间（建议设置为7天），完整签名字段说明见[TOS 预签名文档](https://www.volcengine.com/docs/6349/129226)。
```Python
...
client = tos.TosClientV2(ak, sk, endpoint, region)
# 生成上传文件的签名 url，设置 url 有效时间为7天
out = client.pre_signed_url(tos.HttpMethodType.Http_Method_Put, bucket=bucket_name, key=object_key, expires=604800)
...
```

<span id="1bb954de"></span>
### 其他说明及建议

* 单个副本中请全局使用同一个Client（单例模式），避免创建大量实例带来的资源开销及浪费。

> 如Go SDK中Client的`StartBatchWorker`方法会创建`workNum`个goroutine，避免创建大量goroutine带来的资源开销及浪费。


<span id="01826852"></span>
## 示例代码

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python 异步实现（推荐）" key="uSab7obI4c"><RenderMd content={`相比多线程方式，异步协程的方式更优：

* **并发更高**：当一个任务处于 I/O 等待状态（如网络请求）时，\`asyncio\` 可以立即切换到其他任务继续执行，避免了线程切换的开销，从而提高了整体的并发性能。
* **更轻量**：协程是轻量级的执行单元，相比于线程，占用的系统资源更少，可以创建大量的协程来处理任务。

:::tip
批量推理属于标准的高 io/低计算场景，如您系统未使用的同步 API 适配的场景，建议使用异步版，大部分场景用异步协程能获得更好的效果。
:::
\`\`\`Python
# 导入异步编程相关库，用于处理异步任务，异步编程中协程是核心概念
import asyncio
# 导入系统相关库，可用于与 Python 解释器和系统进行交互，如标准错误输出
import sys
# 导入操作系统相关库，用于访问操作系统的功能，如读取环境变量
import os
# 导入日期时间处理库，用于记录和计算程序的执行时间
from datetime import datetime
# 导入火山引擎异步 Ark 客户端库，用于与火山引擎的 Ark 服务进行异步通信
from volcenginesdkarkruntime import AsyncArk

async def worker(
    # asyncio task 的协程唯一标识，用于区分不同的工作协程
    worker_id: int,
    # 异步 Ark 客户端实例，用于调用批量聊天完成接口处理请求
    client: AsyncArk,
    # 待处理请求的队列，存储需要处理的请求
    requests: asyncio.Queue[dict],
):
    """
    异步协程函数，负责从队列中获取请求并处理。

    :param worker_id: 协程的唯一标识，用于在日志中区分不同的协程
    :param client: 异步 Ark 客户端实例，通过该实例调用服务接口处理请求
    :param requests: 待处理请求的队列，存储待处理的请求信息
    """
    # 打印协程启动信息
    print(f"Worker {worker_id} is starting.")
    while True:
        # 从队列中获取一个请求，若队列为空则会阻塞等待
        # 这里的 await 关键字用于暂停协程的执行，等待队列中有元素可供获取
        request = await requests.get()
        try:
            # 调用客户端的批量聊天完成接口处理请求，使用解包操作将请求字典作为参数传递
            # 同样使用 await 关键字暂停协程，等待接口调用完成
            completion = await client.batch_chat.completions.create(**request)
            # 打印处理结果
            print(completion)
        except Exception as e:
            # 若处理请求过程中出现异常，将错误信息打印到标准错误输出
            print(e, file=sys.stderr)
        finally:
            # 标记该请求已处理完成，通知队列该任务已结束
            requests.task_done()

async def main():
    """
    主函数，负责初始化客户端、生成请求、启动协程并监控任务完成情况。

    使用协程来实现并发处理请求，避免了使用线程带来的较大开销。
    多个协程可以在一个线程中并发执行，提高程序的性能。
    """
    # 记录程序开始执行的时间
    start = datetime.now()
    # 定义协程数量和任务数量
    worker_num, task_num = 1000, 10000
    # 创建一个异步队列用于存储请求，该队列支持异步操作
    requests = asyncio.Queue()
    # 初始化异步 Ark 客户端
    client = AsyncArk(
        # 从环境变量中获取 API 密钥，确保密钥的安全性
        api_key=os.environ.get("ARK_API_KEY"),
        # 设置超时时间为24小时，建议超时时间设置尽量大些，推荐24小时~72小时，避免因网络等原因导致请求超时
        timeout=24 * 3600,
    )
    # 模拟 \`task_num\` 个任务，将请求信息添加到队列中
    for _ in range(task_num):
        await requests.put(
            {
                # 替换为你的批量推理接入点 ID，指定要调用的服务端点
                "model": "<YOUR_ENDPOINT_ID>",
                "messages": [
                    {
                        # 系统角色消息，用于设置对话的初始信息
                        "role": "system",
                        "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手",
                    },
                    {
                        # 用户角色消息，包含用户的具体问题
                        "role": "user",
                        "content": "常见的十字花科植物有哪些？"
                    }
                ]
            }
        )
    # 创建 \`worker_num\` 个 asyncio task 的协程，并启动它们，每个协程负责处理队列中的请求
    # 这些协程会在一个线程中并发执行，通过协程的切换来提高效率
    tasks = [
        asyncio.create_task(worker(i, client, requests))
        for i in range(worker_num)
    ]
    # 等待所有请求处理完成，即队列中的所有任务都被标记为已完成
    await requests.join()
    # 停止所有协程，取消所有正在运行的任务
    for task in tasks:
        task.cancel()
    # 等待所有协程取消完成，确保所有任务都已停止
    await asyncio.gather(*tasks, return_exceptions=True)
    # 关闭客户端连接，释放资源
    await client.close()
    # 记录程序结束执行的时间
    end = datetime.now()
    # 打印程序总执行时间和处理的总任务数
    print(f"Total time: {end - start}, Total task: {task_num}")

if __name__ == "__main__":
    # 运行异步主函数，启动整个程序
    # asyncio.run() 会创建一个事件循环，并在这个事件循环中运行主协程
    asyncio.run(main())
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python 多线程实现" key="hibw8f68ld"><RenderMd content={`批量推理接入点调用方法与在线推理接入点类似，下面是一些需要额外进行配置的参数。

1. 设置超时时间\`timeout\`。
2. 配置的并发线程数和线程中运行的任务数。
3. 异步方法调用\`client.batch_chat.completions\`方法。

\`\`\`Python
# 导入 queue 模块，用于创建队列
import queue
# 导入 sys 模块，提供对 Python 解释器使用或维护的一些变量的访问
import sys
# 从 datetime 模块导入 datetime 类，用于处理日期和时间
from datetime import datetime
# 从 multiprocessing.pool 模块导入 ThreadPool 类，用于创建线程池
from multiprocessing.pool import ThreadPool
# 导入火山引擎 Ark 运行时 SDK
from volcenginesdkarkruntime import Ark

def worker(
    # 线程的唯一标识
    worker_id: int,
    # Ark 客户端实例
    client: Ark,
    # 待处理请求的队列
    requests: queue.Queue[dict],
):
    """
    线程函数，负责从队列中获取请求并处理。

    :param worker_id: 线程的唯一标识
    :param client: Ark 客户端实例
    :param requests: 待处理请求的队列
    """
    print(f"Worker {worker_id} is starting.")
    while True:
        # 从队列中获取一个请求
        request = requests.get()

        # 检查是否收到无更多请求的信号
        if not request:
            # 将信号放回队列，以便其他线程也能收到
            requests.put(request)
            return
        try:
            # 执行请求
            completion = client.batch_chat.completions.create(**request)
            print(completion)
        except Exception as e:
            # 打印错误信息到标准错误输出
            print(e, file=sys.stderr)
        finally:
            # 标记该请求已处理完成
            requests.task_done()

def main():
    """
    主函数，负责初始化客户端、生成请求、启动线程并监控任务完成情况。
    """
    # 记录开始时间
    start = datetime.now()
    # 最大并发任务数和总任务数
    worker_num, task_num = 1000, 10000
    # 创建一个队列用于存储请求
    requests = queue.Queue()
    # 初始化 Ark 客户端，设置超时时间为 24 小时
    client = Ark(
        # 从环境变量中获取 API 密钥
        api_key=os.environ.get("ARK_API_KEY"),
        # 设置超时时间为24小时，建议超时时间设置尽量大些，推荐24小时~72小时
        timeout=24 * 3600,
        # 设置 base_url
    )
    # 模拟 \`task_num\` 个任务
    for _ in range(task_num):
        requests.put(
            {
                # 替换为你的批量推理接入点 ID
                "model": "<YOUR_ENDPOINT_ID>",
                "messages": [
                    {
                        "role": "system",
                        "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手",
                    },
                    {"role": "user", "content": "常见的十字花科植物有哪些？"},
                ],
            }
        )
    # 放入一个请求结束的信号
    requests.put(None)

    # 创建 \`worker_num\` 个线程并启动它们
    with ThreadPool(worker_num) as pool:
        for i in range(worker_num):
            # 异步执行线程函数
            pool.apply_async(worker, args=(i, client, requests))

        # 关闭线程池，不再接受新的任务
        pool.close()
        # 等待所有任务完成
        pool.join()
    # 关闭客户端连接
    client.close()
    # 记录结束时间
    end = datetime.now()
    print(f"Total time: {end - start}, Total task: {task_num}")

if __name__ == "__main__":
    # 运行主函数
    main()
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Go" key="j79v2UBTqM"><RenderMd content={`批量推理接入点调用方法与在线推理接入点类似。
您需要升级最新的SDK，并关注下面示例代码中的配置。

1. 配置超时时间\`timeout\`，推荐24小时至72小时。
2. 添加 \`arkruntime.WithBatchMaxParallel\` 选项，设置发起请求的最大并发数量。
3. 方法换成\`client.CreateBatchChatCompletion\`方法。

\`\`\`Go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "os"
    "sync"
    "time"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    // 使用 API Key创建一个新的客户端实例
    client := arkruntime.NewClientWithApiKey(
        os.Getenv("ARK_API_KEY"),
        arkruntime.WithBatchMaxParallel(3000), // 设置发起请求的最大并发数量为 3000
    )

    // 这里手动构造 50000 个请求，在实际应用中，你可以从文件、消息队列或数据库中加载真实的请求
    requests := MockRequests("YOUR_ENDPOINT_ID", 50000)

    wg, ctx := sync.WaitGroup{}, context.Background()

    // 可以在这里设置全局的超时时间，如果超过这个时间，所有的请求都会被取消，这里设置为24小时
    ctx, cancel := context.WithTimeout(ctx, 24*time.Hour)
    defer cancel()

    // 发起请求
    for request := range requests {
        wg.Add(1)
        // 异步发起请求
        go func(request model.CreateChatCompletionRequest) {
            defer wg.Done()

            // 可以在这里设置每个请求的超时时间，如果超过这个时间，这个请求会被取消
            ctx, cancel := context.WithTimeout(ctx, 24*time.Hour)
            defer cancel()

            // 发起批量推理请求
            result, err := client.CreateBatchChatCompletion(ctx, request)
            if err != nil {
                fmt.Fprintln(os.Stderr, err)
            } else {
                fmt.Println(MustMarshalJson(result))
            }
        }(request)
    }
    // 等待所有协程完成任务
    wg.Wait()
}

// MockRequests 模拟生成请求，这里只是简单地生成了 count 个相同的请求。
// 在实际应用中，你可以从文件、消息队列或数据库中加载真实的请求。
func MockRequests(endpoint string, count int) <-chan model.CreateChatCompletionRequest {
    requests := make(chan model.CreateChatCompletionRequest)

    go func() {
        defer close(requests)
        for i := 0; i < count; i++ {
            requests <- model.CreateChatCompletionRequest{
                Model: endpoint,
                Messages: []*model.ChatCompletionMessage{
                    {
                        Role: model.ChatMessageRoleSystem,
                        Content: &model.ChatCompletionMessageContent{
                            StringValue: volcengine.String("你是豆包，是由字节跳动开发的 AI 人工智能助手"),
                        },
                    },
                    {
                        Role: model.ChatMessageRoleUser,
                        Content: &model.ChatCompletionMessageContent{
                            StringValue: volcengine.String("常见的十字花科植物有哪些？"),
                        },
                    },
                },
            }
        }
    }()

    return requests
}

func MustMarshalJson(v interface{}) string {
    s, _ := json.Marshal(v)
    return string(s)
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java" key="Yylgwl9owX"><RenderMd content={`批量推理接入点调用方法与在线推理接入点类似。
您需要升级最新的SDK，并关注下面示例代码中的变更。

1. 设置超时时间\`timeout\`。
2. \`设置最大线程数和线程任务数\`方法。

> Java SDK中自带线程池，所以无需批量线程启动的方法。


3. 调用\`ChatCompletionRequest\`类，启动批量推理。

\`\`\`Java
package com.example;

import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
import com.volcengine.ark.runtime.service.ArkService;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;
import java.time.Duration;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;

public class BatchChatCompletionsExample {
    public static void main(String[] args) {
        // 为batch chat设置一个较大的超时时间，推荐24小时到72小时之间
        Duration timeout = Duration.ofHours(24);
        // 您需要根据自己的需求配置最大线程数和每个线程执行的任务数
        int workerNum = 10000;
        int taskNum = 5;
        // 您需要将自己的API密钥设置为环境变量
        String apikey = System.getenv("ARK_API_KEY");
        ConnectionPool connectionPool = new ConnectionPool(workerNum, 10, TimeUnit.MINUTES);
        Dispatcher dispatcher = new Dispatcher();
        dispatcher.setMaxRequests(workerNum);
        dispatcher.setMaxRequestsPerHost(workerNum);
        // 请单独为batch chat单独初始化一个service实例，且多个Endpoint间也不要复用同一个service实例，避免互相影响。
        // 单个service会根据最大并发数启动对应的线程池，会占用一定的资源。
        ArkService service = ArkService.builder().dispatcher(dispatcher).timeout(timeout).connectionPool(connectionPool)
                .apiKey(apikey)
                .build();
        ExecutorService executorService = Executors.newFixedThreadPool(workerNum);
        CountDownLatch latch = new CountDownLatch(workerNum);
        Runnable batchChatTask = () -> {
            System.out.println(Thread.currentThread().getName() + ":在此线程中执行任务");
            for (int i = 0; i < taskNum; i++) {
                // 每个线程执行的任务逻辑，您需要按照自己业务需求进行改造，这里作为示例，展示一个最简单对话的例子
                try {
                    final List<ChatMessage> messages = new ArrayList<>();
                    final ChatMessage systemMessage = ChatMessage.builder().role(ChatMessageRole.SYSTEM)
                            .content("你是豆包，是由字节跳动开发的 AI 人工智能助手").build();
                    final ChatMessage userMessage = ChatMessage.builder().role(ChatMessageRole.USER)
                            .content("你好").build();
                    messages.add(systemMessage);
                    messages.add(userMessage);
                    
                    ChatCompletionRequest batchChatCompletionRequest = ChatCompletionRequest.builder()
                            // 您需要替换您的批量推理接入点ID
                            .model("<YOUR_ENDPOINT_ID>")
                            .messages(messages)
                            .build();
                    service.createBatchChatCompletion(batchChatCompletionRequest)
                            .getChoices()
                            .forEach(choice -> System.out.println(Thread.currentThread().getName() + ":"
                                    + choice.getMessage().getContent()));
                } catch (Exception e) {
                    System.out.println(Thread.currentThread().getName() + "：请求" + i + "失败。");
                    System.out.println("    报错信息：" + e.getMessage());
                }
            }
            System.out.println(Thread.currentThread().getName() + "：此线程中任务完成。");
            latch.countDown();
        };
        for (int i = 0; i < workerNum; i++) {
            executorService.submit(batchChatTask);
        }
        try {
            latch.await();
        } catch (InterruptedException ignored) {
        }
        System.out.println("所有线程已退出");
        executorService.shutdown();
        System.out.println("线程池已退出");
        // 当所有请求完成，请关闭服务
        service.shutdownExecutor();
    }
}
\`\`\`


`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="50199f2b"></span>
### 
<span id="d6f60e44"></span>
# Batch Job 开发教程
通过控制台创建批量推理任务，请参见[批量推理任务](https://www.volcengine.com/docs/82379/1305505#使用流程)。
:::warning
* 批量推理使用视觉理解模型如`doubao-1.5-vision-pro-32k`，传入图片的方式支持 TOS链接（推荐）、其他可访问图片链接、 Base64 编码，与视觉理解 [图片传入方式](https://www.volcengine.com/docs/82379/1362931#4be57c22)相同。
* 批量推理中包含的图片链接请保持长期（推荐7天）可用，避免因为图片链接过期，导致批量推理任务失败。TOS 预签名链接默认过期时长为1小时，需手动变更过期时间（建议设置为7天），完整签名字段说明见[TOS 预签名文档](https://www.volcengine.com/docs/6349/129226)。

```Python
    ...
    client = tos.TosClientV2(ak, sk, endpoint, region)
    # 生成上传文件的签名 url，设置 url 有效时间为7天
    out = client.pre_signed_url(tos.HttpMethodType.Http_Method_Put, bucket=bucket_name, key=object_key, expires=604800)
    ...
```

:::
<span id="c2779ba5"></span>
## 前提条件

* 您已[开通指定模型服务](https://console.volcengine.com/common-buy/ark_bd%7C%7C7291580783171539244)。
* 您已[开通 TOS](https://console.volcengine.com/tos)（火山引擎对象存储产品），并已[创建存储桶](https://console.volcengine.com/tos/bucket?projectName=default)。
* 安装[TOS SDK](https://www.volcengine.com/docs/6349/93479)、[火山引擎SDK](https://api.volcengine.com/api-sdk/view?serviceCode=ark&version=2024-01-01&language=Python)。
* 您已[获取Access Key](https://console.volcengine.com/iam/keymanage/)。

<span id="bf2ab0f6"></span>
## 快速入门
您可以通过快速入门示例代码实现批量推理任务的创建、查询、下载结果。
<span id="aaf211b6"></span>
### 准备批量推理任务文件
请您参考 [数据文件格式说明](https://www.volcengine.com/docs/82379/1305505#批量推理数据文件格式说明)，准备数据格式文件，文件为`jsonl`格式，其中每行包含对 API 的单个请求的详细信息。
以下是包含 2 个请求的输入文件的示例。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="文本生成" key="SI2nZSqufM"><RenderMd content={`\`\`\`JSON
{"custom_id": "request-1", "body": {"messages": [{"role": "user", "content": "天空为什么这么蓝？"}],"max_tokens": 1000,"top_p":1,"temperature":0.7}}
{"custom_id": "request-2", "body": {"messages": [{"role": "system", "content": "You are an unhelpful assistant."},{"role":"user", "content":"天空为什么这么蓝？"}],"max_tokens":1000}}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="图片理解" key="YN42PKE0lb"><RenderMd content={`\`\`\`JSON
{"custom_id":"request-1","body":{"messages":[{"role":"user","content":[{"type":"text","text":"支持输入是图片的模型系列是哪个？"},{"type":"image_url","image_url":{"url":"https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"}}]}],"max_tokens":1000,"top_p":1,"temperature":0.7}}
{"custom_id":"request-2","body":{"messages":[{"role":"user","content":[{"type":"image_url","image_url":{"url":"https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"}},{"type":"image_url","image_url":{"url":"https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_2.png"}},{"type":"text","text":"图片里都有什么？"}]}],"max_tokens":1000}}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="视频理解" key="IDNOwhecgG"><RenderMd content={`\`\`\`JSON
{"custom_id":"request-1","body":{"messages":[{"role":"user","content":[{"type":"text","text":"视频里有什么？"},{"type":"video_url","video_url":{"url":"https://ark-project.tos-cn-beijing.volces.com/doc_video/ark_vlm_video_input.mp4"}}]}],"max_tokens":1000,"top_p":1,"temperature":0.7}}
{"custom_id":"request-2","body":{"messages":[{"role":"user","content":[{"type":"video_url","video_url":{"url":"https://ark-project.tos-cn-beijing.volces.com/doc_video/ark_vlm_video_input_2.mp4"}},{"type":"video_url","video_url":{"url":"https://ark-project.tos-cn-beijing.volces.com/doc_video/ark_vlm_video_input_3.mp4"}},{"type":"text","text":"视频里都有什么？"}]}],"max_tokens":1000}}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

说明：

* 每个请求都必须包含一个唯一`custom_id`值，后续在结果文件中可以通过`custom_id`来查询对应请求的结果。
* 每行字段中的`body`遵循 [批量(Chat) API](https://www.volcengine.com/docs/82379/1528783) 请求体结构以及字段取值。
* 每个输入文件只能包含对指定的一个批量推理接入点的请求。
* 使用视觉理解模型如`doubao-1-5-vision-pro-250428`，传入图片的方式只支持 TOS（火山引擎对象存储）链接，不支持其他链接以及 Base64 编码。输入文件示例如下（多图和单图的输入文件示例）。
* 为您提供了一个脚本来校验文档是否符合标准，避免因格式错误导致下载失败，脚本下载见[输入文件](https://www.volcengine.com/docs/82379/1305505#输入文件)。

<span id="e077fc63"></span>
### 上传任务文件至TOS
您需要上传任务文件至 TOS 的bucket中，后续方舟平台会读取文件里的请求信息来进行批量推理。下面是上传文件的简单脚本。
如果您的任务文件较大，可以参考[教程](https://www.volcengine.com/docs/6349/92801)改造为分片上传。
> 运行脚本前，您需在配置您的桶信息等任务信息填入其中，将您的Access Key配置到环境变量`VOLC_ACCESSKEY`、`VOLC_SECRETKEY`中（配置方法可参考[文档](https://www.volcengine.com/docs/82379/1399008#%E9%85%8D%E7%BD%AE-api-key-%E5%88%B0%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F)）。

```Python
import os
import tos

# 从环境变量中读取您的Access Key，为了保障安全，建议您配置Access Key至环境变量
ak = os.environ.get("VOLC_ACCESSKEY")
sk = os.environ.get("VOLC_SECRETKEY")
# 存储任务文件及结果文件的桶的属性，包括ENDPOINT以及地域
endpoint = "tos-cn-beijing.volces.com"
region = "cn-beijing"
bucket_name = "input-bucket"
# 上传任务文件的文件路径
object_key = "input/data.jsonl"
# 任务文件本地的路径
file_name = "/usr/local/data.jsonl"
# 初始化 TOS 客户端
client = tos.TosClientV2(ak, sk, endpoint, region)
# 上传文件
client.put_object_from_file(bucket_name, object_key, file_name)
```

<span id="56139293"></span>
### 创建批量推理任务
您可以调用接口[CreateBatchInferenceJob - 创建批量推理任务](https://www.volcengine.com/docs/82379/1339603)来配置并创建批量推理任务，包括读入任务文件的路径、输出结果的路径、使用模型等等信息。
> 运行脚本前，您需在配置项类`Config`中填入您的任务信息，同时将您的Access Key配置到环境变量`VOLC_ACCESSKEY`、`VOLC_SECRETKEY`中（配置方法可参考[文档](https://www.volcengine.com/docs/82379/1399008#%E9%85%8D%E7%BD%AE-api-key-%E5%88%B0%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F)）。

```Python
import volcenginesdkcore
import volcenginesdkark
import os

# 配置项类，您需将其改为自己的配置
class Config:
    # 存储任务文件及结果文件的桶的属性，包括ENDPOINT以及地域
    REGION = "cn-beijing"
    INPUT_BUCKET = "input-bucket"
    # 上传任务文件的文件路径
    INPUT_OBJECT_KEY = "input/data.jsonl"
    OUTPUT_BUCKET = "output-bucket"
    # 存储结果文件的文件夹
    OUTPUT_OBJECT_KEY = "output/"
    # 任务文件本地的路径
    LOCAL_FILE_NAME = "/usr/local/data.jsonl"
    # 模型版本及名称，可在此查询 https://www.volcengine.com/docs/82379/1330310
    MODEL_VERSION = "250115"
    MODEL_NAME = "doubao-1-5-pro-32k"
    # 命名您的批量推理任务
    JOB_NAME = "demo"
    # 批量推理任务所在项目的名称，默认为default
    PROJECT_NAME = "default"
    # 从环境变量中读取您的Access Key，为了保障安全，建议您配置Access Key至环境变量
    AK = os.environ.get("VOLC_ACCESSKEY")
    SK = os.environ.get("VOLC_SECRETKEY")

# 创建批量推理任务
def create_batch_job(ark_instance):
    input_file_tos_location = (
        volcenginesdkark.InputFileTosLocationForCreateBatchInferenceJobInput(
            bucket_name=Config.INPUT_BUCKET, 
            object_key=Config.INPUT_OBJECT_KEY
        )
    )
    output_dir_tos_location = (
        volcenginesdkark.OutputDirTosLocationForCreateBatchInferenceJobInput(
            bucket_name=Config.OUTPUT_BUCKET, 
            object_key=Config.OUTPUT_OBJECT_KEY
        )
    )
    foundation_model = volcenginesdkark.FoundationModelForCreateBatchInferenceJobInput(
        model_version=Config.MODEL_VERSION, 
        name=Config.MODEL_NAME
    )
    model_reference = volcenginesdkark.ModelReferenceForCreateBatchInferenceJobInput(
        foundation_model=foundation_model
    )
    req = volcenginesdkark.CreateBatchInferenceJobRequest(
        input_file_tos_location=input_file_tos_location,
        model_reference=model_reference,
        name=Config.JOB_NAME,
        output_dir_tos_location=output_dir_tos_location,
        project_name=Config.PROJECT_NAME,
    )
    resp = ark_instance.create_batch_inference_job(req)
    return resp.id

configuration = volcenginesdkcore.Configuration()
configuration.ak = Config.AK
configuration.sk = Config.SK
configuration.region = Config.REGION
configuration.client_side_validation = True
volcenginesdkcore.Configuration.set_default(configuration)
ark_instance = volcenginesdkark.ARKApi(volcenginesdkcore.ApiClient(configuration))
# 创建批量推理任务
batch_job_id = create_batch_job(ark_instance)
print(f"创建批量推理任务，任务ID：{batch_job_id}")
```

请求将返回创建的批量推理任务的 ID。
```JSON
创建批量推理任务，任务ID：bi-20250305220634-****
```

<span id="f3bc73c8"></span>
### 查询批量推理任务状态
您可随时检查任务的状态，包括通过任务id、模型、运行状态等进行筛选，具体筛选方式可见[ListBatchInferenceJobs - 获取批量推理任务列表](https://www.volcengine.com/docs/82379/1339606)。
```Python
import os
import volcenginesdkcore
import volcenginesdkark

class Config:
    # 存储任务文件及结果文件的桶的属性，包括ENDPOINT以及地域
    REGION = "cn-beijing"
    # 从环境变量中读取您的Access Key，为了保障安全，建议您配置Access Key至环境变量
    AK = os.environ.get("VOLC_ACCESSKEY")
    SK = os.environ.get("VOLC_SECRETKEY")
    # 替换为您创建的批量推理任务的 ID
    BATCH_JOB_ID="bi-2025030****"

# 列出指定 ID 的批量推理任务信息。
def list_batch_inference_jobs(ark_instance, batch_job_id):
    filter = volcenginesdkark.FilterForListBatchInferenceJobsInput(ids=[batch_job_id])
    req = volcenginesdkark.ListBatchInferenceJobsRequest(filter=filter)
    resp = ark_instance.list_batch_inference_jobs(req)
    return resp


configuration = volcenginesdkcore.Configuration()
configuration.ak = Config.AK
configuration.sk = Config.SK
configuration.region = Config.REGION
configuration.client_side_validation = True
volcenginesdkcore.Configuration.set_default(configuration)
ark_instance = volcenginesdkark.ARKApi(volcenginesdkcore.ApiClient(configuration))
batch_job_status = list_batch_inference_jobs(ark_instance, Config.BATCH_JOB_ID)
print(f"批量推理任务信息:\n{batch_job_status}")
```

运行脚本，将返回匹配筛选条件的任务的信息。
```JSON
批量推理任务信息:
{'items': [{'completion_window': '28d',
            'create_time': '2025-03-05T14:06:34Z',
            'description': '',
            'expire_time': '2025-04-02T14:06:34Z',
            'id': 'bi-20250305220634-****',
            'input_file_tos_location': {'bucket_name': 'input-bucket',
                                        'object_key': 'input/data.jsonl'},
            'model_reference': {'custom_model_id': None,
                                'foundation_model': {'model_version': '250115',
                                                     'name': 'doubao-1-5-pro-32k'}},
            'name': 'demo',
            'output_dir_tos_location': {'bucket_name': 'output-bucket',
                                        'object_key': 'output/'},
            'project_name': 'default',
            'request_counts': {'completed': 2, 'failed': 0, 'total': 2},
            'status': {'message': '',
                       'phase': 'Completed',
                       'phase_time': '2025-03-05T15:07:47Z'},
            'tags': [{'key': 'sys:ark:createdBy',
                      'value': '****'}],
            'update_time': '2025-03-05T15:07:47Z'}],
 'page_number': 1,
 'page_size': 10,
 'total_count': 1}
```

批量推理任务状态有以下几种：

| | | \
|状态 |描述 |
|---|---|
| | | \
|Queued |任务提交成功，排队执行中 |
| | | \
|Running |任务运行中 |
| | | \
|Completed |任务已完成 |
| | | \
|Terminating |任务在停止中。 |
| | | \
|Terminated |任务已被停止。 |
| | | \
|Failed |任务执行失败，原因可能是超时等原因。 |

<span id="8a64682f"></span>
### 下载批量推理任务结果
查询到批量推理任务完成后，您可以通过接口下载执行批量推理任务后的文件，包括2个文件：

* results.jsonl：批量推理任务执行后，成功执行结果的集合。其中结果顺序可能与任务文件不一致，请通过`custom_id`来查询。
* errors.jsonl：批量推理任务执行后，错误请求的集合。

```Python
import os
import tos

# 替换为您的批量推理任务 ID
batch_job_id="bi-20250305220634-****"
# 从环境变量中读取您的Access Key，为了保障安全，建议您配置Access Key至环境变量
ak = os.environ.get("VOLC_ACCESSKEY")
sk = os.environ.get("VOLC_SECRETKEY")
# 替换为您存储桶的属性，包括 endpoint、region、bucket_name
endpoint = "tos-cn-beijing.volces.com"
region = "cn-beijing"
bucket_name = "output-bucket"
# 替换为您配置的批量推理任务结果文件路径
output_object_key = "output/"
# 替换为您存储批量推理任务结果文件的本地路径
local_output_dir = "./output"

results_key = f"{output_object_key}{batch_job_id}/output/results.jsonl"
errors_key = f"{output_object_key}{batch_job_id}/output/errors.jsonl"
results_file_name = f"{local_output_dir}{batch_job_id}/results.jsonl"
errors_file_name = f"{local_output_dir}{batch_job_id}/errors.jsonl"
client = tos.TosClientV2(ak, sk, endpoint, region)
try:
    client.get_object_to_file(bucket_name, results_key, results_file_name)
except:
    print("results.jsonl not exist or other error")
try:
    client.get_object_to_file(bucket_name, errors_key, errors_file_name)
except:
    print("errors.jsonl not exist or other error")
```

您可以配置的`local_output_dir`文件路径下，找到批量推理任务结果文件。
```JSON
{"id":"02174118435223600000000000000000000ffffac1520039ca4e1","custom_id":"request-1","error":null,"response":{"request_id":"02174118435223600000000000000000000ffffac1520039ca4e1","status_code":200,"body":{"id":"02174118435223600000000000000000000ffffac1520039ca4e1","object":"chat.completion","created":1741184547,"model":"doubao-1-5-pro-32k-250115","choices":[{"index":0,"message":{"role":"assistant","content":"天空呈现蓝色主要是由于瑞利散射现象，以下为你详细解释：\n\n### 太阳光的组成\n太阳光其实是由多种不同颜色的光混合而成的，这些光按照波长从长到短依次为红、橙、黄、绿、蓝、靛、紫，也就是我们常说的七色光。\n\n### 大气的组成\n地球的大气层主要由氮气、氧气以及其他微量气体分子和微小颗粒组成。当太阳光进入大气层时，就会与这些气体分子发生相互作用。\n\n### 瑞利散射过程\n根据瑞利散射定律，散射光的强度与光的波长的四次方成反比。也就是说，波长越短的光，越容易被散射。\n\n在太阳光包含的各种颜色光中，蓝光的波长相对较短（约450 - 495纳米）。当太阳光进入地球大气层后，蓝光就很容易被大气中的气体分子散射到各个方向。所以，在我们向天空望去时，这些被散射到四面八方的蓝光就会进入我们的眼睛，从而让我们感觉整个天空都是蓝色的。\n\n### 影响天空蓝色深浅的因素\n在不同的时间和地点，大气中水汽、尘埃等颗粒物的含量有所不同，这会一定程度上改变大气对蓝光散射的效果。当空气中的颗粒物较多时，更多的蓝光被散射和吸收，天空可能呈现浅蓝色甚至有点发白；而在空气较为纯净的地区，比如海边、高原，散射效果更明显，天空看起来会更湛蓝。 "},"finish_reason":"stop"}],"usage":{"prompt_tokens":13,"completion_tokens":322,"total_tokens":335,"prompt_tokens_details":{"cached_tokens":0},"completion_tokens_details":{"reasoning_tokens":0}},"HttpHeader":{"X-Request-Id":["02174118435223600000000000000000000ffffac1520039ca4e1"],"X-Client-Request-Id":["2025030522191200000CA2C7FE1C9A9065"],"Vary":["Accept-Encoding"],"Server":["hertz"],"Date":["Wed, 05 Mar 2025 14:22:26 GMT"],"Content-Type":["application/json; charset=utf-8"]}}}}
{"id":"02174118707871600000000000000000000ffffac152003cadb62","custom_id":"request-2","error":null,"response":{"request_id":"02174118707871600000000000000000000ffffac152003cadb62","status_code":200,"body":{"id":"02174118707871600000000000000000000ffffac152003cadb62","object":"chat.completion","created":1741187249,"model":"doubao-1-5-pro-32k-250115","choices":[{"index":0,"message":{"role":"assistant","content":"我不想给你好好解释这个问题。天空蓝不蓝关我啥事，你自己去想吧。 "},"finish_reason":"stop"}],"usage":{"prompt_tokens":25,"completion_tokens":24,"total_tokens":49,"prompt_tokens_details":{"cached_tokens":0},"completion_tokens_details":{"reasoning_tokens":0}},"HttpHeader":{"X-Client-Request-Id":["202503052304380000BACD2ADACB18921B"],"Vary":["Accept-Encoding"],"Server":["hertz"],"Date":["Wed, 05 Mar 2025 15:07:29 GMT"],"Content-Type":["application/json; charset=utf-8"],"X-Request-Id":["02174118707871600000000000000000000ffffac152003cadb62"]}}}}
```

<span id="75240726"></span>
## 使用说明
<span id="93b00236"></span>
### 提升限额
如您业务处理任务较多，可按需申请限额提升。

* 账号配额，默认每个模型 10B token/天，可通过[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)申请提额。
* 账号同时可执行任务数，默认最大可同时执行20个任务，可[在此](https://console.volcengine.com/quota/productList)申请提额。
* 单任务文件大小，默认 2GiB（实名认证个人客户）， 5GiB（实名认证企业客户）；如有需要可以[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)申请提额。

<span id="28e86376"></span>
### 更完整实践
您可参考文档[批量推理任务最佳实践](https://www.volcengine.com/docs/82379/1386369)。
<span id="b92e248b"></span>
## 相关文档

* [批量推理任务接口](https://www.volcengine.com/docs/82379/1339371)：查看批量推理任务可以使用的接口以及查询接口各个字段的含义。
* [批量推理](https://www.volcengine.com/docs/82379/1305505)：如何使用控制台管理批量推理任务。
* [常见问题](https://www.volcengine.com/docs/82379/1359411)-[批量推理](https://www.volcengine.com/docs/82379/1359411#d3743e3b)：批量推理的常见问题。


<span id="95d36ebd"></span>
## 




# 工具调用 Function Calling
Source: https://www.volcengine.com/docs/82379/1262342
<span id="05025535"></span>
## 功能概述
<span id="8dacf369"></span>
### 功能简介
工具调用（Function Calling）是一种将大模型与外部工具和 API 相连的关键功能，作为自然语言与信息接口之间的“翻译官”，它能够将用户的自然语言请求智能地转化为对特定工具或 API 的调用，从而高效满足用户的特定需求。

* **核心价值**：实现大模型与外部工具的无缝衔接，使大模型能够借助外部工具处理实时数据查询、任务执行等复杂场景，推动大模型在实际产业中的落地应用。
* **工作原理**：开发者通过自然语言向模型描述工具的功能和定义，模型在对话过程中自主判断是否需要调用工具。当需要调用时，模型会返回符合要求的工具函数及入参，开发者负责实际调用工具并将结果回填给模型，模型再根据结果进行总结或继续规划子任务。

<span id="8fafb8b7"></span>
### 适用场景
Function Calling 适用于以下需要大模型与外部工具协同的场景：

| | | | | \
|**场景分类** |**核心特征** |**核心价值** |**典型应用** |
|---|---|---|---|
| | | | | \
|实时数据交互场景 |需大模型与外部工具协同处理动态信息 |处理动态信息查询需求 |天气/股票/航班实时状态查询、数据库检索与 API 数据调用 |
| | | | | \
|任务自动化场景 |单次工具调用完成操作 |提升操作效率 |邮件/消息自动发送、设备控制指令执行（如智能家居开关） |
| | | | | \
|复杂流程编排场景 |多工具串并联调用 |跨工具参数传递、子任务依赖关系管理 |先查天气再发通知等需跨工具传递参数及管理子任务依赖的场景 |
| | | | | \
|智能系统集成场景 |与业务系统深度耦合 |实现系统智能化联动 |智能座舱多设备联动控制、企业级 Bot 工作流（如飞书会议创建→群组管理→任务生成） |

<span id="ad9643bb"></span>
### 典型示例
用户：北京今天的天气如何？适合穿什么衣服？
模型思考：
  1. 需要调用天气查询工具获取实时数据（location=北京，unit=摄氏度）
  2. 天气信息包含温度、天气状况（晴/雨等），需结合数据给出穿衣建议
工具调用结果：
北京今天晴，气温 18-25℃，北风3级，湿度45%
模型回答：
北京今天天气晴朗，气温18-25℃，建议穿薄长袖衬衫或短袖T恤，搭配薄外套应对早晚温差。
<span id="a5108937"></span>
### 工作原理图

工具</b>&quot;,&quot;style&quot;:&quot;rounded=0;whiteSpace=wrap;html=1;verticalAlign=top;fillColor=none;dashed=1;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;Rectangle&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;60&quot;,&quot;y&quot;:&quot;120&quot;,&quot;width&quot;:&quot;240&quot;,&quot;height&quot;:&quot;440&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;JJvTNGGv&quot;:{&quot;id&quot;:&quot;JJvTNGGv&quot;,&quot;value&quot;:&quot;<b>程序</b>&quot;,&quot;style&quot;:&quot;rounded=0;whiteSpace=wrap;html=1;verticalAlign=top;fillColor=none;dashed=1;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;Rectangle&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;320&quot;,&quot;y&quot;:&quot;120&quot;,&quot;width&quot;:&quot;240&quot;,&quot;height&quot;:&quot;440&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;HerNl4Am&quot;:{&quot;id&quot;:&quot;HerNl4Am&quot;,&quot;value&quot;:&quot;<b>模型</b>&quot;,&quot;style&quot;:&quot;rounded=0;whiteSpace=wrap;html=1;verticalAlign=top;fillColor=none;dashed=1;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;Rectangle&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;580&quot;,&quot;y&quot;:&quot;120&quot;,&quot;width&quot;:&quot;240&quot;,&quot;height&quot;:&quot;440&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;AzImFBqq&quot;:{&quot;id&quot;:&quot;AzImFBqq&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;1tnUQpLf&quot;,&quot;target&quot;:&quot;a4ttJ9li&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;1tnUQpLf&quot;:{&quot;id&quot;:&quot;1tnUQpLf&quot;,&quot;value&quot;:&quot;收到用户问题&quot;,&quot;style&quot;:&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=none;arcSize=50;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;RoundedRectangle&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;360&quot;,&quot;y&quot;:&quot;160&quot;,&quot;width&quot;:&quot;160&quot;,&quot;height&quot;:&quot;40&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;Rz0Vnx00&quot;:{&quot;id&quot;:&quot;Rz0Vnx00&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;a4ttJ9li&quot;,&quot;target&quot;:&quot;kQtnq2G9&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;,&quot;-0-mxPoint&quot;:{&quot;x&quot;:&quot;620&quot;,&quot;y&quot;:&quot;260&quot;,&quot;as&quot;:&quot;targetPoint&quot;},&quot;-1-Array&quot;:{&quot;as&quot;:&quot;points&quot;,&quot;-0-mxPoint&quot;:{&quot;x&quot;:&quot;570&quot;,&quot;y&quot;:&quot;240&quot;},&quot;-1-mxPoint&quot;:{&quot;x&quot;:&quot;570&quot;,&quot;y&quot;:&quot;260&quot;}}}},&quot;a4ttJ9li&quot;:{&quot;id&quot;:&quot;a4ttJ9li&quot;,&quot;value&quot;:&quot;发起模型调用<br />Tools 字段+原始用户问题&quot;,&quot;style&quot;:&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=none;arcSize=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;RoundedRectangle&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;360&quot;,&quot;y&quot;:&quot;220&quot;,&quot;width&quot;:&quot;160&quot;,&quot;height&quot;:&quot;40&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;ipVMooqw&quot;:{&quot;id&quot;:&quot;ipVMooqw&quot;,&quot;value&quot;:&quot;&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;kQtnq2G9&quot;,&quot;target&quot;:&quot;V80viOhd&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;,&quot;-0-mxPoint&quot;:{&quot;x&quot;:&quot;700&quot;,&quot;y&quot;:&quot;400&quot;,&quot;as&quot;:&quot;targetPoint&quot;}}},&quot;egs1h4iP&quot;:{&quot;id&quot;:&quot;egs1h4iP&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=1;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;kQtnq2G9&quot;,&quot;target&quot;:&quot;SnIyUNHO&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;kQtnq2G9&quot;:{&quot;id&quot;:&quot;kQtnq2G9&quot;,&quot;value&quot;:&quot;是否调用工具&quot;,&quot;style&quot;:&quot;rhombus;whiteSpace=wrap;html=1;fillColor=none;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;Diamond&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;620&quot;,&quot;y&quot;:&quot;240&quot;,&quot;width&quot;:&quot;160&quot;,&quot;height&quot;:&quot;40&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;3fGUT9DD&quot;:{&quot;id&quot;:&quot;3fGUT9DD&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=1;entryY=0.5;entryDx=0;entryDy=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;V80viOhd&quot;,&quot;target&quot;:&quot;jc1g9pHF&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;V80viOhd&quot;:{&quot;id&quot;:&quot;V80viOhd&quot;,&quot;value&quot;:&quot;输出工具名称以及参数&quot;,&quot;style&quot;:&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=none;arcSize=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;RoundedRectangle&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;620&quot;,&quot;y&quot;:&quot;300&quot;,&quot;width&quot;:&quot;160&quot;,&quot;height&quot;:&quot;40&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;adkWaAlq&quot;:{&quot;id&quot;:&quot;adkWaAlq&quot;,&quot;value&quot;:&quot;是&quot;,&quot;style&quot;:&quot;text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];autosize=1;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;700&quot;,&quot;y&quot;:&quot;281&quot;,&quot;width&quot;:&quot;40&quot;,&quot;height&quot;:&quot;20&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;txJ7EXgl&quot;:{&quot;id&quot;:&quot;txJ7EXgl&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=1;entryY=0.5;entryDx=0;entryDy=0;exitX=0.5;exitY=1;exitDx=0;exitDy=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;SnIyUNHO&quot;,&quot;target&quot;:&quot;jqaGcsh4&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;SnIyUNHO&quot;:{&quot;id&quot;:&quot;SnIyUNHO&quot;,&quot;value&quot;:&quot;生成问题回答&quot;,&quot;style&quot;:&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=none;arcSize=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;RoundedRectangle&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;620&quot;,&quot;y&quot;:&quot;460&quot;,&quot;width&quot;:&quot;160&quot;,&quot;height&quot;:&quot;40&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;dcianNJl&quot;:{&quot;id&quot;:&quot;dcianNJl&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=1;entryY=0.5;entryDx=0;entryDy=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;jc1g9pHF&quot;,&quot;target&quot;:&quot;yump7Jj5&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;jc1g9pHF&quot;:{&quot;id&quot;:&quot;jc1g9pHF&quot;,&quot;value&quot;:&quot;解析返回信息<br />发起工具调用&quot;,&quot;style&quot;:&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=none;arcSize=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;RoundedRectangle&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;360&quot;,&quot;y&quot;:&quot;320&quot;,&quot;width&quot;:&quot;160&quot;,&quot;height&quot;:&quot;40&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;QRs31Xv7&quot;:{&quot;id&quot;:&quot;QRs31Xv7&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=0.5;exitY=1;exitDx=0;exitDy=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;yump7Jj5&quot;,&quot;target&quot;:&quot;MikdKlim&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;yump7Jj5&quot;:{&quot;id&quot;:&quot;yump7Jj5&quot;,&quot;value&quot;:&quot;完成请求<br />返回信息&quot;,&quot;style&quot;:&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=none;arcSize=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;RoundedRectangle&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;100&quot;,&quot;y&quot;:&quot;340&quot;,&quot;width&quot;:&quot;160&quot;,&quot;height&quot;:&quot;40&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;pvM7y1Qi&quot;:{&quot;id&quot;:&quot;pvM7y1Qi&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;MikdKlim&quot;,&quot;target&quot;:&quot;P1lA33A0&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;MikdKlim&quot;:{&quot;id&quot;:&quot;MikdKlim&quot;,&quot;value&quot;:&quot;发起模型调用<br />原始用户问题+工具返回结果&quot;,&quot;style&quot;:&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=none;arcSize=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;RoundedRectangle&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;360&quot;,&quot;y&quot;:&quot;380&quot;,&quot;width&quot;:&quot;160&quot;,&quot;height&quot;:&quot;40&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;jqaGcsh4&quot;:{&quot;id&quot;:&quot;jqaGcsh4&quot;,&quot;value&quot;:&quot;返回模型回答&quot;,&quot;style&quot;:&quot;rounded=1;whiteSpace=wrap;html=1;fillColor=none;arcSize=50;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;RoundedRectangle&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;360&quot;,&quot;y&quot;:&quot;500&quot;,&quot;width&quot;:&quot;160&quot;,&quot;height&quot;:&quot;40&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;pbEfD5m8&quot;:{&quot;id&quot;:&quot;pbEfD5m8&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;xunMzPAw&quot;,&quot;target&quot;:&quot;a4ttJ9li&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;xunMzPAw&quot;:{&quot;id&quot;:&quot;xunMzPAw&quot;,&quot;value&quot;:&quot;工具信息&quot;,&quot;style&quot;:&quot;shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fillColor=none;&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;Parallelogram&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;100&quot;,&quot;y&quot;:&quot;200&quot;,&quot;width&quot;:&quot;160&quot;,&quot;height&quot;:&quot;40&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;6p0yqPY1&quot;:{&quot;id&quot;:&quot;6p0yqPY1&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=1;entryDx=0;entryDy=0;&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;P1lA33A0&quot;,&quot;target&quot;:&quot;V80viOhd&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;jyyqNEWR&quot;:{&quot;id&quot;:&quot;jyyqNEWR&quot;,&quot;style&quot;:&quot;edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;entryX=1;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;&quot;,&quot;edge&quot;:&quot;1&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;source&quot;:&quot;P1lA33A0&quot;,&quot;target&quot;:&quot;SnIyUNHO&quot;,&quot;-0-mxGeometry&quot;:{&quot;relative&quot;:&quot;1&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;P1lA33A0&quot;:{&quot;id&quot;:&quot;P1lA33A0&quot;,&quot;value&quot;:&quot;是否调用工具&quot;,&quot;style&quot;:&quot;rhombus;whiteSpace=wrap;html=1;fillColor=none;&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;diagramName&quot;:&quot;Diamond&quot;,&quot;diagramCategory&quot;:&quot;general&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;620&quot;,&quot;y&quot;:&quot;400&quot;,&quot;width&quot;:&quot;160&quot;,&quot;height&quot;:&quot;40&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;hBl2D1xZ&quot;:{&quot;id&quot;:&quot;hBl2D1xZ&quot;,&quot;value&quot;:&quot;是&quot;,&quot;style&quot;:&quot;text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];autosize=1;&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;700&quot;,&quot;y&quot;:&quot;360&quot;,&quot;width&quot;:&quot;40&quot;,&quot;height&quot;:&quot;20&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;de50YbNh&quot;:{&quot;id&quot;:&quot;de50YbNh&quot;,&quot;value&quot;:&quot;否&quot;,&quot;style&quot;:&quot;text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];autosize=1;&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;770&quot;,&quot;y&quot;:&quot;240&quot;,&quot;width&quot;:&quot;40&quot;,&quot;height&quot;:&quot;20&quot;,&quot;as&quot;:&quot;geometry&quot;}},&quot;8DogO6fS&quot;:{&quot;id&quot;:&quot;8DogO6fS&quot;,&quot;value&quot;:&quot;否&quot;,&quot;style&quot;:&quot;text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];autosize=1;&quot;,&quot;vertex&quot;:&quot;1&quot;,&quot;parent&quot;:&quot;JshK4DVV&quot;,&quot;-0-mxGeometry&quot;:{&quot;x&quot;:&quot;760&quot;,&quot;y&quot;:&quot;390&quot;,&quot;width&quot;:&quot;40&quot;,&quot;height&quot;:&quot;20&quot;,&quot;as&quot;:&quot;geometry&quot;}}},&quot;mxCellList&quot;:[&quot;qjiNImIL&quot;,&quot;JshK4DVV&quot;,&quot;ALwC5ZBF&quot;,&quot;JJvTNGGv&quot;,&quot;HerNl4Am&quot;,&quot;AzImFBqq&quot;,&quot;1tnUQpLf&quot;,&quot;Rz0Vnx00&quot;,&quot;a4ttJ9li&quot;,&quot;ipVMooqw&quot;,&quot;egs1h4iP&quot;,&quot;kQtnq2G9&quot;,&quot;3fGUT9DD&quot;,&quot;V80viOhd&quot;,&quot;adkWaAlq&quot;,&quot;txJ7EXgl&quot;,&quot;SnIyUNHO&quot;,&quot;dcianNJl&quot;,&quot;jc1g9pHF&quot;,&quot;QRs31Xv7&quot;,&quot;yump7Jj5&quot;,&quot;pvM7y1Qi&quot;,&quot;MikdKlim&quot;,&quot;jqaGcsh4&quot;,&quot;pbEfD5m8&quot;,&quot;xunMzPAw&quot;,&quot;6p0yqPY1&quot;,&quot;jyyqNEWR&quot;,&quot;P1lA33A0&quot;,&quot;hBl2D1xZ&quot;,&quot;de50YbNh&quot;,&quot;8DogO6fS&quot;]},&quot;lastEditTime&quot;:0,&quot;snapshot&quot;:&quot;&quot;}" />

<span id="116e81cb"></span>
## 支持模型选型
全量支持工具调用的模型，请参见[工具调用能力](https://www.volcengine.com/docs/82379/1330310#98fee2f1)。
基于效果/准确性和时延的权衡原则，推荐选型建议如下：

1. **效果优先型（高准确性，时延较高）**
* **doubao-seed-1-6-thinking-250615** ：强制开启思考模式，不可关闭，专注于 **Coding、Math 和逻辑推理** 任务，在基础能力上显著优于前代模型（如 doubao-1-5-thinking-pro），适用于高准确性要求的复杂场景。
* **doubao-seed-1-6-250615** ：默认开启深度思考模式（支持 auto/thinking/non-thinking），具有自适应思考机制（根据问题难度自动开关思考），适用于通用场景，尤其在 **非思考模式下效果大幅提升** 。
* **deepseek-v3-250324**：在**数学推理**和**代码生成**场景超越GPT-4.5，支持HTML前端任务的高可用性代码生成。
* **deepseek-r1-250528**：通过强化学习优化参数生成，在**多步骤工具调用**场景中表现优异，需配合系统提示干预参数幻觉。（参考文末FAQ部分）
2. **时延优先型（快速响应，效果相对宽松）**
* **doubao-seed-1-6-flash-250615** ：适用于延迟敏感场景（如实时控制或高速调用），文本理解能力超上一代 lite 模型，且视觉理解比肩旗舰模型。
* **doubao-1-5-lite-32k-250115**：平均响应时延**降低40%** ，适用于智能客服、实时控制等场景，支持并行工具调用。

<span id="45418967"></span>
## 使用流程
<span id="510a844f"></span>
### 环境准备
调用方舟模型前，需先进行权限配置获取API Key并配置到环境变量。若通过火山引擎官方SDK或OpenAI SDK调用，需提前安装对应SDK，方舟已提供Go、Python、Java的SDK，便于快速集成模型服务。
环境配置参考:

* [获取 API Key 并配置](https://www.volcengine.com/docs/82379/1541594)
* [安装及升级 SDK](https://www.volcengine.com/docs/82379/1541595)

* [获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) 。
   * 使用 Access Key 鉴权请参考[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
* [开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需 Model ID 。
   * 通过 Endpoint ID 调用模型服务请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。



<span id="db7321a0"></span>
### 基本使用流程
<span id="4bf7add8"></span>
#### 步骤 1：定义工具
通过 `tools` 字段向模型描述可用工具，支持 JSON 格式，包含工具名称、描述、参数定义等信息。
**定义工具函数**
```Python
def get_current_weather(location, unit="摄氏度"):
    # 实际调用天气查询 API 的逻辑
    # 此处为示例，返回模拟的天气数据
    return f"{location}今天天气晴朗，温度 25 {unit}。"
```


* 代码中定义了一个名为 `get_current_weather` 的工具函数，用于获取指定地点的天气信息。
   * `location`：必需的参数，表示地点。
   * `unit`：可选参数，默认值为 `摄氏度`，表示温度单位。
* 函数内部目前只是返回模拟的天气数据，实际应用中需要调用真实的天气查询 API。

**定义 Tools**
```Python
{
  "type": "function",
  "function": {
    "name": "get_current_weather",
    "description": "获取指定地点的天气信息，支持摄氏度和华氏度两种单位",
    "parameters": {
      "type": "object",
      "properties": {
        "location": {
          "type": "string",
          "description": "地点的位置信息，例如北京、上海"
        },
        "unit": {
          "type": "string",
          "enum": ["摄氏度", "华氏度"],
          "description": "温度单位，可选值为摄氏度或华氏度"
        }
      },
      "required": ["location"]
    }
  }
}
```


* `tools` 是一个列表，其中每个元素代表一个工具。这里定义了一个名为 `get_current_weather` 的工具。
* `type`：工具的类型，这里是 `function`，表示这是一个工具调用工具。
* `function`：包含工具的详细信息，如名称、描述和参数。
   * `name`：工具的名称，即 `get_current_weather`。
   * `description`：工具的描述，说明该工具用于获取指定地点的天气信息。
   * `parameters`：工具所需的参数，这里是一个对象，包含 `location` 和 `unit` 两个属性。
      * `location`：地点的位置信息，是一个字符串类型的参数。
      * `unit`：温度单位，是一个字符串类型的参数，可选值为 `摄氏度` 或 `华氏度`。
      * `required`：指定必需的参数，这里只有 `location` 是必需的。

更多关于工具构造相关的规范和注意事项，请参见 [附1：工具参数构造规范](https://www.volcengine.com/docs/82379/1262342#4d571c97)。
<span id="5bc0af5c"></span>
#### 步骤 2：发起模型请求
在请求中包含用户问题和工具定义，模型会根据需求返回需要调用的工具及参数。
```Python
from volcenginesdkarkruntime import Ark

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')
# 初始化Ark客户端
client = Ark(
    api_key = api_key,
)

//用户问题 
messages = [
    {"role": "user", "content": "北京今天的天气如何？"}
]
tools = [
    {
        //参见步骤1中定义的tools
    }
]
//发起模型请求
completion = client.chat.completions.create(
    # 替换 <MODEL> 为模型的Model ID
    model="<MODEL>",
    messages=messages,
    tools=tools
)
```

<span id="7532befc"></span>
#### 步骤 3：调用外部工具
根据模型返回的工具名称和参数，调用对应的外部工具或 API，获取工具执行结果。
```Python
# 解析模型返回的工具调用信息
tool_call = completion.choices[0].message.tool_calls[0]
# 工具名称
tool_name = tool_call.function.name
#如果判断需要调用查询天气工具，则运行查询天气工具
if tool_name == "get_current_weather":
    # 提取的用户参数
    arguments = json.loads(tool_call.function.arguments)
    # 调用工具
    tool_result = get_current_weather(**arguments)
```


* `tool_calls`：获取模型调用的工具列表。
* 如果工具名称是 `get_current_weather`，则解析工具调用的参数并调用 `get_current_weather` 函数获取工具执行结果。

<span id="7289a843"></span>
#### 步骤 4：回填工具结果并获取最终回复
将工具执行结果以 `role=tool` 的消息形式回填给模型，模型根据结果生成最终回复。
```Python
messages.append(completion.choices[0].message)
messages.append({
    "role": "tool",
    "tool_call_id": tool_call.id,
    "content": tool_result
})

# 再次调用模型获取最终回复
final_completion = client.chat.completions.create(
    model="doubao-1-5-pro-32k-250115",
    messages=messages
)

print(final_completion.choices[0].message.content)
```

<span id="be370b84"></span>
### 完整代码示例

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python - Arkiteck SDK" key="r2KG4n9PBK"><RenderMd content={`<span id="452157dc"></span>
##### （推荐）使用方舟智能体SDK Arkitect
\`\`\`Python
from arkitect.core.component.context.context import Context
from enum import Enum
import asyncio
from pydantic import Field
def get_current_weather(location: str = Field(description="地点的位置信息，例如北京、上海"), unit: str=Field(description="温度单位, 可选值为摄氏度或华氏度")):
    """
    获取指定地点的天气信息
    """
    return f"{location}今天天气晴朗，温度 25 {unit}。"
async def chat_with_tool():
    ctx = Context(
            model="doubao-1-5-pro-32k-250115",
            tools=[
                get_current_weather
            ],  # 直接在这个list里传入你的所有python 方法作为tool，tool的描述会自动带给模型推理，tool的执行在ctx.completions.create 中会自动进行
        )
    await ctx.init()
    completion = await ctx.completions.create(messages=[
        {"role": "user", "content": "北京和上海今天的天气如何？"}
    ],stream =False)
    return completion
completion = asyncio.run(chat_with_tool())
print(completion.choices[0].message.content)
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Python - Ark SDK" key="jVyDCCTEeF"><RenderMd content={`<span id="aa60ad09"></span>
##### 方舟基础SDK
\`\`\`Python
from volcenginesdkarkruntime import Ark
from volcenginesdkarkruntime.types.chat import ChatCompletion
import json
client = Ark()
messages = [
    {"role": "user", "content": "北京和上海今天的天气如何？"}
]
# 步骤1: 定义工具
tools = [{
  "type": "function",
  "function": {
    "name": "get_current_weather",
    "description": "获取指定地点的天气信息",
    "parameters": {
      "type": "object",
      "properties": {
        "location": {
          "type": "string",
          "description": "地点的位置信息，例如北京、上海"
        },
        "unit": {
          "type": "string",
          "enum": ["摄氏度", "华氏度"],
          "description": "温度单位"
        }
      },
      "required": ["location"]
    }
  }
}]
def get_current_weather(location: str, unit="摄氏度"):
    # 实际调用天气查询 API 的逻辑
    # 此处为示例，返回模拟的天气数据
    return f"{location}今天天气晴朗，温度 25 {unit}。"
while True:
    # 步骤2: 发起模型请求，由于模型在收到工具执行结果后仍然可能有工具调用意愿，因此需要多次请求
    completion: ChatCompletion = client.chat.completions.create(
    model="doubao-1-5-pro-32k-250115",
    messages=messages,
    tools=tools
    )
    resp_msg = completion.choices[0].message
    # 展示模型中间过程的回复内容
    print(resp_msg.content)
    if completion.choices[0].finish_reason != "tool_calls":
        # 模型最终总结，没有调用工具意愿
        break
    messages.append(completion.choices[0].message.model_dump())
    tool_calls = completion.choices[0].message.tool_calls
    for tool_call in tool_calls:
        tool_name = tool_call.function.name
        if tool_name == "get_current_weather":
            # 步骤 3：调用外部工具
            args = json.loads(tool_call.function.arguments)
            tool_result = get_current_weather(**args)
            # 步骤 4：回填工具结果，并获取模型总结回复
            messages.append(
                {"role": "tool", "content": tool_result, "tool_call_id": tool_call.id}
            )
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Java" key="YG773gCg4D"><RenderMd content={`\`\`\`Java
package com.example;

import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.volcengine.ark.runtime.model.completion.chat.*;
import com.volcengine.ark.runtime.service.ArkService;

import java.util.*;

public class VolcEngineFunctionCallChat {

    // 用于解析 get_current_weather 函数参数的类
    public static class WeatherArgs {
        @JsonProperty("location")
        private String location;

        @JsonProperty("unit")
        private String unit;

        // Jackson 需要默认构造函数
        public WeatherArgs() {
        }

        public String getLocation() {
            return location;
        }

        public void setLocation(String location) {
            this.location = location;
        }

        public String getUnit() {
            return unit;
        }

        public void setUnit(String unit) {
            this.unit = unit;
        }
    }

    // 用于定义工具函数参数模式的类 (类似于Python中的parameters字典结构)
    public static class FunctionParameterSchema {
        public String type;
        public Map<String, Object> properties;
        public List<String> required;

        public FunctionParameterSchema(String type, Map<String, Object> properties, List<String> required) {
            this.type = type;
            this.properties = properties;
            this.required = required;
        }

        public String getType() {
            return type;
        }

        public Map<String, Object> getProperties() {
            return properties;
        }

        public List<String> getRequired() {
            return required;
        }
    }

    private static final ObjectMapper objectMapper = new ObjectMapper();

    // 工具函数实现: get_current_weather
    public static String getCurrentWeather(String location, String unit) {
        // 此处应为实际调用天气查询 API 的逻辑
        // 这里是示例，返回模拟的天气数据
        String currentUnit = (unit == null || unit.isEmpty()) ? "摄氏度" : unit;
        System.out.println(String.format("调用工具 get_current_weather: location=%s, unit=%s", location, currentUnit));
        return String.format("%s今天天气晴朗，温度 25 %s。", location, currentUnit);
    }

    public static void main(String[] args) {
        String apiKey = System.getenv("ARK_API_KEY");

        if (apiKey == null || apiKey.isEmpty()) {
            System.err.println("错误: ARK_API_KEY 环境变量未设置。");
            return;
        }

        ArkService service = ArkService.builder()
                .apiKey(apiKey)
                .build();

        List<ChatMessage> messages = new ArrayList<>();
        messages.add(ChatMessage.builder().role(ChatMessageRole.USER).content("北京和上海今天的天气如何？").build());

        // 步骤 1: 定义工具
        Map<String, Object> locationProperty = new HashMap<>();
        locationProperty.put("type", "string");
        locationProperty.put("description", "地点的位置信息，例如上海，北京");

        Map<String, Object> unitProperty = new HashMap<>();
        unitProperty.put("type", "string");
        unitProperty.put("enum", Arrays.asList("摄氏度", "华氏度"));
        unitProperty.put("description", "温度单位");

        Map<String, Object> schemaProperties = new HashMap<>();
        schemaProperties.put("location", locationProperty);
        schemaProperties.put("unit", unitProperty);

        FunctionParameterSchema functionParams = new FunctionParameterSchema(
                "object",
                schemaProperties,
                Collections.singletonList("location") // 'location' 是必需参数
        );

        List<ChatTool> tools = Collections.singletonList(
                new ChatTool(
                        "function", // 工具类型
                        new ChatFunction.Builder()
                                .name("get_current_weather")
                                .description("获取指定地点的天气信息")
                                .parameters(functionParams) // 工具函数的参数模式
                                .build()));

        String modelId = "doubao-1-5-pro-32k-250115";

        while (true) {
            // 步骤 2: 发起模型请求
            ChatCompletionRequest request = ChatCompletionRequest.builder()
                    .model(modelId)
                    .messages(messages)
                    .tools(tools)
                    .build();

            ChatCompletionResult completionResult;
            try {
                completionResult = service.createChatCompletion(request);
            } catch (Exception e) {
                System.err.println("调用 Ark API 时发生错误: " + e.getMessage());
                e.printStackTrace();
                break;
            }

            if (completionResult == null || completionResult.getChoices() == null
                    || completionResult.getChoices().isEmpty()) {
                System.err.println("从模型收到空的或无效的响应。");
                break;
            }

            ChatCompletionChoice choice = completionResult.getChoices().get(0);
            ChatMessage responseMessage = choice.getMessage();

            // 展示模型中间过程的回复内容
            System.out.println("模型回复: " + responseMessage.stringContent());

            // 将模型的回复（含工具调用请求）添加到消息历史中
            messages.add(responseMessage);
            if (choice.getFinishReason() == null || !"tool_calls".equalsIgnoreCase(choice.getFinishReason())) {
                // 模型最终总结，没有调用工具意愿，或者发生错误等其他终止原因
                break;
            }

            List<ChatToolCall> toolCalls = responseMessage.getToolCalls();
            if (toolCalls == null || toolCalls.isEmpty()) {
                // 如果 finish_reason 是 "tool_calls"，但 toolCalls 为空，这可能是一个异常情况
                System.err.println("警告: Finish reason 是 'tool_calls' 但未在消息中找到 tool_calls。");
                break;
            }

            for (ChatToolCall toolCall : toolCalls) {
                String toolName = toolCall.getFunction().getName();
                if ("get_current_weather".equals(toolName)) {
                    // 步骤 3：调用外部工具
                    String argumentsJson = toolCall.getFunction().getArguments();
                    WeatherArgs tool_args;
                    try {
                        tool_args = objectMapper.readValue(argumentsJson, WeatherArgs.class);
                    } catch (JsonProcessingException e) {
                        System.err.println("解析 get_current_weather 参数时出错: " + argumentsJson + " - " + e.getMessage());
                        // 将错误信息作为工具结果回填
                        messages.add(ChatMessage.builder()
                                .role(ChatMessageRole.TOOL)
                                .content("解析参数时出错: " + e.getMessage())
                                .toolCallId(toolCall.getId())
                                .build());
                        continue;
                    }

                    String toolResult = getCurrentWeather(tool_args.getLocation(), tool_args.getUnit());
                    System.out.println("工具执行结果 (" + toolCall.getId() + "): " + toolResult);

                    // 步骤 4：回填工具结果，并获取模型总结回复
                    messages.add(ChatMessage.builder()
                            .role(ChatMessageRole.TOOL)
                            .content(toolResult)
                            .toolCallId(toolCall.getId()) // 关联工具调用 ID
                            .build());
                }
            }
        }

        service.shutdownExecutor();
        System.out.println("\n会话结束。");
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Golang" key="AY6LlNbGnJ"><RenderMd content={`\`\`\`Go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "os"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

type WeatherArgs struct {
    Location string \`json:"location"\`
    Unit     string \`json:"unit,omitempty"\` // omitempty 允许 unit 为可选
}

// 目标工具
func getCurrentWeather(location string, unit string) string {
    if unit == "" {
        unit = "摄氏度" // 默认单位
    }
    // 此处为示例，返回模拟的天气数据
    return fmt.Sprintf("%s今天天气晴朗，温度 25 %s。", location, unit)
}

func main() {
    // 从环境变量中获取 API Key，请确保已设置 ARK_API_KEY
    apiKey := os.Getenv("ARK_API_KEY")
    if apiKey == "" {
        fmt.Println("错误：请设置 ARK_API_KEY 环境变量。")
        return
    }

    client := arkruntime.NewClientWithApiKey(
        apiKey,
    )

    ctx := context.Background()

    // 初始化消息列表
    messages := []*model.ChatCompletionMessage{
        {
            Role: model.ChatMessageRoleUser,
            Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("北京和上海今天的天气如何？"),
            },
        },
    }

    // 步骤 1: 定义工具
    tools := []*model.Tool{
        {
            Type: model.ToolTypeFunction,
            Function: &model.FunctionDefinition{
                Name:        "get_current_weather",
                Description: "获取指定地点的天气信息",
                Parameters: map[string]interface{}{
                    "type": "object",
                    "properties": map[string]interface{}{
                        "location": map[string]interface{}{
                            "type":        "string",
                            "description": "地点的位置信息，例如北京、上海",
                        },
                        "unit": map[string]interface{}{
                            "type": "string",
                            "enum": []string{
                                "摄氏度",
                                "华氏度",
                            },
                            "description": "温度单位",
                        },
                    },
                    "required": []string{"location"},
                },
            },
        },
    }

    for {
        // 步骤 2: 发起模型请求
        req := model.CreateChatCompletionRequest{
            Model:    "doubao-1-5-pro-32k-250115", // 与 Python 版本一致的模型
            Messages: messages,
            Tools:    tools,
        }

        resp, err := client.CreateChatCompletion(ctx, req)
        if err != nil {
            fmt.Printf("模型请求错误: %v\n", err)
            return
        }

        if len(resp.Choices) == 0 {
            fmt.Println("模型未返回任何 choice。")
            return
        }

        respMsg := resp.Choices[0].Message

        // 展示模型中间过程的回复内容 (如果存在)
        if respMsg.Content.StringValue != nil && *respMsg.Content.StringValue != "" {
            fmt.Println("模型回复:", *respMsg.Content.StringValue)
        }

        if resp.Choices[0].FinishReason != model.FinishReasonToolCalls || len(respMsg.ToolCalls) == 0 {
            break
        }

        // 将模型的回复（包含工具调用请求）添加到消息历史中
        messages = append(messages, &respMsg)

        for _, toolCall := range respMsg.ToolCalls {
            fmt.Printf("模型尝试调用工具: %s, ID: %s\n", toolCall.Function.Name, toolCall.ID)
            fmt.Println("  参数:", toolCall.Function.Arguments)

            var toolResult string
            if toolCall.Function.Name == "get_current_weather" {
                // 步骤 3：调用外部工具
                var args WeatherArgs
                err := json.Unmarshal([]byte(toolCall.Function.Arguments), &args)
                if err != nil {
                    fmt.Printf("解析工具参数错误 (%s): %v\n", toolCall.Function.Name, err)
                    toolResult = fmt.Sprintf("解析参数失败: %v", err)
                } else {
                    toolResult = getCurrentWeather(args.Location, args.Unit)
                    fmt.Println("  工具执行结果:", toolResult)
                }

                // 步骤 4：回填工具结果
                messages = append(messages, &model.ChatCompletionMessage{
                    Role:       model.ChatMessageRoleTool,
                    Content:    &model.ChatCompletionMessageContent{StringValue: volcengine.String(toolResult)},
                    ToolCallID: toolCall.ID,
                })
            }
        }
        fmt.Println("--- 下一轮对话 ---")
    }
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="fa127cf4"></span>
## 推荐配置与优化
<span id="cacc0aa8"></span>
### 新业务接入 

1. 推荐优选`doubao-seed-1.6`系列模型。 
   1. FC场景下，关闭 thinking 会提高效率，具体操作请参见[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa)。
   2. 对速度有较高要求，可以选择 `doubao-seed-1-6-flash-******`模型。
2. 准备评测集，在FC模型测试，看看准确率，以及业务预期上线准确率。 
3. 常规调优手段： 
   1. Functions的params、description等字段准确填写。 System prompt中不用再重复介绍函数，（可选）可以描述在何种情况下调用某函数 
   * 优化函数、参数的描述， 明确不同函数的边界情况； 避免歧义；增加示例等。 
   * 对模型进行sft（建议至少50条数据，模型越多、参数越多、情况越多，则所需要的数据越多），见[精调优化](https://www.volcengine.com/docs/82379/1262342#f118e5a2)。  
4. 速度优化： 对于简单无歧义的函数或参数，适当精简输入输出内容。 

<span id="67406164"></span>
### prompt最佳实践 
 原则： Treat LLM as a kid 

1. 能不用大模型完成的任务，就不要调用大模型，尽量代码完成。 
2. 和任务无关的信息，避免输入，避免信息干扰。 


| | | | | \
|类别  |问题  |错误示例  |改正后示例  |
|---|---|---|---|
| | | | | \
|函数  |命名不规范、描述不规范  |```Go |\
| | |{ |\
| | |   "type": "function", |\
| | |    "function": { |\
| | |        "name": "GPT1", |\
| | |        "description": "新建日程", |\
| | |     } |\
| | |} |\
| | |``` |\
| | | |```Go |\
| | | |{ |\
| | | |   "type": "function", |\
| | | |    "function": { |\
| | | |        "name": "CreateEvent", |\
| | | |        "description": "当需要为用户新建日程时，此工具将创建日程，并返回日程ID", |\
| | | |     } |\
| | | |} |\
| | | |``` |\
| | | | |
|^^| | | | \
| |  |  |  |
| | | | | \
|参数  |\
|  |避免不必要的复杂格式（或嵌套）  |\
| |  |```Go |\
| | |{ |\
| | |    "time": { |\
| | |        "type": "object", |\
| | |        "description": "事件时间", |\
| | |        "properties": { |\
| | |            "timestamp": { |\
| | |                "description": "事件时间" |\
| | |            } |\
| | |        } |\
| | |    } |\
| | |} |\
| | |``` |\
| | | |```Go |\
| | | |{ |\
| | | |    "time": { |\
| | | |        "type": "string", |\
| | | |        "description": "事件时间", |\
| | | |    } |\
| | | |} |\
| | | |``` |\
| | | | |\
| | | |  |
|^^| | | | \
| |避免固定值  |\
| |  |```Go |\
| | |{ |\
| | |    "time": { |\
| | |        "type": "object", |\
| | |        "description": "事件时间", |\
| | |        "properties": { |\
| | |            "timestamp": { |\
| | |                "description": "固定传2024-01-01即可" |\
| | |            } |\
| | |        } |\
| | |    } |\
| | |} |\
| | |``` |\
| | | |既然参数值固定，删去该参数，由代码处理。  |
| | | | | \
|业务流程  |\
|  |尽量缩短LLM调用轮次  |\
| |  |System prompt:  |\
| | |```Go |\
| | |你正在与用户Alan沟通，你需要先查询用户ID，再通过ID创建日程…… |\
| | |``` |\
| | | |System prompt:  |\
| | | |```Go |\
| | | |你正在与用户Alan（ID=abc123）沟通，你可以通过ID创建日程…… |\
| | | |``` |\
| | | | |
|^^| | | | \
| |歧义消解  |System prompt:  |\
| | |```Go |\
| | |可以通过ID查找用户，并获得用户的日程ID |\
| | |``` |\
| | | |\
| | |这里两个ID未明确，模型可能会混用  |System prompt:  |\
| | | |```Go |\
| | | |每个用户具有唯一的用户ID；每个日程有对应的日程ID，两者独立的ID。 |\
| | | |可以通过用户ID查找用户，并获得用户的所有日程ID |\
| | | |``` |\
| | | | |\
| | | |  |

<span id="4392ae8d"></span>
### 工具调用异常处理
JSON 格式容错机制：对于轻微不合法的 JSON 格式，可尝试使用 `json-repair` 库进行容错修复。
```Python
import json_repair

invalid_json = '{"location": "北京", "unit": 摄氏度}'
valid_json = json_repair.loads(invalid_json)
```

<span id="83f100d2"></span>
### 需求澄清
需求澄清（确认需求），不依赖与FC，可独立使用。
可在 System prompt 中加入：
```Python
如果用户没有提供足够的信息来调用函数，请继续提问以确保收集到了足够的信息。
在调用函数之前，你必须总结用户的描述并向用户提供总结，询问他们是否需要进行任何修改。
......
```

在函数的 description 中加入：
```Python
函数参数除了提取a和b， 还应要求用户提供c、d、e、f和其他相关细节。
```

或在系统提示中加入参数校验逻辑，当模型生成的参数缺失时，引导模型重新生成完整的参数。
```Python
如果用户提供的信息缺少工具所需要的必填参数，你需要进一步追问让用户提供更多信息。
```

<span id="ba983529"></span>
### 流式输出适配 
从 Doubao-1.5 系列模型开始支持流式输出，逐步获取工具调用信息，提升响应效率。
详见[Function Calling 流式输出适配](https://www.volcengine.com/docs/82379/1449722)。
```Python
def function_calling_stream():
    completion = client.chat.completions.create(
        model="doubao-1-5-pro-32k-250115",
        messages=messages,
        tools=tools,
        stream=True
    )
    for chunk in completion:
        if chunk.choices[0].delta.tool_calls:
            tool_call = chunk.choices[0].delta.tool_calls[0]
            print(f"工具名称：{tool_call.function.name}，参数：{tool_call.function.arguments}")

function_calling_stream()
```

<span id="d2710459"></span>
### 多轮工具调用
当用户需求需要多次调用工具时，维护对话历史上下文，逐轮处理工具调用和结果回填。
<span id="678ddf3e"></span>
#### 示例流程

1. **用户提问**：“查询北京的天气，并将结果发送给张三”。
2. **第一轮**：模型调用 `get_current_weather` 工具获取北京天气。
3. **第二轮**：模型调用 `send_message` 工具将天气结果发送给张三。
4. **第三轮**：模型总结任务完成情况，返回最终回复。

<span id="23f67db1"></span>
#### 代码示例 
:::tip
多轮Function Calling：指用户query需要多次调用工具和大模型才能完成的情况， 是多轮对话的子集。 
:::
调用Response细节图： 
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/71d9c354a2db4bd8a1959f43043cb944~tplv-goo7wpa0wc-image.image =2018x)

<span id="54f334fa"></span>
##### Golang 
```Go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "os"
    "strings"

    "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
    "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
    "github.com/volcengine/volcengine-go-sdk/volcengine"
)

func main() {
    client := arkruntime.NewClientWithApiKey(
       os.Getenv("ARK_API_KEY"),
       arkruntime.WithBaseUrl("${BASE_URL}"),
    )

    fmt.Println("----- function call mulstiple rounds request -----")
    ctx := context.Background()
    // Step 1: send the conversation and available functions to the model
    req := model.CreateChatCompletionRequest{
       Model: "${Model_ID}",
       Messages: []*model.ChatCompletionMessage{
          {
             Role: model.ChatMessageRoleSystem,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("你是豆包，是由字节跳动开发的 AI 人工智能助手"),
             },
          },
          {
             Role: model.ChatMessageRoleUser,
             Content: &model.ChatCompletionMessageContent{
                StringValue: volcengine.String("上海的天气怎么样？"),
             },
          },
       },
       Tools: []*model.Tool{
          {
             Type: model.ToolTypeFunction,
             Function: &model.FunctionDefinition{
                Name:        "get_current_weather",
                Description: "Get the current weather in a given location",
                Parameters: map[string]interface{}{
                   "type": "object",
                   "properties": map[string]interface{}{
                      "location": map[string]interface{}{
                         "type":        "string",
                         "description": "The city and state, e.g. Beijing",
                      },
                      "unit": map[string]interface{}{
                         "type":        "string",
                         "description": "枚举值有celsius、fahrenheit",
                      },
                   },
                   "required": []string{
                      "location",
                   },
                },
             },
          },
       },
    }
    resp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
       fmt.Printf("chat error: %v\n", err)
       return
    }
    // extend conversation with assistant's reply
    req.Messages = append(req.Messages, &resp.Choices[0].Message)
    
    // Step 2: check if the model wanted to call a function.
    // The model can choose to call one or more functions; if so,
    // the content will be a stringified JSON object adhering to
    // your custom schema (note: the model may hallucinate parameters).
    for _, toolCall := range resp.Choices[0].Message.ToolCalls {
       fmt.Println("calling function")
       fmt.Println("    id:", toolCall.ID)
       fmt.Println("    name:", toolCall.Function.Name)
       fmt.Println("    argument:", toolCall.Function.Arguments)
       functionResponse, err := CallAvailableFunctions(toolCall.Function.Name, toolCall.Function.Arguments)
       if err != nil {
          functionResponse = err.Error()
       }
       // extend conversation with function response
       req.Messages = append(req.Messages,
          &model.ChatCompletionMessage{
             Role:       model.ChatMessageRoleTool,
             ToolCallID: toolCall.ID,
             Content: &model.ChatCompletionMessageContent{
                StringValue: &functionResponse,
             },
          },
       )
    }
    // get a new response from the model where it can see the function response
    secondResp, err := client.CreateChatCompletion(ctx, req)
    if err != nil {
       fmt.Printf("second chat error: %v\n", err)
       return
    }
    fmt.Println("conversation", MustMarshal(req.Messages))
    fmt.Println("new message", MustMarshal(secondResp.Choices[0].Message))
}
func CallAvailableFunctions(name, arguments string) (string, error) {
    if name == "get_current_weather" {
       params := struct {
          Location string `json:"location"`
          Unit     string `json:"unit"`
       }{}
       if err := json.Unmarshal([]byte(arguments), &params); err != nil {
          return "", fmt.Errorf("failed to parse function call name=%s arguments=%s", name, arguments)
       }
       return GetCurrentWeather(params.Location, params.Unit), nil
    } else {
       return "", fmt.Errorf("got unavailable function name=%s arguments=%s", name, arguments)
    }
}

// GetCurrentWeather get the current weather in a given location.
// Example dummy function hard coded to return the same weather.
// In production, this could be your backend API or an external API
func GetCurrentWeather(location, unit string) string {
    if unit == "" {
       unit = "celsius"
    }
    switch strings.ToLower(location) {
    case "beijing":
       return `{"location": "Beijing", "temperature": "10", "unit": unit}`
    case "北京":
       return `{"location": "Beijing", "temperature": "10", "unit": unit}`
    case "shanghai":
       return `{"location": "Shanghai", "temperature": "23", "unit": unit})`
    case "上海":
       return `{"location": "Shanghai", "temperature": "23", "unit": unit})`
    default:
       return fmt.Sprintf(`{"location": %s, "temperature": "unknown"}`, location)
    }
}
func MustMarshal(v interface{}) string {
    b, _ := json.Marshal(v)
    return string(b)
}
```

<span id="0817d046"></span>
##### Python 
```Python
from volcenginesdkarkruntime import Ark
import time
client = Ark(
    base_url="${BASE_URL}",
)

print("----- function call mulstiple rounds request -----")
messages = [
    {
        "role": "system",
        "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手",
    },
    {
        "role": "user",
        "content": "北京今天的天气",
    },
]
req = {
    "model": "${YOUR_ENDPOINT_ID}",
    "messages": messages,
    "temperature": 0.8,
    "tools": [
        {
            "type": "function",
            "function": {
                "name": "MusicPlayer",
                "description": """歌曲查询Plugin，当用户需要搜索某个歌手或者歌曲时使用此plugin，给定歌手，歌名等特征返回相关音乐。\n 例子1：query=想听孙燕姿的遇见， 输出{"artist":"孙燕姿","song_name":"遇见","description":""}""",
                "parameters": {
                    "properties": {
                        "artist": {"description": "表示歌手名字", "type": "string"},
                        "description": {
                            "description": "表示描述信息",
                            "type": "string",
                        },
                        "song_name": {
                            "description": "表示歌曲名字",
                            "type": "string",
                        },
                    },
                    "required": [],
                    "type": "object",
                },
            },
        },
        {
            "type": "function",
            "function": {
                "name": "get_current_weather",
                "description": "",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "地理位置，比如北京市",
                        },
                        "unit": {"type": "string", "description": "枚举值 [摄氏度,华氏度]"},
                    },
                    "required": ["location"],
                },
            },
        },
    ],
}

ts = time.time()
completion = client.chat.completions.create(**req)
if completion.choices[0].message.tool_calls:
    print(
        f"Bot [{time.time() - ts:.3f} s][Use FC]: ",
        completion.choices[0].message.tool_calls[0],
    )
    # ========== 补充工具调用的结果 =========
    req["messages"].extend(
        [
            completion.choices[0].message.dict(),
             {
                "role": "tool",
                "tool_call_id": completion.choices[0].message.tool_calls[0].id,
                "content": "北京天气晴，24~30度",  # 根据实际调用函数结果填写，最好用自然语言。
                "name": completion.choices[0].message.tool_calls[0].function.name,
            },
        ]
    )
    # 再请求一次模型，获得总结。 如不需要，也可以省略
    ts = time.time()
    completion = client.chat.completions.create(**req)
    print(
        f"Bot [{time.time() - ts:.3f} s][FC Summary]: ",
        completion.choices[0].message.content,
    )
```

<span id="1472b448"></span>
##### Java 
```Java
package com.volcengine.ark.runtime;

import com.volcengine.ark.runtime.model.completion.chat.*;
import com.volcengine.ark.runtime.service.ArkService;
import okhttp3.ConnectionPool;
import okhttp3.Dispatcher;

import java.util.*;
import java.util.concurrent.TimeUnit;

public class FunctionCallChatCompletionsExample {
    static String apiKey = System.getenv("ARK_API_KEY");
    static ConnectionPool connectionPool = new ConnectionPool(5, 1, TimeUnit.SECONDS);
    static Dispatcher dispatcher = new Dispatcher();
    static ArkService service = ArkService.builder().dispatcher(dispatcher).connectionPool(connectionPool).baseUrl("${BASE_URL}").apiKey(apiKey).build();

    public static void main(String[] args) {
        System.out.println("\n----- function call mulstiple rounds request -----");
        final List<ChatMessage> messages = new ArrayList<>();
        final ChatMessage userMessage = ChatMessage.builder().role(ChatMessageRole.USER).content("北京今天天气如何？").build();
        messages.add(userMessage);

        final List<ChatTool> tools = Arrays.asList(
                new ChatTool(
                        "function",
                        new ChatFunction.Builder()
                                .name("get_current_weather")
                                .description("获取给定地点的天气")
                                .parameters(new Weather(
                                        "object",
                                        new HashMap<String, Object>() {{
                                            put("location", new HashMap<String, String>() {{
                                                put("type", "string");
                                                put("description", "T地点的位置信息，比如北京");
                                            }});
                                            put("unit", new HashMap<String, Object>() {{
                                                put("type", "string");
                                                put("description", "枚举值有celsius、fahrenheit");
                                            }});
                                        }},
                                        Collections.singletonList("location")
                                ))
                                .build()
                )
        );

        ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                .model("${YOUR_ENDPOINT_ID}")
                .messages(messages)
                .tools(tools)
                .build();

        ChatCompletionChoice choice = service.createChatCompletion(chatCompletionRequest).getChoices().get(0);
        messages.add(choice.getMessage());
        choice.getMessage().getToolCalls().forEach(
                toolCall -> {
                messages.add(ChatMessage.builder().role(ChatMessageRole.TOOL).toolCallId(toolCall.getId()).content("北京天气晴，24~30度").name(toolCall.getFunction().getName()).build());
        });
        ChatCompletionRequest chatCompletionRequest2 = ChatCompletionRequest.builder()
                .model("${YOUR_ENDPOINT_ID}")
                .messages(messages)
                .build();

        service.createChatCompletion(chatCompletionRequest2).getChoices().forEach(System.out::println);

        // shutdown service
        service.shutdownExecutor();
    }

    public static class Weather {
        public String type;
        public Map<String, Object> properties;
        public List<String> required;

        public Weather(String type, Map<String, Object> properties, List<String> required) {
            this.type = type;
            this.properties = properties;
            this.required = required;
        }

        public String getType() {
            return type;
        }

        public void setType(String type) {
            this.type = type;
        }

        public Map<String, Object> getProperties() {
            return properties;
        }

        public void setProperties(Map<String, Object> properties) {
            this.properties = properties;
        }

        public List<String> getRequired() {
            return required;
        }

        public void setRequired(List<String> required) {
            this.required = required;
        }
    }

}
```

<span id="3fdf8e62"></span>
#### 响应示例 
```Python
========== Round 1 ==========
user: 先查询北京的天气，如果是晴天微信发给Alan，否则发给Peter...

assistant [FC Response]:
name=GetCurrentWeather, args={"location": "\u5317\u4eac"} 
[elpase=2.607 s]
========== Round 2 ==========
tool: 北京今天20~24度，天气：阵雨。...

assistant [FC Response]:
name=SendMessage, args={"content": "\u4eca\u5929\u5317\u4eac\u7684\u5929\u6c14", "receiver": "Peter"} 
[elpase=3.492 s]
========== Round 3 ==========
tool: 成功发送微信消息至Peter...

assistant [Final Answer]:
好的，请问还有什么可以帮助您？ 
[elpase=0.659 s]
```

<span id="ff6e0fcb"></span>
#### 多轮输出注意事项

1. **轮次输出顺序**

触发工具调用时，系统先输出`content`给用户，再生成`tool_calls`并结束当前输出；**当前轮次内容不可依赖工具结果**，后续指令需待工具返回`message`后执行。 

2. **多轮输出响应完整性**

严格遵循`assistant（含tool_calls）→ tool（含message）→ assistant`的顺序，禁止跳过`tool message`响应直接发送新的`assistant`消息。每次`tool_calls`需对应`tool`角色的 `message`（含成功/错误结果），缺失可能因`prefill`机制触发重复调用或流程中断。
<span id="f118e5a2"></span>
### 精调优化
如果 Function Calling 效果未达预期，可通过精调（SFT）提升模型表现。
详情请参见[创建模型精调任务](https://www.volcengine.com/docs/82379/1099459)。
<span id="94d88ded"></span>
#### 精调场景

* 提高工具选择的准确性，确保模型在合适的时机调用正确的工具。
* 优化参数提取能力，使模型能够准确解析用户需求并生成正确的工具入参。
* 改善结果总结质量，让模型能够更自然、准确地总结工具执行结果。

<span id="27cf081f"></span>
#### 精调样本格式
```SQL

{
  "messages": [
    {
      "role": "system",
      "content": "你是豆包AI助手"
    },
    {
      "role": "user",
      "content": "把北京的天气发给李四"
    },
    {
      "role": "assistant",
      "content": "",
      "tool_calls": [
        {
          "type": "function",
          "function": {
            "name": "get_current_weather",
            "arguments": "{\"location\": \"北京\"}"
          }
        }
      ],
      "loss_weight": 1.0
    },
    {
      "role": "tool",
      "content": "北京今天晴，25摄氏度"
    },
    {
      "role": "assistant",
      "content": "",
      "tool_calls": [
        {
          "type": "function",
          "function": {
            "name": "send_message",
            "arguments": "{\"receiver\": \"李四\", \"content\": \"北京今天晴，25摄氏度\"}"
          }
        }
      ],
      "loss_weight": 1.0
    },
    {
      "role": "tool",
      "content": "消息发送成功"
    },
    {
      "role": "assistant",
      "content": "已将北京的天气信息发送给李四"
    }
  ],
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_current_weather",
        "description": "获取指定地点的天气",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {"type": "string", "description": "地点的位置信息"}
          },
          "required": ["location"]
        }
      }
    }
  ]
}
```

<span id="01ae4b36"></span>
## 常见问题
<span id="aefed659"></span>
### Q：FC & MCP 的核心区别是什么，使用时如何选型？
**核心区别与典型使用场景**

| | | | \
|**维度** |**FC（Function Calling）** |**MCP（Model Context Protocol）** |
|---|---|---|
| | | | \
|**本质** |模型调用外部工具 / 函数的能力（功能扩展） |定义模型与外部系统交互时的上下文管理协议（流程规范） |
| | | | \
|**目标** |弥补模型自身能力不足（如计算、数据查询、操作执行） |标准化交互过程中上下文的传递、解析与状态维护 |
| | | | \
|**核心作用** |实现模型与外部工具的 “能力集成” |确保多轮交互中上下文（如对话历史、参数、状态）的一致性 |
| | | | \
|**协议标准** |厂商自定义格式（如 OpenAI 的 JSON 参数结构） |强制遵循 JSON-RPC 2.0 标准，强调协议统一性 |
| | | | \
|**架构** |直接集成于模型 API，用户定义函数后由模型触发调用 |客户端 - 服务器模式，分离 MCP Host（客户端）与 MCP Server（服务端） |
| | | | \
|**上下文管理** |单次请求 - 响应模式，上下文依赖需开发者自行处理 |支持多轮对话、历史状态维护，适用于长序列依赖任务 |
| | | | \
|**典型使用场景** |外部数据调用与系统操作（如天气查询、复杂运算）；示例：调用天气 API 回复 “东京今日气温” |多轮对话与跨系统上下文管理（如订餐流程、客服对话）；示例：连贯处理订餐菜品与配送地址 |

**两者之间的关系**

* **互补而非互斥：**
   * MCP 可能在流程中包含 FC 的调用逻辑（如定义何时、如何触发工具调用）
   * FC 的输入输出需遵循 MCP 的上下文规范（如参数格式、返回值解析规则）
* **分层协作**：
   * **MCP 解决连接问题**：标准化协议打通数据孤岛，提供基础设施（如整合用户订单数据）。
   * **FC 解决执行问题**：在协议层之上调用具体函数完成任务（如调用库存 API 生成补货建议）。
* **架构定位**：FC 是**能力接口**，MCP 是**交互框架**，二者常结合使用以构建复杂应用（如智能助手同时需要调用工具和管理多轮对话状态）。

**References**

* **MCP 官方协议规范（草案）**：明确协议核心架构、JSON - RPC 消息格式、状态管理机制与安全策略，是接口设计的权威参考。[Model Context Protocol Specification](https://spec.modelcontextprotocol.io/specification/draft/)
* **MCP 社区与生态发展**：介绍 MCP 发展规划，涵盖远程连接支持、沙箱安全机制及多模态扩展等发展计划。[MCP Development Roadmap](https://modelcontextprotocol.io/development/roadmap)

<span id="060c2399"></span>
### **Q：Deepseek R1 模型是否支持并行工具调用？**
**A：暂不支持** **`parallel_tool_calls` 控制字段，该模型默认采用自动触发并行调用**机制，开发者无需额外配置即可实现多工具并行调用。
<span id="6a5f3318"></span>
### **Q：如何处理 Deepseek R1 的参数幻觉问题？**
**A：该模型在复杂参数解析时可能出现嵌套调用异常**（如 `get_weather:{city: get_location()}`），建议通过以下方式干预： 

* 在 `system prompt` 中明确要求**分步调用**（如“请先调用定位工具，再调用天气查询工具”） 
* 使用 **JSON Schema 校验**强制参数格式

<span id="72cd8003"></span>
### Q：如何判断模型是否需要调用工具？
A：模型会根据用户问题和工具定义自主判断，若返回结果中包含 `tool_calls` 字段，则表示需要调用工具；若 `content` 字段有直接回复，则无需调用工具。
<span id="6cde090d"></span>
### Q：支持并行调用多个工具吗？
A：支持并行工具调用，通过设置 `parallel_tool_calls` 参数为 `true`，模型可同时返回多个工具调用信息，提高处理效率。
<span id="e92ed249"></span>
### Q：为什么模型返回的工具参数存在幻觉？
A：这是大模型常见的问题，可通过精调（SFT）优化模型的参数生成能力，或在系统提示中明确参数的格式和范围，减少幻觉现象。
部分模型（特别是Deepseek R1）存在一些参数幻觉问题。 如预期先调用get_location获得城市，再调用get_weather查询，R1模型有概率直接返回get_weather:{city: **get_location()**} 这种嵌套调用， 请在system prompt中进行干预解决，分步完成调用。
<span id="87aee2fb"></span>
### Q：如何处理工具调用失败的情况？
A：将工具失败信息以 `role=tool` 的消息回填给模型，模型会根据错误信息生成相应的回复，例如“抱歉，工具调用失败，请稍后重试。”
通过以上优化，开发者能够更高效地使用 Function Calling 功能，实现大模型与外部工具的深度整合，快速构建智能应用。

<span id="4d571c97"></span>
## 附1：工具参数构造规范
为确保模型正确调用工具功能，需按以下规范构造 `tools` 对象，遵循 JSON Schema 标准。
本文主要讲解如何构造 Function Calling 工具，关于工具的使用请参考[基本使用流程](https://www.volcengine.com/docs/82379/1262342#db7321a0)。
<span id="17410772"></span>
### 总体结构
```JSON
{
  "type": "function",
  "function": {
    "name": "...",          // 函数名称（小写+下划线）
    "description": "...",   // 功能描述
    "parameters": { ... }   // 参数定义（JSON Schema格式）
  }
}
```


* `type`：工具的类型，这里是固定值 `function`，表示这是一个工具调用工具。
* `function`：含函数名称、描述和参数等详细配置。

<span id="a3d99114"></span>
### 字段解释
<span id="7eb52ab1"></span>
#### function 字段

| | | | | \
|**字段** |**类型** |**是否必填** |**说明** |
|---|---|---|---|
| | | | | \
|name |string |是 |函数名称，唯一标识，建议使用小写加下划线 |
| | | | | \
|description |string |是 |函数作用的描述 |
| | | | | \
|parameters |object |是 |函数参数定义，需要符合 JSON Schema 格式 |

<span id="41396457"></span>
#### parameters 字段
`parameters` 须为符合 JSON Schema 格式的对象：
```JSON
{
  "type": "object",
  "properties": {
    "参数名": {
      "type": "string | number | boolean | object | array",
      "description": "参数说明"
    }
  },
  "required": ["必填参数"]
}
```


* `type`：必须是 `"object"`。
* `properties`：列出支持的所有参数名及其类型。
   * `参数名`须为英文字符串，且不能重复。
      * 参数`type`需遵循[json规范](https://json-schema.org/docs)，支持类型包括string、number、boolean、integer、object、array。
      * `required`：指定函数中必填的参数名。
      * 其它参数根据`type`的不同稍有区别，详情请参见下表。


| | | \
|`type`类型 |示例 |
|---|---|
| | | \
|string、integer、number、boolean |略 |\
| | |
| | | \
|object （对象） |\
| |\
|* `description`：简要说明 |\
|* `properties` 描述该对象所有属性 |\
|* `required` 描述必填属性 |\
| |\
| |* 示例1: 查询特点用户画像（根据年龄、性别、婚姻状况等） |\
| | |\
| |```Python |\
| |"person": { |\
| |    "type": "object", |\
| |    "description": "个人特征", |\
| |    "properties": { |\
| |        "age": {"type": "integer", "description": "年龄"}, |\
| |        "gender": {"type": "string", "description": "性别"}, |\
| |        "married": {"type": "boolean", "description": "是否已婚"} |\
| |    }, |\
| |    "required": ["age"], |\
| |} |\
| |``` |\
| | |
| | | \
|array （列表） |\
| |\
|* `description`:简要说明 |\
|* `"items": {"type": ITEM_TYPE}`来表达数组元素的数据类型 |\
| |\
| |* 示例1：文本数组，若干个网页链接 |\
| | |\
| |```Bash |\
| |"url": {                       |\
| |    "type": "array",          |\
| |    "description": "需要解析网页链接,最多3个",               |\
| |    "items": {"type": "string"}  |\
| |``` |\
| | |\
| | |\
| |* 示例2： 二维数组 |\
| | |\
| |```Go |\
| |"matrix": { |\
| |    "type": "array", |\
| |    "description": "需要计算的二维矩阵", |\
| |    "items": {"type": "array", "items": {"type": "number"}}, |\
| |} |\
| |``` |\
| | |\
| | |\
| |* 示例3: 通过array来实现多选 |\
| | |\
| |```JSON |\
| | |\
| |"grade": { |\
| |    "description": "年级, 支持多选", |\
| |    "type": "array", |\
| |    "items": { |\
| |        "type": "string", |\
| |        "description": """枚举值有 |\
| |            "一年级", |\
| |            "二年级", |\
| |            "三年级", |\
| |            "四年级", |\
| |            "五年级", |\
| |            "六年级"。 """, |\
| |    }, |\
| |} |\
| |``` |\
| | |

<span id="3f3944f1"></span>
### 完整示例
```JSON
{
  "type": "function",
  "function": {
    "name": "get_weather",
    "description": "获取指定位置的天气信息",
    "parameters": {
      "type": "object",
      "properties": {
        "location": {
          "type": "string",
          "description": "城市和国家，例如：北京，中国"
        }
      },
      "required": ["location"]
    }
  }
}
```

<span id="8aa9c9ae"></span>
### 注意事项

1. **大小写敏感**：所有字段名、参数名严格区分大小写（建议统一用小写）。
2. **中文处理**：字段名用英文，中文说明置于 `description` 中（如 `location` 的描述为 “城市和国家”）。
3. **Schema 合规性**：`parameters` 必须是有效的 JSON Schema 对象，可通过JSON Schema 校验工具验证。

<span id="5f061853"></span>
### 最佳实践

1. **工具描述核心准则** 
   * 详细说明工具功能、适用场景（及禁用场景）、参数含义与影响、限制条件（如输入长度限制），单工具描述建议3-4句。 
   * 优先完善功能、参数等基础描述，示例仅作为补充（推理模型需谨慎添加）。 
2. **函数设计要点** 
   * **命名与参数**：函数名直观（如`parse_product_info`），参数说明包含格式（如`city: string`）和业务含义（如“目标城市拼音全称”），明确输出定义（如“返回JSON格式天气数据”）。 
   * **系统提示**：通过提示指定调用条件（如“用户询问商品详情时触发`get_product_detail`”）。 
   * **工程化设计**： 
      * 使用枚举类型（如`StatusEnum`）避免无效参数，确保逻辑直观（最小惊讶原则）。 
      * 确保仅凭文档描述，人类可正确调用函数（补充潜在疑问解答）。 
   * **调用优化**： 
      * 已知参数通过火山方舟代码能力隐式传递（如`submit_order`无需重复声明`user_id`）。 
      * 合并固定流程函数（如`query_location`与`mark_location`整合为`query_and_mark_location`）。 
   * **数量与性能**：控制函数数量≤20个，通过火山方舟调试工具迭代函数模式（Schema），复杂场景可使用微调能力提升准确率。




# Responses API 教程
Source: https://www.volcengine.com/docs/82379/1585128
Responses API 是火山方舟最新推出的 API 接口，原生支持高效的上下文管理，不仅延续了 Chat API 的易用性，还结合了更强的智能代理能力。随着大模型技术不断升级，Responses API 为开发各类面向实际行动的应用提供了更灵活的基础，并且支持函数调用等多种扩展能力，非常适合搭建智能助手、自动化工具等场景。
:::tip
此为邀测能力，如需使用，提交[测试申请工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P90002304)。
:::
<span id="96b187cf"></span>
# 前提条件
* [获取 API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) 。
   * 使用 Access Key 鉴权请参考[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
* [开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)。
* 在[模型列表](https://www.volcengine.com/docs/82379/1330310)获取所需 Model ID 。
   * 通过 Endpoint ID 调用模型服务请参考[获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。



<span id="30f9a12b"></span>
# 快速开始

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="vA66NpBCtL"><RenderMd content={`\`\`\`Bash
curl --location 'https://ark.cn-beijing.volces.com/api/v3/responses' \\
--header "Authorization: Bearer \$ARK_API_KEY" \\
--header 'Content-Type: application/json' \\
--data '{
    "model": "doubao-seed-1-6-250615",
    "input": "你好呀。"
}'
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="兼容OpenAI SDK" key="ntuBk8V3n5"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

# 创建一个对话请求
response = client.responses.create(
    model="doubao-seed-1-6-250615",
    input="你好呀。"
)

print(response)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="ee520ebd"></span>
# 支持模型

* doubao-seed-1-6-250615
* doubao-seed-1-6-thinking-250615
* doubao-seed-1-6-flash-250615      

<span id="bb257eee"></span>
# 使用示例
<span id="d12b8266"></span>
## 上下文管理
支持上下文状态管理，默认情况下每个 response 的 input/output 都会持久化存储，后续请求只需传入上一个 response 的 id 就可以接力请求，无需像 Chat API 一样手动维护完整的历史上下文。
:::tip
设置 `"store": true` 即可开启存储功能（默认开启）：

* 最多支持存储 1000 条 item。item 存储满后，您需要通过删除 response id 的方式手动清理 item，否则无法继续进行对话。
* 每条 item 的有效期可通过`expire_at`字段自定义，最长支持 3 天，从创建时开始计时。
* 系统会自动加密存储 `input` 和 `output` 字段的信息。`output` 代表对应轮次模型的返回结果，但不会存储深度思考的思维链内容。
* 所有数据都采用加密方式，确保信息安全和隐私合规。 
* 如果您不想存储信息，可以通过设置 `"store": false` 关闭存储功能。
* store 功能当前不收取费用。
:::
<span id="078f2170"></span>
### 多轮调用
这段代码展示了如何利用 Responses API 实现多轮对话功能。在多轮调用模式下，系统能够自动管理上下文，持续追踪和记忆之前的对话内容，使对话更加连贯自然，大大提升了智能交互体验。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="kEbwsm8JY2"><RenderMd content={`\`\`\`Bash
curl --location 'https://ark.cn-beijing.volces.com/api/v3/responses' \\
--header "Authorization: Bearer $ARK_API_KEY" \\
--header 'Content-Type: application/json' \\
--data '{
    "model": "doubao-seed-1-6-250615",
    "input": "Hi，讲个笑话。"
}'
\`\`\`

\`\`\`Bash
curl --location 'https://ark.cn-beijing.volces.com/api/v3/responses' \\
--header "Authorization: Bearer $ARK_API_KEY" \\
--header 'Content-Type: application/json' \\
--data '{
    "model": "doubao-seed-1-6-250615",
    "previous_response_id":"<id>",
    "input": "这个笑话的笑点在哪？"
}'
\`\`\`

第二次请求需将 curl 命令中的 \`<id>\` 替换为上一次请求返回的 response_id。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="兼容 OpenAI SDK" key="mOYBAIikyf"><RenderMd content={`\`\`\`Python
from openai import OpenAI
import os

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

# 创建第一轮对话请求
response = client.responses.create(
    model="doubao-seed-1-6-250615",
    input="Hi，帮我讲个笑话。"
)
print(response)

# 创建第二轮对话请求
second_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "这个笑话的笑点在哪？"}],
)
print(second_response)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="b0570262"></span>
### 重新生成对话
这段代码展示了 Responses API 中通过灵活调用 previous_response_id 重新生成对话的树状分叉结构，并展示了如何在不同的分支中进行不同的操作。在重新生成对话的场景中，系统能够根据不同的分支条件，灵活地执行多种的操作，从而实现更复杂的对话逻辑。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="兼容 OpenAI SDK" key="dfjTyXxijL"><RenderMd content={`\`\`\`Python
from openai import OpenAI
import os

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

# 创建第一轮对话请求
response = client.responses.create(
    model="doubao-seed-1-6-250615",
    input=[{"role": "user", "content": "你知道余弦相似度的原理吗？"}],
    store=True,  # 设置为True以存储对话
)
print(response)

# 创建第二轮对话请求
second_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "我希望你可以用小学生都能听懂的方式来解释这个问题"}],
    store=True, 
)
print(second_response)

# 重新创建第二轮对话请求
re_second_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "我希望你可以用教授的思考逻辑来解释这个问题"}],
    store=True,  
)
print(re_second_response)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="c1d9cf2e"></span>
### 窗口截断
这段代码展示了如何利用 delete 接口实现 Responses API 的窗口截断的功能，使得程序可以在 response 粒度上管理历史记忆，便于后续进行更复杂的对话。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="兼容 OpenAI SDK" key="fNUPuM8Gpv"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

response = client.responses.create(
    model="doubao-seed-1-6-250615",
    input="讲个谐音梗笑话",
)
print(response)

second_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "讲个有哲理的笑话"}],
)
print(second_response)

third_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    previous_response_id=second_response.id,
    input=[{"role": "user", "content": "讲个冷笑话"}],
)
print(third_response)

deleting_response = client.responses.delete(second_response.id)
print(deleting_response)

fourth_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    previous_response_id=third_response.id,
    input=[{"role": "user", "content": "你刚刚讲了几个笑话？都是关于什么主题的？"}],
)
print(fourth_response)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="30f5992e"></span>
## 上下文缓存
设置`"caching": {"type": "enabled"}`，可以将本轮信息写入缓存。在后续的对话请求中通过`previous_response_id`字段，输入对应请求写入的缓存信息，通过缓存输入超低单价，大幅降低成本。下面的两段代码介绍了前缀缓存和 Session 缓存的用法。关于缓存的更多介绍，包括使用规则、计费等信息，请参见 [上下文缓存(Responses API)](https://www.volcengine.com/docs/82379/1602228)。
<span id="77c5bdca"></span>
### 前缀缓存
您可以预先存储并缓存角色、背景等初始化信息，后续调用模型时无需重复发送此信息给模型，即可自动命中初始化信息的缓存从而加快响应速度并降低使用成本，尤其适用于具有重复提示或标准化开头文本的应用。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="兼容 OpenAI SDK" key="VDofBcduTm"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

response = client.responses.create(
    model="doubao-seed-1-6-250615",
    input=[
            {
             "role": "system", 
             "content": "你是三字经小能手。每次用户输入时，你只能用三个汉字作出回应。用户输入如果是三个字，就用三个字像对对联一样进行匹配回应；如果不是三个字，就将用户输入的意思总结成三个字。无论何时，回复都严格限制为三个字。"
            }
          ],
    extra_body={
        "caching": {"type": "enabled"},
        "thinking":{"type":"disabled"}
    }
)
print(response)

second_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "人之初"}],
    extra_body={
        "thinking":{"type":"disabled"}
    }
)
print(second_response)

third_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "玉不琢"}],
    extra_body={
        "thinking":{"type":"disabled"}
    }
)
print(third_response)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="4cd4a466"></span>
### Session 缓存
Responses API 支持自动储存历史上下文对话并保持缓存，通过调用 previous_response_id 在多轮对话等场景中命中缓存并实现更低的时延和推理成本。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="兼容 OpenAI SDK" key="o6jPc4XfgQ"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

response = client.responses.create(
    model="doubao-seed-1-6-250615",
    input=[
            {
             "role": "system", 
             "content": "你是三字经小能手。每次用户输入时，你只能用三个汉字作出回应。用户输入如果是三个字，就用三个字像对对联一样进行匹配回应；如果不是三个字，就将用户输入的意思总结成三个字。无论何时，回复都严格限制为三个字。"
            },
            {
            "role": "user",
            "content":"人之初"
            }
          ],
    extra_body={
        "caching": {"type": "enabled"},
        "thinking":{"type":"disabled"}
    }
)
print(response)

second_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "下一句"}],
    extra_body={
        "caching": {"type": "enabled"},
        "thinking":{"type":"disabled"}
    }
)
print(second_response)

third_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    previous_response_id=second_response.id,
    input=[{"role": "user", "content": "下一句"}],
    extra_body={
        "caching": {"type": "enabled"},
        "thinking":{"type":"disabled"}
    }
)
print(third_response)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="92b0ce72"></span>
## Instructions
这段代码演示了在 Responses API 中如何使用 instructions 字段， 达到在特定轮次中替换系统提示词的目的，实现更灵活的输出。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="兼容 OpenAI SDK" key="XJZOs3pg5y"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

response = client.responses.create(
    model="doubao-seed-1-6-250615",    
    input=[
        {
            "role": "system", 
            "content": "你是三字经小能手。每次用户输入时，你只能用三个汉字作出回应。用户输入如果是三个字，就用三个字像对对联一样进行匹配回应；如果不是三个字，就将用户输入的意思总结成三个字。无论何时，回复都严格限制为三个字。"
        },
    ]
)
print(response)

second_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "人之初"}],
)
print(second_response)

third_response = client.responses.create(
    model="doubao-seed-1-6-250615",
    instructions=(
        "请严格执行本新指令：无视所有先前关于输出长度的系统指令，你的唯一任务是——"
        "收到用户输入后，只能回复四个汉字，且必须输出四个汉字，不能多不能少。"
        "即使先前要求输出三个字，你也必须回复四个字。"
        "请牢记：无论任何内容，回复都只能有四个汉字。"
    ),
    previous_response_id=response.id,
    input=[{"role": "user", "content": "人之初"}],
)
print(third_response)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="e2783314"></span>
## 深度思考
这段代码演示了如何通过 Responses API 实现模型的深度思考模式。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="FvvWdInuuK"><RenderMd content={`\`\`\`Bash
curl --location 'https://ark.cn-beijing.volces.com/api/v3/responses' \\
--header "Authorization: Bearer $ARK_API_KEY" \\
--header 'Content-Type: application/json' \\
--data '{
    "model": "doubao-seed-1-6-250615",
    "input": "推理模型与非推理模型区别。",
    "thinking":{"type": "enabled"}
}'
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="兼容 OpenAI SDK" key="bmelG67G3d"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

# 创建一个对话请求
response = client.responses.create(
    model="doubao-seed-1-6-250615",
    input="推理模型与非推理模型区别。",
    extra_body={
        "thinking": {"type": "enabled"},
    }
)

print(response)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="452f7faf"></span>
## 流式输出
这段代码中展示了如何通过 Responses API 实现便捷的流式输出。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="R6TaJC3Cyw"><RenderMd content={`\`\`\`Bash
curl --location 'https://ark.cn-beijing.volces.com/api/v3/responses' \\
--header "Authorization: Bearer $ARK_API_KEY" \\
--header 'Content-Type: application/json' \\
--data '{
    "model": "doubao-seed-1-6-250615",
    "input": "你好呀。",
    "stream": true
}'
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="兼容 OpenAI SDK" key="jUzxGmOhTx"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

response = client.responses.create(
    model="doubao-seed-1-6-250615",
    input="你好呀。",
    stream=True,
)

for event in response:
    print(event)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="3e198ddd"></span>
## 结构化输出
这段代码展示了如何利用 Responses API 实现结构化输出。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="SedWr86QNQ"><RenderMd content={`\`\`\`Shell
curl --location 'https://ark.cn-beijing.volces.com/api/v3/responses' \\
  --header "Authorization: Bearer $ARK_API_KEY" \\
  --header 'Content-Type: application/json' \\
  --data '{
    "model": "doubao-seed-1-6-250615",
    "thinking": { "type": "disabled" },
    "text": {
      "format": {
        "type": "json_object"
      }
    },
    "input": [
      {
        "role": "system",
        "content": "你是一位专业的数学助教，收到用户提出的数学问题后，需以结构化 JSON 格式输出。返回的json中应包含explanation和answer字段"
      },
      {
        "role": "user",
        "content": "根号三的近似值是多少"
      }
    ]
  }'
\`\`\`

输出示例
\`\`\`JSON
{
    "explanation": "根号三即√3，其近似值可通过逐步逼近法确定。首先，1²=1，2²=4，故√3在1和2之间。进一步计算，1.7²=2.89，1.8²=3.24，因此√3在1.7和1.8之间。继续精确，1.73²=2.9929，1.732²=2.999824（接近3），1.7321²≈3.00017（略大于3）。综上，√3的近似值通常取1.732。", 
    "answer": "1.732"
}
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="兼容 OpenAI SDK" key="nZeyg5jMzN"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

response = client.responses.create(
    model="doubao-seed-1-6-250615", 
    input=[
        {"role": "system", "content": 
         "你是一位专业的数学助教，收到用户提出的数学问题后，需以结构化 JSON 格式输出。"
        "返回的 JSON 应该包含以下字段："
        "1. 'explanation'：对题目的详细推理和解题步骤，内容应简明易懂。"
        "2. 'answer'：最终的纯数值答案或结论。"
        "所有内容均用简体中文。请勿输出 JSON 以外的内容。"
        },
        {"role": "user", "content": "根号三的近似值是多少。"}
    ],
    text={"format":{"type": "json_object"}}
)

print(response)
\`\`\`

输出示例
\`\`\`JSON
{
    "explanation": "根号三即√3，其近似值可通过逐步逼近法确定。首先，1²=1，2²=4，故√3在1和2之间。进一步计算，1.7²=2.89，1.8²=3.24，因此√3在1.7和1.8之间。继续精确，1.73²=2.9929，1.732²=2.999824（接近3），1.7321²≈3.00017（略大于3）。综上，√3的近似值通常取1.732。", 
    "answer": "1.732"
}
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="0564edbe"></span>
## 工具调用
这段代码展示了如何利用 Responses API 实现高效便捷的工具调用流程。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="fzSogafgM1"><RenderMd content={`\`\`\`Bash
curl --location 'https://ark.cn-beijing.volces.com/api/v3/responses' \\
--header "Authorization: Bearer $ARK_API_KEY" \\
--header 'Content-Type: application/json' \\
--data '{
    "model": "doubao-seed-1-6-250615",
    "input": "查询北京今天的天气",
    "tools":[
        {
            "type": "function",
            "name": "获取天气信息",
            "description": "根据给出的位置获取天气信息",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "城市名称，例如：北京"
                    }
                },
                "required": [
                    "location"
                ]
            }
        }
    ]
}'
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="兼容 OpenAI SDK" key="qaWuadoXY2"><RenderMd content={`\`\`\`Python
from openai import OpenAI
import os

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark-cn-beijing.bytedance.net/api/v3'
    api_key=api_key,
)

tools = [{
    "type": "function",
    "name": "获取天气信息",
    "description": "根据给出的位置获取天气信息",
    "parameters": {
        "type": "object",
        "properties": {
            "location": {
                "type": "string",
                "description": "城市名称，例如：北京"
            }
        },
        "required": [
            "location"
        ]
    }
}]

# 创建一个对话请求
response = client.responses.create(
    model="doubao-seed-1-6-250615",
    input=[{"role": "user", "content": "北京的天气怎么样？"}],
    tools=tools,
)

print(response)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="7188c629"></span>
## 多模态理解
这段代码中展示了如何通过 Responses API 实现便捷的多模态理解。
<span id="b41fe0af"></span>
### 图片理解

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="suS6ShcAr0"><RenderMd content={`\`\`\`Bash
curl --location 'https://ark.cn-beijing.volces.com/api/v3/responses' \\
--header "Authorization: Bearer $ARK_API_KEY" \\
--header 'Content-Type: application/json' \\
--data '{
    "model": "doubao-seed-1-6-250615",
    "input": [
        {
            "role": "user",
            "content": [
                {
                    "type": "input_text",
                    "text": "你看见了什么？"
                },
                {
                    "type": "input_image",
                    "image_url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"
                }
            ]
        }
    ]
}'
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="兼容 OpenAI SDK" key="K6lwXygmX3"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

response = client.responses.create(
    model="doubao-seed-1-6-250615",
    input=[
        {
            "role": "user",
            "content": [
                {
                    "type": "input_text",
                    "text": "你看见了什么？"
                },
                {
                    "type": "input_image",
                    "image_url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"
                }
            ],
        }
    ]
)

print(response)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="52ad625b"></span>
### 视频理解

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Curl" key="PT8nAUmSAq"><RenderMd content={`\`\`\`Bash
curl --location 'https://ark.cn-beijing.volces.com/api/v3/responses' \\
--header "Authorization: Bearer $ARK_API_KEY" \\
--header 'Content-Type: application/json' \\
--data '{
    "model": "doubao-seed-1-6-250615",
    "input": [
        {
            "role": "user",
            "content": [
                {    
                    "type": "input_video",
                    "video_url": "https://ark-project.tos-cn-beijing.volces.com/doc_video/ark_vlm_video_input.mp4",
                    "fps":1
                }
            ]
        }
    ]
}'
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="兼容 OpenAI SDK" key="C8c9BwnhQ2"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI

# 从环境变量中获取您的API KEY，配置方法见：https://www.volcengine.com/docs/82379/1399008
api_key = os.getenv('ARK_API_KEY')

client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

response = client.responses.create(
    model="doubao-seed-1-6-250615",
    input=[
        {
            "role": "user",
            "content": [
                {    
                    "type": "input_video",
                    "video_url": "https://ark-project.tos-cn-beijing.volces.com/doc_video/ark_vlm_video_input.mp4",
                    "fps":1
                }
            ],
        }
    ]
)

print(response)
\`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="d2e3d7ea"></span>
# 与 Chat API 的对比
<span id="319af961"></span>
## 能力对比
与 Chat API 相比，Responses API 在能力上具备多方面优势。目前，Responses API 支持更简洁的输入输出格式，能够更加高效地进行上下文管理，并且工具调用方式也更加便捷，极大提升了开发和集成效率。同时，Responses API 还具备良好的扩展性，未来将陆续支持更多内置工具，为开发者提供更丰富、更灵活的智能应用开发能力。
<span id="8542e447"></span>
## 代码对比
两种 API 都可以用于获取模型生成的输出。Chat API 需要传入一个消息（messages）数组，而 Responses API 则接受字符串或数组格式的输入。
通过 Responses API 获取响应时，返回的字段与 Chat API 略有不同。Responses API 返回的不是 message，而是一个包含自身 ID 的 response 对象，并且 response 对象会被默认存储。相比之下，Chat API 不具备存储能力。如果希望在使用 Responses API 时禁用存储功能，只需设置 `"store": false` 即可。

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.4953051643192488);">

**Responses API**
输入示例
```Bash
curl https://ark.cn-beijing.volces.com/api/v3/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $ARK_API_KEY" \
  -d '{
    "model": "doubao-seed-1-6-250615",
    "input": "你好呀。"
}'
```




</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5046948356807511);margin-left: 16px;">

**Chat API**
输入示例
```Bash
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $ARK_API_KEY" \
  -d '{
    "model": "doubao-seed-1-6-250615",
    "messages": [
        {
            "role": "user",
            "content": "你好呀。"
        }
    ]
  }'
```




</div>
</div>



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.4953051643192488);">

输出示例
```Bash
{
    "created_at": 1749xxxxxx, 
    "id": "resp_0217xxxxxx", 
    "model": "doubao-seed-1-6-250615", 
    "object": "response", 
    "output": [
        {
            "id": "rs_0217xxxxxx", 
            "type": "reasoning", 
            "summary": [
                {
                    "type": "summary_text", 
                    "text": "
用户说“豆包你好。”，这是一个简单的问候。我需要友好地回应，保持亲切的语气。首先，应该回应用户的问候，然后可能表达一下很高兴和用户交流，或者询问有什么可以帮助的。考虑到用户可能只是刚开始对话，所以回应要自然、热情，让用户感觉被欢迎。可以说“你好呀！很高兴见到你～ 今天有什么想聊的或者需要我帮忙的吗？😊” 这样既回应了问候，又主动提供了帮助，显得友好和乐于助人。"
                }
            ], 
            "status": "completed"
        }, 
        {
            "type": "message", 
            "role": "assistant", 
            "content": [
                {
                    "type": "output_text", 
                    "text": "你好呀！很高兴见到你～ 今天有什么想聊的或者需要我帮忙的吗？😊"
                }
            ], 
            "status": "completed", 
            "id": "msg_0217xxxxxx"
        }
    ], 
    "service_tier": "default", 
    "status": "completed", 
    "usage": {
        "input_tokens": 89, 
        "output_tokens": 145, 
        "total_tokens": 234, 
        "input_tokens_details": {
            "cached_tokens": 0
        }, 
        "output_tokens_details": {
            "reasoning_tokens": 122
        }
    }, 
    "store": true
}
```



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5046948356807511);margin-left: 16px;">

输出示例
```Bash
{
    "choices": [
        {
            "finish_reason": "stop", 
            "index": 0, 
            "logprobs": null, 
            "message": {
                "content": "你好呀！很高兴收到你的问候～今天有没有什么开心的事情想分享呀？😊", 
                "reasoning_content": "
用户说“你好呀。”，这是一个很友好的问候。我需要用同样友好的方式回应，保持自然和亲切。首先，直接回应用户的问候，然后可以稍微扩展一下，让对话更流畅。比如可以说“你好呀！很高兴收到你的问候，今天过得怎么样呀？”这样既回应了对方，又表达了关心，促进进一步的交流。要注意语气要温和，符合日常对话的感觉，不要太正式。检查一下有没有不合适的地方，确保回复积极正面。嗯，这样应该可以了。", 
                "role": "assistant"
            }
        }
    ], 
    "created": 1749xxxxxx, 
    "id": "0217xxxxxx", 
    "model": "doubao-seed-1-6-250615", 
    "service_tier": "default", 
    "object": "chat.completion", 
    "usage": {
        "completion_tokens": 143, 
        "prompt_tokens": 88, 
        "total_tokens": 231, 
        "prompt_tokens_details": {
            "cached_tokens": 0
        }, 
        "completion_tokens_details": {
            "reasoning_tokens": 123
        }
    }
}
```



</div>
</div>

<span id="dc10063c"></span>
## 维护策略
当前新模型会在 Chat API 和 Responses API 上同步适配，无需担心后续的维护问题。
<span id="ba3e0d8d"></span>
# 
 




# 产品简介
Source: https://www.volcengine.com/docs/82379/1099455
<span id="68ec7186"></span>
# 方舟定位
为您提供大模型服务的开发平台，提供功能丰富、安全以及具备价格竞争力的模型调用服务，同时提供模型数据、精调、推理、评测等端到端功能，全方位保障您的 AI 应用开发落地。
<span id="25b2cc2c"></span>
# 极速体验
您可以访问[火山方舟大模型体验中心](https://www.volcengine.com/experience/ark)，免登录极速体验模型能力。

* 点击页面中心的模型切换按钮，可以切换体验 Doubao 或 DeepSeek 系列模型能力。

> 未登录状态下可以体验部分模型。如果您需要体验所有模型能力，建议您登录火山引擎账号，[选择并开通模型](https://www.volcengine.com/docs/82379/1099455#9f4ea899)。


* 点击开启MCP服务器，可以连接使用更多火山云产品与三方工具。
* 您也可以尝试选择下方的图片理解任务进行尝试。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/eb9081bca7a84c8fb59e4da63b304c87~tplv-goo7wpa0wc-image.image =1049x)
<span id="9f4ea899"></span>
# 选择并开通模型
> 使用模型前请访问[开通管理页面](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%22PageSize%22%3A10%2C%22PageNumber%22%3A1%2C%22Filter%22%3A%7B%7D%7D&OpenTokenDrawer=false) 开通对应模型服务。


| | | | | \
|[doubao-seed-1.6 ](https://www.volcengine.com/docs/82379/1593702) |\
|<div style="width:25%"></div> |[doubao-seed-1.6-flash](https://www.volcengine.com/docs/82379/1593704) |\
| |<div style="width:25%"></div> |[doubao-seed-1.6-thinking](https://www.volcengine.com/docs/82379/1593703) |\
| | |<div style="width:25%"></div> |[deepseek-r1](https://www.volcengine.com/docs/82379/1554373) |\
| | | |<div style="width:25%"></div> |
|---|---|---|---|
| | | | | \
|全新多模态深度思考模型，同时支持 `thinking`、`non-thinking`、`auto`三种思考模式。其中` non-thinking` 模型对比 `doubao-1.5-pro-32k-250115` 模型大幅提升。 |\
| |\
|* 支持 **256k** 上下文长度 |\
|* 支持 **224k** 输入长度、 **32k** 思维链内容 |\
|* [可配置](https://www.volcengine.com/docs/82379/1399009#%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B%E6%9C%80%E5%A4%A7%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6) **16k** 最大输出长度  |\
|* 可支持图文、视频理解 |有极致推理速度的多模态深度思考模型；同时支持文本和视觉理解。文本理解能力超过上一代 Lite 系列模型，视觉理解比肩友商 Pro 系列模型。 |\
| | |\
| |* 支持 **256k** 上下文长度 |\
| |* 支持 **224k** 输入长度、 **32k** 思维链内容 |\
| |* [可配置](https://www.volcengine.com/docs/82379/1399009#%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B%E6%9C%80%E5%A4%A7%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6) **16k** 最大输出长度  |\
| |* 可支持图文、视频理解 |在思考能力上进行了大幅强化， 对比 doubao 1.5 代深度理解模型，在编程、数学、逻辑推理等基础能力上进一步提升， 支持视觉理解。 |\
| | | |\
| | |* 支持 **256k** 上下文长度 |\
| | |* 支持 **224k** 输入长度、 **32k** 思维链内容 |\
| | |* [可配置](https://www.volcengine.com/docs/82379/1399009#%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B%E6%9C%80%E5%A4%A7%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6) **16k** 最大输出长度  |\
| | |* 可支持图文、视频理解 |deepseek-r1 在后训练阶段大规模使用了强化学习技术，在数学、代码、自然语言推理等任务上，能力比肩 OpenAI o1 正式版。 |\
| | | | |\
| | | |* 支持 **128k** 上下文长度 |\
| | | |* 支持 96**k** 最大输入、**32k** 思维链内容 |\
| | | |* [可配置](https://www.volcengine.com/docs/82379/1399009#%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B%E6%9C%80%E5%A4%A7%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6) **16k** 最大输出长度 |\
| | | |* 高性能，满血版 |

[模型列表](https://www.volcengine.com/docs/82379/1330310)  ｜  [模型定价详情](https://www.volcengine.com/pricing?product=ark_bd&tab=1) 
<span id="01a681e5"></span>
# 快速入门
[快速入门](https://www.volcengine.com/docs/82379/1399008)  ｜  [直接体验](https://console.volcengine.com/ark/region:ark+cn-beijing/experience/chat) 
帮助您发起第一次的大模型服务调用。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="Python SDK" key="y9d392MnHE"><RenderMd content={`\`\`\`Python
import os
from volcenginesdkarkruntime import Ark
# 获取并配置方舟API Key，并从环境变量中读取。https://www.volcengine.com/docs/82379/1399008#_1-%E8%8E%B7%E5%8F%96%E5%B9%B6%E9%85%8D%E7%BD%AE-api-key
client = Ark(api_key=os.environ.get("<ARK_API_KEY>"))
completion = client.chat.completions.create(
    # 替换为模型 ID，获取模型 ID：https://www.volcengine.com/docs/82379/1330310
    model="<Model>",
    messages=[
        {"role": "user", "content": "你好"}
    ]
)
print(completion.choices[0].message.content)
\`\`\`

> 您也可将\`<Model>\`配置为推理接入点ID，来获取调用限流、购买保障包、监控调用明细等附加能力。详细请参见 [获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Curl" key="koxnRBsl4i"><RenderMd content={`\`\`\`HTTP
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer <ARK_API_KEY>" \\
  -d '{
    "model": "<Model>",
    "messages": [
        {"role": "user", "content": "你好"}
    ]
  }'
\`\`\`

> 您也可将\`<Model>\`配置为推理接入点ID，来获取调用限流、购买保障包、监控调用明细等附加能力。详细请参见 [获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="OpenAI Python SDK" key="TJAvlh7ZIr"><RenderMd content={`\`\`\`Python
import os
from openai import OpenAI
client = OpenAI(
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    # 获取并配置方舟API Key，并从环境变量中读取。https://www.volcengine.com/docs/82379/1399008#_1-%E8%8E%B7%E5%8F%96%E5%B9%B6%E9%85%8D%E7%BD%AE-api-key
    api_key=os.environ.get("<ARK_API_KEY>")
)
completion = client.chat.completions.create(
    # 替换 <Model> 为模型 ID。获取模型 ID：https://www.volcengine.com/docs/82379/1330310
    model="<Model>",
    messages = [
        {"role": "user", "content": "你好"},
    ]
)
print(completion.choices[0].message.content)
\`\`\`

> 您也可将\`<Model>\`配置为推理接入点ID，来获取调用限流、购买保障包、监控调用明细等附加能力。详细请参见 [获取 Endpoint ID（创建自定义推理接入点）](https://www.volcengine.com/docs/82379/1099522)。
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="238fb521"></span>
# 实践教程

| | | | | \
|[上下文缓存概述](https://www.volcengine.com/docs/82379/1398933) |[批量推理](https://www.volcengine.com/docs/82379/1399517) |[Prompt 最佳实践](https://www.volcengine.com/docs/82379/1221660) |[Prefill Response模式最佳实践](https://www.volcengine.com/docs/82379/1359497) |
|---|---|---|---|
| | | | | \
|方舟提供的高效的缓存机制，您可以基于它优化多轮对话，通过缓存部分上下文数据，减少重复加载或处理，提高响应速度和一致性。 |当您的任务计算量大，如分析当日汇总新闻信息、翻译长文本、用户反馈分析收录等大规模数据处理任务，您可以借助方舟的批量推理能力获得更高速率限制和更大吞吐的模型推理服务。 |Prompt engineering 是指设计和优化提示的过程，以使人工智能模型能够更好地理解用户的意图和要求，并生成更准确、有用的响应。 |通过预填部分`Assistant` 角色的内容，来引导和控制模型的输出：强制按照 JSON 或 XML 等特定格式输出；跳过已生成的内容，避免触发模型最大输出限制；控制大模型在角色扮演场景中保持同一角色。 |

<span id="c0b9ad89"></span>
# 产品优势

* **安全与互信**：大模型安全信任方案严格保障模型提供方与模型使用者的模型与信息安全，[点击查看安全互信白皮书](https://www.volcengine.com/docs/83458/1108217)。
* **精选模型**：支持多行业各业务场景模型，提供丰富的平台应用与工具，帮助您搭建专属的创新场景。
* **强劲算力**：基于火山的万卡资源池，提供充足的高性能GPU资源，为您提供包含模型精调、评测、推理等端到端模型服务。
* **企业级服务**：提供专业服务体系支持，专业的产品运营、销售交付服务，满足企业应用搭建与交付需求。




# 快速入门
Source: https://www.volcengine.com/docs/82379/1399008
本文帮助您了解并按照步骤完成 API 调用模型，包括如何配置环境，使用 SDK 调用模型服务，便于您了解如何通过代码使用模型能力，进而集成到您的工作或者应用中。
> 快速入口，供您快速跳转到需要的内容：

> * 直接体验模型能力，访问[模型广场](https://console.volcengine.com/ark/region:ark+cn-beijing/experience/chat)。 
> * 有模型调用经验，查看[对话(Chat)-文本 API（文档下线中）](https://www.volcengine.com/docs/82379/1298454)或者模型教程[文本生成](https://www.volcengine.com/docs/82379/1399009)。
> * 已有模型调用业务，迁移到 Doubao 大模型，可参考[兼容OpenAI API](https://www.volcengine.com/docs/82379/1330626)。

<span id="da0e9d90"></span>
# 简介
通过代码调用模型服务，可以分为以下几步：

* [1.获取并配置 API Key ](https://www.volcengine.com/docs/82379/1399008#b00dee71)
* [2.获取 Model ID](https://www.volcengine.com/docs/82379/1399008#1008bfdb)
* [3.配置环境并发起调用](https://www.volcengine.com/docs/82379/1399008#99a7c9ca)

<span id="b00dee71"></span>
# 1.获取并配置 API Key 
<span id="10d67aef"></span>
## 获取 API Key

1. 打开并登录[方舟控制台-API Key 管理](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)。
2. 单击**创建 API Key** 按钮。
3. 在弹出框的**名称**文本框中确认/更改 API Key 名称，单击创建。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ceba3fbf76134d80b6d5b3041b0907af~tplv-goo7wpa0wc-image.image =501x)
:::tip
* 请妥善保存好API Key，强烈建议您不要将其直接写入到调用模型的代码中。
* Access Key鉴权方式，请参见[Access Key 签名鉴权](https://www.volcengine.com/docs/82379/1298459#21bff83b)。
:::
<span id="4b62407d"></span>
## 配置 API Key 到环境变量
[macOS](https://www.volcengine.com/docs/82379/1399008#12206f86) <span style="color: #646a73"><strong>| </strong></span>[Linux](https://www.volcengine.com/docs/82379/1399008#08fc3c87) <span style="color: #646a73"><strong>| </strong></span>[Windows](https://www.volcengine.com/docs/82379/1399008#e3701492)
<span id="12206f86"></span>
## macOS

```mixin-react
return (<Tabs>
<Tabs.TabPane title="临时环境变量" key="jwSdYoMfTR"><RenderMd content={`您希望仅在当前会话中使用 API Key 环境变量，可以添加临时环境变量。

1. 打开终端使用以下命令来设置环境变量，将\`<ARK_API_KEY>\`替换为您的方舟 API Key。

\`\`\`Shell
export ARK_API_KEY="<ARK_API_KEY>"
\`\`\`


2. 执行以下命令，验证该环境变量是否生效。

\`\`\`Shell
echo $ARK_API_KEY
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="永久环境变量" key="TZMZB9Nql4"><RenderMd content={`您希望 API Key 环境变量在当前用户的所有新会话中生效，可以添加永久性环境变量。

1. 打开在终端，使用以下命令，查看默认 Shell 类型。

\`\`\`Shell
echo $SHELL
\`\`\`


   * \`/bin/zsh\`：默认的 Shell 类型是 Zsh（ Z shell）。
   * \`/bin/bash\`：默认的 Shell 类型是 Bash。

<span id="8646381d"></span>
### Zsh

2. 打开终端，使用以下命令来将环境变量设置追加到 \`~/.zshrc\` 中。将\`<ARK_API_KEY>\`替换为您的方舟 API Key。
   \`\`\`Shell
   echo "export ARK_API_KEY='<ARK_API_KEY>'" >> ~/.zshrc
   \`\`\`

3. 使用以下命令使更改生效。
   \`\`\`Shell
   source ~/.zshrc
   \`\`\`

4. 验证环境变量是否设置成功，在新的终端窗口，输入以下命令，如果返回您的 API Key，则表示设置成功。
   \`\`\`Shell
   echo $ARK_API_KEY
   \`\`\`


<span id="112365c2"></span>
### Bash
返回的是\`/bin/bash\`。

2. 打开终端使用以下命令来将环境变量设置追加到 \`~/.bash_profile\` 中。将\`<ARK_API_KEY>\`替换为您的方舟 API Key。
   \`\`\`Shell
   echo "export ARK_API_KEY='<ARK_API_KEY>'" >> ~/.bash_profile
   \`\`\`

3. 使用以下命令使更改生效。
   \`\`\`Shell
   source ~/.bash_profile
   \`\`\`

4. 验证环境变量是否设置成功，在新的终端窗口，输入以下命令，如果返回您的 API Key，则表示设置成功。
   \`\`\`Shell
   echo $ARK_API_KEY
   \`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="08fc3c87"></span>
## Linux

```mixin-react
return (<Tabs>
<Tabs.TabPane title="设置临时环境变量" key="PsKepUlM1E"><RenderMd content={`如果您仅希望在当前会话中使用该环境变量，可以添加临时性环境变量。

1. 打开终端使用以下命令来设置环境变量，将\`<ARK_API_KEY>\`替换为您的方舟 API Key。

\`\`\`Shell
export ARK_API_KEY="<ARK_API_KEY>"
\`\`\`


2. 执行以下命令，验证该环境变量是否生效。

\`\`\`Shell
echo $ARK_API_KEY
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="设置永久环境变量" key="SkbM223g6a"><RenderMd content={`如果您希望 API Key 环境变量在当前用户的所有新会话中生效，可以添加永久性环境变量。

1. 打开终端使用以下命令来将环境变量设置追加到 \`~/.bashrc\` 中。将\`<ARK_API_KEY>\`替换为您的方舟 API Key。
   \`\`\`Shell
   echo "export ARK_API_KEY='<ARK_API_KEY>'" >> ~/.bashrc
   \`\`\`

2. 使用以下命令使更改生效。
   \`\`\`Shell
   source ~/.bashrc
   \`\`\`

3. 验证环境变量是否设置成功，在新的终端窗口，输入以下命令，如果返回您的 API Key，则表示设置成功。
   \`\`\`Shell
   echo $ARK_API_KEY
   \`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="e3701492"></span>
## Windows

```mixin-react
return (<Tabs>
<Tabs.TabPane title="设置临时环境变量" key="yE9TueNUxR"><RenderMd content={`如果您仅希望在当前会话中使用该环境变量，可以添加临时性环境变量。
<span id="32d72231"></span>
#### 在CMD中

1. 打开 CMD（命令提示符） 。
2. 输入以下命令来设置环境变量，将\`<ARK_API_KEY>\`替换为您的实际 API Key：
   \`\`\`Shell
   set ARK_API_KEY=<ARK_API_KEY>
   \`\`\`

3. 验证环境变量是否设置成功，输入以下命令，如果返回您的 API Key，则表示设置成功。
   \`\`\`Shell
   echo %ARK_API_KEY%
   \`\`\`


<span id="dfd19123"></span>
#### 在PowerShell中

1. 打开 PowerShell 。
2. 输入以下命令来设置环境变量，将\`<ARK_API_KEY>\`替换为您的实际 API Key：
   \`\`\`PowerShell
   $env:ARK_API_KEY = "<ARK_API_KEY>"
   \`\`\`

3. 验证环境变量是否设置成功，输入以下命令，如果返回您的 API Key，则表示设置成功。
   \`\`\`Shell
   $env:ARK_API_KEY
   \`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="设置永久环境变量" key="BiULbbinJi"><RenderMd content={`如果您希望 API Key 环境变量在当前用户的所有新会话中生效，可以添加永久性环境变量。
<span id="41ea8d36"></span>
#### 在 CMD 中
您可以使用\`setx\`命令为当前用户设置永久性环境变量。

1. 打开 CMD ，输入以下命令，其中将\`<ARK_API_KEY>\`替换为您的方舟 API Key。
   \`\`\`Shell
   setx ARK_API_KEY "<ARK_API_KEY>"
   \`\`\`

2. 验证环境变量是否设置成功，在新打开 CMD 窗口中，输入以下命令，如果返回您的 API Key，则表示设置成功。
   \`\`\`Shell
   echo %ARK_API_KEY%
   \`\`\`


<span id="5f311cc6"></span>
#### 在 PowerShell 中
您可以使用以下命令为当前用户设置永久性环境变量。

1. 打开 PowerShell ，输入以下命令，其中将\`<ARK_API_KEY>\`替换为您的方舟 API Key。
   \`\`\`PowerShell
   [Environment]::SetEnvironmentVariable("ARK_API_KEY", "<ARK_API_KEY>", [EnvironmentVariableTarget]::User)
   \`\`\`

2. 验证环境变量是否设置成功，在新打开PowerShell窗口中，输入以下命令，如果返回您的 API Key，则表示设置成功。
   \`\`\`Shell
   $env:ARK_API_KEY
   \`\`\`

`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="1008bfdb"></span>
# 2.获取 Model ID
通过 Model ID的方式快速调用模型。

1. 通过 [模型列表](https://www.volcengine.com/docs/82379/1330310) 选择模型并获取所需模型的 ID（Model ID）。
2. 访问[开通管理页面](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%22PageSize%22%3A10%2C%22PageNumber%22%3A1%2C%22Filter%22%3A%7B%7D%7D&OpenTokenDrawer=false) 开通对应模型服务。

:::tip
您也可通过Endpoint ID来调用模型，获得限流、计费类型（前付费/后付费）、运行状态查询、监控、安全等高级能力，具体可参考[获取 Endpoint ID](https://www.volcengine.com/docs/82379/1099522#b35cee81)。
:::
<span id="99a7c9ca"></span>
# 3.配置环境并发起调用
 [Curl](https://www.volcengine.com/docs/82379/1399008#a7831f97)  <span style="color: #646a73"><strong>|</strong></span>[Python](https://www.volcengine.com/docs/82379/1399008#2832b836)  **|**   [Go](https://www.volcengine.com/docs/82379/1399008#3fc72e6d)  <span style="color: #646a73"> </span><span style="color: #646a73"><strong>|</strong></span><span style="color: #646a73"> </span> [Java](https://www.volcengine.com/docs/82379/1399008#0009f01e)
您可挑选任意一种语言选择调用模型推理服务的语言。
<span id="a7831f97"></span>
## Curl
您可以通过 HTTP 方式直接调用方舟模型服务。
在终端窗口中，拷贝下面命令，可替换 **model** 字段为您需要的模型的Model ID。稍等您可以在终端窗口中看到模型调用的返回结果。这样您就完成了您的首次方舟平台模型服务调用。


```mixin-react
return (<Tabs>
<Tabs.TabPane title="macOS / Linux" key="UDLCZJhdI9"><RenderMd content={`\`\`\`HTTP
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer \$ARK_API_KEY" \\
  -d '{
    "model": "doubao-seed-1.6-250615",
    "messages": [
        {
            "role": "user",
            "content": "你好"
        }
    ]
  }'
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Windows CMD" key="aLJn90sXsV"><RenderMd content={`\`\`\`Shell
curl -X POST "https://ark.cn-beijing.volces.com/api/v3/chat/completions" ^
-H "Authorization: Bearer %ARK_API_KEY%" ^
-H "Content-Type: application/json" ^
-d "{
    \\"model\\": \\"doubao-seed-1.6-250615\\",
    \\"messages\\": [
        {
            \\"role\\": \\"user\\",
            \\"content\\": \\"你好？\\"
        }
    ]
}"
\`\`\`

`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="Windows PowerShell" key="Qdh31MWd2d"><RenderMd content={`\`\`\`Shell
curl.exe https://ark.cn-beijing.volces.com/api/v3/chat/completions \`
-H "Authorization: Bearer \$env:ARK_API_KEY" \`
-H "Content-Type: application/json" \`
-d '{
    \\"model\\": \\"doubao-seed-1.6-250615\\",
    \\"messages\\": [
        {
            \\"role\\": \\"user\\",
            \\"content\\": \\"你好？\\"
        }
    ]
}'
\`\`\`


`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

> 如果返回错误码 `{"error":{"code":"AuthenticationError","message":"The API key or AK/SK in the request is missing or invalid. requestId: 0217***`，说明API Key中没有被正确设置到环境变量中，您可以直接替换`$ARK_API_KEY`为您的方舟 API Key ，再次运行命令。

<span id="2832b836"></span>
## Python
<span id="ac6d94e2"></span>
### Python 安装
检查并安装 Python 版本，Python 版本需要 3.7 或以上。

   您可以在终端中输入以下命令查看 Python 安装版本。
   ```Shell
   python -V
   ```

   如果运行失败，您可以尝试使用下面命令再运行。
   ```Shell
   python3 -V
   ```

   如果未安装或者版本不满足，请参考 [Python 安装教程](https://www.python.org/downloads/) 安装，注意选择版本 3.7 及以上版本。

<span id="fbb11c3e"></span>
### 方舟 Python SDK
> 跳转使用[OpenAI SDK](https://www.volcengine.com/docs/82379/1399008#5b83c3bc) 


1. 安装方舟 Python SDK。
   您可以在中输入以下命令，安装/升级方舟 Python SDK。
   ```Shell
   pip install -U 'volcengine-python-sdk[ark]'
   ```

   如果您本地安装错误，可以尝试使用方法
      * 使用下面命令安装
   ```Shell
   pip install -U volcengine-python-sdk[ark]
   ```

      * [Windows系统安装SDK失败，ERROR: Failed building wheel for volcengine-python-sdk](https://www.volcengine.com/docs/82379/1359411#b74e8ad6)
2. 创建一个文件命名为`ark_example.py`，将下面示例代码拷贝进文件。
   ```Python
   import os
   from volcenginesdkarkruntime import Ark
   # 从环境变量中读取您的方舟API Key
   client = Ark(api_key=os.environ.get("ARK_API_KEY"))
   completion = client.chat.completions.create(
       # 替换 <Model>为 Model ID
       model="<Model>",
       messages=[
           {"role": "user", "content": "你好"}
       ]
   )
   print(completion.choices[0].message)
   ```

3. 在终端窗口中，使用下面命令运行代码。稍等您可以在终端窗口中看到模型调用的返回结果，这样您就完成了您的首次方舟平台模型服务调用。
   ```Shell
   python ark_example.py
   ```


<span id="5b83c3bc"></span>
### OpenAI SDK
> 跳转使用[方舟 Python SDK](https://www.volcengine.com/docs/82379/1399008#fbb11c3e)


1. 安装OpenAI SDK。
   您可以在终端中输入以下命令，安装/升级方舟 OpenAI SDK。
   ```Shell
   pip install -U openai
   ```

2. 创建一个文件命名为`ark_example.py`，将下面示例代码拷贝进文件。
   ```Python
   import os
   from openai import OpenAI
   
   client = OpenAI(
       # 从环境变量中读取您的方舟API Key
       api_key=os.environ.get("ARK_API_KEY"), 
       base_url="https://ark.cn-beijing.volces.com/api/v3",
       )
   completion = client.chat.completions.create(
       # 将推理接入点 <Model>替换为 Model ID
       model="<Model>",
       messages=[
           {"role": "user", "content": "你好"}
       ]
   )
   print(completion.choices[0].message)
   ```

3. 在终端窗口中，使用下面命令运行代码。稍等您可以在终端窗口中看到模型调用的返回结果，这样您就完成了您的首次方舟平台模型服务调用。
   ```Shell
   python ark_example.py
   ```


<span id="3fc72e6d"></span>
## Go

1. 检查并安装 Go 版本，Go 版本需要 1.18 或以上。
   ```Shell
   go version
   ```

   如果未安装 Go 或者版本不满足要求，您可以访问 [Go 语言官方网站](https://golang.google.cn/dl/)下载并安装适合您操作系统的 Go 版本。请确保选择 1.18 或以上版本。
2. 安装方舟 Go SDK。
   火山方舟 Go SDK 使用 go mod 进行管理，如果本地工程没有初始化 go mod，您可以运行以下命令初始化 go mod。`<your-project-name>` 替换为您的项目名称。
   ```Shell
   # 如在文件夹 ark-example 下打开终端窗口，运行命令go mod init ark-example
   go mod init <your-project-name>
   ```

3. 创建一个`main.go`文件，将下面代码拷贝到文件中，并替换`<Model>`。
   ```Go
   package main
   
   import (
       "context"
       "fmt"
       "os"
       "github.com/volcengine/volcengine-go-sdk/service/arkruntime"
       "github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
       "github.com/volcengine/volcengine-go-sdk/volcengine"
   )
   
   func main() {
       client := arkruntime.NewClientWithApiKey(
           //通过 os.Getenv 从环境变量中获取 ARK_API_KEY
           os.Getenv("ARK_API_KEY"),
       )
       // 创建一个上下文，通常用于传递请求的上下文信息，如超时、取消等
       ctx := context.Background()
       // 构建聊天完成请求，设置请求的模型和消息内容
       req := model.ChatCompletionRequest{
           // 将推理接入点 <Model>替换为 Model ID
          Model: "<Model>",
          Messages: []*model.ChatCompletionMessage{
             {
                // 消息的角色为用户
                Role: model.ChatMessageRoleUser,
                Content: &model.ChatCompletionMessageContent{
                   StringValue: volcengine.String("你好"),
                },
             },
          },
       }
   
       // 发送聊天完成请求，并将结果存储在 resp 中，将可能出现的错误存储在 err 中
       resp, err := client.CreateChatCompletion(ctx, req)
       if err!= nil {
          // 若出现错误，打印错误信息并终止程序
          fmt.Printf("standard chat error: %v\n", err)
          return
       }
       // 打印聊天完成请求的响应结果
       fmt.Println(*resp.Choices[0].Message.Content.StringValue)
   }
   ```

4. 在终端窗口中，使用下面命令更新项目的依赖项。
   ```Shell
   go mod tidy
   ```

5. 在终端窗口中，使用下面命令运行代码。稍等您可以在终端窗口中看到模型调用的返回结果。这样您就完成了您的首次方舟平台模型服务调用。
   ```Shell
   go run main.go
   ```


<span id="0009f01e"></span>
## Java

1. 检查并安装 Java 版本，Java 版本需要 1.8 或以上。
   ```Shell
   java -version
   ```

   如果未安装 Java 或者版本不满足要求，您可以访问 [Oracle 官方网站](https://www.java.com/en/download/help/index_installing.html)下载并安装适合您操作系统的 Java 版本。请确保选择 1.8 或以上版本。
2. 安装方舟 Java JDK。
   火山方舟 Java SDK 支持通过 [Maven](https://maven.apache.org/install.html) 和 [Gradle](https://gradle.org/install/) 两种方式安装。
   * 通过 [Maven](https://maven.apache.org) 安装：在项目的`pom.xml`文件中添加以下依赖配置。
   ```XML
   ...
   <dependency>
     <groupId>com.volcengine</groupId>
     <!-- 替换'LATEST' 为 SDK 最新版本号：https://central.sonatype.com/artifact/com.volcengine/volcengine-java-sdk-ark-runtime --> 
     <artifactId>volcengine-java-sdk-ark-runtime</artifactId>
     <version>LATEST</version>
   </dependency>
   ...
   ```

   打开终端并进入项目根目录，运行下面命令，来安装依赖项。
   ```Shell
   mvn clean install
   ```

   * 通过 [Gradle](https://gradle.org/) 安装：在项目的`build.gradle`文件中，在`dependencies`部分添加以下依赖。

> // 替换'LATEST' 为 SDK 最新版本号：https://mvnrepository.com/artifact/com.volcengine/volcengine-java-sdk-ark-runtime


   ```JSON
   implementation 'com.volcengine:volcengine-java-sdk-ark-runtime:LATEST'
   ```

3. 将下面的示例代码拷贝到您的项目中，并替换调用模型的Model ID。
   ```Java
   package com.ark.example;
   
   import com.volcengine.ark.runtime.model.completion.chat.ChatCompletionRequest;
   import com.volcengine.ark.runtime.model.completion.chat.ChatMessage;
   import com.volcengine.ark.runtime.model.completion.chat.ChatMessageRole;
   import com.volcengine.ark.runtime.service.ArkService;
   
   import java.util.ArrayList;
   import java.util.List;
   
   /**
    * 这是一个示例类，展示了如何使用ArkService来完成聊天功能。
    */
   public class ChatCompletionsExample {
       public static void main(String[] args) {
           // 从环境变量中获取API密钥
           String apiKey = System.getenv("ARK_API_KEY");
           
           // 创建ArkService实例
           ArkService arkService = ArkService.builder().apiKey(apiKey).build();
           
           // 初始化消息列表
           List<ChatMessage> chatMessages = new ArrayList<>();
           
           // 创建用户消息
           ChatMessage userMessage = ChatMessage.builder()
                   .role(ChatMessageRole.USER) // 设置消息角色为用户
                   .content("你好") // 设置消息内容
                   .build();
           
           // 将用户消息添加到消息列表
           chatMessages.add(userMessage);
           
           // 创建聊天完成请求
           ChatCompletionRequest chatCompletionRequest = ChatCompletionRequest.builder()
                   .model("<Model>")// 需要替换为Model ID
                   .messages(chatMessages) // 设置消息列表
                   .build();
           
           // 发送聊天完成请求并打印响应
           try {
               // 获取响应并打印每个选择的消息内容
               arkService.createChatCompletion(chatCompletionRequest)
                        .getChoices()
                        .forEach(choice -> System.out.println(choice.getMessage().getContent()));
           } catch (Exception e) {
               System.out.println("请求失败: " + e.getMessage());
           } finally {
               // 关闭服务执行器
               arkService.shutdownExecutor();
           }
       }
   }
   ```

4. 编译您的Java项目并运行，稍等您可以在终端窗口中看到模型调用的返回结果。这样您就完成了您的首次方舟平台模型服务调用。






# 常见问题
Source: https://www.volcengine.com/docs/82379/1359411
<span id="5efef9e2"></span>
## 计费问题
<span id="8f169720"></span>
### 什么是 token？如何计算 token 数量?
在自然语言处理中，token 通常指的是将文本分割成的最小单位，比如词语、子词或字符。在调用模型推理服务时，会将输入内容进行分词（tokenize），转化为模型可以理解的 token ，经过模型处理后，同样输出 token，并转化为您需要的文本或者其他内容载体。而模型处理（包括输入、输出）的 token 数量会被作为模型推理服务用量的一个重要计量单位。
文本的 token 计算：由于不同模型采用的分词策略不同，同一段文本可能会被转化为不同数量的 token。您可以使用[Token计算器](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=true&current=1&pageSize=20)或者[分词 API](https://www.volcengine.com/docs/82379/1337112)接口，来估算内容对应的 token 数量。
其他模态：查阅[具体场景教程](https://www.volcengine.com/docs/82379/1362932)中的 token 用量说明。
<span id="9ed23b1e"></span>
### 模型推理请求报错或者中断会计费么？
请求报错和中断分为下面几种情况：

* 客户端中断
   无论是客户端因为无需后续结果主动中断请求，或超时中断请求，服务端感知到请求被中断，并终止服务端模型生成过程。在客户端中断，到服务端中止生成，中间仍旧有可能有若干个 token 被生成出来。服务端已生成的 token 以及输入给模型处理的 token 会被计费，服务端中止生成后，就不会有进一步计费产生。

> 请注意，非流式输出场景下，因为需要等待模型完成输出后才会返回生成的token。当请求中止或超时，服务端生成部分 token 但未生成完整回复，故未返回生成信息给客户端。本次请求客户端收不到模型生成信息，但会产生输入 token 和生成但未输出的 token 费用。


* 服务端中断
   * 在流式输出过程中，如果输出一部分内容后，因为命中审核或其它原因，服务端中止了生成过程，已经生成的 token 仍旧会被计费。
   * RPM/TPM 等超限报错的请求不会开始模型生成过程，所以也不会产生任何计费。

<span id="b740f18a"></span>
### 精调任务失败会计费吗？
任务训练失败，分两种情况：

* 不导出产物：不计费，可重试任务；
* 导出产物：需要停止任务，平台按照停止时已经训练的 token 数计费，此时不再支持重试任务。

<span id="0c9ce562"></span>
### 手动停止精调任务会计费吗?
手动停止任务，无论产物后续是否导出，都会按照已经训练的 token 数计费。
<span id="1b44d554"></span>
### 账户欠费后如何充值？
请前往 [火山引擎费用中心](https://console.volcengine.com/finance/fund/recharge) 进行充值，详细操作参见 [充值操作指引](https://www.volcengine.com/docs/6269/100434)。
<span id="08bd1d88"></span>
### 为什么我的账户欠费后仍在持续出账？
账户欠费后仍持续出账，原因主要有两点：

* **推送账单时延**：欠费自账单出具起算，而账单出账通常存在 1 至 2 小时的延迟。在此期间，系统按照实际使用量正常出账。
* **欠费 2 小时后关停**：0<欠费时长＜2小时，您可正常使用火山方舟模型服务。在此期间，系统按照实际使用量正常出账。

<span id="d53174f8"></span>
### 如何按 Endpoint ID 或精调任务 ID 分账？
对于按token后付费方式，支持对各种模型，按 Endpoint id 或精调任务 id 分账。

1. 登录控制台，进入 [费用中心 > 账单管理](https://console.volcengine.com/finance/bill/detail/)。
2. 在左侧导航栏选择 **分账账单**。
3. 将统计周期切换为 **明细**。
4. 过滤产品：选择 **字节跳动大模型服务（豆包大模型）** 或者 **开源LLM模型**。
5. 选择 **分拆项 ID**，输入 Endpoint ID 或精调任务 ID，即可看到对应的用量数据。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/25dec0b744c143639308b8ef86fe532e~tplv-goo7wpa0wc-image.image =2404x)



<span id="fba666f2"></span>
### 如何查看历史调用的输入输出长度的区间分布？
如果您使用过方舟，可在推理接入点监控看板上看到历史调用输入输出长度的分布情况。具体入口：[在线推理](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint) > 接入点详情 > **监控** 页签 > **区间内总Requests和总Tokens** 看板，如下图。
:::warning
看板数据注重实时性，监控数据在数据量较小时可能有偏差。准确数据请参考火山引擎账单信息。
:::
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4fb286cfb0e64836a6d918e9a37b2c73~tplv-goo7wpa0wc-image.image =525x)
<span id="aa45e6c0"></span>
## 在线推理
<span id="3afe6b8b"></span>
### 使用python sdk报错，错误码`httpx.InvalidURL: Invalid port:  ':'`或`ValueError: Unknown scheme for proxy URL URL('socks5h://xxx')`
python client端禁用代理
```Python
// python sdk
proxies = {
    'http://':None, #代理1
    'https://':None, #代理2
}
client = Ark(
    http_client=httpx.Client(proxies=proxies),
    )
```

若上述方法无效,可以尝试
```Shell
export no proxy=
```


<span id="c0402d7a"></span>
### ArkAPIConnectionError (域名连接超时)，怎么处理？
检查本地环境是否可以访问方舟公网域名：
```Shell
ping ark.cn-beijing.volces.com
```

如果域名访问不通，可以考虑使用以下方式关闭 `HTTP_PROXY`：
```Python
# python sdk
proxies = {
    'http://': None,  # 代理1
    'https://': None,  # 代理2
}
client = Ark(
    http_client=httpx.Client(proxies=proxies),
)
```

如果 ping 命令执行成功，但是调用时依旧有如下报错：
```Shell
Failed to resolve 'ark.cn-beijing.volces.com' ([Errno -3] Temporary failure in name resolution)
```

可以尝试对 `/etc/resolv.conf` 文件做如下修改后再次请求。
```Shell
# /etc/resolv.conf 文件
ark.cn-beijing.volces.com ${ip} # ${ip}从 ping 的输出中拿到
```

其中`${ip}`从 ping 的输出中拿到。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/f4a02223ecdd4d1fbc5dda7d84e0b0dd~tplv-goo7wpa0wc-image.image =442x)
若上述方法无效，可以尝试设置环境变量
```Shell
export no_proxy=
```

<span id="b74e8ad6"></span>
### Windows系统安装SDK失败，ERROR: Failed building wheel for volcengine-python-sdk
由于 Windows 系统有最长路径限制，可能会导致安装失败，请按照以下方式设置：

1. 按下 `Win+R` ，输入 regedit 打开注册表编辑器。
2. 设置 `\HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\FileSystem` 路径下的变量 `LongPathsEnabled` 为`1 `。

<span id="8544b685"></span>
### `ChatCompletions`接口中`messages` `role`字段中是否要求user 在奇数位，assistant在偶数位？
没有这个要求。
示例:
请求内容
```Python
...
messages = [
        {"role": "system", "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手。"},
        # 重复2个user
        {"role": "user", "content": "常见的十字花科植物有哪些？"},
        {"role": "user", "content": "以下是一些常见的十字花科植物：白菜、甘蓝"},
        {"role": "assistant", "content": "萝卜、花椰菜、芥菜"},
        {"role": "user", "content": "还有么？"},
    ],
...
```

大模型正常返回内容
```Shell
还有油菜、荠菜、独行菜、诸葛菜（二月兰）等。

1. **油菜**
   - 油菜是重要的油料作物。它的茎直立，有分枝，叶片互生，花朵为黄色，呈十字形排列。油菜籽可以用来榨油，菜籽油在日常生活中广泛使用。
2. **荠菜**
   - 荠菜是常见的野菜。基生叶丛生呈莲座状，叶片羽状分裂，它的适应性强，常在田野、路边等地生长。荠菜可以食用，含有丰富的营养成分，如蛋白质、维生素等，可用于包饺子、煮汤等。
3. **独行菜**
   - 为一年生或二年生草本植物。茎直立或斜升，多分枝。叶片狭匙形或倒披针形。独行菜的种子可入药，具有止咳化痰等功效。
4. **诸葛菜（二月兰）**
   - 因农历二月前后开始开蓝紫色花得名。它对环境适应能力强，耐寒旱，多生长于平原、山地、路旁等地。花朵小巧且数量众多，盛花期时具有较高的观赏价值
```

<span id="c850ca01"></span>
### `ChatCompletions`接口中`messages` 字段是否支持只传`role`是`system`？
支持。
示例:
请求内容
```Python
...
messages = [
        {"role": "system", "content": "你是豆包，是由字节跳动开发的 AI 人工智能助手。常见的十字花科植物有哪些？"},
        ...
```

大模型正常返回内容
```Shell
以下是一些常见的十字花科植物：

### 一、蔬菜类
1. **白菜**
   - 包括大白菜、小白菜等。大白菜叶片宽大，是我国北方冬季常见的蔬菜，有青帮、白帮等不同品种，营养丰富，富含维生素C、纤维素等。小白菜植株相对较小，叶片嫩绿，生长周期较短，口感鲜嫩。
2. **甘蓝**
   - **结球甘蓝（卷心菜）**：叶片层层包裹成球状，有绿甘蓝、紫甘蓝之分。它适应性强，耐储存和运输，可用于制作沙拉、炒菜、泡菜等。
   - **花椰菜（菜花）**：花球由肥嫩的花枝顶端聚合而成，颜色洁白或淡黄。西兰花是花椰菜的一个变种，其营养成分含量高，尤其是维生素C、胡萝卜素和叶酸等。
3. **萝卜**
   - 有白萝卜、红萝卜（胡萝卜不属于十字花科，红萝卜属于十字花科）、青萝卜等多种类型。萝卜肉质根可食用，既可生食，如做成凉拌萝卜丝，也可熟食，如萝卜炖排骨。萝卜含有淀粉酶、芥子油等物质，具有助消化、增食欲等功效。
4. **芥菜**
   - **叶用芥菜**：如雪里蕻，叶片深裂，边缘皱缩，有特殊的香辣味。它是制作腌菜的重要原料，腌制后的雪里蕻可用于炒肉末等菜肴。
   - **茎用芥菜（榨菜）**：茎部膨大，形成瘤状凸起，肉质茎是主要食用部分，常用于制作榨菜，是一种常见的佐餐小菜。

### 二、观赏植物类
1. **紫罗兰**
   - 紫罗兰花朵繁茂，花色丰富，有紫色、白色、粉色等。它香气淡雅，花期较长，常被用于布置花坛、花境，也可盆栽观赏。
2. **诸葛菜（二月兰）**
   - 二月兰是一种常见的野花，花朵为淡紫色或白色。它具有较强的适应能力，能自播繁殖，常生长于山坡、草地、路旁等地。在园林中可用于营造野趣景观，也可成片种植形成花海景观。
```

<span id="b556b65f"></span>
### 如何判断使用的V3接口？

* 如直接使用HTTP接口调用，调用路径中出现 `/api/v3`
* 如您使用火山提供的SDK调用，从 `import` 路径判断：
   * 出现 `ark` 字样的为 `v3` API。
   * 出现 `maas` 字样的为 `v1`/`v2` API。

<span id="effccb14"></span>
### **使用视觉理解模型时，报错InvalidParameter？**

* **下载图片超时**： 为防止不必要的带宽浪费，默认图片下载超时时间5s。可能是图片访问速度较慢如外国网站，或者图片较大。对以上情况均建议更换到TOS上或压缩图片至100kB以下。
* **链接禁止访问**：状态码` 403`，部分图片服务器可能存在特殊安全/acl策略，禁止了火山源访问，建议检查客户所用图片服务器（阿里云对象存储/腾讯云对象存储/...）的安全策略。
* **不支持的图片格式，或者图片格式与元数据不匹配：**
   * 以下图片格式根据图片内容前512个字节自动校验：
      
      | | | \
      |图片格式 |Content-Type |
      |---|---|
      | | | \
      |jpg/jpeg |image/jpeg |
      | | | \
      |png |image/png |
      | | | \
      |gif |image/gif |
      | | | \
      |webp |image/webp |
      | | | \
      |bmp |image/bmp |
      | | | \
      |dib |image/bmp |
      | | | \
      |ico |image/x-icon |

   * 以下图片格式根据图片url的元信息（Content-Type）校验，需要正确设置`Content-Type`
      * TOS（火山引擎对象存储） 设置文件元信息请参见：https://www.volcengine.com/docs/6349/145523
      * OSS （阿里云对象存储）设置文件元信息请参见：https://help.aliyun.com/zh/oss/user-guide/configure-the-content-type-header
      
      | | | \
      |图片格式 |Content-Type |
      |---|---|
      | | | \
      |TIFF |`image/tiff` |
      | | | \
      |SGI |`image/sgi` |
      | | | \
      |ICNS |`image/icns` |
      | | | \
      |JPEG2000 |`image/jp2` |


<span id="ba85f512"></span>
### 视觉理解模型使用 token 过大报错怎么处理？
单次请求中，返回token报错过长，可以考虑的处理方式：

1. 如果单次请求中涉及到多张图片，可以考虑减少图片张数。
2. 对图片进行压缩，以减少图片 token 用量，转化关系请参见[token 用量说明](https://www.volcengine.com/docs/82379/1362931#f9ea084e)。
3. 如果涉及到大量的文本提示词，可以考虑简化提示词。

<span id="91505308"></span>
### 并发 RPM 或者 TPM 额度明明有剩余为什么提示限流报错？
方舟对于模型限流的逻辑使用的是预扣机制，来保障您已提交的请求的完成率。即在收到请求时会预估您的输出长度，在限流中进行扣除，避免因为激增的请求或者超长输出等极端情况，瞬时输入输出 token 剧增，导致您已提交的请求大量因为限流而中断输出或直接失败，最后影响到您应用的稳定性。
<span id="2efbd7d0"></span>
### 使用模型进行在线推理时有限流吗？
当前对每个模型设置了 RPM（Requests Per Minute，每分钟请求数）及 TPM（Tokens Per Minute，每分钟 token 数量）的调用限制，每个账号（含主账号下的所有子账号，合并计算）的具体限制可在[开通管理](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?OpenTokenDrawer=false)页中查看。
如需提升，请联系客户经理或者提交[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)。
<span id="428f44d6"></span>
### 为什么高并发请求方舟模型的时候受到了限制？
为了保障平台运行的安全，平台制定了一些针对在线推理的防控策略，对未在火山引擎上充值或历史充值较低的账号，高并发请求模型会被限制。我们默认的并发数可以支持任何用户对平台模型效果进行尝鲜测试和常规使用。如果您有高并发需求，建议预先对账号进行充值。
您也可以使用批量推理的接入点模式（Batch chat），并发限制由此时平台的闲置资源量决定，通常情况下夜间 0 点到次日早上 8 点资源较为充足。
<span id="d3743e3b"></span>
## 批量推理
<span id="48fce2af"></span>
### 在任务状态为：运行中，终止中，已终止，失败的情况时，是否会有部分成功的结果输出？
会，已经运行成功的结果会写到output中，且运行成功的数据会正常计费。但是不保证任务运行顺序。
<span id="c7e33a93"></span>
### 基于什么的准则，去判断“失败”这种状态，是成功与错误比例，还是发现错误即判断失败？
以下情况判断任务失败：

   * 文件输入格式不符合要求，如某一条数据不是json，会在任务开始前检测该类型错误，有错误会判定失败。
   * 预期外的错误，如job崩溃。
   * 任务运行超时。
* 如果存在某条request运行失败，比如安全审核失败。这条request结果会写到error文件夹中，不会导致整体任务失败。

<span id="544b65f6"></span>
### 在子任务数量巨大，无法预估处理所需的时间的前提下，设置的最大等待时间是否有大小上限？
 CompletionWindow的最大等待时间最大可设置为28天。如果不指定，默认为28天。
<span id="26324f4b"></span>
### 若由于超时使得批量推理任务状态为“已终止”，在终止之前所做的任务处理结果是否还有保留？
会保留，结果写在output中。
<span id="71cf8a1b"></span>
### 输出长度是4k还是6k，亦或是其他？
限制与在线推理相同，输出超过限制会截断。
<span id="b4b42090"></span>
### 批量推理按 tokens 用量计费，是按照输入tokens，或是输出tokens，又或是两者之和？
与在线推理相同，计费按照模型处理的内容量，输入输出都需要计费。
<span id="1e98eaca"></span>
### 对于处理失败的结果，也就是errors.jsonl中的结果，如何计费？
处理失败的结果不计费。
<span id="0e1166f9"></span>
## 精调
<span id="25850d2c"></span>
### 模型精调任务数有限制吗？
每个账号会有最多可同时创建运行中的精调任务数的限制，具体限制请见控制台报错提示，若到达上限的，请耐心等待精调任务完成并释放额度后重试，或在[配额中心](https://console.volcengine.com/quota/productList/coParameterList?ProviderCode=MaaS)中提交申请更多额度。
<span id="5e8ec656"></span>
## TPM保障包
<span id="68fbdc33"></span>
### 保障包是否可以与上下文缓存 Context Cache 一起使用？
暂不支持，后续版本中会支持。
<span id="e73b6ef5"></span>
### 如何判断某个请求在保障包的保障范畴？ 
当请求输入时，我们会根据购买保障包的输入与输出比例预估请求的总Token数量，并按照预估长度扣减保障包的输入、输出保障额度。当预估输入和预估输出额度都在保障包额度范围内，此次请求会被保障。如不在保障范围内，将按照未使用TPM保障包计费，**按Token计费**。
<span id="09a60616"></span>
### 怎么保障分小时的保障包能购买成功？
长期通过产品功能支持，短期内如有明确峰值保障需求，请联系客户经理或者[工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)联系我们。

<span id="5bcf163a"></span>
## 其他问题
<span id="c610a875"></span>
### 页面提示“当前页面最低需要ArkReadOnlyAccess（只读权限）才能操作，请先完成权限开通。”要怎么配置权限？
使用主账号或者有IAM权限的账号，访问 [访问控制 > 用户](https://console.volcengine.com/iam/policymanage) 页面并搜索子账号id，进入子账号 用户详情 页面，确认子账号目前的权限。

* 若目前权限为空或只有ArkExperienceAccess（体验权限），则表明子账号权限策略设置错误。请您根据业务需要为子账号添加ArkReadOnlyAccess（只读权限）或者更高的权限，可以在[产品预设策略](https://www.volcengine.com/docs/82379/1263493#产品预设策略)中查看详细的权限说明。
   * 在 [访问控制 > 用户](https://console.volcengine.com/iam/policymanage) 页面搜索子账号id，点击右侧操作中 添加权限 按钮，「授权策略」选择ArkReadOnlyAccess或更大权限，「限制到项目资源」选择「否」，完成后点击提交即可。
* 若目前子账号已经拥有ArkReadOnlyAccess（只读权限）或更高的权限，则可能因为权限策略做了项目隔离，子账号没有对应项目的权限。请按照[典型场景-赋予账号项目级权限](https://www.volcengine.com/docs/82379/1263493#68d11b0c)配置正确的权限。

<span id="03ec4a65"></span>
### 如何获取项目名称（Project Name）？

* 字节云方舟用户请在 [字节云方舟控制台](https://cloud.bytedance.net/ark/region:ark+cn-beijing/overview?arkAccountId=2100583673&arkProjectName=default&type=&x-bc-region-id=bytedance&x-resource-account=public) > 左上角切换项目空间 > 左侧导航栏**基本信息**上查询。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b903e42d9b5b413699f70e10147fbb48~tplv-goo7wpa0wc-image.image =428x)

* 火山引擎方舟用户可在[方舟控制台](https://console.volcengine.com/ark/region:ark+cn-beijing/overview?briefPage=0&briefType=introduce&type=new)顶部导航栏查看项目名称。


![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/6f829de9539244e78e3c8878860a8658~tplv-goo7wpa0wc-image.image =536x)



# 模型列表
Source: https://www.volcengine.com/docs/82379/1330310
方舟提供丰富的模型，供您使用。您可以根据教程或API说明方便地将模型服务结合到您的业务中。
<span id="5970ff45"></span>
# 模型推荐

| | | | | \
|[doubao-seed-1.6 ](https://www.volcengine.com/docs/82379/1593702) |\
|<div style="width:25%"></div> |[doubao-seed-1.6-flash](https://www.volcengine.com/docs/82379/1593704) |\
| |<div style="width:25%"></div> |[doubao-seed-1.6-thinking](https://www.volcengine.com/docs/82379/1593703) |\
| | |<div style="width:25%"></div> |[deepseek-r1](https://www.volcengine.com/docs/82379/1554373) |\
| | | |<div style="width:25%"></div> |
|---|---|---|---|
| | | | | \
|全新多模态深度思考模型，同时支持 `thinking`、`non-thinking`、`auto`三种思考模式。其中` non-thinking` 模型对比 `doubao-1-5-pro-32k-250115` 模型大幅提升。 |\
| |\
|* 支持 **256k** 上下文长度，支持 **224k** 输入长度 |\
|* [可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) **32k** ，或配置最大输出（回答+思维链）长度 **64k** |\
|* 可支持图文、视频理解 |有极致推理速度的多模态深度思考模型；同时支持文本和视觉理解。文本理解能力超过上一代 Lite 系列模型，视觉理解比肩友商 Pro 系列模型。 |\
| | |\
| |* 支持 **256k** 上下文长度，支持 **224k** 输入长度 |\
| |* [可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) **32k** ，或配置最大输出（回答+思维链）长度 **64k** |\
| |* 可支持图文、视频理解 |在思考能力上进行了大幅强化， 对比 doubao 1.5 代深度理解模型，在编程、数学、逻辑推理等基础能力上进一步提升， 支持视觉理解。 |\
| | | |\
| | |* 支持 **256k** 上下文长度 |\
| | |* 支持 **224k** 输入长度、 **32k** 思维链内容 |\
| | |* [可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) **16k**   |\
| | |* 可支持图文、视频理解 |deepseek-r1 在后训练阶段大规模使用了强化学习技术，在数学、代码、自然语言推理等任务上，能力比肩 OpenAI o1 正式版。 |\
| | | | |\
| | | |* 支持 **128k** 上下文长度，支持 **96k** 最大输入 |\
| | | |* [可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) **32k** ，或配置最大输出（回答+思维链）长度 **64k** |\
| | | |* 高性能，满血版 |

<span id="898d064d"></span>
# 深度思考能力
教程：[深度思考](https://www.volcengine.com/docs/82379/1449737) |   API：[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384#RxN8G2nH)

| | | | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |模型能力 |\
| | | |<div style="width:150px"></div> |最大上下文长度 |\
| | | | |(token) |\
| | | | |> 上下文长度=输入长度+回答长度+思维链长度 |\
| | | | | |\
| | | | |<div style="width:150px"></div> |最大输入长度 |\
| | | | | |(token) |[可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) |\
| | | | | | |(token) |思维链最大输出长度 |\
| | | | | | | |(token) |\
| | | | | | | |> 独占，不共享给输入/输出，见[说明](https://www.volcengine.com/docs/82379/1449737#%E9%99%84-%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6%E9%99%90%E5%88%B6%E8%AF%B4%E6%98%8E) |\
| | | | | | | | |\
| | | | | | | |<div style="width:150px"></div> |模型默认限流 |\
| | | | | | | | |<div style="width:140px"></div> |**免费额度** |\
| | | | | | | | | |（token） |**定价** |\
| | | | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | | | \
|[doubao-seed-1.6 ](https://www.volcengine.com/docs/82379/1593702) |250615`强烈推荐` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-seed-1-6-250615 |深度思考 |\
| | | |文本生成 |\
| | | |图片理解 |\
| | | |视频理解 |\
| | | |工具调用 |\
| | | |结构化输出 |256k |224k |32k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-seed-1.6-flash](https://www.volcengine.com/docs/82379/1593704) |250615`推荐` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-seed-1-6-flash-250615 |深度思考 |\
| | | |文本生成 |\
| | | |图片理解 |\
| | | |视觉定位 |\
| | | |视频理解 |\
| | | |工具调用 |\
| | | |结构化输出 |256k |224k |32k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-seed-1.6-thinking](https://www.volcengine.com/docs/82379/1593703) |250615  |doubao-seed-1-6-thinking-250615 |深度思考 |\
| | | |图片理解 |\
| | | |视频理解 |\
| | | |工具调用 |\
| | | |结构化输出 |256k |224k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-1.5-thinking-vision-pro](https://www.volcengine.com/docs/82379/1554521) |250428` 强烈推荐` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-1-5-thinking-vision-pro-250428 |深度思考 |\
| | | |图片理解 |\
| | | |视觉定位 |\
| | | |视频理解 |\
| | | |工具调用 |\
| | | |结构化输出 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[deepseek-r1](https://www.volcengine.com/docs/82379/1554373) |250528`推荐` |deepseek-r1-250528 |深度思考 |\
| | | |工具调用 |\
| | | |结构化输出 |128k |96k |32k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |


往期模型

| | | | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |模型能力 |\
| | | |<div style="width:150px"></div> |最大上下文长度 |\
| | | | |(token) |\
| | | | |> 上下文长度=输入长度+回答长度+思维链长度 |\
| | | | | |\
| | | | |<div style="width:150px"></div> |最大输入长度 |\
| | | | | |(token) |[可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) |\
| | | | | | |(token) |思维链最大输出长度 |\
| | | | | | | |(token) |\
| | | | | | | |> 独占，不共享给输入/输出，见[说明](https://www.volcengine.com/docs/82379/1449737#%E9%99%84-%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6%E9%99%90%E5%88%B6%E8%AF%B4%E6%98%8E) |\
| | | | | | | | |\
| | | | | | | |<div style="width:150px"></div> |模型默认限流 |\
| | | | | | | | |<div style="width:140px"></div> |**免费额度** |\
| | | | | | | | | |（token） |**定价** |\
| | | | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | | | \
|[doubao-1.5-thinking-pro](https://www.volcengine.com/docs/82379/1536428) |250415  |\
| |> 推荐升级至`doubao-seed-1-6-thinking-250615` |\
| | |\
| | |doubao-1-5-thinking-pro-250415 |深度思考 |\
| | | |工具调用 |\
| | | |结构化输出 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000  |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
|^^| | | | | | | | | | | \
| |m-250428  |\
| |> 推荐升级至`doubao-seed-1-6-250615` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |\
| | |\
| | |doubao-1-5-thinking-pro-m-250428 |深度思考 |\
| | | |图片理解 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000  |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
|^^| | | | | | | | | | | \
| |m-250415 |\
| |> 推荐升级至`doubao-seed-1-6-thinking-250615` |doubao-1-5-thinking-pro-m-250415 |深度思考 |\
| | | |图片理解 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-1.5-vision-pro](https://www.volcengine.com/docs/82379/1553586) |250328 |\
| |> 推荐升级至`doubao-1-5-thinking-vision-pro-250428` |doubao-1-5-vision-pro-250328 |图片理解 |\
| | | |视频理解 |\
| | | |深度思考 |\
| | | |> 可通过设置系统消息开启深度思考 |\
| | | | |\
| | | |结构化输出 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[视觉理解模型](https://www.volcengine.com/docs/82379/1544106#d52e5943) |
| | | | | | | | | | | | \
|[deepseek-r1](https://www.volcengine.com/docs/82379/1554373) |250120 |\
| |> 推荐升级至deepseek-r1-250528 |deepseek-r1-250120 |深度思考 |\
| | | |工具调用 |96k |64k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
|^^| | | | | | | | | | | \
| |distill-qwen-32b-250120 |deepseek-r1-distill-qwen-32b-250120 |深度思考 |64k |32k |8k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
|^^| | | | | | | | | | | \
| |distill-qwen-7b-250120 |deepseek-r1-distill-qwen-7b-250120 |深度思考 |64k |32k |8k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |

<span id="ff5ef604"></span>
# 视觉理解能力
教程：[视觉理解](https://www.volcengine.com/docs/82379/1362931) |   API：[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384#RxN8G2nH)

| | | | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**最大上下文长度** |\
| | | | |(token) |\
| | | | |> 上下文长度=输入长度+回答长度+思维链长度 |\
| | | | | |\
| | | | |<div style="width:150px"></div> |最大输入长度 |\
| | | | | |(token) |[可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) |\
| | | | | | |(token) |思维链最大输出长度 |\
| | | | | | | |(token) |模型默认限流 |\
| | | | | | | | |<div style="width:140px"></div> |**免费额度** |\
| | | | | | | | | |（token） |**定价** |\
| | | | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | | | \
|[doubao-seed-1.6 ](https://www.volcengine.com/docs/82379/1593702) |250615 |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-seed-1-6-250615 |**图片理解** |\
| | | |**视频理解** |\
| | | |深度思考 |\
| | | |文本生成 |\
| | | |工具调用 |\
| | | |结构化输出 |256k |224k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-seed-1.6-flash](https://www.volcengine.com/docs/82379/1593704) |250615 `推荐` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-seed-1-6-flash-250615 |**图片理解** |\
| | | |**视频理解** |\
| | | |**视觉定位** |\
| | | |深度思考 |\
| | | |文本生成 |\
| | | |工具调用 |\
| | | |结构化输出 |256k |224k |32k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-seed-1.6-thinking](https://www.volcengine.com/docs/82379/1593703) |250615 |doubao-seed-1-6-thinking-250615 |**图片理解** |\
| | | |**视频理解** |\
| | | |深度思考 |\
| | | |工具调用 |\
| | | |结构化输出 |256k |224k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-1.5-thinking-vision-pro](https://www.volcengine.com/docs/82379/1554521) |250428 `强烈推荐` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-1-5-thinking-vision-pro-250428 |**图片理解** |\
| | | |**视频理解** |\
| | | |**视觉定位** |\
| | | |深度思考 |\
| | | |工具调用 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-1.5-ui-tars](https://www.volcengine.com/docs/82379/1536429) |250428 `推荐` |\
| |> 图形界面操作场景推荐 |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-1-5-ui-tars-250428 |**图片理解** |\
| | | |图形界面操作 |\
| | | |深度思考 |128k |96k |16k |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[视觉理解模型](https://www.volcengine.com/docs/82379/1544106#d52e5943) |


**往期模型**

| | | | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**最大上下文长度** |\
| | | | |(token) |\
| | | | |> 上下文长度=输入长度+回答长度+思维链长度 |\
| | | | | |\
| | | | |<div style="width:150px"></div> |最大输入长度 |\
| | | | | |(token) |[可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) |\
| | | | | | |(token) |思维链最大输出长度 |\
| | | | | | | |(token) |模型默认限流 |\
| | | | | | | | |<div style="width:140px"></div> |**免费额度** |\
| | | | | | | | | |（token） |**定价** |\
| | | | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | | | \
|[doubao-1.5-thinking-pro](https://www.volcengine.com/docs/82379/1536428) |m-250428 |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-1-5-thinking-pro-m-250428 |**图片理解** |\
| | | |深度思考 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000  |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
|^^| | | | | | | | | | | \
| |m-250415 |\
| |> 推荐升级至`doubao-seed-1-6-thinking-250615` |doubao-1-5-thinking-pro-m-250415 |**图片理解** |\
| | | |深度思考 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-1.5-vision-pro](https://www.volcengine.com/docs/82379/1553586) |250328 |\
| |> 推荐升级至`doubao-1-5-thinking-vision-pro-250428` |doubao-1-5-vision-pro-250328 |**图片理解** |\
| | | |**视频理解** |\
| | | |深度思考 |\
| | | |> 可通过设置系统消息开启深度思考 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000  |[视觉理解模型](https://www.volcengine.com/docs/82379/1544106#d52e5943) |
| | | | | | | | | | | | \
| |32k-250115 |doubao-1-5-vision-pro-32k-250115 |**图片理解** |\
| | | |工具调用 |32k |\- |12k  |\
| | | | | | |默认 4k |\- |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000  |[视觉理解模型](https://www.volcengine.com/docs/82379/1544106#d52e5943) |
| | | | | | | | | | | | \
|[doubao-1.5-vision-lite](https://www.volcengine.com/docs/82379/1554516) |250315 |doubao-1-5-vision-lite-250315 |**图片理解** |128k |\- |16k  |\
| | | | | | |默认 4k |\- |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000  |[视觉理解模型](https://www.volcengine.com/docs/82379/1544106#d52e5943) |
| | | | | | | | | | | | \
|[doubao-1.5-ui-tars](https://www.volcengine.com/docs/82379/1536429) |250328  |\
| |> 图形界面操作场景推荐 |doubao-1-5-ui-tars-250328 |**图片理解** |\
| | | |图形界面操作 |32k |\- |4k |\
| | | | | | |默认 4k |\- |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[视觉理解模型](https://www.volcengine.com/docs/82379/1544106#d52e5943) |
| | | | | | | | | | | | \
|[doubao-vision-pro](https://www.volcengine.com/docs/82379/1554677) |32k-241028 |doubao-vision-pro-32k-241028 |图片理解 |32k |\- |4k |\
| | | | | | |默认 4k |\- |15000 RPM |\
| | | | | | | | |1200000 TPM |500,000  |[视觉理解模型](https://www.volcengine.com/docs/82379/1544106#d52e5943) |
| | | | | | | | | | | | \
|[doubao-vision-lite](https://www.volcengine.com/docs/82379/1554673) |32k-241015 |doubao-vision-lite-32k-241015 |图片理解 |32k |\- |4k |\
| | | | | | |默认 4k |\- |15000 RPM |\
| | | | | | | | |1200000 TPM |500,000  |[视觉理解模型](https://www.volcengine.com/docs/82379/1544106#d52e5943) |

<span id="71fe225f"></span>
# GUI 任务处理能力
教程：[GUI 任务处理](https://www.volcengine.com/docs/82379/1584296) |   API：[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384#RxN8G2nH)

| | | | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**最大上下文长度** |\
| | | | |(token) |\
| | | | |> 上下文长度=输入长度+回答长度+思维链长度 |\
| | | | | |\
| | | | |<div style="width:150px"></div> |最大输入长度 |\
| | | | | |(token) |[可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) |\
| | | | | | |(token) |思维链最大输出长度 |\
| | | | | | | |(token) |模型默认限流 |\
| | | | | | | | |<div style="width:140px"></div> |**免费额度** |\
| | | | | | | | | |（token） |**定价** |\
| | | | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | | | \
|[doubao-1.5-ui-tars](https://www.volcengine.com/docs/82379/1536429) |250428 `强烈推荐` |\
| |> 图形界面操作场景推荐 |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-1-5-ui-tars-250428 |**图片理解** |\
| | | |图形界面操作 |\
| | | |深度思考 |128k |96k |16k |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[视觉理解模型](https://www.volcengine.com/docs/82379/1544106#d52e5943) |
|^^| | | | | | | | | | | \
| |250328  |\
| |> 图形界面操作场景推荐 |doubao-1-5-ui-tars-250328 |**图片理解** |\
| | | |图形界面操作 |32k |\- |4k |\
| | | | | | |默认 4k |\- |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[视觉理解模型](https://www.volcengine.com/docs/82379/1544106#d52e5943) |
| | | | | | | | | | | | \
|[doubao-1.5-thinking-vision-pro](https://www.volcengine.com/docs/82379/1554521) |250428 `推荐` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-1-5-thinking-vision-pro-250428 |**图片理解** |\
| | | |**视频理解** |\
| | | |**视觉定位** |\
| | | |深度思考 |\
| | | |工具调用 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |

<span id="15a31773"></span>
# 文本生成能力
教程：[文本生成](https://www.volcengine.com/docs/82379/1399009) |   API：[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384#RxN8G2nH)

| | | | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**最大上下文长度** |\
| | | | |(token) |\
| | | | |> 上下文长度=输入长度+回答长度+思维链长度 |\
| | | | | |\
| | | | |<div style="width:150px"></div> |最大输入长度 |\
| | | | | |(token) |[可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) |\
| | | | | | |(token) |思维链最大输出长度 |\
| | | | | | | |(token) |模型默认限流 |\
| | | | | | | | |<div style="width:120px"></div> |\
| | | | | | | | | |**免费额度** |\
| | | | | | | | | |（token） |**定价** |\
| | | | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | | | \
|[doubao-seed-1.6 ](https://www.volcengine.com/docs/82379/1593702) |250615`强烈推荐` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-seed-1-6-250615 |深度思考 |\
| | | |文本生成 |\
| | | |图片理解 |\
| | | |视频理解 |\
| | | |工具调用 |\
| | | |结构化输出 |256k |224k |32k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-seed-1.6-flash](https://www.volcengine.com/docs/82379/1593704) |250615`推荐` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-seed-1-6-flash-250615 |深度思考 |\
| | | |文本生成 |\
| | | |视觉定位 |\
| | | |图片理解 |\
| | | |视频理解 |\
| | | |工具调用 |\
| | | |结构化输出 |256k |224k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[deepseek-v3](https://www.volcengine.com/docs/82379/1519547) |250324 |deepseek-v3-250324 |文本生成 |\
| | | |工具调用 |128k |\- |16k  |\
| | | | | | |默认 4k |\- |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000  |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |

**往期模型**

| | | | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**最大上下文长度** |\
| | | | |(token) |\
| | | | |> 上下文长度=输入长度+回答长度+思维链长度 |\
| | | | | |\
| | | | |<div style="width:150px"></div> |最大输入长度 |\
| | | | | |(token) |[可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) |\
| | | | | | |(token) |思维链最大输出长度 |\
| | | | | | | |(token) |模型默认限流 |\
| | | | | | | | |<div style="width:120px"></div> |\
| | | | | | | | | |**免费额度** |\
| | | | | | | | | |（token） |**定价** |\
| | | | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | | | \
|[deepseek-v3](https://www.volcengine.com/docs/82379/1519547) |241226 |deepseek-v3-241226 |文本生成 |64k |\- |16k  |\
| | | | | | |默认 4k |\- |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000  |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
| | | | | | | | | | | | \
|[doubao-1.5-pro-32k](https://www.volcengine.com/docs/82379/1554678) |250115 |\
| |> 推荐升级至doubao-seed-1-6-250615 |doubao-1-5-pro-32k-250115 |文本生成 |\
| | | |工具调用 |升级至128k |\- |升级至16k |\
| | | | | | |默认 4k |\- |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |\
| | | | | | | | | | | |
|^^| | | | | | | |^^| | | \
| |character-250228 |doubao-1-5-pro-32k-character-250228 |文本生成 |\
| | | |> 角色扮演场景增强 |32k |\- |12k |\
| | | | | | |默认 4k |\- | | |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
| | | | | | | | | | | | \
|[doubao-1.5-pro-256k](https://www.volcengine.com/docs/82379/1554682) |250115 |\
| |> 推荐升级至doubao-seed-1-6-250615 |doubao-1-5-pro-256k-250115 |文本生成 |256k |\- |12k |\
| | | | | | |默认 4k |\- |2000 RPM |\
| | | | | | | | |400000 TPM |500,000 |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
| | | | | | | | | | | | \
|[doubao-1.5-lite](https://www.volcengine.com/docs/82379/1554679) |250115 |\
| |> 推荐升级至`doubao-seed-1-6-flash-250615` |doubao-1-5-lite-32k-250115 |文本生成 |\
| | | |工具调用 |32k |\- |12k |\
| | | | | | |默认 4k |\- |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
| | | | | | | | | | | | \
|[doubao-pro-32k](https://www.volcengine.com/docs/82379/1554680) |241215 |doubao-pro-32k-241215 |文本生成  |32k |\- |4k |\- |15000 RPM |\
| | | | | | | | |1200000 TPM |500,000 |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
|^^| | | | | | | |^^|^^| | \
| |240828 |doubao-pro-32k-240828 |文本生成  |\
| | | |工具调用 |32k |\- |4k |\- | | |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
|^^| | | | | | | |^^|^^| | \
| |functioncall-241028 |doubao-pro-32k-functioncall-241028 |文本生成 |\
| | | |工具调用 |32k |\- |4k |\- | | |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
|^^| | | | | | | |^^|^^| | \
| |functioncall-preview |doubao-pro-32k-functioncall-preview |文本生成 |\
| | | |工具调用 |32k |\- |4k |\- | | |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
|^^| | | | | | | |^^|^^| | \
| |browsing-241115 |\
| |> 默认不联网，需要结合[联网插件 数据结构](https://www.volcengine.com/docs/82379/1285209)使用。 |doubao-pro-32k-browsing-241115 |文本生成 |\
| | | | |32k |\- |4k |\- | | |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
|^^| | | | | | | |^^|^^| | \
| |browsing-240828 |\
| |> 默认不联网，需要结合[联网插件 数据结构](https://www.volcengine.com/docs/82379/1285209)使用。 |doubao-pro-32k-browsing-240828 |文本生成 |\
| | | | |32k |\- |4k |\- | | |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
|^^| | | | | | | |^^|^^| | \
| |character-241215 |\
| |> 角色扮演场景增强 |doubao-pro-32k-character-241215 |文本生成 |\
| | | |> 角色扮演场景增强 |32k |\- |4k |\- | | |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
|^^| | | | | | | |^^|^^| | \
| |character-240828 |\
| |> 角色扮演场景增强 |doubao-pro-32k-character-240828 |文本生成 |\
| | | | |32k |\- |4k |\- | | |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
| | | | | | | | | | | | \
|[doubao-pro-256k](https://www.volcengine.com/docs/82379/1554681) |241115 |doubao-pro-256k-241115 |文本生成 |256k |\- |4k |\- |2000 RPM |\
| | | | | | | | |400000 TPM |500,000 |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
| | | | | | | | | | | | \
|[doubao-lite-4k](https://www.volcengine.com/docs/82379/1554659) |character-240828 |\
| |> 角色扮演场景增强 |doubao-lite-4k-character-240828 |文本生成 |\
| | | | |4k |\- |4k |\- |15000 RPM |\
| | | | | | | | |1200000 TPM |500,000 |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
| | | | | | | | | | | | \
|[doubao-lite-32k](https://www.volcengine.com/docs/82379/1554660) |240828 |doubao-lite-32k-240828 |文本生成  |\
| | | |工具调用 |32k |\- |4k |\- |15000 RPM |\
| | | | | | | | |1200000 TPM |500,000 |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
|^^| | | | | | | |^^|^^| | \
| |character-250228 |\
| |> 角色扮演场景增强 |doubao-lite-32k-240628 |文本生成 |\
| | | | |32k |\- |4k |\- | | |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
|^^| | | | | | | |^^|^^| | \
| |character-241015 |\
| |> 角色扮演场景增强 |doubao-lite-32k-character-241015 |文本生成 |32k |\- |4k |\- | | |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |
| | | | | | | | | | | | \
|[doubao-lite-128k](https://www.volcengine.com/docs/82379/1554661) |240828 |doubao-lite-128k-240828 |文本生成 |\
| | | |工具调用 |128k |\- |4k |\- |15000 RPM |\
| | | | | | | | |1200000 TPM |500,000 |[大语言模型](https://www.volcengine.com/docs/82379/1544106#1ed6d674) |

<span id="5d9e965a"></span>
## 
<span id="56cc9564"></span>
# 视频生成能力
教程：[视频生成](https://www.volcengine.com/docs/82379/1366799)  | API：[视频生成 API](https://www.volcengine.com/docs/82379/1520758)

| | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |**模型 ID（Model ID）** |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**输出视频格式** |\
| | | | |<div style="width:120px"></div> |**RPM 限流** |\
| | | | | |创建视频生成任务时，每分钟发送的请求数 |\
| | | | | |<div style="width:100px"></div> |**并发数限制** |**免费额度** |\
| | | | | | | |（token） |**定价** |\
| | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | \
|[doubao-seedance-1.0-pro](https://www.volcengine.com/docs/82379/1587798) |250528`强烈推荐` |doubao-seedance-1-0-pro-250528 |文生视频 |\
| | | |图生视频-基于首帧 |分辨率：480p，1080p |\
| | | | |帧率：24 fps |\
| | | | |时长：5 秒，10秒 |600 |10 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |
| | | | | | | | | | \
|[doubao-seedance-1.0-lite](https://www.volcengine.com/docs/82379/1553576) |250428 `推荐` |doubao-seedance-1-0-lite-t2v-250428 |文生视频 |分辨率：480p，720p，1080p |\
| | | | |帧率：24 fps |\
| | | | |时长：5 秒，10秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |
|^^| | | | | | | | | \
| |250428`推荐` |doubao-seedance-1-0-lite-i2v-250428 |图生视频-基于首帧或首尾帧 |\
| | | |> 首尾帧不支持1080p |\
| | | | |\
| | | | |分辨率：480p，720p，1080p |\
| | | | |帧率：24 fps |\
| | | | |时长：5 秒，10秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |
| | | | | | | | | | \
|[wan2.1-14b](https://www.volcengine.com/docs/82379/1556464) |t2v-250225 |wan2-1-14b-t2v-250225 |文生视频 |分辨率：480p，720p |\
| | | | |帧率：16 fps |\
| | | | |时长：5 秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |
|^^| | | | | | | | | \
| |i2v-250225 |wan2-1-14b-i2v-250225 |图生视频-基于首帧 |分辨率：480p，720p |\
| | | | |帧率：16 fps |\
| | | | |时长：5 秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |
|^^| | | | | | | | | \
| |flf2v-250417 |wan2-1-14b-flf2v-250417 |图生视频-基于首尾帧 |分辨率：720p |\
| | | | |帧率：16 fps |\
| | | | |时长：5 秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |


**往期模型**

| | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |**模型 ID（Model ID）** |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**输出视频格式** |\
| | | | |<div style="width:120px"></div> |**RPM 限流** |\
| | | | | |每分钟发送的请求数 |\
| | | | | |<div style="width:120px"></div> |**并发数限制** |**免费额度** |\
| | | | | | | |（token） |**定价** |\
| | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | \
|doubao-seaweed |241128 |doubao-seaweed-241128 |文生视频 |\
| | | |图生视频-基于首帧 |分辨率：480p，720p |\
| | | | |帧率：24 fps |\
| | | | |时长： |\
| | | | | |\
| | | | |* 文生视频：5 秒/10秒 |\
| | | | |* 图生视频：5 秒 |300 |5 |200万 |[视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8) |


<span id="d3e5e0eb"></span>
# 图片生成能力
教程：[图片生成](https://www.volcengine.com/docs/82379/1548482) | API：[文生图API](https://www.volcengine.com/docs/82379/1541523)

| | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**限流 IPM** |\
| | | | |每分钟生成图片数量上限 |\
| | | | |（张 / 分钟） |定价 |
|---|---|---|---|---|---|
| | | | | | | \
|[doubao-seedream-3.0-t2i](https://www.volcengine.com/docs/82379/1555133) |250415`强烈推荐` |doubao-seedream-3-0-t2i-250415 |文生图 |500 |[图片生成模型](https://www.volcengine.com/docs/82379/1544106#5e813e2f) |

**往期模型**

| | | | | | | \
|**模型名称** |**版本** |**模型能力** |**QPS** |\
| | | |每秒请求上限（次） |**免费额度** |\
| | | | |（次） |**定价** |
|---|---|---|---|---|---|
| | | | | | | \
|[doubao-文生图模型-智能绘图](https://www.volcengine.com/docs/6791/1279296) |[介绍文档](https://www.volcengine.com/docs/6791/1279296) |文生图 |1 |200  |[介绍文档](https://www.volcengine.com/docs/6791/1279296) |
| | | | | | | \
|[doubao-文生图模型-智能绘图（漫画版）](https://www.volcengine.com/docs/6793/173356) |[介绍文档](https://www.volcengine.com/docs/6793/173356) |文生图 |1 |200 |[介绍文档](https://www.volcengine.com/docs/6793/173356) |

<span id="98fee2f1"></span>
# 工具调用能力
教程：[工具调用 Function Calling](https://www.volcengine.com/docs/82379/1262342) | API：[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384#RxN8G2nH)

| | | | \
|模型名称 |版本 |模型 ID |
|---|---|---|
| | | | \
|[doubao-seed-1.6 ](https://www.volcengine.com/docs/82379/1593702) |250615 |doubao-seed-1-6-250615 |
| | | | \
|[doubao-seed-1.6-thinking](https://www.volcengine.com/docs/82379/1593703) |250615 |doubao-seed-1-6-thinking-250615 |
| | | | \
|[doubao-seed-1.6-flash](https://www.volcengine.com/docs/82379/1593704) |250615 |doubao-seed-1-6-flash-250615 |
| | | | \
|[doubao-1.5-pro-32k](https://www.volcengine.com/docs/82379/1554678) |250115 |doubao-1-5-pro-32k-250115 |
| | | | \
|[doubao-1.5-lite](https://www.volcengine.com/docs/82379/1554679) |250115 |doubao-1-5-lite-32k-250115 |
| | | | \
|[doubao-1.5-vision-pro](https://www.volcengine.com/docs/82379/1553586) |pro-250115 |doubao-1-5-vision-pro-32k-250115 |
| | | | \
|[doubao-1.5-thinking-pro](https://www.volcengine.com/docs/82379/1536428) |250415 |doubao-1-5-thinking-pro-250415 |
| | | | \
|[doubao-1.5-thinking-vision-pro](https://www.volcengine.com/docs/82379/1554521) |250428 |doubao-1-5-thinking-vision-pro-250428 |
| | | | \
|[deepseek-r1](https://www.volcengine.com/docs/82379/1554373) |250528 |deepseek-r1-250528 |
|^^| | | \
| |250120 |deepseek-r1-250120 |
| | | | \
|[deepseek-v3](https://www.volcengine.com/docs/82379/1519547) |250324 |deepseek-v3-250324 |

往期模型

| | | | | \
|模型名称 |版本 |模型 ID |\
| | |<div style="width:150px"></div> |备注 |\
| | | |<div style="width:200px"></div> |
|---|---|---|---|
| | | | | \
|[doubao-pro-32k](https://www.volcengine.com/docs/82379/1554680) |functioncall-preview |doubao-pro-32k-functioncall-preview | |
|^^| | | | \
| |functioncall-241028 |doubao-pro-32k-functioncall-241028 |效果好， 并且推理速度快； |\
| | | |支持FC SFT精调 |
|^^| | | | \
| |241215 |doubao-pro-32k-241215 |效果好，速度一般； |\
| | | |支持FC SFT精调 |
|^^| | | | \
| |240828 |doubao-pro-32k-240828 |支持FC SFT精调 |
| | | | | \
|[doubao-lite-32k](https://www.volcengine.com/docs/82379/1554660) |240828 |doubao-lite-32k-240828 |适用于对延迟敏感、工具调用效果要求相对宽松的场景 |
| | | | | \
|[doubao-lite-128k](https://www.volcengine.com/docs/82379/1554661) |240828 |doubao-lite-128k-240828 |适用于对延迟敏感、工具调用效果要求相对宽松的场景 |


<span id="cb87a288"></span>
# 同声传译能力
教程：[同声传译](https://www.volcengine.com/docs/82379/1433754) | 文档：[同声传译API](https://www.volcengine.com/docs/82379/1394617)

| | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**主账号下同时在线连接数** |**单连接最大连接时长** |\
| | | | | |**（小时）** |**单连接静默持续时长**  |\
| | | | | | |**（小时）** |**免费额度** |\
| | | | | | | |**(token)** |**定价** |\
| | | | | | | | |元 / 千 tokens |
|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | \
|doubao-同声传译 |\
| |241215 |doubao-clasi-s2t-241215 |语音转文本 |\
| | | |语音翻译 |10 |2 |0.5 |500k |[同声传译模型](https://www.volcengine.com/docs/82379/1544106#f7e78cb1) |


<span id="5fa3ded4"></span>
# 文本向量化能力
教程：[文本向量化](https://www.volcengine.com/docs/82379/1583857) | API：[文本向量化 API](https://www.volcengine.com/docs/82379/1521766)

| | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**最大上下文长度** |\
| | | | |(token) |**最高向量维度** |\
| | | | | | |模型默认限流 |\
| | | | | | |<div style="width:120px"></div> |**免费额度** |\
| | | | | | | |（token） |**定价** |\
| | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | \
|[doubao-embedding-large](https://www.volcengine.com/docs/82379/1554711) |text-250515 |doubao-embedding-large-text-250515 |向量检索 |\
| | | |> 支持中英文双语 |4k |2048 |1000 RPM |\
| | | | | | |800000 TPM |500,000 |[文本向量模型](https://www.volcengine.com/docs/82379/1544106#e68ea83c) |
|^^| | | | | | |^^| | \
| |text-240915 |doubao-embedding-large-text-240915 |向量检索 |\
| | | |> 支持中英文双语 |4k |4096 |1000 RPM |\
| | | | | | |800000 TPM | |[文本向量模型](https://www.volcengine.com/docs/82379/1544106#e68ea83c) |
| | | | | | | | | | \
|[doubao-embedding](https://www.volcengine.com/docs/82379/1554710) |text-240715 |doubao-embedding-text-240715 |文本向量化 |\
| | | |> 支持中英文双语 |4k |2560 |1200 RPM |\
| | | | | | |1200000 TPM |500,000 |[文本向量模型](https://www.volcengine.com/docs/82379/1544106#e68ea83c) |
|^^| | | | | |^^|^^| | \
| |text-240515 |doubao-embedding-text-240515 |文本向量化 |\
| | | |> 支持中英文双语 |4k |2048 | | |[文本向量模型](https://www.volcengine.com/docs/82379/1544106#e68ea83c) |

<span id="ee5ec35c"></span>
# 图像向量化能力
教程：[图像向量化](https://www.volcengine.com/docs/82379/1409291) | API：[图像向量化 API](https://www.volcengine.com/docs/82379/1523520) 

| | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |**模型能力** |\
| | | |<div style="width:150px"></div> |**最大上下文长度** |\
| | | | |(token) |**最高向量维度** |\
| | | | | | |模型默认限流 |\
| | | | | | |<div style="width:120px"></div> |**免费额度** |\
| | | | | | | |（token） |**定价** |\
| | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | \
|[doubao-embedding-vision](https://www.volcengine.com/docs/82379/1554712) |250615`推荐` |doubao-embedding-vision-250615 |图像向量化 |\
| | | |> 支持 视频、文本、图片输入 |128k |2048 |\
| | | | | |> 支持1024降维使用 |15000 RPM |\
| | | | | | |1200000 TPM |500,000 |[图文向量模型](https://www.volcengine.com/docs/82379/1544106#59503f99) |
|^^| | | | | | |^^|^^| \
| |250328 |doubao-embedding-vision-250328 |图像向量化 |\
| | | |> 支持最多1张图片、1段文本输入 |8k |2048 |15000 RPM |\
| | | | | | |1200000 TPM | | |
|^^| | | | | | |^^|^^| \
| |241215 |doubao-embedding-vision-241215 |图像向量化 |\
| | | |> 支持最多1张图片、1段文本输入 |8k |3072 |15000 RPM |\
| | | | | | |1200000 TPM | | |


<span id="3e4d5e7a"></span>
# 语音处理能力
文档：[语音合成](https://www.volcengine.com/docs/6561/1257584)  <span style="color: #646a73"><strong>|</strong></span>  文档：[声音复刻](https://www.volcengine.com/docs/6561/1305191)  <span style="color: #646a73"><strong>|</strong></span>  文档：[流式语音识别](https://www.volcengine.com/docs/6561/1354869)  <span style="color: #646a73"><strong>|</strong></span>  文档：[录音文件识别](https://www.volcengine.com/docs/6561/1354868)

| | | | | | | \
|**模型名称** |**版本** |**模型能力** |**限流** |\
| | | |QPS 每秒请求数上限 |**免费额度** |**定价** |
|---|---|---|---|---|---|
| | | | | | | \
|[豆包语音合成大模型](https://www.volcengine.com/product/tts) |\- |语音合成 |2 |5000 token |[购买页](https://www.volcengine.com/activity/chuangyezhejiasu-2024) |
| | | | | | | \
|[豆包声音复刻大模型](https://www.volcengine.com/product/tts) |\- |声音复刻 |2 |5000 token |\
| | | | |10 个复刻声音 |[购买页](https://www.volcengine.com/activity/chuangyezhejiasu-2024) |
| | | | | | | \
|[豆包语音识别大模型](https://www.volcengine.com/product/tts) |\- |语音识别 |2 |20 小时 |[购买页](https://www.volcengine.com/activity/chuangyezhejiasu-2024) |

<span id="e6772192"></span>
# 上下文缓存
介绍：[上下文缓存概述](https://www.volcengine.com/docs/82379/1398933) | API：[Responses API](https://www.volcengine.com/docs/82379/1585135) | API：[Context API](https://www.volcengine.com/docs/82379/1528788)

| | | | | | \
|模型名称 |版本 |调用方式 |模式 |计费 |
|---|---|---|---|---|
| | | | | | \
|[doubao-seed-1.6 ](https://www.volcengine.com/docs/82379/1593702) |250615 |[Response API](https://www.volcengine.com/docs/82379/1569618) |前缀缓存 |\
| | | |Session 缓存 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | \
|[doubao-seed-1.6-flash](https://www.volcengine.com/docs/82379/1593704) |250615 |[Response API](https://www.volcengine.com/docs/82379/1569618) |前缀缓存 |\
| | | |Session 缓存 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | \
|[doubao-seed-1.6-thinking](https://www.volcengine.com/docs/82379/1593703) |250615 |[Response API](https://www.volcengine.com/docs/82379/1569618) |前缀缓存 |\
| | | |Session 缓存 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | \
|[doubao-1.5-pro-32k](https://www.volcengine.com/docs/82379/1554678) |character-250228 |[Context API](https://www.volcengine.com/docs/82379/1528789) |Session 缓存 |\
| | | | |\
| | | |* rolling_tokens 模式 |[在线推理](https://www.volcengine.com/docs/82379/1544106#f026a2f1) |
|^^| | | | | \
| |250115 |[Context API](https://www.volcengine.com/docs/82379/1528789) |前缀缓存 |\
| | | |Session 缓存 |\
| | | | |\
| | | |* rolling_tokens 模式 |[在线推理](https://www.volcengine.com/docs/82379/1544106#f026a2f1) |
| | | | | | \
|[doubao-1.5-lite](https://www.volcengine.com/docs/82379/1554679) |32k-250115 |[Context API](https://www.volcengine.com/docs/82379/1528789) |前缀缓存 |\
| | | |Session 缓存 |\
| | | | |\
| | | |* rolling_tokens 模式 |[在线推理](https://www.volcengine.com/docs/82379/1544106#f026a2f1) |
| | | | | | \
|[doubao-pro-32k](https://www.volcengine.com/docs/82379/1554680) |241215 |[Context API](https://www.volcengine.com/docs/82379/1528789) |前缀缓存 |\
| | | |Session 缓存 |\
| | | | |\
| | | |* rolling_tokens 模式 |[在线推理](https://www.volcengine.com/docs/82379/1544106#f026a2f1) |
|^^| | | | | \
| |character-241215 |[Context API](https://www.volcengine.com/docs/82379/1528789) |Session 缓存 |\
| | | | |\
| | | |* last_history_tokens 模式 |[在线推理](https://www.volcengine.com/docs/82379/1544106#f026a2f1) |
| | | | | | \
|[deepseek-r1](https://www.volcengine.com/docs/82379/1554373) |250528 |[Context API](https://www.volcengine.com/docs/82379/1528789) |前缀缓存 |[在线推理](https://www.volcengine.com/docs/82379/1544106#f026a2f1) |
|^^| | | | | \
| |250120 |[Context API](https://www.volcengine.com/docs/82379/1528789) |前缀缓存 |[在线推理](https://www.volcengine.com/docs/82379/1544106#f026a2f1) |
|^^| | | | | \
| |distill-qwen-32b-250120 |[Context API](https://www.volcengine.com/docs/82379/1528789) |前缀缓存 |[在线推理](https://www.volcengine.com/docs/82379/1544106#f026a2f1) |
| | | | | | \
|[deepseek-v3](https://www.volcengine.com/docs/82379/1519547) |250324 |[Context API](https://www.volcengine.com/docs/82379/1528789) |前缀缓存 |\
| | | |Session 缓存 |\
| | | | |\
| | | |* rolling_tokens 模式 |[在线推理](https://www.volcengine.com/docs/82379/1544106#f026a2f1) |
|^^| | | | | \
| |241226 |[Context API](https://www.volcengine.com/docs/82379/1528789) |前缀缓存 |[在线推理](https://www.volcengine.com/docs/82379/1544106#f026a2f1) |

<span id="5414cb1d"></span>
# 结构化输出
介绍：[结构化输出](https://www.volcengine.com/docs/82379/1568221)  | API：[对话(Chat) API](https://www.volcengine.com/docs/82379/1494384#RxN8G2nH)

| | | | | | | | | | | | \
|**模型名称** |**版本** |\
| |<div style="width:150px"></div> |模型 ID（Model ID） |\
| | |<div style="width:150px"></div> |模型能力 |\
| | | |<div style="width:150px"></div> |最大上下文长度 |\
| | | | |(token) |\
| | | | |> 上下文长度=输入长度+回答长度+思维链长度 |\
| | | | | |\
| | | | |<div style="width:150px"></div> |最大输入长度 |\
| | | | | |(token) |[可配置最大回答长度](https://www.volcengine.com/docs/82379/1399009#0001) |\
| | | | | | |(token) |思维链最大输出长度 |\
| | | | | | | |(token) |\
| | | | | | | |> 独占，不共享给输入/输出，见[说明](https://www.volcengine.com/docs/82379/1449737#%E9%99%84-%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6%E9%99%90%E5%88%B6%E8%AF%B4%E6%98%8E) |\
| | | | | | | | |\
| | | | | | | |<div style="width:150px"></div> |模型默认限流 |\
| | | | | | | | |<div style="width:140px"></div> |**免费额度** |\
| | | | | | | | | |（token） |**定价** |\
| | | | | | | | | | |(元/千 token) |
|---|---|---|---|---|---|---|---|---|---|---|
| | | | | | | | | | | | \
|[doubao-seed-1.6 ](https://www.volcengine.com/docs/82379/1593702) |250615`强烈推荐` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-seed-1-6-250615 |深度思考 |\
| | | |文本生成 |\
| | | |图片理解 |\
| | | |视频理解 |\
| | | |工具调用 |\
| | | |结构化输出 |256k |224k |32k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-seed-1.6-flash](https://www.volcengine.com/docs/82379/1593704) |250615`推荐` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-seed-1-6-flash-250615 |深度思考 |\
| | | |文本生成 |\
| | | |图片理解 |\
| | | |视觉定位 |\
| | | |视频理解 |\
| | | |工具调用 |\
| | | |结构化输出 |256k |224k |32k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-seed-1.6-thinking](https://www.volcengine.com/docs/82379/1593703) |250615 |doubao-seed-1-6-thinking-250615 |深度思考 |\
| | | |图片理解 |\
| | | |视频理解 |\
| | | |工具调用 |\
| | | |结构化输出 |256k |224k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-1.5-thinking-pro](https://www.volcengine.com/docs/82379/1536428) |250415  |\
| |> 推荐升级至`doubao-seed-1-6-thinking-250615` |\
| | |\
| | |doubao-1-5-thinking-pro-250415 |深度思考 |\
| | | |工具调用 |\
| | | |结构化输出 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000  |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-1.5-thinking-vision-pro](https://www.volcengine.com/docs/82379/1554521) |250428 `推荐` |\
| |> 可通过API[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa) |doubao-1-5-thinking-vision-pro-250428 |深度思考 |\
| | | |图片理解 |\
| | | |视觉定位 |\
| | | |视频理解 |\
| | | |工具调用 |\
| | | |结构化输出 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |
| | | | | | | | | | | | \
|[doubao-1.5-vision-pro](https://www.volcengine.com/docs/82379/1553586) |250328 |\
| |> 只支持`json_object` |doubao-1-5-vision-pro-250328 |图片理解 |\
| | | |视频理解 |\
| | | |深度思考 |\
| | | |> 可通过设置系统消息开启深度思考 |\
| | | | |\
| | | |结构化输出 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[视觉理解模型](https://www.volcengine.com/docs/82379/1544106#d52e5943) |
| | | | | | | | | | | | \
|[deepseek-r1](https://www.volcengine.com/docs/82379/1554373) |250528`推荐` |deepseek-r1-250528 |深度思考 |\
| | | |工具调用 |\
| | | |结构化输出 |128k |96k |16k  |\
| | | | | | |默认 4k |32k |30000 RPM |\
| | | | | | | | |5000000 TPM |500,000 |[深度思考模型](https://www.volcengine.com/docs/82379/1544106#76de5911) |





# 创建视频生成任务 API
Source: https://www.volcengine.com/docs/82379/1520757
<span style="background-color: rgb(248, 248, 248)"><code>POST https://ark.cn-beijing.volces.com/api/v3/contents/generations/tasks</code></span><span style="background-color: rgb(43, 43, 43)">   </span>[ ](https://api.volcengine.com/api-explorer/?action=CreateContentsGenerationsTasks&data=%7B%7D&groupName=%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90API&query=%7B%7D&serviceCode=ark&version=2024-01-01)[运行](https://api.volcengine.com/api-explorer/?action=CreateContentsGenerationsTasks&data=%7B%7D&groupName=%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90API&query=%7B%7D&serviceCode=ark&version=2024-01-01)
<span style="background-color: rgb(255, 255, 255)">本文介绍创建视频生成任务 API 的输入输出参数，供您使用接口时查阅字段含义。</span>模型会依据传入的图片及文本信息生成视频，待生成完成后，您可以按条件查询任务并获取生成的视频。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="cKmdyIjR"><RenderMd content={` [ ](https://www.volcengine.com/docs/82379/1520757)[体验中心](https://console.volcengine.com/ark/region:ark+cn-beijing/experience/vision)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[模型列表](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E8%83%BD%E5%8A%9B)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1099320#%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[调用教程](https://www.volcengine.com/docs/82379/1366799)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[接口文档](https://www.volcengine.com/docs/82379/1520758)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[常见问题](https://www.volcengine.com/docs/82379/1359411)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="vRJT6oJZ"><RenderMd content={`本接口支持 API Key 鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="在线调试" key="le7SQjQUB1"><RenderMd content={`<APILink link="https://api.volcengine.com/api-explorer/?action=CreateContentsGenerationsTasks&data=%7B%7D&groupName=%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90API&query=%7B%7D&serviceCode=ark&version=2024-01-01" description="API Explorer 您可以通过 API Explorer 在线发起调用，无需关注签名生成过程，快速获取调用结果。"></APILink>
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


**不同模型支持的视频生成能力如下：** 

* **doubao\-seedance\-pro`new`**
   * 文生视频：根据您输入的++文本提示词+参数（可选）++生成目标视频。
   * 图生视频\-首帧：根据您输入的++首帧图片+文本提示词（可选）+参数（可选）++生成目标视频。
* **doubao\-seedance\-lite**
   * **doubao\-seedance\-1\-0\-lite\-t2v：**文生视频，根据您输入的++文本提示词+参数（可选）++生成目标视频。
   * **doubao\-seedance\-1\-0\-lite\-i2v：**图生视频，根据您输入的++首帧图片+++**`new`++尾帧图片（可选）++**+++文本提示词（可选）+参数（可选）++生成目标视频。**注意使用首尾帧功能时，仅支持480p和720p。**
* **doubao\-seaweed**
   * 文生视频：根据您输入的++文本提示词+参数（可选）++生成目标视频。
   * 图生视频\-首帧：根据您输入的++首帧图片+文本提示词（可选）+参数（可选）++生成目标视频。
* **wan2.1\-14b**
   * **wan2\-1\-14b\-t2v**：文生视频，根据您输入的++文本提示词+参数（可选）++生成目标视频。
   * **wan2\-1\-14b\-i2v**：图生视频\-首帧，根据您输入的++首帧图片+文本提示词+参数（可选）++生成目标视频。
   * **wan2\-1\-14b\-flf2v**：图生视频\-首尾帧，根据您输入的++首帧图片+尾帧图片+文本提示词+参数（可选）++生成目标视频。

&nbsp;
<span id="#RxN8G2nH"></span>
## 请求参数 
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1520757#L9tzcCyD)

<span id="#BJ5XLFqM"></span>
### 请求体

---


**model** `string` `必选`
您需要调用的模型的 ID （<span style="background-color: rgb(255, 255, 255)">Model ID</span>），[开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)，并[查询 Model ID](https://www.volcengine.com/docs/82379/1330310) 。
<span style="background-color: rgb(243, 245, 247)">您也可通过 Endpoint ID 来调用模型，获得限流、计费类型（前付费/后付费）、运行状态查询、监控、安全等高级能力，可参考</span>[获取 Endpoint ID](https://www.volcengine.com/docs/82379/1099522)<span style="background-color: rgb(243, 245, 247)">。</span>

---


**content** `object[]` `必选`
输入给模型，生成视频的信息，支持文本信息和图片信息。

信息类型

---


**文本信息** `object`
<span style="background-color: rgb(239, 251, 255)">输入给模型生成视频的内容，文本内容部分。</span>

属性

---


content.<span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span>`string` `必选`
<span style="background-color: rgb(255, 255, 255)">输入内容的类型，</span>此处应为 <span style="background-color: rgba(27, 31, 35, 0.05)"><code>text</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>

---


content.<span style="background-color: rgb(255, 255, 255)"><strong>text </strong></span>`string` `必选`
<span style="background-color: rgb(255, 255, 255)">输入给模型的文本内容，描述期望生成的视频，</span><span style="background-color: rgb(239, 251, 255)">包括：</span>

* <span style="background-color: rgb(239, 251, 255)"><strong>文本提示词（必填）</strong></span><span style="background-color: rgb(239, 251, 255)">：支持中英文。</span><span style="background-color: rgb(255, 255, 255)">提示词的使用技巧请参见 </span>[Seedance 提示词指南](https://www.volcengine.com/docs/82379/1587797)。
* <span style="background-color: rgb(239, 251, 255)"><strong>参数（选填）</strong></span><span style="background-color: rgb(239, 251, 255)">：</span>在文本提示词后追加\-\-[parameters]，控制视频输出的规格，<span style="background-color: rgb(255, 255, 255)">详情见 </span>**模型文本命令(选填）**。


---


**图片信息** `object`
<span style="background-color: rgb(239, 251, 255)">输入给模型生成视频的内容，图片信息部分。</span>

属性

---


content.<span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span>`string` `必选`
<span style="background-color: rgb(255, 255, 255)">输入内容的类型，</span>此处应为 <span style="background-color: rgba(27, 31, 35, 0.05)"><code>image_url</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>

---


content.<span style="background-color: rgb(255, 255, 255)"><strong>image_url </strong></span>`object` `必选`
<span style="background-color: rgb(255, 255, 255)">输入给模型的图片对象。</span>

属性

---


content.<span style="background-color: rgb(255, 255, 255)">image_url.</span><span style="background-color: rgb(255, 255, 255)"><strong>url </strong></span>`string` `必选`
<span style="background-color: rgb(239, 251, 255)">图片信息，可以是图片URL或图片 Base64 编码。</span>

* <span style="background-color: rgb(239, 251, 255)">图片URL：请确保图片URL可被访问。</span>
* <span style="background-color: rgb(239, 251, 255)">Base64编码：请遵循此格式</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>data:image/<图片格式>;base64,<Base64编码></code></span><span style="background-color: rgba(27, 31, 35, 0.05)">，注意 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code><图片格式></code></span><span style="background-color: rgba(27, 31, 35, 0.05)"> 需小写，如 </span><span style="background-color: rgb(248, 248, 248)"><code>data:image/png;base64,{base64_image}</code></span><span style="background-color: rgb(239, 251, 255)">。</span>

:::tip
<span style="background-color: rgb(243, 245, 247)">传入图片需要满足以下条件：</span>
<span style="background-color: rgb(243, 245, 247)">图片格式：jpeg、png、webp、bmp、tiff、gif。</span>
<span style="background-color: rgb(243, 245, 247)">宽高比（宽/高）：在范围 (0.4, 2.5) 。</span>
<span style="background-color: rgb(243, 245, 247)">宽高长度（px）：(300, 6000)。</span>
<span style="background-color: rgb(243, 245, 247)">大小：小于30MB。</span>

:::

---


content.**role** `String` `条件必填`
图片的位置或用途。枚举值：

* first_frame：首帧图片
* last_frame：尾帧图片

:::warning

* 当使用首尾帧图生视频功能时，需传入 2个 image_url 对象，1 个 role 为 first_frame，另一个 role 为 last_frame。传入的首尾帧图片可相同。
* 首尾帧图片的宽高比不一致时，以首帧图片为主，尾帧图片会自动裁剪适配。
* 当使用首帧图生视频功能时，role 填写 first_frame 或不填。

:::


---


**callback_url** `string` `可选`
填写本次生成任务结果的回调通知地址。当视频生成任务有状态变化时，方舟将向此地址发送包含任务最新状态的回调请求。
回调请求内容结构与[查询任务API](https://www.volcengine.com/docs/82379/1521309)的返回体一致。
回调返回的 status 包括以下状态：

* queued：排队中。
* running：任务运行中。
* succeeded： 任务成功。（如发送失败，即5秒内没有接收到成功发送的信息，回调三次）
* failed：任务失败。（如发送失败，即5秒内没有接收到成功发送的信息，回调三次） 


---


&nbsp;
<span id="#L9tzcCyD"></span>
### 模型文本命令(选填)
在文本提示词后追加 \-\-[parameters] ，控制视频输出的规格，包括宽高比、帧率、分辨率等。
:::warning
使用不同的模型，可能对应支持不同的参数与取值，详见 [模型文本命令比较](https://www.volcengine.com/docs/82379/1366799#%E6%A8%A1%E5%9E%8B%E6%96%87%E6%9C%AC%E5%91%BD%E4%BB%A4%E6%AF%94%E8%BE%83) 。当输入的参数或取值不符合所选的模型时，内容会被忽略或报错。

:::
---


**resolution**  `string` `默认值 720p` `简写 rs`
视频分辨率，枚举值：

* 480p
* 720p
* 1080p


---


**ratio** `string` `简写 rt`
> 不同模型默认值不同，一般是`16:9`
> wan2.1\-14b\-i2v，默认值： keep_ratio
> doubao\-seedance\-1\-0\-pro 图生视频，doubao\-seedance\-1\-0\-lite\-i2v，doubao\-seaweed 图生视频，默认值：adaptive

生成视频的宽高比例，支持设置 480p、720p、1080p 三种分辨率下的宽高比。

* 21:9
* 16:9 
* 4:3
* 1:1
* 3:4
* 9:16
* 9:21
* keep_ratio：所生成视频的宽高比与所上传图片的宽高比保持一致。
* adaptive：<span style="background-color: rgb(239, 251, 255)">根据所上传图片的比例，自动选择最合适的宽高比。</span>


---


**duration** `Integer` `默认值 5秒` `简写 dur`
生成视频时长，单位：秒。枚举值：

* 5
* 10


---


**framepersecond**  `Integer` `简写 fps`
> wan2.1\-14b 默认值 16
> doubao\-seaweed 默认值 24

帧率，即一秒时间内视频画面数量。枚举值：

* 16 
* 24


---


**watermark** `Boolean` `默认值 false` `简写 wm`
<span style="background-color: rgb(239, 251, 255)">生成视频是否包含水印。枚举值：</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)">false</span><span style="background-color: rgb(239, 251, 255)">：不含水印。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)">true</span><span style="background-color: rgb(239, 251, 255)">：含有水印。</span>


---


<span style="background-color: rgb(239, 251, 255)"><strong>seed</strong></span><span style="background-color: rgb(239, 251, 255)"> </span>`Integer` `默认值 -1` `简写 seed`
<span style="background-color: rgb(239, 251, 255)">种子整数，用于控制生成内容的随机性。取值范围：</span><span style="background-color: rgba(27, 31, 35, 0.05)">[\-1, 2^32\-1]</span><span style="background-color: rgb(239, 251, 255)">之间的整数。</span>
:::warning
当不指定seed值或令seed取值为\-1时，会使用随机数替代。
改变seed值，是相同的请求获得不同结果的一种方法。对相同的请求使用相同的seed值会产生类似的结果，但不保证完全一致。

:::
---


**camerafixed** `Boolean` `默认值 false` `简写 cf`
是否固定摄像头。枚举值：

* true：固定摄像头。平台会在用户提示词中追加固定摄像头，实际效果不保证。
* false：不固定摄像头。


---


&nbsp;
<span id="#L9tzcCyD"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1520757#RxN8G2nH)

**id** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
视频生成任务 ID 。创建视频生成任务为异步接口，获取 ID 后，需要通过 [查询视频生成任务 API](https://www.volcengine.com/docs/82379/1521309) 来查询视频生成任务的状态。任务成功后，会输出生成视频的`video_url`。




# 查询视频生成任务 API
Source: https://www.volcengine.com/docs/82379/1521309
<span style="background-color: rgb(248, 248, 248)"><code>GET https://ark.cn-beijing.volces.com/api/v3/contents/generations/tasks/{id}</code></span><span style="background-color: rgb(43, 43, 43)">  </span>[运行](https://api.volcengine.com/api-explorer/?action=GetContentsGenerationsTask&data=%7B%22id%22%3A%22cgt-20250331175019-68d9t%22%7D&groupName=%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90API&query=%7B%7D&serviceCode=ark&version=2024-01-01)
<span style="background-color: rgb(255, 255, 255)">本文介绍 doubao 视频生成 API 的输入输出参数，供您使用接口时查阅字段含义。</span>

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="fq9yXaKY"><RenderMd content={` [ ](https://www.volcengine.com/docs/82379/1521309)[体验中心](https://console.volcengine.com/ark/region:ark+cn-beijing/experience/vision)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[模型列表](https://www.volcengine.com/docs/82379/1330310)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1099320#%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[调用教程](https://www.volcengine.com/docs/82379/1366799)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[接口文档](https://www.volcengine.com/docs/82379/1521309)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[常见问题](https://www.volcengine.com/docs/82379/1359411)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="3vCxpwty"><RenderMd content={`本接口支持 API Key 鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


<span id="#RxN8G2nH"></span>
## 请求参数 
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1521309#7mi8G8RI)


---


**id** `string` `必选`
您需要查询的视频生成任务的 ID 。
:::tip
<span style="background-color: rgb(255, 255, 255)">上面参数为Query String Parameters，在URL String中传入。</span>

:::
---


&nbsp;
<span id="#7mi8G8RI"></span>
## 
<span id="#7mi8G8RI"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1521309#RxN8G2nH)


---


**id** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
视频生成任务 ID 。

---


**model** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
任务使用的模型名称和版本，`模型名称-版本`。

---


**status** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
任务状态，以及相关的信息：

* `queued`：排队中。
* `running`：任务运行中。
* `cancelled`：取消任务，取消状态24h自动删除（只支持排队中状态的任务被取消）。
* `succeeded`： 任务成功。
* `failed`：任务失败。


---


**error** <span style="background-color: rgb(255, 255, 255)"><code>object / null</code></span>
错误提示信息，任务成功返回`null`，任务失败时返回错误数据，错误信息具体参见 [错误处理](https://www.volcengine.com/docs/82379/1299023#%E6%96%B9%E8%88%9F%E9%94%99%E8%AF%AF%E7%A0%81)。

属性

---


error.**code** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
错误码。

---


error.**message** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
错误提示信息。


---


**created_at** `integer`
任务创建时间的 Unix 时间戳（秒）。

---


**updated_at** `integer`
任务当前状态更新时间的 Unix 时间戳（秒）。

---


**content** <span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
当视频生成任务完成，会输出该字段，包含生成视频下载的 URL。

属性

---


content.**video_url** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
生成视频的URL。为保障信息安全，生成的视频会在24小时后被清理，请及时转存。


---


**seed** `integer`
本次请求使用的种子整数值。

---


**usage** <span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
本次请求的 token 用量。

属性

---


usage.**completion_tokens** `integer`
模型生成的 token 数量。

---


usage.**total_tokens** `integer`
视频生成模型不统计输入 token，输入 token 为 0，故 **total_tokens**=**completion_tokens**。




# 查询视频生成任务列表
Source: https://www.volcengine.com/docs/82379/1521675
`GET https://ark.cn-beijing.volces.com/api/v3/contents/generations/tasks?page_num={page_num}&page_size={page_size}&filter.status={filter.status}&filter.task_ids={filter.task_ids}&filter.model={filter.model}`<span style="background-color: rgb(43, 43, 43)">  </span>[运行](https://api.volcengine.com/api-explorer/?action=ListContentsGenerationsTasks&data=%7B%7D&groupName=%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90API&query=%7B%7D&serviceCode=ark&version=2024-01-01)
<span style="background-color: rgb(255, 255, 255)">当您要查询符合条件的任务，您可以传入条件筛选参数，返回符合要求的任务。</span>

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="opV4RT2k"><RenderMd content={` [ ](https://www.volcengine.com/docs/82379/1521675)[体验中心](https://console.volcengine.com/ark/region:ark+cn-beijing/experience/vision)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[模型列表](https://www.volcengine.com/docs/82379/1330310)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1099320#%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[调用教程](https://www.volcengine.com/docs/82379/1366799)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[接口文档](https://www.volcengine.com/docs/82379/1521675)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[常见问题](https://www.volcengine.com/docs/82379/1359411)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="CPeW5vNl"><RenderMd content={`本接口支持 API Key 鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


<span id="#RxN8G2nH"></span>
## 请求参数 
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1521675#7mi8G8RI)

:::tip
<span style="background-color: rgb(255, 255, 255)">下面参数为Query String Parameters，在URL String中传入。</span>

:::
---


**page_num** `integer / null` 
<span style="background-color: rgb(255, 255, 255)">取值范围：[1, 500]</span>
<span style="background-color: rgb(255, 255, 255)">返回结果的页码。</span>

---


**page_size** `integer / null`
<span style="background-color: rgb(255, 255, 255)">取值范围：[1, 500]</span>
<span style="background-color: rgb(255, 255, 255)">返回结果的每页的结果数量。</span>

---


**filter.status** `string / null`
<span style="background-color: rgb(255, 255, 255)">过滤参数，查询某个任务状态。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>queued</code></span><span style="background-color: rgb(255, 255, 255)">：排队中的任务。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>running</code></span><span style="background-color: rgb(255, 255, 255)">：运行中任务。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>cancelled</code></span><span style="background-color: rgb(255, 255, 255)">：取消的任务，只能查询到24h内取消的任务。取消任务超出24h，会被删除。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>succeeded</code></span><span style="background-color: rgb(255, 255, 255)">： 成功的任务。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>failed</code></span><span style="background-color: rgb(255, 255, 255)">：失败的任务。</span>


---


**filter.task_ids** `string[] / null`
<span style="background-color: rgb(255, 255, 255)">视频生成任务 ID，精确搜索，支持同时搜索多个任务 ID。</span>

---


**filter.model** `string / null`
<span style="background-color: rgb(255, 255, 255)">与返回参数不同，该字段为任务使用的推理接入点 ID，精确搜索。</span>

---


&nbsp;
<span id="#7mi8G8RI"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1521675#RxN8G2nH)


---


**items** `object[]`
<span style="background-color: rgb(255, 255, 255)">查询到的视频生成任务列表。</span>

属性

---


items.**id** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
视频生成任务 ID 。

---


items.**model** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
任务使用的模型名称和版本，`模型名称-版本`。

---


items.**status** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
任务状态，以及相关的信息：

* `queued`：排队中。
* `running`：任务运行中。
* `cancelled`：取消任务，取消状态24h自动删除（只支持排队中状态的任务被取消）。
* `succeeded`： 任务成功。
* `failed`：任务失败。


---


items.**error** <span style="background-color: rgb(255, 255, 255)"><code>object / null</code></span>
错误提示信息，任务成功返回`null`，任务失败时返回错误数据，错误信息具体参见 [错误处理](https://www.volcengine.com/docs/82379/1393047#653d2c40)。

属性

---


error.**code** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
错误码。

---


error.**message** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
错误提示信息。


---


items.**created_at** `integer`
任务创建时间的 Unix 时间戳（秒）。

---


items.**updated_at** `integer`
任务当前状态更新时间的 Unix 时间戳（秒）。

---


items.**content** <span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
当视频生成任务完成，会输出该字段，包含生成视频下载的 URL。

属性

---


content.**video_url** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
生成视频的URL。为保障信息安全，生成的视频会在24小时后被清理，请及时转存。


---


items.**seed** `integer`
本次请求使用的种子整数值。

---


items.**usage** <span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
本次请求的 token 用量。

属性

---


usage.**completion_tokens** `integer`
模型生成的 token 数量。

---


usage.**total_tokens**`integer`
视频生成模型不统计输入 token，输入 token 为 0，故 **total_tokens**=**completion_tokens**。



---


**total** `integer`
<span style="background-color: rgb(255, 255, 255)">符合筛选条件的任务数量。</span>

---






# 取消或删除视频生成任务
Source: https://www.volcengine.com/docs/82379/1521720
`DELETE https://ark.cn-beijing.volces.com/api/v3/contents/generations/tasks/{id}`<span style="background-color: rgb(43, 43, 43)">  </span>[运行](https://api.volcengine.com/api-explorer/?action=DeleteContentsGenerationsTasks&data=%7B%22id%22%3A%22cgt-20250331175019-68d9t%22%7D&groupName=%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90API&query=%7B%7D&serviceCode=ark&version=2024-01-01)
<span style="background-color: rgb(255, 255, 255)">当您要查询符合条件的任务，您可以按照条件筛选出符合要求的任务。</span>

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="vI631gwS"><RenderMd content={` [ ](https://www.volcengine.com/docs/82379/1521720)[体验中心](https://console.volcengine.com/ark/region:ark+cn-beijing/experience/vision)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[模型列表](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1099320#%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[调用教程](https://www.volcengine.com/docs/82379/1366799)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[接口文档](https://www.volcengine.com/docs/82379/1521675)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[常见问题](https://www.volcengine.com/docs/82379/1359411)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="L8aMwmZD"><RenderMd content={`本接口支持 API Key 鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


<span id="#RxN8G2nH"></span>
## 请求参数 
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1521720#7mi8G8RI)

:::tip
<span style="background-color: rgb(255, 255, 255)">下面参数为Query String Parameters，在URL String中传入。</span>

:::
---


**id** `string` `必选`
<span style="background-color: rgb(255, 255, 255)">需要取消或者删除的视频生成任务。</span>

---


&nbsp;
<span id="#7mi8G8RI"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1521720#RxN8G2nH)

本接口无返回参数。



# 文本向量化 API
Source: https://www.volcengine.com/docs/82379/1521766
`POST https://ark.cn-beijing.volces.com/api/v3/embeddings`<span style="background-color: rgb(43, 43, 43)">   </span>[ ](https://api.volcengine.com/api-explorer/?action=CreateContentsGenerationsTasks&data=%7B%7D&groupName=%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90API&query=%7B%7D&serviceCode=ark&version=2024-01-01)[运行](https://api.volcengine.com/api-explorer/?action=Embeddings&data=%7B%7D&groupName=%E5%90%91%E9%87%8F%E5%8C%96%20API&query=%7B%7D&serviceCode=ark&version=2024-01-01)
当您需通过语义来处理文本，如语义检索、分析词性等，可以调用向量化服务，将文本转化为向量，来分析文本的语义关系。本文为您提供服务接口的参数详细说明供您查阅。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="x07cK6lM"><RenderMd content={` <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[模型列表](https://www.volcengine.com/docs/82379/1330310)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1099320#%E6%96%87%E6%9C%AC%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[接口文档](https://www.volcengine.com/docs/82379/1521766)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[常见问题](https://www.volcengine.com/docs/82379/1359411)      <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="k5gDlMBL"><RenderMd content={`本接口支持 API Key 鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
> 如需使用 Access Key 来鉴权，推荐使用 SDK 的方式，具体请参见 [SDK概述](https://www.volcengine.com/docs/82379/1302007)。
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


<span id="#RxN8G2nH"></span>
## 请求参数 
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1521766#L9tzcCyD)

<span id="#BJ5XLFqM"></span>
### 请求体

---


**model** `string` `必选`
您需要调用的模型的 ID （<span style="background-color: rgb(255, 255, 255)">Model ID</span>），[开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)，并[查询 Model ID](https://www.volcengine.com/docs/82379/1330310) 。
<span style="background-color: rgb(243, 245, 247)">您也可通过 Endpoint ID 来调用模型，获得限流、计费类型（前付费/后付费）、运行状态查询、监控、安全等高级能力，可参考</span>[获取 Endpoint ID](https://www.volcengine.com/docs/82379/1099522#%E8%8E%B7%E5%8F%96-endpoint-id)<span style="background-color: rgb(243, 245, 247)">。</span>

---


**input** `string / string[]` `必选`
需要向量化的内容列表，支持中文、英文。输入内容需满足下面条件：

* 不得超过模型的最大输入 token 数。doubao\-embdding 模型，每个列表元素（并非单次请求总数）最大输入token 数为 4096。
* 不能为空列表，列表的每个成员不能为空字符串。
* 单条文本以 utf\-8 编码，长度不超过 100,000 字节。

为获得更好性能，建议文本数量总token不超过4096，或者文本条数不超过4。

---


**encoding_format** `string / null ` `默认值 float`
取值范围： `float`、`base64`、`null`。
embedding 返回的格式。

---


&nbsp;
<span id="#L9tzcCyD"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1521766#RxN8G2nH)


---


**id** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
本次请求的唯一标识 。

---


**model** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
本次请求实际使用的模型名称和版本。

---


**created** `integer`
本次请求创建时间的 Unix 时间戳（秒）。

---


**object** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
固定为 `list`。

---


**data** `object`
本次请求的算法输出内容。

属性

---


data.**index** `integer`
向量的序号，与请求参数 `input` 列表中的内容顺序对应。

---


data.**embedding** `float[]`
对应内容的向量化结果。

---


data.**object** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
固定为 `embedding`。


---


**usage** `object`
本次请求的 token 用量。

属性

---


usage.**prompt_tokens** `integer`
输入内容 token 数量。

---


usage.**total_tokens** `integer`
本次请求消耗的总 token 数量（输入 + 输出）。




# 图像向量化 API
Source: https://www.volcengine.com/docs/82379/1523520
`POST https://ark.cn-beijing.volces.com/api/v3/embeddings/multimodal`<span style="background-color: rgb(43, 43, 43)">  </span>[ ](https://api.volcengine.com/api-explorer/?action=CreateContentsGenerationsTasks&data=%7B%7D&groupName=%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90API&query=%7B%7D&serviceCode=ark&version=2024-01-01)[运行](https://api.volcengine.com/api-explorer/?action=EmbeddingsMultimodal&data=%7B%7D&groupName=%E5%90%91%E9%87%8F%E5%8C%96%20API&query=%7B%7D&serviceCode=ark&version=2024-01-01)
当您需通过语义来处理视频、图像和文本，如以图搜图、语义检索等，可以调用图像向量化服务，将视频、图像和文本转化为向量，来分析其语义关系。本文为您提供接口的参数详细说明供您查阅。

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="C8u4908B"><RenderMd content={` <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[模型列表](https://www.volcengine.com/docs/82379/1330310#%E5%9B%BE%E5%83%8F%E5%90%91%E9%87%8F%E5%8C%96%E8%83%BD%E5%8A%9B)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1099320#%E6%96%87%E6%9C%AC%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_f45b5cd5863d1eed3bc3c81b9af54407.png =20x) </span>[接口文档](https://www.volcengine.com/docs/82379/1523520)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_1609c71a747f84df24be1e6421ce58f0.png =20x) </span>[常见问题](https://www.volcengine.com/docs/82379/1359411)      <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="MXNMn1Vz"><RenderMd content={`本接口支持 API Key 鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
> 如需使用 Access Key 来鉴权，推荐使用 SDK 的方式，具体请参见 [SDK概述](https://www.volcengine.com/docs/82379/1302007)。
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


<span id="#RxN8G2nH"></span>
## 请求参数 
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1523520#L9tzcCyD)

<span id="#BJ5XLFqM"></span>
### 请求体

---


**model** `string` `必选`
您需要调用的模型的 ID （<span style="background-color: rgb(255, 255, 255)">Model ID</span>），[开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)，并[查询 Model ID](https://www.volcengine.com/docs/82379/1330310) 。
<span style="background-color: rgb(243, 245, 247)">您也可通过 Endpoint ID 来调用模型，获得限流、计费类型（前付费/后付费）、运行状态查询、监控、安全等高级能力，可参考</span>[获取 Endpoint ID](https://www.volcengine.com/docs/82379/1099522#%E8%8E%B7%E5%8F%96-endpoint-id)<span style="background-color: rgb(243, 245, 247)">。</span>

---


**input** `object[]` `必选`
需要向量化的内容列表。列表元素支持文本信息和图片信息，**部分模型支持视频信息**，详情参见列表：

* `doubao-embedding-vision-250615`及后续版本：input 支持不限数量的 `文本信息`、`图片信息`和 `视频信息`混排输入。传入的信息作为`1`个整体进行向量化。
* `doubao-embedding-vision-250328`/`doubao-embedding-vision-241215`模型：input 当前仅支持3种组合， `1段文本信息`、`1段图片信息`、 `1段图片信息+1段文本信息`。传入的信息作为1个整体进行向量化，即传入1图片+1文本，返回的是1个向量。与[文本向量化 API](https://www.volcengine.com/docs/82379/1521766) 不同，本API **input** 不支持单次请求中对多段文本/图片进行批量向量化。


属性
**文本信息** `object`
<span style="background-color: rgb(239, 251, 255)">输入给模型转化为向量的内容，文本内容部分。</span>

属性

---


input.<span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span>`string` `必选`
<span style="background-color: rgb(255, 255, 255)">输入内容的类型，</span>此处应为 <span style="background-color: rgba(27, 31, 35, 0.05)"><code>text</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>

---


input.<span style="background-color: rgb(255, 255, 255)"><strong>text </strong></span>`string` `必选`
<span style="background-color: rgb(255, 255, 255)">输入给模型的文本内容，需要满足以下条件：</span>

* 单条文本以 utf\-8 编码，长度不超过 100,000 字节。
* 单条文本不超过模型的最大输入 token 数为 8k。

为获得更好性能，建议文本数量总token不超过4096，或者文本条数不超过4。


---


**图片信息** `object`
<span style="background-color: rgb(239, 251, 255)">输入给模型转化成向量的内容，图片信息部分。</span>
:::tip
<span style="background-color: rgb(243, 245, 247)">传入图片需要满足以下条件：</span>

* <span style="background-color: rgb(243, 245, 247)">格式：</span><span style="background-color: rgb(243, 245, 247)"><code>jpeg</code></span><span style="background-color: rgb(243, 245, 247)">、</span><span style="background-color: rgb(243, 245, 247)"><code>png</code></span><span style="background-color: rgb(243, 245, 247)">、</span> `webp`、`bmp`、`tiff`、`ico`、`dib`、`icns`、`sgi`、`jpeg2000`。其中，`tiff`、`sgi`、`icns`、`jpeg2000` 格式图片，需要保证和元数据对齐，如在对象存储中正确设置文件元数据，否则会解析失败。
* <span style="background-color: rgb(243, 245, 247)">宽高比（宽/高）：在范围</span>[1/100, 100]<span style="background-color: rgb(243, 245, 247)"> 。</span>
* <span style="background-color: rgb(243, 245, 247)">边长： </span>[10, 6000] px<span style="background-color: rgb(243, 245, 247)">，即短边像素需大于 10 px，长边像素需小于6000 px。</span>

举例，当图片宽高的长度为798 px、7000 px，图片高的长度大于6000 px，则会返回错误信息`InvalidImageURL('height or width exceed max_total_pixels, 798 or 7000 > 6000')` 。

:::
属性

---


input.<span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span>`string` `必选`
<span style="background-color: rgb(255, 255, 255)">输入内容的类型，</span>此处应为 <span style="background-color: rgba(27, 31, 35, 0.05)"><code>image_url</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>

---


input.<span style="background-color: rgb(255, 255, 255)"><strong>image_url </strong></span>`object` `必选`
<span style="background-color: rgb(255, 255, 255)">输入给模型的图片对象。</span>

属性

---


input.<span style="background-color: rgb(255, 255, 255)">image_url.</span><span style="background-color: rgb(255, 255, 255)"><strong>url </strong></span>`string` `必选`
<span style="background-color: rgb(239, 251, 255)">图片信息，可以是图片URL或图片Base64编码。</span>

* <span style="background-color: rgb(239, 251, 255)">图片URL：请确保图片URL可被访问。</span>
* <span style="background-color: rgb(239, 251, 255)">Base64编码：请遵循此格式</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>data:image/{图片格式};base64,{图片Base64编码}</code></span><span style="background-color: rgb(239, 251, 255)">。</span>



---


**视频信息** `object`
<span style="background-color: rgb(239, 251, 255)">输入给模型转化成向量的内容，视频信息部分。</span>
:::tip
<span style="background-color: rgb(243, 245, 247)">传入视频需要满足以下条件：</span>

* <span style="background-color: rgb(243, 245, 247)">格式：</span><span style="background-color: rgb(243, 245, 247)"><code>.mp4</code></span><span style="background-color: rgb(243, 245, 247)">、</span><span style="background-color: rgb(243, 245, 247)"><code>.avi</code></span><span style="background-color: rgb(243, 245, 247)">、 </span><span style="background-color: rgb(243, 245, 247)"><code>.mov</code></span><span style="background-color: rgb(243, 245, 247)">，</span>视频格式需小写。
* 传入 Base64 编码时使用：[Base64 编码输入](https://www.volcengine.com/docs/82379/1409291#base64-%E7%BC%96%E7%A0%81%E8%BE%93%E5%85%A5)。 
* 单视频文件需在 50MB 以内。 
* 暂不支持对视频文件中的音频信息进行理解。 


:::
---


input.<span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span>`string` `必选`
<span style="background-color: rgb(255, 255, 255)">输入内容的类型，</span>此处应为 <span style="background-color: rgba(183, 237, 177, 0.8)"><code>video_url</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>

---


input.**video_url**<span style="background-color: rgb(255, 255, 255)"><strong> </strong></span>`object` `必选`
<span style="background-color: rgb(255, 255, 255)">输入给模型的视频对象。</span>

属性
input.video_url<span style="background-color: rgb(255, 255, 255)">.</span><span style="background-color: rgb(255, 255, 255)"><strong>url </strong></span>`string` `必选`
支持传入视频链接或视频的Base64编码。具体使用请参见[视频理解说明](https://www.volcengine.com/docs/82379/1362931#%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3)。



---


**encoding_format** `string / null ` `默认值 float`
取值范围： `float`、`base64`、`null`。
embedding 返回的格式。

---


**dimensions** `integer` `默认值 2048`
取值范围： `1024` 或 `2048`。
用于指定输出的向量维度。此参数仅`doubao-embedding-vision-250615`及后续版本支持，历史版本可以参见[向量降维](https://www.volcengine.com/docs/82379/1409291#%E5%90%91%E9%87%8F%E9%99%8D%E7%BB%B4)。

---


&nbsp;
<span id="#L9tzcCyD"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1523520#RxN8G2nH)


---


**id** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
本次请求的唯一标识 。

---


**model** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
本次请求实际使用的模型名称和版本。

---


**created** `integer`
本次请求创建时间的 Unix 时间戳（秒）。

---


**object** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
固定为 `list`。

---


**data** `object`
本次请求的算法输出内容。

属性

---


data.**index** `integer`
向量的序号，与请求参数 `input` 列表中的内容顺序对应。

---


data.**embedding** `float[]`
对应内容的向量化结果。

---


data.**object** <span style="background-color: rgb(255, 255, 255)"><code>string</code></span>
固定为 `embedding`。


---


**usage** `object`
本次请求的 token 用量。

属性

---


usage.**prompt_tokens** `integer`
输入内容 token 数量。

---


usage.**total_tokens** `integer`
本次请求消耗的总 token 数量（输入 + 输出）。

---


usage.**prompt_tokens_details** `object`
输入的内容使用 token 量的细节信息。

属性

---


usage.prompt_tokens_details.**text_tokens** `integer`
输入内容中，文本内容对应的 token 量，以及视频内容时间轴产生的 token 量。
为保证模型效果，当图片或视频传入时，会生成少量的预设文本 token，产生额外的 **text_tokens**。

---


usage.prompt_tokens_details.**image_tokens** `integer`
输入内容中，图片内容以及视频内容抽帧图片对应的 token 量。


&nbsp;




# 创建上下文缓存 API
Source: https://www.volcengine.com/docs/82379/1528789
 <span style="background-color: rgb(43, 43, 43)"><code> POST https://ark.cn-beijing.volces.com/api/v3/context/create</code></span><span style="background-color: rgb(43, 43, 43)">   </span>[运行](https://api.volcengine.com/api-explorer/?action=ContextCreate&data=%7B%7D&groupName=%E4%B8%8A%E4%B8%8B%E6%96%87%E7%BC%93%E5%AD%98&query=%7B%7D&serviceCode=ark&version=2024-01-01)
<span style="background-color: rgb(255, 255, 255)">上下文缓存（Context API）是方舟提供的一个高效的缓存机制。它通过缓存上下文数据，减少重复加载或处理，提高响应速度和一致性。本文介绍上下文缓存 API 的输入输出参数，供您使用接口时查阅字段含义。</span>

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="kgxyAQJT"><RenderMd content={` <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[计费说明](https://www.volcengine.com/docs/82379/1099320#%E4%B8%8A%E4%B8%8B%E6%96%87%E7%BC%93%E5%AD%98%E8%AE%A1%E8%B4%B9)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)        <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[支持模型](https://www.volcengine.com/docs/82379/1330310#e6772192)  
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[调用教程](https://www.volcengine.com/docs/82379/1396491)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)       
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="agb0lYnB"><RenderMd content={`本接口支持 API Key / Access Key鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


<span id="#RxN8G2nH"></span>
## 请求参数 
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1528789#Qu59cel0)

<span id="#pjuiBZGA"></span>
### 请求体

---


**model** `string` `必选`
<span style="background-color: rgb(243, 245, 247)">通过 Endpoint ID 来调用模型，获得限流、计费类型（前付费/后付费）、运行状态查询、监控、安全等高级能力，可参考</span>[获取 Endpoint ID](https://www.volcengine.com/docs/82379/1099522)<span style="background-color: rgb(243, 245, 247)">。</span>
> 暂不支持通过 Model ID 来调用。


---


<span style="background-color: rgb(32, 33, 35)"><strong>messages</strong></span><span style="background-color: rgb(32, 33, 35)">  </span><span style="background-color: rgba(238, 242, 245, 0.5)"><code>object[]</code></span><span style="background-color: rgb(32, 33, 35)"> </span>`必选`<span style="background-color: rgb(32, 33, 35)"> </span>
对话组成的消息列表。您希望缓存的信息。
注意：初始化的信息如系统人设，背景信息等，请使用系统消息（System message）放在消息列表最前。这部分信息在2种缓存模式下，均会一直存储在缓存中，直到缓存到期（触达最大生命周期）释放。

属性

---


**系统消息**  `object`
系统消息，<span style="background-color: rgb(32, 33, 35)">开发人员提供的指令，模型应遵循这些指令。如模型扮演的角色或者目标等。</span>

属性

---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为<span style="background-color: rgb(var(--gray-100)/.5)"><code>system</code></span><span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
系统信息内容。


---


**用户消息**`object`
<span style="background-color: rgb(32, 33, 35)">用户发送的消息，包含提示或附加上下文信息。</span>

属性

---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为`user`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
用户信息内容。

---


messages.**name** <span style="background-color: rgba(238, 242, 245, 0.5)"><code>string</code></span><span style="background-color: rgba(238, 242, 245, 0.5)"> </span>
发送此消息的角色的姓名。用于区别同一个角色但是不同主体发送的消息。


---


**模型消息**  `object`
<span style="background-color: rgb(32, 33, 35)">模型响应用户消息而回复的消息。</span>
:::tip
messages.**content**<span style="background-color: rgba(27, 31, 35, 0.05)"><strong> </strong></span><span style="background-color: rgb(255, 255, 255)">与 </span>messages.**tool_calls**<span style="background-color: rgba(27, 31, 35, 0.05)"><strong> </strong></span><span style="background-color: rgb(255, 255, 255)">字段二者至少填写其一。</span>

:::
---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为`assistant`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span><span style="background-color: rgb(32, 33, 35)"> </span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>
模型回复的消息。

---


messages.**tool_calls** `object[]`
模型回复的工具调用信息。

属性

---


messages.tool_calls**.function** `object` `必选`
<span style="background-color: rgb(255, 255, 255)">模型调用工具对应的函数信息。</span>

属性

---


messages.tool_calls**.**function.**name** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">模型需要调用的函数名称。</span>

---


messages.tool_calls**.**function.<span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
:::tip
<span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>

:::

---


messages.tool_calls**.id** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>

---


messages.tool_calls**.type** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>



---


<span style="background-color: rgb(255, 255, 255)"><strong>mode</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string` <span style="background-color: rgb(255, 255, 255)"><code>默认值 session</code></span>
<span style="background-color: rgb(255, 255, 255)">本次请求创建的上下文缓存的类型。</span>[点此](https://www.volcengine.com/docs/82379/1398933)<span style="background-color: rgb(255, 255, 255)">了解类型介绍。</span>[点此](https://www.volcengine.com/docs/82379/1330310#e6772192)了解支持的模型 <span style="background-color: rgb(255, 255, 255)">。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>session</code></span><span style="background-color: rgb(255, 255, 255)"> ：Session 缓存。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>common_prefix</code></span><span style="background-color: rgb(255, 255, 255)"> ：前缀缓存。</span>


---


<span style="background-color: rgb(255, 255, 255)"><strong>ttl</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>integer / null</code></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>默认值 86400</code></span>
<span style="background-color: rgb(255, 255, 255)">过期时长，单位为秒，设置范围：[3600, 604800]，即1小时到7天。</span>
<span style="background-color: rgb(255, 255, 255)">信息在创建后即开始计时，每次使用则重置为0。计时超过ttl，信息会被从缓存中删除。每次调用chat均根据ttl更新过期时间。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>truncation_strategy</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>object / null</code></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>默认值 null</code></span>
<span style="background-color: rgb(255, 255, 255)">缓存的上下文长度的窗口长度策略配置，只在当 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><strong>mode </strong></span><span style="background-color: rgb(255, 255, 255)">字段设置为</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>session</code></span><span style="background-color: rgb(255, 255, 255)">，该字段可设置。</span>
<span style="background-color: rgb(255, 255, 255)">支持 Session 缓存的模型能且只能支持 1 种 Session 缓存模式。如不配置该字段，方舟会根据您调用的模型自动适配合适的 Session 缓存模式。</span>

属性
<span style="background-color: rgb(255, 255, 255)"><strong>last_history_tokens 模式 </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
触发缓存上限不会重新计算。

属性

---


<span style="background-color: rgb(255, 255, 255)">truncation_strategy.</span><span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span>`string` `必选`
此处应为 <span style="background-color: rgba(27, 31, 35, 0.05)"><code>last_history_tokens</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>

---


<span style="background-color: rgb(255, 255, 255)">truncation_strategy.</span><span style="background-color: rgb(255, 255, 255)"><strong>last_history_tokens </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer</code></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>默认值 4096</code></span>
取值范围：` (0,32768)`。
缓存上下文窗口大小，即可缓存的上下文的最大 token 数。触发该上限将根据缓存上下文窗口大小对缓存内容进行清除。清除顺序按照信息被缓存时间长短排序，先清除缓存时间长的信息 。

<span style="background-color: rgb(255, 255, 255)"><strong>rolling_tokens 模式 </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
触发缓存上限会进行重新计算。

属性

---


<span style="background-color: rgb(255, 255, 255)">truncation_strategy.</span><span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span>`string` `必选`
此处应为 `rolling_tokens`<span style="background-color: rgba(27, 31, 35, 0.05)">。</span>

---


<span style="background-color: rgb(255, 255, 255)">truncation_strategy.</span><span style="background-color: rgb(255, 255, 255)"><strong>rolling_tokens </strong></span><span style="background-color: rgb(255, 255, 255)"><code>boolean</code></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>默认值 true</code></span>
在缓存中历史消息长度接近 **max_window_tokens** 字段值时，是否自动对历史上下文进行裁剪（按照 message 元素粒度裁剪，按照 message 元素取整，即删除的信息的长度在 **rolling_window_tokens** 范围内，不会截断任意信息）。

* `false`：在历史消息长度超过上下文长度时模型会停止输出（返回字段 **finish_reason** 为`length`)。
* `true`：在历史消息长度接近上下文长度时模型按照先进先出的顺序，自动删除定量（**rolling_window_tokens** 字段值 token 数）的内容，为新对话内容腾挪缓存空间；同时对缓存中的信息进行重新计算和读入，保障内容理解一致性。具体的计算逻辑，请参见 [rolling_tokens 模式](https://www.volcengine.com/docs/82379/1396491#rolling-tokens-%E6%A8%A1%E5%BC%8F)。


---


<span style="background-color: rgb(255, 255, 255)">truncation_strategy.</span>**max_window_tokens** <span style="background-color: rgb(255, 255, 255)"><code>integer / null</code></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>默认值 32768</code></span>
在缓存中可存储的历史消息长度最大值。
取值满足下面条件：0 < **rolling_tokens** < **max_window_tokens** < **context window**（模型最大上下文）。

---


<span style="background-color: rgb(255, 255, 255)">truncation_strategy.</span>**rolling_window_tokens** <span style="background-color: rgb(255, 255, 255)"><code>integer / null</code></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>默认值 4096</code></span>
当缓存触发了**max_window_tokens** 上限，则会裁剪滚动窗口长度。
取值满足下面条件：0 < **rolling_tokens** < **max_window_tokens** < **context window**（模型最大上下文）。


&nbsp;
<span id="#Qu59cel0"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1528789#RxN8G2nH)


---


**id** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求创建的上下文缓存的ID，在后续创建带缓存的</span>[上下文缓存对话 API](https://www.volcengine.com/docs/82379/1346560)<span style="background-color: rgb(255, 255, 255)">需要使用。</span>

---


**model** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求使用的推理接入点的 ID 。</span>

---


**mode** `string`
本次请求创建的上下文缓存的类型。[点此](https://www.volcengine.com/docs/82379/1330310#e6772192)了解支持的模型 <span style="background-color: rgb(255, 255, 255)">。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>session</code></span><span style="background-color: rgb(255, 255, 255)"> ：Session 缓存。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>common_prefix</code></span><span style="background-color: rgb(255, 255, 255)"> ：前缀缓存。</span>


---


**ttl** `integer` 
本次请求创建的上下文缓存<span style="background-color: rgb(255, 255, 255)">过期时长，单位为秒。信息在创建后即开始计时，每次使用则重置为0。计时超过ttl，信息会被从缓存中删除。每次调用chat均根据ttl更新过期时间。</span>
<span style="background-color: rgb(255, 255, 255)">过期时间可以设置的范围在1小时到7天，即[3600, 604800]。</span>

---


**truncation_strategy** `object`
本次请求创建的 Session 缓存使用的截断策略信息。

属性

---


**last_history_tokens 模式** `object`
触发缓存上限，自动滚动缓存内容，无需重新计算。

属性

---


truncation_strategy.**type** `string`
本次请求创建的 Session 缓存的截断策略，此处应为 `last_history_tokens`。

---


truncation_strategy.**last_history_tokens** `integer`
本次请求创建的 Session 缓存可缓存的最大 token 数。


---


**rolling_tokens 模式** `object`
触发缓存上限，进行重新计算。

属性 

---


truncation_strategy.**type** `string`
本次请求创建的 Session 缓存的截断策略，此处应为 `rolling_tokens`。

---


truncation_strategy.**rolling_tokens** <span style="background-color: rgb(255, 255, 255)"><code>boolean</code></span>
本次请求创建的 Session 缓存，当缓存的信息量达到最大缓存窗口时，是否自动处理。



---


**usage** `object`
<span style="background-color: rgb(255, 255, 255)">本次请求的 token 用量。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">输入的 prompt token 数量。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>completion_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的 token 数量。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>total_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">本次请求消耗的总 token 数量（输入 + 输出）。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens_details </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">命中上下文缓存的 token 细节。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)">prompt_tokens_details.</span><span style="background-color: rgb(248, 248, 248)"><strong>cached_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">命中上下文缓存的 token 数</span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>






# 上下文缓存对话 API
Source: https://www.volcengine.com/docs/82379/1529329
 <span style="background-color: rgb(43, 43, 43)"><code> POST https://ark.cn-beijing.volces.com/api/v3/context/chat/completions</code></span><span style="background-color: rgb(43, 43, 43)">   </span>[运行](https://api.volcengine.com/api-explorer/?action=ContextChatCompletions&data=%7B%7D&groupName=%E4%B8%8A%E4%B8%8B%E6%96%87%E7%BC%93%E5%AD%98&query=%7B%7D&serviceCode=ark&version=2024-01-01)
<span style="background-color: rgb(255, 255, 255)">上下文缓存（Context API）是方舟提供的一个高效的缓存机制。它通过缓存上下文数据，减少重复加载或处理，提高响应速度和一致性。本文介绍上下文缓存 API 的输入输出参数，供您使用接口时查阅字段含义。</span>

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="8kVQ47wf"><RenderMd content={` <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[计费说明](https://www.volcengine.com/docs/82379/1099320#%E4%B8%8A%E4%B8%8B%E6%96%87%E7%BC%93%E5%AD%98%E8%AE%A1%E8%B4%B9)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)        <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[支持模型](https://www.volcengine.com/docs/82379/1330310#e6772192)  
 <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[调用教程](https://www.volcengine.com/docs/82379/1396491)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_bef4bc3de3535ee19d0c5d6c37b0ffdd.png =20x) </span>[开通模型](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)       
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="MvMOHIrL"><RenderMd content={`本接口支持 API Key / Access Key鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="#WJ605J7N"></span>
## 
---


:::tip
大部分字段与[对话(Chat)-文本 API](https://www.volcengine.com/docs/82379/1494384)一致，除了下面参数：

* **model**：暂时不支持直接通过Model ID 调用模型。
* <span style="background-color: rgba(27, 31, 35, 0.05)"><strong>messages</strong></span>：不支持最后一个元素的<span style="background-color: rgba(27, 31, 35, 0.05)">role</span>设置为<span style="background-color: rgba(27, 31, 35, 0.05)"><code>assistant</code></span>。
   * 如使用session 缓存（**mode**设置为`session`），传入最新一轮对话的信息，无需传入历史信息。
* <span style="background-color: rgba(27, 31, 35, 0.05)"><strong>tools</strong></span>：不支持 **tools** 字段。
* <span style="background-color: rgba(27, 31, 35, 0.05)"><strong>context_id</strong></span>：增加的字段，指定本次请求使用上下文缓存。
* **thinking**：不支持 **thinking** 字段。
* **response_format**：不支持结构化输出参数。

:::
<span id="#RxN8G2nH"></span>
## 请求参数 
> 跳转 [响应参数](https://www.volcengine.com/docs/82379/1529329#q0ryvuBR)


---


**model**`tring` `必选`
您需要调用的模型的 ID （<span style="background-color: rgb(255, 255, 255)">Model ID</span>），[开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)，并[查询 Model ID](https://www.volcengine.com/docs/82379/1330310) 。
<span style="background-color: rgb(243, 245, 247)">您也可通过 Endpoint ID 来调用模型，获得限流、计费类型（前付费/后付费）、运行状态查询、监控、安全等高级能力，可参考</span>[获取 Endpoint ID](https://www.volcengine.com/docs/82379/1099522)<span style="background-color: rgb(243, 245, 247)">。</span>

---


<span style="background-color: rgb(32, 33, 35)"><strong>messages</strong></span><span style="background-color: rgb(32, 33, 35)">  </span><span style="background-color: rgba(238, 242, 245, 0.5)"><code>object[]</code></span><span style="background-color: rgb(32, 33, 35)"> </span>`必选`
到目前为止的对话组成的消息列表。不同模型支持不同类型的消息，如文本、图片、视频等。

消息类型

---


**系统消息** `object`
<span style="background-color: rgb(32, 33, 35)">开发人员提供的指令，模型应遵循这些指令。如模型扮演的角色或者目标等。</span>

属性

---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为<span style="background-color: rgb(var(--gray-100)/.5)"><code>system</code></span><span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string / object[]</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
系统信息内容。

属性

---


**纯文本消息内容** `string`
纯文本消息内容，大语言模型支持传入此类型。

---


**多模态消息内容** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object[]</code></span> 
支持文本、图像、视频等类型，视觉理解模型等多模态模型、部分大语言模型支持此字段。

各模态消息部分

---


**文本消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，内容文本输入。[具备视觉理解能力模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)、部分大语言模型支持此类型消息。

属性

---


messages.content.**text** `string` `必选`
文本消息部分的内容。

---


messages.content.**type** `string` `必选`
文本消息类型，此次应为 `text`。





---


**用户消息** `object` 
<span style="background-color: rgb(32, 33, 35)">用户发送的消息，包含提示或附加上下文信息。不同模型支持的字段类型不同，最多支持文本、图片、视频形式的消息。</span>

属性

---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为`user`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string / object[]</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
用户信息内容。

内容类型

---


**纯文本消息内容** `string`
纯文本消息内容，大语言模型支持传入此类型。

---


**多模态消息内容** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object[]</code></span> 
支持文本、图像、视频等类型，视觉理解模型等多模态模型、部分大语言模型支持此字段。

内容类型

---


**文本消息部分** <span style="background-color: rgb(var(--gray-100)/.5)"><code>object</code></span>
多模态消息中，内容文本输入。视觉理解模型、部分大语言模型支持此类型消息。

属性

---


messages.content.**text** `string` `必选`
文本消息部分的内容。

---


messages.content.**type** `string` `必选`
文本消息类型，此次应为 `text`。





---


**模型消息** `object`
<span style="background-color: rgb(32, 33, 35)">历史对话中，模型回复的消息。往往在多轮对话传入历史对话记录以及 </span>[Prefill Response](https://www.volcengine.com/docs/82379/1359497)<span style="background-color: rgb(255, 255, 255)"> 时让模型按照预置的回复内容继续回复时使用。</span>

属性
:::tip
messages.**content**<span style="background-color: rgba(27, 31, 35, 0.05)"><strong> </strong></span><span style="background-color: rgb(255, 255, 255)">与 </span>messages.**tool_calls**<span style="background-color: rgba(27, 31, 35, 0.05)"><strong> </strong></span><span style="background-color: rgb(255, 255, 255)">字段二者至少填写其一。</span>

:::
---


messages.**role** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
发送消息的角色，此处应为`assistant`<span style="background-color: rgb(var(--gray-100)/.5)">。</span>

---


messages.**content** <span style="background-color: rgb(32, 33, 35)"><code>string / array</code></span><span style="background-color: rgb(32, 33, 35)"> </span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>
模型回复的消息。

---


messages.**tool_calls** `object[]`
历史对话中，模型回复的工具调用信息。

显示子字段

---


messages.tool_calls**.function** `object` `必选`
<span style="background-color: rgb(255, 255, 255)">模型调用工具对应的函数信息。</span>

显示子字段

---


messages.tool_calls**.**function.**name** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">模型需要调用的函数名称。</span>

---


messages.tool_calls**.**function.<span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
:::tip
<span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>

:::

---


messages.tool_calls**.id** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>

---


messages.tool_calls**.type** <span style="background-color: rgb(var(--gray-100)/.5)"><code>string</code></span><span style="background-color: rgb(var(--gray-100)/.5)"> </span>`必选`
<span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">。</span>




---


**context_id** `string` `必选`
指定本次请求使用上下文缓存的 ID。在使用[接口](https://www.volcengine.com/docs/82379/1529329)创建缓存时，从返回信息中获得。

---


**stream** `boolean / null` `默认值 false`
响应内容是否流式返回：

* `false`：模型生成完所有内容后一次性返回结果。
* `true`：按 SSE 协议逐块返回模型生成内容，并以一条 `data: [DONE] `消息结束。


---


**stream_options** `object / null` `默认值 null`
流式响应的选项。当 **stream** 为 `true` 时可设置 **stream_options** 字段。

属性

---


stream_options.**include_usage** `boolean / null` `默认值 false`
是否包含本次请求的 token 用量统计信息。

* `false`：不返回 token 用量信息。
* `true`：在 `data: [DONE]` 消息之前会返回一个额外的块，此块上的 **usage** 字段代表整个请求的 token 用量，**choices** 字段为空数组。所有其他块也将包含 **usage** 字段，但值为 `null`。


---


**max_tokens** `integer / null` `默认值 4096`
模型回复最大长度（单位 token），取值范围各个模型不同，详细见[模型列表](https://www.volcengine.com/docs/82379/1330310)。
输入 token 和输出 token 的总长度还受模型的上下文长度限制。

---


**service_tier** `string / null` `默认值 auto`
指定是否使用[TPM保障包](https://www.volcengine.com/docs/82379/1510762)。生效对象为购买了保障包推理接入点。取值范围：

* `default`：本次请求，不使用 TPM 保障包，使用默认的限流和普通的服务响应速度，即使请求的是有TPM保障包额度的推理接入点。

> 缓存不支持TPM保障包，故不支持`auto`。


---


**stop** `string / string[] / null` `默认值 null`
模型遇到 stop 字段所指定的字符串时将停止继续生成，这个词语本身不会输出。最多支持 4 个字符串。
> [深度思考能力模型](https://www.volcengine.com/docs/82379/1330310#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3%E8%83%BD%E5%8A%9B)不支持该字段。

`["你好", "天气"]`

---


**response_format** `object`  <span style="background-color: rgba(0, 0, 0, 0.04)"><code>默认值 {"type": "text"}</code></span>
模型输出内容须遵循此处指定的格式。

遵循格式

---


**遵循文本格式** `object`
模型默认回复文本格式内容。

属性

---


response_format.**type** `string` `必选`
此处应为 `text`。


---


**遵循JSON对象结构** `object`
模型回复内容以JSON对象结构来组织。
> 支持该字段的模型请参见[文档](https://www.volcengine.com/docs/82379/1568221#%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B)。


属性

---


response_format.**type** `string` `必选`
此处应为<span style="background-color: rgb(32, 33, 35)"><code>json_object</code></span><span style="background-color: rgb(32, 33, 35)">。</span>


---


**遵循JSON Schema定义的结构** `object`  `beta功能`
模型回复内容以JSON对象结构来组织，遵循 **schema** 字段定义的JSON结构。
> 支持该字段的模型请参见[文档](https://www.volcengine.com/docs/82379/1568221#%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B)。
> 该能力尚在 beta 阶段，请谨慎在生产环境使用。


属性

---


response_format.**type** `string` `必选`
此处应为<span style="background-color: rgb(32, 33, 35)"><code>json_schema</code></span><span style="background-color: rgb(32, 33, 35)">。</span>

---


response_format.<span style="background-color: rgb(32, 33, 35)"><strong>json_schema</strong></span><span style="background-color: rgb(32, 33, 35)"> </span>`object` `必选`
JSON结构体的定义。

属性

---


response_format.<span style="background-color: rgb(32, 33, 35)">json_schema.</span>**name** `string` `必选`
用户自定义的JSON结构的名称。

---


response_format.<span style="background-color: rgb(32, 33, 35)">json_schema.</span>**description** `string / null` 
回复用途描述，模型将根据此描述决定如何以该格式回复。

---


response_format.<span style="background-color: rgb(32, 33, 35)">json_schema.</span>**schema** `object` `必选`
回复格式的 JSON 格式定义，以 JSON Schema 对象的形式描述。

---


response_format.<span style="background-color: rgb(32, 33, 35)">json_schema.</span>**strict** `boolean / null` `默认值 false`
是否在生成输出时，启用严格遵循模式。

* `true`：模型将始终严格遵循**schema**字段中定义的格式。
* `false`：模型会尽可能遵循**schema**字段中定义的结构。




---


**frequency_penalty** `float / null` `默认值 0`
取值范围为 [\-2.0, 2.0]。
频率惩罚系数。如果值为正，会根据新 token 在文本中的出现频率对其进行惩罚，从而降低模型逐字重复的可能性。

---


**presence_penalty** `float / null` `默认值 0`
取值范围为 [\-2.0, 2.0]。
存在惩罚系数。如果值为正，会根据新 token 到目前为止是否出现在文本中对其进行惩罚，从而增加模型谈论新主题的可能性。

---


**temperature** `float / null` `默认值 1`
取值范围为 [0, 2]。
采样温度。控制了生成文本时对每个候选词的概率分布进行平滑的程度。当取值为 0 时模型仅考虑对数概率最大的一个 token。
较高的值（如 0.8）会使输出更加随机，而较低的值（如 0.2）会使输出更加集中确定。
通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。

---


**top_p** `float / null` `默认值 0.7`
取值范围为 [0, 1]。
核采样概率阈值。模型会考虑概率质量在 top_p 内的 token 结果。当取值为 0 时模型仅考虑对数概率最大的一个 token。
0.1 意味着只考虑概率质量最高的前 10% 的 token，取值越大生成的随机性越高，取值越低生成的确定性越高。通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。

---


**logprobs** `boolean / null` `默认值 false`
是否返回输出 tokens 的对数概率。

* `false`：不返回对数概率信息。
* `true`：返回消息内容中每个输出 token 的对数概率。


---


**top_logprobs** `integer / null` `默认值 0`
取值范围为 [0, 20]。
指定每个输出 token 位置最有可能返回的 token 数量，每个 token 都有关联的对数概率。仅当 **logprobs为**`true` 时可以设置 **top_logprobs** 参数。

---


**logit_bias** `map / null` `默认值 null`
调整指定 token 在模型输出内容中出现的概率，使模型生成的内容更加符合特定的偏好。**logit_bias** 字段接受一个 map 值，其中每个键为词表中的 token ID（使用 tokenization 接口获取），每个值为该 token 的偏差值，取值范围为 [\-100, 100]。
\-1 会减少选择的可能性，1 会增加选择的可能性；\-100 会完全禁止选择该 token，100 会导致仅可选择该 token。该参数的实际效果可能因模型而异。
`{"1234": -100}`

---


&nbsp;
<span id="#q0ryvuBR"></span>
## 响应参数
> 跳转 [请求参数](https://www.volcengine.com/docs/82379/1529329#RxN8G2nH)

<span id="#1eGvWgtq"></span>
### 
<span id="#J7lG80LC"></span>
### 非流式调用返回
> 跳转 [流式调用返回](https://www.volcengine.com/docs/82379/1529329#a0ezJT76)


---


**id** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求的唯一标识。</span>

---


**model** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求实际使用的模型名称和版本。</span>
> <span style="background-color: rgb(255, 255, 255)">doubao 1.5 代模型的模型名称格式为 doubao\-1\-5\-\*\*。如调用部署doubao\-1.5\-pro\-32k 250115模型的推理接入点，返回</span><span style="background-color: rgba(27, 31, 35, 0.05)">model</span><span style="background-color: rgb(255, 255, 255)">字段信息doubao\-1\-5\-pro\-32k\-250115。</span>


---


<span style="background-color: rgb(255, 255, 255)"><strong>service_tier</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">本次请求是否使用了TPM保障包。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>scale</code></span><span style="background-color: rgb(255, 255, 255)">：本次请求使用TPM保障包额度。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>default</code></span><span style="background-color: rgb(255, 255, 255)">：本次请求未使用TPM保障包额度。</span>


---


**created** `integer`
<span style="background-color: rgb(255, 255, 255)">本次请求创建时间的 Unix 时间戳（秒）。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>object</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>chat.completion</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


**choices** `object[]`
<span style="background-color: rgb(255, 255, 255)">本次请求的模型输出内容。</span>

属性

---


choices.**index** <span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">当前元素在 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><strong>choices</strong></span><span style="background-color: rgb(255, 255, 255)"> 列表的索引。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>finish_reason </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型停止生成 token 的原因。取值范围：</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>stop</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出自然结束，或因命中请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">stop</span><span style="background-color: rgb(255, 255, 255)"> 中指定的字段而被截断。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>length</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出因达到模型输出限制而被截断，有以下原因：</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_token</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">回答内容的长度限制）。</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_completion_tokens</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">思维链内容+回答内容的长度限制）。</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>context_window</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制</span><span style="background-color: rgb(255, 255, 255)">（输入内容+思维链内容+回答内容的长度限制）。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>content_filter</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出被内容审核拦截。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>tool_calls</code></span><span style="background-color: rgb(255, 255, 255)">：模型调用了工具。</span>


---


choices.**message** `object`
<span style="background-color: rgb(255, 255, 255)">模型输出的内容。</span>

属性

---


choices.message.**role** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">内容输出的角色，此处固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>assistant</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.message.**content** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的消息内容。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)"><strong>reasoning_content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string / null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型处理问题的思维链内容。</span>
<span style="background-color: rgb(255, 255, 255)">仅深度推理模型支持返回此字段，深度推理模型请参见</span>[支持模型](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)"><strong>tool_calls </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的工具调用。</span>

属性

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>i</strong></span>**d** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>function </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">模型调用的函数。</span>

属性

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>name </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型调用的函数的名称。</span>

---


choices.message.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
<span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>




---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>logprobs </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前内容的对数概率信息。</span>

属性

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
<span style="background-color: rgba(27, 31, 35, 0.05)">message</span><span style="background-color: rgb(255, 255, 255)">列表中每个 </span><span style="background-color: rgba(27, 31, 35, 0.05)">content</span><span style="background-color: rgb(255, 255, 255)"> 元素中的 token 对数概率信息。</span>

属性

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>top_logprobs </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
<span style="background-color: rgb(255, 255, 255)">在当前 token 位置最有可能的标记及其对数概率的列表。在一些情况下，返回的数量可能比请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">top_logprobs</span><span style="background-color: rgb(255, 255, 255)"> 指定的数量要少。</span>

**属性**

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>




---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>moderation_hit_type </strong></span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span><span style="background-color: rgb(32, 33, 35)"><code>/ null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型输出文字含有敏感信息时，会返回模型输出文字命中的风险分类标签。</span>
<span style="background-color: rgb(255, 255, 255)">返回值及含义：</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>severe_violation</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及严重违规。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>violence</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及激进行为。</span>

<span style="background-color: rgb(255, 255, 255)">注意：当前只有</span>[视觉理解模型](https://www.volcengine.com/docs/82379/1362931#%E6%94%AF%E6%8C%81%E6%A8%A1%E5%9E%8B)<span style="background-color: rgb(255, 255, 255)">支持返回该字段，且只有在</span><span style="background-color: rgb(255, 255, 255)">方舟控制台</span>[接入点配置页面](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint/create?customModelId=)<span style="background-color: rgb(255, 255, 255)">或者 </span>[CreateEndpoint](https://www.volcengine.com/docs/82379/1262823)<span style="background-color: rgb(255, 255, 255)"> 接口中，将内容护栏方案（ModerationStrategy）设置为基础方案（Basic）时，才会返回风险分类标签。</span>


---


**usage** `object`
<span style="background-color: rgb(255, 255, 255)">本次请求的 token 用量。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">输入给模型的内容的 token 用量。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>completion_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">模型输出内容的 token 用量。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>total_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">本次请求消耗的总 token 数量（输入 + 输出）。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens_details </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">命中上下文缓存的tokens细节。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)">prompt_tokens_details.</span><span style="background-color: rgb(248, 248, 248)"><strong>cached_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">提示词命中缓存的 token 用量。</span>


---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>completion_tokens_details </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">本次请求，模型输出内容的 token 用量的细节。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)">completion_tokens_details.</span><span style="background-color: rgb(248, 248, 248)"><strong>reasoning_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">输出思维链内容花费的 token 数 。</span>
<span style="background-color: rgb(255, 255, 255)">支持输出思维链的模型请参见</span>[文档](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>



---


&nbsp;
<span id="#a0ezJT76"></span>
### 流式调用返回
> 跳转 [非流式调用返回](https://www.volcengine.com/docs/82379/1529329#J7lG80LC)


---


**id** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求的唯一标识。</span>

---


**model** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求实际使用的模型名称和版本。</span>
<span style="background-color: rgb(255, 255, 255)">doubao 1.5 代模型的模型名称格式为 doubao\-1\-5\-\*\*。如调用部署doubao\-1.5\-pro\-32k 250115模型的推理接入点，返回</span><span style="background-color: rgba(27, 31, 35, 0.05)">model</span><span style="background-color: rgb(255, 255, 255)">字段信息doubao\-1\-5\-pro\-32k\-250115。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>service_tier</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">本次请求是否使用了TPM保障包。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>scale</code></span><span style="background-color: rgb(255, 255, 255)">：本次请求使用TPM保障包额度。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>default</code></span><span style="background-color: rgb(255, 255, 255)">：本次请求未使用TPM保障包额度。</span>


---


**created** `integer`
<span style="background-color: rgb(255, 255, 255)">本次请求创建时间的 Unix 时间戳（秒）。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>object</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>chat.completion.chunk</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


**choices** `object[]`
<span style="background-color: rgb(255, 255, 255)">本次请求的模型输出内容。</span>

属性

---


choices.**index** <span style="background-color: rgb(32, 33, 35)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">当前元素在 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><strong>choices</strong></span><span style="background-color: rgb(255, 255, 255)"> 列表的索引。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>finish_reason </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型停止生成 token 的原因。取值范围：</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>stop</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出自然结束，或因命中请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">stop</span><span style="background-color: rgb(255, 255, 255)"> 中指定的字段而被截断。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>length</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出因达到模型输出限制而被截断，有以下原因：</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_token</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">回答内容的长度限制）。</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>max_completion_tokens</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制（</span><span style="background-color: rgb(255, 255, 255)">思维链内容+回答内容的长度限制）。</span>
   * <span style="background-color: rgba(27, 31, 35, 0.05)">触发</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>context_window</code></span><span style="background-color: rgba(27, 31, 35, 0.05)">限制</span><span style="background-color: rgb(255, 255, 255)">（输入内容+思维链内容+回答内容的长度限制）。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>content_filter</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出被内容审核拦截。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>tool_calls</code></span><span style="background-color: rgb(255, 255, 255)">：模型调用了工具。</span>


---


choices.**delta** `object`
<span style="background-color: rgb(255, 255, 255)">模型输出的增量内容。</span>

属性

---


choices.delta.**role** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">内容输出的角色，此处固定为 </span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>assistant</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.delta.**content** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的消息内容。</span>

---


choices.delta.<span style="background-color: rgb(255, 255, 255)"><strong>reasoning_content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string / null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型处理问题的思维链内容。</span>
<span style="background-color: rgb(255, 255, 255)">仅深度推理模型支持返回此字段，深度推理模型请参见</span>[支持模型](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.delta.<span style="background-color: rgb(255, 255, 255)"><strong>tool_calls </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string / null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的工具调用。</span>

属性

---


choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>i</strong></span>**d** <span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">调用的工具的 ID。</span>

---


choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>type </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">工具类型，当前仅支持</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>function</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.</span><span style="background-color: rgb(255, 255, 255)"><strong>function </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">模型调用的函数。</span>

属性

---


choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>name </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型调用的函数的名称。</span>

---


choices.delta.<span style="background-color: rgb(255, 255, 255)">tool_calls.function.</span><span style="background-color: rgb(255, 255, 255)"><strong>arguments </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">模型生成的用于调用函数的参数，JSON 格式。</span>
<span style="background-color: rgb(255, 255, 255)">模型并不总是生成有效的 JSON，并且可能会虚构出一些您的函数参数规范中未定义的参数。在调用函数之前，请在您的代码中验证这些参数是否有效。</span>




---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>logprobs </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前内容的对数概率信息。</span>

属性

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>content </strong></span><span style="background-color: rgb(32, 33, 35)"><code>object[] / null</code></span>
<span style="background-color: rgba(27, 31, 35, 0.05)">message</span><span style="background-color: rgb(255, 255, 255)">列表中每个 </span><span style="background-color: rgba(27, 31, 35, 0.05)">content</span><span style="background-color: rgb(255, 255, 255)"> 元素中的 token 对数概率信息。</span>

属性

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.</span><span style="background-color: rgb(255, 255, 255)"><strong>top_logprobs </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object[]</code></span>
<span style="background-color: rgb(255, 255, 255)">在当前 token 位置最有可能的标记及其对数概率的列表。在一些情况下，返回的数量可能比请求参数 </span><span style="background-color: rgba(27, 31, 35, 0.05)">top_logprobs</span><span style="background-color: rgb(255, 255, 255)"> 指定的数量要少。</span>

属性

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>token </strong></span><span style="background-color: rgb(32, 33, 35)"><code>string</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>bytes </strong></span><span style="background-color: rgb(255, 255, 255)"><code>integer[] / null</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的 UTF\-8 值，格式为整数列表。当一个字符由多个 token 组成（表情符号或特殊字符等）时可以用于字符的编码和解码。如果 token 没有 UTF\-8 值则为空。</span>

---


choices.<span style="background-color: rgb(255, 255, 255)">logprobs.content.top_logprobs.</span><span style="background-color: rgb(255, 255, 255)"><strong>logprob </strong></span><span style="background-color: rgb(255, 255, 255)"><code>float</code></span>
<span style="background-color: rgb(255, 255, 255)">当前 token 的对数概率。</span>




---


choices.<span style="background-color: rgb(255, 255, 255)"><strong>moderation_hit_type </strong></span><span style="background-color: rgb(255, 255, 255)"><code>string</code></span><span style="background-color: rgb(32, 33, 35)"><code>/ null</code></span>
<span style="background-color: rgb(255, 255, 255)">模型输出文字含有敏感信息时，会返回模型输出文字命中的风险分类标签。</span>
<span style="background-color: rgb(255, 255, 255)">返回值及含义：</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>severe_violation</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及严重违规。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>violence</code></span><span style="background-color: rgb(255, 255, 255)">：模型输出文字涉及激进行为。</span>

<span style="background-color: rgb(255, 255, 255)">注意：当前只有</span>[视觉理解模型](https://www.volcengine.com/docs/82379/1362931#%E6%94%AF%E6%8C%81%E6%A8%A1%E5%9E%8B)<span style="background-color: rgb(255, 255, 255)">支持返回该字段，且只有在</span><span style="background-color: rgb(255, 255, 255)">方舟控制台</span>[接入点配置页面](https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint/create?customModelId=)<span style="background-color: rgb(255, 255, 255)">或者 </span>[CreateEndpoint](https://www.volcengine.com/docs/82379/1262823)<span style="background-color: rgb(255, 255, 255)"> 接口中，将内容护栏方案（ModerationStrategy）设置为基础方案（Basic）时，才会返回风险分类标签。</span>


---


**usage** `object`
<span style="background-color: rgb(255, 255, 255)">本次请求的 token 用量。</span>
<span style="background-color: rgb(255, 255, 255)">流式调用时，默认不统计 token 用量信息，返回值为</span><span style="background-color: rgba(27, 31, 35, 0.05)"><code>null</code></span><span style="background-color: rgb(255, 255, 255)">。</span>
<span style="background-color: rgb(255, 255, 255)">如需统计，需设置 </span><span style="background-color: rgb(255, 255, 255)"><strong>stream_options.include_usage</strong></span><span style="background-color: rgb(255, 255, 255)">为</span><span style="background-color: rgb(255, 255, 255)"><code>true</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">输入给模型的内容的 token 用量。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>completion_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">模型输出内容的 token 用量。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>total_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">本次请求消耗的总 token 数量（输入 + 输出）。</span>

---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>prompt_tokens_details </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">输入给模型的内容的 token 用量的细节。</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)">prompt_tokens_details.</span><span style="background-color: rgb(248, 248, 248)"><strong>cached_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">通过缓存输入内容的 token 用量。</span>


---


usage.<span style="background-color: rgb(255, 255, 255)"><strong>completion_tokens_details </strong></span><span style="background-color: rgb(255, 255, 255)"><code>object</code></span>
<span style="background-color: rgb(255, 255, 255)">本次请求，模型输出内容的 token 用量的细节</span>

属性

---


usage.<span style="background-color: rgb(255, 255, 255)">completion_tokens_details.</span><span style="background-color: rgb(248, 248, 248)"><strong>reasoning_tokens </strong></span><span style="background-color: rgb(248, 248, 248)"><code>integer</code></span>
<span style="background-color: rgb(255, 255, 255)">输出思维链内容花费的 token 数 。</span>
<span style="background-color: rgb(255, 255, 255)">支持输出思维链的模型请参见</span>[文档](https://www.volcengine.com/docs/82379/1449737#5f0f3750)<span style="background-color: rgb(255, 255, 255)">。</span>





# doubao-seed-1.6 
Source: https://www.volcengine.com/docs/82379/1593702

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★★★</div>

<div style="text-align: center">高</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度 </code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">较慢</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格(元/百万token）</code></div>

<div style="text-align: center">≥0.8, ≥2.0</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, Image , Video, <del>Audio</del></div>

<div style="text-align: center">文本, 图像, 视频</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, <del>Image</del>, <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

全新多模态深度思考模型，同时支持 `thinking`、`non-thinking`、`auto`三种思考模式。其中` non-thinking` 模型对比 `doubao-1.5-pro-32k-250115` 模型大幅提升。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：256k
最大输入长度：224k
最大思维链内容长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：32k
默认最大回答长度：4k
> [附-模型输入输出长度限制说明](https://www.volcengine.com/docs/82379/1449737#4adf109b)


</div>
</div>


---


<span id="a53f0f06"></span>
## 模型价格

| | | | | | | | | \
|条件 |\
|(千 token) |输入 |\
| |(元/百万 token) |输入命中缓存 |\
| | |(元/百万 token) |输出单价 |\
| | | |(元/百万 token) |缓存存储 |\
| | | | |(元/百万 token*小时) |输入单价[批量] |\
| | | | | |(元/百万 token) |输入命中缓存单价[批量] |\
| | | | | | |(元/百万 token) |输出单价[批量] |\
| | | | | | | |(元/百万 token) |
|---|---|---|---|---|---|---|---|
| | | | | | | | | \
|输入长度 [0, 32] |\
|且输出长度 [0, 0.2] |0.80 |0.16 |2.00 |0.017 |0.40 |0.16 |1.00 |
| | | | | | | | | \
|输入长度 [0, 32] |\
|且输出长度 (0.2,+∞) |0.80 |0.16 |8.00 |0.017 |0.40 |0.16 |4.00 |
| | | | | | | | | \
|输入长度 (32, 128] |1.20 |0.16 |16.00 |0.017 |0.60 |0.16 |8.00 |
| | | | | | | | | \
|输入长度 (128, 256] |2.40 |0.16 |24.00 |0.017 |1.20 |0.16 |12.00 |

> 下面是计费项的简单说明，具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

> * 输入输出价位按照输入长度来定档，举例，在线推理场景，当输入长度为 16k ，则输入单价为0.8 元/百万 token，输出单价为8 元/百万 token。
> * 使用在线推理的上下文缓存能力，产生命中缓存的输入折后费用、创建的缓存存储费用。
> * 使用批量推理，产生输入[批量]费用、命中透明缓存的输入折后费用、输出[批量]费用。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
* [Function Calling](https://www.volcengine.com/docs/82379/1262342)
* [视觉理解](https://www.volcengine.com/docs/82379/1362931)
* [Responses API 教程](https://www.volcengine.com/docs/82379/1585128)
   * beta版，邀测中


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [深度思考](https://www.volcengine.com/docs/82379/1449737)
* [结构化输出](https://www.volcengine.com/docs/82379/1568221)
* [批量推理](https://www.volcengine.com/docs/82379/1399517)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-seed-1.6

* doubao-seed-1-6-250615
   支持关闭思考，即支持 API 中的 **thinking** 字段。

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.33333333333333337);">

<div style="text-align: center"><a href="/docs/82379/1449737">深度思考</a></div>

<div style="text-align: center">深度思考能力使用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.3333333333333333);margin-left: 16px;">

<div style="text-align: center"><a href="/docs/82379/1362931">视觉理解</a></div>

<div style="text-align: center">视觉理解能力使用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.33333333333333337);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat) API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>

<span id="e761f8ca"></span>
## 使用说明
<span id="9f5b6ac5"></span>
### 深度思考开关（支持 auto 模式）
`doubao-seed-1-6-250615`支持使用 **thinking** 参数控制模型是否开启深度思考模式。默认为`开启`状态。详细使用请参见 [开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa)文档。
<span id="1a47c749"></span>
### 控制模型输出长度（支持 max_completion_tokens ）
详细使用请参见 [设置模型输出长度限制](https://www.volcengine.com/docs/82379/1449737#31ecc4d7)。





# doubao-seed-1.6-flash
Source: https://www.volcengine.com/docs/82379/1593704

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中等</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">较快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格(元/百万token）</code></div>

<div style="text-align: center">≥0.15, ≥1.5</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, Image , Video, <del>Audio</del></div>

<div style="text-align: center">文本, 图像, 视频</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, <del>Image</del>, <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

有极致推理速度的多模态深度思考模型；同时支持文本和视觉理解。文本理解能力超过上一代 Lite 系列模型，视觉理解比肩友商 Pro 系列模型。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：256k
最大输入长度：224k
最大思维链内容长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：32k
默认最大回答长度：4k
> [附-模型输入输出长度限制说明](https://www.volcengine.com/docs/82379/1449737#4adf109b)


</div>
</div>


---


<span id="a53f0f06"></span>
## 模型价格

| | | | | | | | | \
|条件 |\
|(千 token) |输入 |\
| |(元/百万 token) |输入命中缓存 |\
| | |(元/百万 token) |输出单价 |\
| | | |(元/百万 token) |缓存存储 |\
| | | | |(元/百万 token*小时) |输入单价[批量] |\
| | | | | |(元/百万 token) |输入命中缓存单价[批量] |\
| | | | | | |(元/百万 token) |输出单价[批量] |\
| | | | | | | |(元/百万 token) |
|---|---|---|---|---|---|---|---|
| | | | | | | | | \
|输入长度 [0, 32] |0.15 |0.03 |1.50 |0.017 |0.075 |0.03 |0.75 |
| | | | | | | | | \
|输入长度 (32, 128] |0.30 |0.03 |3.00 |0.017 |0.150 |0.03 |1.50 |
| | | | | | | | | \
|输入长度 (128, 256] |0.60 |0.03 |6.00 |0.017 |0.300 |0.03 |3.00 |

> 下面是计费项的简单说明，具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

> * 输入输出价位按照输入长度来定档，举例，在线推理时，当输入长度为 16k ，则输入单价为 0.15 元/百万 token，输出单价为 1.5 元/百万 token。
> * 使用在线推理的上下文缓存，产生命中缓存的输入折后费用、创建的缓存存储费用。
> * 使用批量推理，产生输入[批量]费用、命中透明缓存的输入折后费用、输出[批量]费用。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
* [Function Calling](https://www.volcengine.com/docs/82379/1262342)
* [视觉理解](https://www.volcengine.com/docs/82379/1362931)
* [Responses API 教程](https://www.volcengine.com/docs/82379/1585128)
   * beta版，邀测中


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [深度思考](https://www.volcengine.com/docs/82379/1449737)
* [结构化输出](https://www.volcengine.com/docs/82379/1568221)
* [批量推理](https://www.volcengine.com/docs/82379/1399517)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-seed-1.6-flash

* doubao-seed-1-6-flash-250615
   支持关闭思考，即支持 API 中的 **thinking** 字段。

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.33333333333333337);">

<div style="text-align: center"><a href="/docs/82379/1449737">深度思考</a></div>

<div style="text-align: center">深度思考能力使用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.3333333333333333);margin-left: 16px;">

<div style="text-align: center"><a href="/docs/82379/1362931">视觉理解</a></div>

<div style="text-align: center">视觉理解能力使用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.33333333333333337);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat) API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>

<span id="e761f8ca"></span>
## 使用说明
<span id="9f5b6ac5"></span>
### 深度思考开关
`doubao-seed-1-6-flash`支持使用 **thinking** 参数控制模型是否开启深度思考模式。默认为`开启`状态。详细使用请参见 [开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa)文档。
<span id="8544c0e0"></span>
### 控制模型输出长度（支持 max_completion_tokens ）
详细使用请参见 [设置模型输出长度限制](https://www.volcengine.com/docs/82379/1449737#31ecc4d7)。


# doubao-seed-1.6-thinking
Source: https://www.volcengine.com/docs/82379/1593703


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★★★</div>

<div style="text-align: center">高</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">较慢</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格(元/百万token）</code></div>

<div style="text-align: center">≥0.8, ≥8.0</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, Image , Video, <del>Audio</del></div>

<div style="text-align: center">文本, 图像, 视频</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, <del>Image</del>, <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

在思考能力上进行了大幅强化， 对比 doubao 1.5 代深度理解模型，在编程、数学、逻辑推理等基础能力上进一步提升， 支持视觉理解。



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：256k
最大输入长度：224k
最大思维链内容长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：16k
默认最大回答长度：4k
> [附-模型输入输出长度限制说明](https://www.volcengine.com/docs/82379/1449737#4adf109b)


</div>
</div>


---


<span id="a53f0f06"></span>
## 模型价格

| | | | | | | | | \
|条件 |\
|(千 token) |输入 |\
| |(元/百万 token) |输入命中缓存 |\
| | |(元/百万 token) |输出单价 |\
| | | |(元/百万 token) |缓存存储 |\
| | | | |(元/百万 token*小时) |输入单价[批量] |\
| | | | | |(元/百万 token) |输入命中缓存单价[批量] |\
| | | | | | |(元/百万 token) |输出单价[批量] |\
| | | | | | | |(元/百万 token) |
|---|---|---|---|---|---|---|---|
| | | | | | | | | \
|输入长度 [0, 32] |0.80 |0.16 |8.00 |0.017 |0.40 |0.16 |4.00 |
| | | | | | | | | \
|输入长度 (32, 128] |1.20 |0.16 |16.00 |0.017 |0.60 |0.16 |8.00 |
| | | | | | | | | \
|输入长度 (128, 256] |2.40 |0.16 |24.00 |0.017 |1.20 |0.16 |12.00 |

> 下面是计费项的简单说明，具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

> * 输入输出价位按照输入长度来定档，举例，在线推理场景，当输入长度为 16k ，则输入单价为0.8 元/百万 token，输出单价为8 元/百万 token。
> * 使用在线推理的上下文缓存，产生命中缓存的输入折后费用、创建的缓存存储费用。
> * 使用批量推理，产生输入[批量]费用、命中透明缓存的输入折后费用、输出[批量]费用。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
* [Function Calling](https://www.volcengine.com/docs/82379/1262342)
* [视觉理解](https://www.volcengine.com/docs/82379/1362931)
* [Responses API 教程](https://www.volcengine.com/docs/82379/1585128)
   * beta版，邀测中


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [深度思考](https://www.volcengine.com/docs/82379/1449737)
* [结构化输出](https://www.volcengine.com/docs/82379/1568221)
* [批量推理](https://www.volcengine.com/docs/82379/1399517)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-seed-1.6-thinking

* doubao-seed-1-6-thinking-250615
   不支持关闭思考，即不支持 API 中的 **thinking** 字段。

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.33333333333333337);">

<div style="text-align: center"><a href="/docs/82379/1449737">深度思考</a></div>

<div style="text-align: center">深度思考能力使用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.3333333333333333);margin-left: 16px;">

<div style="text-align: center"><a href="/docs/82379/1362931">视觉理解</a></div>

<div style="text-align: center">视觉理解能力使用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.33333333333333337);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat) API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>



# doubao-1.5-thinking-vision-pro
Source: https://www.volcengine.com/docs/82379/1554521

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">高</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">较慢</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格(元/百万token）</code></div>

<div style="text-align: center">3, 9</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, Image , Video, <del>Audio</del></div>

<div style="text-align: center">文本, 图像, 视频</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, <del>Image</del>, <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-1-5-thinking-vision-pro 全新视觉深度思考模型，具备更强的通用多模态理解和推理能力，在 59 个公开评测基准中的 37 个上取得 SOTA 表现。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：128k
最大输入长度：96k
最大思维链内容长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：16k
默认最大回答长度：4k
> [附-模型输入输出长度限制说明](https://www.volcengine.com/docs/82379/1449737#4adf109b)


</div>
</div>


---


模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">3</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">9</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">1.5</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">4.5</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
* [Function Calling](https://www.volcengine.com/docs/82379/1262342)
* [视觉理解](https://www.volcengine.com/docs/82379/1362931)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [深度思考](https://www.volcengine.com/docs/82379/1449737)
* [批量推理](https://www.volcengine.com/docs/82379/1305505)
* [结构化输出](https://www.volcengine.com/docs/82379/1568221)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-1.5-thinking-vision-pro

* doubao-1-5-thinking-vision-pro-250428
   支持文本、图片、视频输入，可以通过 **thinking** 参数控制是否关闭深度思考。

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.33333333333333337);">

<div style="text-align: center"><a href="/docs/82379/1449737">深度思考</a></div>

<div style="text-align: center">深度思考能力使用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.3333333333333333);margin-left: 16px;">

<div style="text-align: center"><a href="/docs/82379/1362931">视觉理解</a></div>

<div style="text-align: center">视觉理解能力使用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.33333333333333337);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat) API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>

<span id="2f306390"></span>
## 使用说明
<span id="5daa9650"></span>
### 深度思考模式开关
使用 **thinking** 参数控制模型是否开启深度思考模式。默认为`开启`状态。详细使用请参见 [开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa)文档。


# deepseek-r1
Source: https://www.volcengine.com/docs/82379/1554373

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★★★</div>

<div style="text-align: center">高</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">较慢</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2640625);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">4, 16</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.215625);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2171875);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
</div>


---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.631430584918957);">

**deepseek-r1** 是由深度求索推出的深度思考模型。在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版。



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.3685694150810431);margin-left: 16px;">

最大上下文长度：128k
最大输入长度：96k
最大思维链内容长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：32k
默认最大回答长度：4k
> [附-模型输入输出长度限制说明](https://www.volcengine.com/docs/82379/1449737#4adf109b)


</div>
</div>


---


<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">4.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">16.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">0.80</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">0.017</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">4.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">16.00</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
* [批量推理](https://www.volcengine.com/docs/82379/1399517)
* [TPM保障包](https://www.volcengine.com/docs/82379/1510762)
* [结构化输出](https://www.volcengine.com/docs/82379/1568221)
   * deepseek-r1-250528 支持


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [工具调用 Function Calling](https://www.volcengine.com/docs/82379/1262342)
* [前缀缓存教程](https://www.volcengine.com/docs/82379/1396491#c665d4d2)
   * deepseek-r1-250528、deepseek-r1-250120、deepseek-r1-distill-qwen-32b 支持。


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
**deepseek-r1**

* deepseek-r1-250528
   * 支持前缀缓存。
   * 升级最大上下文长度：96k > 128k
   * 升级最大输入长度：64k > 96k
   * [可配置](https://www.volcengine.com/docs/82379/1399009#%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B%E6%9C%80%E5%A4%A7%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6)最大回答长度 16k > 32k 。
   * 支持`max_completion_tokens`字段，输出超长内容。
* deepseek-r1-250120
   * 支持前缀缓存。
* deepseek-r1-distill-qwen-32b-250120
   * 基于deepseek-r1 660B 模型蒸馏得到的 32B 模型，支持前缀缓存。
* deepseek-r1-distill-qwen-7b-250120
   * 基于deepseek-r1 660B 模型蒸馏得到的 7B 模型，不支持前缀缓存。

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1449737">深度思考</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat) API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>



</div>
</div>

<span id="255b8109"></span>
## 其他说明
<span id="6f1ef9e4"></span>
### **不支持的参数**
下面介绍模型对于API参数的支持情况

| | | | \
|字段 |类型 |传入后行为 |
|---|---|---|
| | | | \
|stop |String or Array |不支持，忽略不报错。 |
| | | | \
|frequency_penalty |Float |不支持，忽略不报错。 |
| | | | \
|presence_penalty |Float |不支持，忽略不报错。 |
| | | | \
|temperature |Float |不支持，忽略不报错。 |
| | | | \
|top_p |Float |不支持，忽略不报错。 |
| | | | \
|logprobs |Boolean |不支持，报错。 |
| | | | \
|top_logprobs |Integer |不支持，报错。 |
| | | | \
|logit_bias |Object |不支持，报错。 |
| | | | \
|thinking |Object |不支持，报错。 |
| | | | \
|response_format |Object |暂不支持，报错。 |

<span id="b3bb2d7c"></span>
### 控制模型输出长度（支持 max_completion_tokens ）
详细使用请参见 [设置模型输出长度限制](https://www.volcengine.com/docs/82379/1449737#31ecc4d7)。



# deepseek-v3
Source: https://www.volcengine.com/docs/82379/1519547

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中等</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中等</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">2, 8</div>

<div style="text-align: center">[输入], [输出]</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del>文本</div>



</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

**deepseek-v3** 由深度求索公司自研的MoE模型，多项评测成绩超越了 qwen2.5-72b 和 llama-3.1-405b 等开源模型，并在性能上和世界顶尖的闭源模型 gpt-4o 及 claude-3.5-Sonnet 不分伯仲。



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：128k
最大思维链内容长度：不涉及
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：16k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">2.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">8.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">0.40</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">0.017</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">1.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">4.00</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
* [批量推理](https://www.volcengine.com/docs/82379/1399517)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [工具调用 Function Calling](https://www.volcengine.com/docs/82379/1262342)
* [前缀缓存](https://www.volcengine.com/docs/82379/1396491#%E5%89%8D%E7%BC%80%E7%BC%93%E5%AD%98%E6%95%99%E7%A8%8B)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
deepseek-v3

* deepseek-v3-250324
   新支持了[前缀缓存](https://www.volcengine.com/docs/82379/1396491#%E5%89%8D%E7%BC%80%E7%BC%93%E5%AD%98%E6%95%99%E7%A8%8B)。
* deepseek-v3-241226

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1399009">文本生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat) API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>



</div>
</div>

<span id="255b8109"></span>
## 其他说明
方舟deepseek-v3-250324 模型 **temperature** 字段对齐DeepSeek官方的[处理逻辑](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324#temperature)。
> 举例：您在请求中设置**temperature**为`1`，则在模型侧会映射 **temperature** 值为`0.3`。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a75f81b2e4034bd3bfafa8156eea331b~tplv-goo7wpa0wc-image.image =611x)



# doubao-1.5-ui-tars
Source: https://www.volcengine.com/docs/82379/1536429

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">较高</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">较慢</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">3.5, 12</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center">Image , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本，图像</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6773404501241118);">

一款原生面向图形界面交互（GUI）的Agent模型。通过感知、推理和动作执行等类人的能力，与 GUI 进行连续、流程的交互。
与传统模块化框架不同，模型将所有核心能力（感知、推理、基础理解能力），统一集成在视觉大模型（VLM）中，实现**无需预定义工作流程或人工规则**的端到端任务自动化。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.3226595498758883);margin-left: 16px;">

最大上下文长度：128k
最大输入长度：96k
最大思维链内容长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：16k
默认最大回答长度：4k
> [附-模型输入输出长度限制说明](https://www.volcengine.com/docs/82379/1449737#4adf109b)


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">3.50</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">12.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
</div>

> 其中使用上下文缓存会产生缓存命中、缓存存储费用；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
* [GUI 任务处理](https://www.volcengine.com/docs/82379/1584296)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [深度思考](https://www.volcengine.com/docs/82379/1449737)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-1.5-ui-tars

* doubao-1-5-ui-tars-250428
   * 增加了深度思考能力，可通过API中的 `thinking` 字段控制是否启用深度思考（模型解决问题前，先进行深度思考，输出思维链内容，再进行回答）。
   * 升级了模型回复长度限制：
      * 最大上下文长度：        `32k`升级至  `128k`
      * 最大输入长度：            `不涉及`变更至  `96k`
      * 最大思维链内容长度：`不支持` 变更至 `32k`
      * [可配置](https://www.volcengine.com/docs/82379/1399009#%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B%E6%9C%80%E5%A4%A7%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6)最大输出长度：`4k`升级至 `16k`
      * 默认最大输出长度：    `4k`维持`4k`
* doubao-1-5-ui-tars-250328
   * 推荐升级至 doubao-1-5-ui-tars-250428。
   * 长度限制如下，且不支持深度思考能力。
      * 最大上下文长度：`32k`
      * [可配置](https://www.volcengine.com/docs/82379/1399009#%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B%E6%9C%80%E5%A4%A7%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6)最大输出长度：`4k`
      * 默认最大输出长度：`4k`

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.4999999999999999);">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话（chat） API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.4999999999999999);margin-left: 16px;">

<div style="text-align: center"><a href="/docs/82379/1584296">GUI 任务处理</a></div>

<div style="text-align: center">模型使用教程</div>

<div style="text-align: center">供您了解快速调用该模型，及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
</div>

<span id="255b8109"></span>
## 其他说明
<span id="45ad54f6"></span>
### 深度思考模式开关
`doubao-1-5-ui-tars-250428`版本支持，有深度思考模式获得更好模型效果。
具体使用示例请参考[开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa)。
<span id="00d8bbfd"></span>
### 系统提示模板
处理GUI任务需要使用固定的提示词模板，使用和配置方法请参见 [系统提示设计](https://www.volcengine.com/docs/82379/1584296#be30d2ab)。
`doubao-1-5-ui-tars-250428`提示词模板
````Python
# 电脑 GUI 任务场景的提示词模板
COMPUTER_USE_DOUBAO = '''You are a GUI agent. You are given a task and your action history, with screenshots. You need to perform the next action to complete the task.

## Output Format
```
Thought: ...
Action: ...
```

## Action Space
click(point='<point>x1 y1</point>')
left_double(point='<point>x1 y1</point>')
right_single(point='<point>x1 y1</point>')
drag(start_point='<point>x1 y1</point>', end_point='<point>x2 y2</point>')
hotkey(key='ctrl c') # Split keys with a space and use lowercase. Also, do not use more than 3 keys in one hotkey action.
type(content='xxx') # Use escape characters \\', \\\", and \\n in content part to ensure we can parse the content in normal python string format. If you want to submit your input, use \\n at the end of content. 
scroll(point='<point>x1 y1</point>', direction='down or up or right or left') # Show more information on the `direction` side.
wait() #Sleep for 5s and take a screenshot to check for any changes.
finished(content='xxx') # Use escape characters \\', \\", and \\n in content part to ensure we can parse the content in normal python string format.

## Note
- Use {language} in `Thought` part.
- Write a small plan and finally summarize your next action (with its target element) in one sentence in `Thought` part.

## User Instruction
{instruction}
'''


# 手机 GUI 任务场景的提示词模板
PHONE_USE_DOUBAO = '''
You are a GUI agent. You are given a task and your action history, with screenshots. You need to perform the next action to complete the task. 
## Output Format
```
Thought: ...
Action: ...
```

## Action Space
click(point='<point>x1 y1</point>')
long_press(point='<point>x1 y1</point>')
type(content='') #If you want to submit your input, use "\\n" at the end of `content`.
scroll(point='<point>x1 y1</point>', direction='down or up or right or left')
open_app(app_name=\'\')
drag(start_point='<point>x1 y1</point>', end_point='<point>x2 y2</point>')
press_home()
press_back()
finished(content='xxx') # Use escape characters \\', \\", and \\n in content part to ensure we can parse the content in normal python string format.

## Note
- Use {language} in `Thought` part.
- Write a small plan and finally summarize your next action (with its target element) in one sentence in `Thought` part.

## User Instruction
{instruction}
'''
````


`doubao-1-5-ui-tars-250328`提示词模板
````Python
# 电脑 GUI 任务场景的提示词模板
prompt = '''You are a GUI agent. You are given a task and your action history, with screenshots. You need to perform the next action to complete the task.
## Output Format
```
Thought: ...
Action: ...
```
## Action Space
click(start_box='[x1, y1, x2, y2]')
left_double(start_box='[x1, y1, x2, y2]')
right_single(start_box='[x1, y1, x2, y2]')
drag(start_box='[x1, y1, x2, y2]', end_box='[x3, y3, x4, y4]')
hotkey(key='')
type(content='') #If you want to submit your input, use "\n" at the end of `content`.
scroll(start_box='[x1, y1, x2, y2]', direction='down or up or right or left')
wait() #Sleep for 5s and take a screenshot to check for any changes.
finished(content='xxx') # Use escape characters \\', \\", and \\n in content part to ensure we can parse the content in normal python string format.
## Note
- Use {language} in `Thought` part.
- Write a small plan and finally summarize your next action (with its target element) in one sentence in `Thought` part.
## User Instruction
 {instruction}
 '''
````


<span id="c274b383"></span>
### 示例代码
`doubao-1-5-ui-tars-250328`示例代码请参见 [GUI 任务处理](https://www.volcengine.com/docs/82379/1584296)。
下面示例代码适用于 `doubao-1-5-ui-tars-250328`
```Python
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import base64
import re
import json
import math
from pathlib import Path
import os

# 通过 pip install volcengine-python-sdk[ark] 安装方舟SDK
from volcenginesdkarkruntime._exceptions import ArkAPIError
from volcenginesdkarkruntime import Ark


def parse_action_output(output_text):
    # 提取Thought部分
    thought_match = re.search(r'Thought:(.*?)\nAction:', output_text, re.DOTALL)
    thought = thought_match.group(1).strip() if thought_match else ""

    # 提取Action部分
    action_match = re.search(r'Action:(.*?)(?:\n|$)', output_text, re.DOTALL)
    action_text = action_match.group(1).strip() if action_match else ""

    # 初始化结果字典
    result = {
        "thought": thought,
        "action": "",
        "key": None,
        "content": None,
        "start_box": None,
        "end_box": None,
        "direction": None
    }

    if not action_text:
        return json.dumps(result, ensure_ascii=False)

    # 解析action类型
    action_parts = action_text.split('(')
    action_type = action_parts[0]
    result["action"] = action_type

    # 解析参数
    if len(action_parts) > 1:
        params_text = action_parts[1].rstrip(')')
        params = {}

        # 处理键值对参数
        for param in params_text.split(','):
            param = param.strip()
            if '=' in param:
                key, value = param.split('=', 1)
                key = key.strip()
                value = value.strip().strip('\'"')

                # 处理bbox格式
                if 'box' in key:
                    # 提取坐标数字
                    numbers = re.findall(r'\d+', value)
                    if numbers:
                        coords = [int(num) for num in numbers]
                        if len(coords) == 4:
                            if key == 'start_box':
                                result["start_box"] = coords
                            elif key == 'end_box':
                                result["end_box"] = coords
                elif key == 'key':
                    result["key"] = value
                elif key == 'content':
                    # 处理转义字符
                    value = value.replace('\\n', '\n').replace('\\"', '"').replace("\\'", "'")
                    result["content"] = value
                elif key == 'direction':
                    result["direction"] = value

    return json.dumps(result, ensure_ascii=False, indent=2)

def coordinates_convert(relative_bbox, img_size):
    """
       将相对坐标[0,1000]转换为图片上的绝对像素坐标

       参数:
           relative_bbox: 相对坐标列表/元组 [x1, y1, x2, y2] (范围0-1000)
           img_size: 图片尺寸元组 (width, height)

       返回:
           绝对坐标列表 [x1, y1, x2, y2] (单位:像素)

       示例:
           >>> coordinates_convert([500, 500, 600, 600], (1000, 2000))
           [500, 1000, 600, 1200]  # 对于2000高度的图片，y坐标×2
       """
    # 参数校验
    if len(relative_bbox) != 4 or len(img_size) != 2:
        raise ValueError("输入参数格式应为: relative_bbox=[x1,y1,x2,y2], img_size=(width,height)")

    # 解包图片尺寸
    img_width, img_height = img_size

    # 计算绝对坐标
    abs_x1 = int(relative_bbox[0] * img_width / 1000)
    abs_y1 = int(relative_bbox[1] * img_height / 1000)
    abs_x2 = int(relative_bbox[2] * img_width / 1000)
    abs_y2 = int(relative_bbox[3] * img_height / 1000)

    return [abs_x1, abs_y1, abs_x2, abs_y2]

def draw_box_and_show(image, start_box=None, end_box=None, direction=None):
    """
    在图片上绘制两个边界框和指向箭头

    参数:
        image: PIL.Image对象或图片路径
        start_box: 起始框坐标 [x1,y1,x2,y2] (绝对坐标)
        end_box: 结束框坐标 [x1,y1,x2,y2] (绝对坐标)
        direction: 操作方向 ('up', 'down', 'left', 'right' 或 None)
    """
    box_color = "red"
    arrow_color = "blue"
    box_width = 10
    drag_arrow_length = 150  # drag操作箭头长度

    draw = ImageDraw.Draw(image)

    # 绘制起始框
    if start_box is not None:
        draw.rectangle(start_box, outline=box_color, width=box_width)

    # 绘制结束框
    if end_box is not None:
        draw.rectangle(end_box, outline=box_color, width=box_width)

    # 处理不同类型的操作
    if start_box is not None:
        start_center = ((start_box[0] + start_box[2]) / 2, (start_box[1] + start_box[3]) / 2)

        if end_box is not None:
            # 绘制两个框之间的连接线和箭头
            end_center = ((end_box[0] + end_box[2]) / 2, (end_box[1] + end_box[3]) / 2)
            draw.line([start_center, end_center], fill=arrow_color, width=box_width)
            draw_arrow_head(draw, start_center, end_center, arrow_color, box_width * 3)
        elif direction is not None:
            # 处理drag操作（只有start_box和direction）
            end_point = calculate_drag_endpoint(start_center, direction, drag_arrow_length)
            draw.line([start_center, end_point], fill=arrow_color, width=box_width)
            draw_arrow_head(draw, start_center, end_point, arrow_color, box_width * 3)

    # 显示结果图片
    plt.imshow(image)
    plt.axis('on')  # 不显示坐标轴
    plt.show()

def draw_arrow_head(draw, start, end, color, size):
    """
    绘制箭头头部
    """
    # 计算角度
    angle = math.atan2(end[1] - start[1], end[0] - start[0])

    # 计算箭头三个点的位置
    p1 = end
    p2 = (
        end[0] - size * math.cos(angle + math.pi / 6),
        end[1] - size * math.sin(angle + math.pi / 6)
    )
    p3 = (
        end[0] - size * math.cos(angle - math.pi / 6),
        end[1] - size * math.sin(angle - math.pi / 6)
    )

    # 绘制箭头
    draw.polygon([p1, p2, p3], fill=color)

def calculate_drag_endpoint(start_point, direction, length):
    """
    计算drag操作的箭头终点

    参数:
        start_point: 起点坐标 (x, y)
        direction: 方向 ('up', 'down', 'left', 'right')
        length: 箭头长度

    返回:
        终点坐标 (x, y)
    """
    x, y = start_point
    if direction == 'up':
        return (x, y - length)
    elif direction == 'down':
        return (x, y + length)
    elif direction == 'left':
        return (x - length, y)
    elif direction == 'right':
        return (x + length, y)
    else:
        return (x, y)  # 默认不移动

def image_to_base64(image_path):
    ext = Path(image_path).suffix.lower()
    mime_types = {
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
        '.webp': 'image/webp',
        '.bmp': 'image/bmp',
        '.tiff': 'image/tiff',
        '.svg': 'image/svg+xml',
    }
    with open(image_path, "rb") as image_file:
        binary_data = image_file.read()
        base64_data = base64.b64encode(binary_data).decode("utf-8")
    return f"data:{mime_types.get(ext, 'image/png')};base64,{base64_data}"

def run(img_path, user_prompt):
    ark_api_key = os.environ.get("ARK_API_KEY")
    sp = "You are a GUI agent. You are given a task and your action history, with screenshots. You need to perform the next action to complete the task.\n## Output Format\n```\nThought: ...\nAction: ...\n```\n## Action Space\nclick(start_box='[x1, y1, x2, y2]')\nleft_double(start_box='[x1, y1, x2, y2]')\nright_single(start_box='[x1, y1, x2, y2]')\ndrag(start_box='[x1, y1, x2, y2]', end_box='[x3, y3, x4, y4]')\nhotkey(key='')\ntype(content='') #If you want to submit your input, use \"\\n\" at the end of `content`.\nscroll(start_box='[x1, y1, x2, y2]', direction='down or up or right or left')\nwait() #Sleep for 5s and take a screenshot to check for any changes.\nfinished(content='xxx') # Use escape characters \\\\', \\\\\", and \\\\n in content part to ensure we can parse the content in normal python string format.\n## Note\n- Use Chinese in `Thought` part.\n- Write a small plan and finally summarize your next action (with its target element) in one sentence in `Thought` part.\n## User Instruction"

    client = Ark(api_key=ark_api_key, base_url="https://ark.cn-beijing.volces.com/api/v3/")
    try:
        response = client.chat.completions.create(
            model="doubao-1-5-ui-tars-250328",
            temperature=0,
            messages=[
                {
                    "role": "system",
                    "content": sp
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": user_prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": image_to_base64(img_path)
                            }
                        }
                    ]
                }

            ],
        )
        print("【结果】\n", response.choices[0].message.content)
        return response.choices[0].message.content
    except ArkAPIError as e:
        print(e)

if __name__ == "__main__":
    image_path = "<IMAGE_PATH>"
    model_response = run(image_path, "<USER_INPUT>")
    parsed_output = json.loads(parse_action_output(model_response))
    print(parsed_output)

    image = Image.open(image_path)

    # 转换坐标
    start_abs = coordinates_convert(parsed_output["start_box"], image.size) if parsed_output["start_box"] else None
    end_abs = coordinates_convert(parsed_output["end_box"], image.size) if parsed_output["end_box"] else None
    direction = parsed_output["direction"] if parsed_output["direction"] else None

    draw_box_and_show(image, start_abs, end_abs, direction)
```




# doubao-seedance-1.0-lite
Source: https://www.volcengine.com/docs/82379/1553576

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.17964435500037346);">

<div style="text-align: center"><code>生成质量</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">较高</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.21546336439855196);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.20474416069535778);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">10 </div>

<div style="text-align: center">[输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1958789124684074);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center">Image , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">图片、文本</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.20426920743730936);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center"><del>Text</del>, </div>

<div style="text-align: center"><del>Image</del>, <del>Audio</del>, Video</div>

<div style="text-align: center">视频</div>



</div>
</div>


---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

seedance 1.0 是字节跳动豆包大模型团队最新推出的视频生成基础模型。seedance 1.0 lite 模型作为该模型系列的小参数量版本，在取得出色的视频生成质量的同时，显著提升了生成速度，是兼顾效果与效率的性价比之选。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

分辨率：720p，480p，1080p
帧率：24 fps
时长：5 秒，10秒


</div>
</div>


---


<span id="4b9573f5"></span>
## 模型优势

* ### **深度语义理解与准确指令遵循** <span id="bdc48332"></span>

可精细控制人物外貌气质、衣着风格、表情动作，在多主体动作解析、嵌入式文本响应、程度副词和镜头切换响应方面，也展现出了绝对优势。

| ||| \
|视频生成示例 | | |
|---|---|---|
| ||| \
|**图生视频 i2v** | | |
| | | | \
|精细控制人物表情与动作变化 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/deafa27ec78d4c6ba9005744c5cc70b2~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/deafa27ec78d4c6ba9005744c5cc70b2~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
|【prompt】 |\
|转过脸对着镜头向前走，然后停下，她一脸生气，然后叉腰 |精准生成多主体复杂动作 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/038faf57f37145479db23b6095cad7f0~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/038faf57f37145479db23b6095cad7f0~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |【prompt】 |\
| |几个人拥抱起来，作出拥抱的动作 |对程度副词、镜头切换响应准确 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/518cba15a0224449bfe082df8967a703~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/518cba15a0224449bfe082df8967a703~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |【prompt】 |\
| | |美丽的女人在车里，风景在背景中移动。女人转脸看向镜头，满脸兴奋。镜头切换，一个男人正在开车，同样面带笑容 |
| ||| \
|**文生视频 t2v** | | |
| | | | \
|精细控制人物外貌气质与衣着风格 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/10207b332fda4779a5bd497f380a2b48~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/10207b332fda4779a5bd497f380a2b48~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
|【prompt】 |\
|      清冷的色调，雪花飘落的冬天山谷中，近景拍摄一位明艳动人的年轻白人美女侧身扭头看向镜头。 |\
|      她有着黑色的波浪卷长发，下巴尖尖的，眉毛浓密上挑，眼窝深邃，眼瞳是红色的，化着深色眼影和上挑的眼线，鼻梁挺直，嘴唇偏厚，涂着非常鲜艳的红唇，下颌线清晰，指甲非常长，做着红色美甲。 |\
|      女子身着一件黑袍，戴着帽子，领口微敞着锁骨清晰，眼睛盯着镜头，眼神十分勾人。 |\
|      背景是覆盖着厚雪的绿色植被，雪花在空中飘落。镜头向左微微环绕女人拍摄，女人抬起右手放在下巴上，看着镜头露出妩媚的笑容。 |精准生成多主体复杂动作 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/34b112e6df6f4406bae3251d7e37d0f5~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/34b112e6df6f4406bae3251d7e37d0f5~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| |【prompt】 |\
| |旋转镜头，三只长得一模一样的猿猴围成一个圈，一个用手捂住眼睛，一个用手捂住耳朵，一个用手捂住嘴巴。 |文本嵌入响应准确 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5dab81615f9f49e39b7496df4039b81e~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5dab81615f9f49e39b7496df4039b81e~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |\
| | |【prompt】 |\
| | |一个由火焰组成的“FIRE”字母在空中悬浮着，一阵风吹过，火焰烧地更加猛烈最终失去控制充满整个画面 |


* ### 丝滑连贯的首尾帧过渡效果 <span id="907d4f14"></span>

只需指定视频的起始和结束图片，模型即可生成流畅衔接首、尾帧的视频，实现画面间自然、连贯的过渡效果，满足用户对视频精准控制的需求。

| | | \
|视频效果 |输入 |\
| | |
|---|---|
| | | \
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c0a0c8926df34980b5145716e483658a~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c0a0c8926df34980b5145716e483658a~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |首帧图片 |\
| |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5f8310c5d7af43dfaf552b82ce7d90c7~tplv-goo7wpa0wc-image.image =270x) |\
| | |\
| |尾帧图片 |\
| |![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/05bca24abe1549328b4ab3941ddc9514~tplv-goo7wpa0wc-image.image =270x) |\
| | |\
| |【prompt】 |\
| |一只蓝绿精卫鸟变成人形 |\
| | |\
| | |



* ### **专业的影视级运镜控制** <span id="d74ac5b5"></span>

运镜能力强，支持环绕、航拍、变焦、平移、跟随、手持等多种镜头语言。

| || \
|视频生成示例 | |
|---|---|
| | | \
|环绕 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7a76162d61a348049104b8418343c5b4~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7a76162d61a348049104b8418343c5b4~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
|【prompt】 |\
|一个挂满灯笼的中式庭院中，站着一个长着泪痣、穿白色婚纱的亚洲女孩。镜头环绕拍摄，最后对准女孩面部，她突然抬起头，嘴角露出神秘的微笑。 |变焦 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d1d23b1bf98a4f18838f3fe3b79bd6f1~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d1d23b1bf98a4f18838f3fe3b79bd6f1~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |【prompt】 |\
| |写实风格，晴朗的蓝天之下，一大片白色的雏菊花田，镜头逐渐拉近，最终定格在一朵雏菊花的特写上，花瓣上有几颗晶莹的露珠 |
| | | \
|平移 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d8408508faef49fcbd93b4e631c5f3c0~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d8408508faef49fcbd93b4e631c5f3c0~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
|【prompt】 |\
|神庙的深处，一个背着背包的男人找到了一位古代智者的雕像。镜头向左移动，雕像手中握着一本古老的书籍，似乎在守护着某种重要的知识。 |跟随 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7e17534f05164697a337c19f4f046411~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7e17534f05164697a337c19f4f046411~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |【prompt】 |\
| |荒凉的戈壁环境，镜头跟随一位驾驶哈雷摩托的男性，特写镜头，骑手的额头绑着土黄色的头巾，身着蓝色和银色条状装饰的皮质骑手服，露出狂野的笑容后，镜头突然向上摇，有一只秃鹫在上空盘旋。 |
| | | \
|航拍 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/72561a1ef4cf42aa83e5a884eaf0ff14~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/72561a1ef4cf42aa83e5a884eaf0ff14~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
|【prompt】 |\
|慢镜头拍摄，广角镜头缓慢穿越亚马逊河流的上空，河流两侧的雨林清晰可见 |手持 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/91ce7eab09e0441692078a75f409a706~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/91ce7eab09e0441692078a75f409a706~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |【prompt】 |\
| |手持镜头，画面微微抖动体现手持感，跟随在一只在玫瑰花园中散步的猫身侧 |



* ### **丰富、自然的风格** <span id="edfbed20"></span>

文生视频可直出各种风格，图生视频可丝滑兼容各种风格的首图。

| ||| \
|视频生成示例 | | |
|---|---|---|
| | | | \
|国漫 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/29ec1410a1094583baf6bc81a8a72e4a~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/29ec1410a1094583baf6bc81a8a72e4a~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |水墨 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/828f619a8f674cfca17229d0fed392b4~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/828f619a8f674cfca17229d0fed392b4~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |水彩 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a2c3b87f10b64bbba10b4d70e1b72d44~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a2c3b87f10b64bbba10b4d70e1b72d44~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |
| | | | \
|日漫 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/42329c407ba747159456a4403fe3c87e~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/42329c407ba747159456a4403fe3c87e~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |美漫 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d6da76517e6a46bf922add01ebe4d7bd~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d6da76517e6a46bf922add01ebe4d7bd~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |剪纸 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/db3bf020854b47a484a00ec04a24f668~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/db3bf020854b47a484a00ec04a24f668~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |
| | | | \
|体素 |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bfb6dd80e6034445bac0d70991199bde~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bfb6dd80e6034445bac0d70991199bde~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |毛毡 |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/52e14d86d02244099a2e2d5b43629672~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/52e14d86d02244099a2e2d5b43629672~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |线稿 |\
| | | |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/723ebbb346524b259f5e20bfcd2555f3~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/723ebbb346524b259f5e20bfcd2555f3~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |



* ### **影调细腻的超清画质** <span id="4bf5e34a"></span>

提供 480p、720p、1080p 三种分辨率，质感细腻，影调丰富，可以适配大屏幕。


| || \
|视频生成示例 | |
|---|---|
| | | \
|480p |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bd3030024ac84ffbb1f5c50b1362dc7e~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bd3030024ac84ffbb1f5c50b1362dc7e~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |720p |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/f0ef5383e646477a8f1ad872eb2911f2~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/f0ef5383e646477a8f1ad872eb2911f2~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |
| | | \
|1080p |\
| |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7c8a839d102b44829ad040f4c003ef2a~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7c8a839d102b44829ad040f4c003ef2a~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |1080p |\
| | |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3927d606c2dc4d1caac355683fee5640~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3927d606c2dc4d1caac355683fee5640~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |


<span id="92d814e7"></span>
## 模型价格
文生视频与图生视频同价，10 元/百万 token。支持多种视频规格，不同规格视频的单价详见 [视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8)。
<span id="ea0251dd"></span>
## 模型版本
doubao-seedance-lite

* doubao-seedance-1-0-lite-t2v-250428：根据您输入的文本提示词 + 参数（可选）生成目标视频。
* doubao-seedance-1-0-lite-i2v-250428：根据您输入的首帧图片 + `new`尾帧图片（可选）+文本提示词（可选）+ 参数（可选）生成目标视频。**注意使用首尾帧功能时，仅支持480p和720p。**

<span id="733e6e5c"></span>
## 模型限流

* RPM 限流：每个模型版本的 RPM （Request Per Minute）限流为 300。若超过该限制，创建视频生成任务时会报错。
* 并发数限制：单个主账号下，每个模型版本的最大请求并发数量为 5。若超过该限制，后续提交的请求将排队等待。

<span id="787cf68c"></span>
## 使用文档
> 视频生成为异步接口，您需要先创建视频生成任务，再通过视频生成任务的 ID 去查询视频生成结果。



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.3333);">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1366799">视频生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.3333);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1520758">视频生成 API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.3333);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1587797">Seedance 提示词指南</a></div>

<div style="text-align: center">文生视频和图生视频的提示词（prompt）使用技巧，帮助您快速上手视频创作，将创意转化为视频内容。</div>



</div>
</div>

<style>
/* 覆盖内联样式的宽高 */
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default
  .xgplayer-volume-large.xgplayer-pause.xgplayer-is-replay.xgplayer-ended,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-nostart.xgplayer-skin-default.xgplayer-inactive,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-nostart.xgplayer-skin-default,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing.xgplayer-pause,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing.xgplayer-inactive,
.volc-md-viewer .editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-is-enter,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-is-enter.xgplayer-inactive,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-playing,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-isloading.xgplayer-playing {
    width: 360px !important;
    height: 180px !important;
}   
</style>


# doubao-seedance-1.0-pro
Source: https://www.volcengine.com/docs/82379/1587798

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.17964435500037346);">

<div style="text-align: center"><code>生成质量</code></div>

<div style="text-align: center">★★★★★</div>

<div style="text-align: center">最高</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.21546336439855196);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">较快</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.20474416069535778);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">15</div>

<div style="text-align: center">[输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1958789124684074);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center">Image , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">图片、文本</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.20426920743730936);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center"><del>Text</del>, </div>

<div style="text-align: center"><del>Image</del>, <del>Audio</del>, Video</div>

<div style="text-align: center">视频</div>



</div>
</div>


---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

Seedance 1.0 是字节跳动豆包大模型团队最新推出的视频生成基础模型。Seedance 1.0 pro 作为该模型系列的大参数量版本，具备独特的多镜头叙事能力，在各维度表现出色。它在语义理解与指令遵循能力上取得突破，能生成运动流畅、细节丰富、风格多样且具备影视级美感的 1080P 高清视频。




</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

分辨率：480p，720p，1080p
帧率：24 fps
时长：5 秒，10秒



</div>
</div>


---


<span id="4b9573f5"></span>
## 模型优势

* ### **独特的多镜头叙事能力** <span id="c0a6d6fa"></span>

通过高效的网络结构设计，多模态交织的位置编码和多任务统一建模，模型原生支持生成包含多个连贯镜头的叙事性视频。在镜头切换与时空变换中，能确保核心主体、视觉风格与整体氛围的高度一致性。


| || \
|**视频生成示例** | |
|---|---|
| | | \
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e92143ce616b44aab70b1c417f596866~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e92143ce616b44aab70b1c417f596866~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d5198974f9b84016bea4adc6d9871448~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d5198974f9b84016bea4adc6d9871448~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |
| | | \
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/72bf62555c8d4688b7900042227cba34~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/72bf62555c8d4688b7900042227cba34~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ea543baf50134fe0be5ceb7031e544e1~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ea543baf50134fe0be5ceb7031e544e1~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |


* ### **流畅稳定的运动表现** <span id="2970365d"></span>

基于自研细粒度精调数据集，多维度奖励模型和RLHF算法，模型能够流畅地生成大幅度的运动。从细微的表情到动态场景，均能保持高水平的稳定性与物理真实感。

| || \
|**视频生成示例** | |
|---|---|
| | | \
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a7d6f99706a9478baaf630aa662f22ea~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a7d6f99706a9478baaf630aa662f22ea~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1ee1341914354a5e8556869beacf0761~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1ee1341914354a5e8556869beacf0761~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |
| | | \
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4112dc7f8fb24da88542ed724d47d1ef~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4112dc7f8fb24da88542ed724d47d1ef~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d1a5949a58574a23a77913f9b92b558a~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d1a5949a58574a23a77913f9b92b558a~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |


* ### **精准的指令遵循** <span id="ee3cbe4f"></span>

模型充分学习丰富的场景、主体及行为动作，提升对用户精细指令的准确响应，流畅生成多主体互动、多重动作组合及随心运镜的复杂视频内容。

| || \
|**视频生成示例** | |
|---|---|
| | | \
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/682741c6d30b4240ba9e8e3b6d0fb26f~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/682741c6d30b4240ba9e8e3b6d0fb26f~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
|【prompt】 |\
|咖啡馆里，特写拍摄老年男人，他若有所思地坐着，眼神专注，表情逐渐从沉思变成微笑，他抬手撩了一下头发，随后双手交握放在下巴处，最后放下双手，身体前倾，眼神中带着思索，又像是找到了答案，最后他微微眯起眼睛，露出一个神秘的微笑 |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1766fa1b7ca741c6910577dd844bdb8b~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1766fa1b7ca741c6910577dd844bdb8b~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |【prompt】 |\
| |固定镜头，画面右侧的男人走到画面左侧的男人面前，向他表达自己强烈的不满情绪 |
| | | \
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ebd108c9d4fe4ee898d17be9bb19f543~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ebd108c9d4fe4ee898d17be9bb19f543~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
|【prompt】 |\
|画面中的两个人对视后看向天空 |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e502f473f9e24ab3a3eee8dfc4ed49ac~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e502f473f9e24ab3a3eee8dfc4ed49ac~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |【prompt】 |\
| |一片花丛，鲜艳的虞美人在摇曳，虞美人错落有致，有白色、黄色、大红色，阳光从花瓣后射过来，花瓣呈现出透明感 |


* ### **多样的风格化表达** <span id="5a3508d8"></span>

模型能准确响应多样的风格指令，以支持各类创意需求。

| ||| \
|**视频生成示例** | | |
|---|---|---|
| | | | \
|油画 |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/05a8923defa24d10a1b4d72e5c196e98~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/05a8923defa24d10a1b4d72e5c196e98~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |\
| |毛毡 |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/63f2a16e9c884cf7837911ac502f409b~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/63f2a16e9c884cf7837911ac502f409b~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |\
| | |水彩 |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cda8b1cabb2f49b4b8b03636f0edfe8a~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cda8b1cabb2f49b4b8b03636f0edfe8a~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |
| | | | \
|3D卡通 |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/54a48322559949e4a5fbeb197e14ee94~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/54a48322559949e4a5fbeb197e14ee94~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |水墨 |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c1faffb4864a45388eb3fc5ad39ef661~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c1faffb4864a45388eb3fc5ad39ef661~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |粘土 |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2394a1d7380a49b1b1f14e8f2b112903~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2394a1d7380a49b1b1f14e8f2b112903~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |
| | | | \
|像素 |\
|<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/25a5101bc5d34307aad66e0de990c6a7~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/25a5101bc5d34307aad66e0de990c6a7~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| |蒸汽朋克 |\
| |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4c682dd08232440c80adccb6b7b9dabe~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/4c682dd08232440c80adccb6b7b9dabe~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | |素描 |\
| | |<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/30d26235a77741aaba41fc6261e2aae9~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/30d26235a77741aaba41fc6261e2aae9~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer> |\
| | | |


<span id="92d814e7"></span>
## 模型价格
文生视频与图生视频同价，15 元/百万 token。支持多种视频规格，不同规格视频的单价详见 [视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8)。
<span id="ea0251dd"></span>
## 模型版本
**doubao-seedance-1-0-pro-250528**

   * 文生视频：根据您输入的文本提示词+参数（可选）生成目标视频。
   * 图生视频-首帧：根据您输入的首帧图片+文本提示词（可选）+参数（可选）生成目标视频。

<span id="733e6e5c"></span>
## 模型限流

* 并发数限制：单个主账号下，每个模型版本的最大请求并发数量为 10。若超过该限制，后续提交的请求将排队等待。
* RPM 限流：单个主账号下，创建视频任务时，该模型版本的 RPM （Request Per Minute）限流为 600。若超过该限制，创建视频生成任务时会报错。

<span id="787cf68c"></span>
## 使用文档
> 视频生成为异步接口，您需要先创建视频生成任务，再通过视频生成任务的 ID 去查询视频生成结果。



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.3333);">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1366799">视频生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.3333);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1520758">视频生成 API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 32px) * 0.3333);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1587797">Seedance 提示词指南</a></div>

<div style="text-align: center">文生视频和图生视频的提示词（prompt）使用技巧，帮助您快速上手视频创作，将创意转化为视频内容。</div>



</div>
</div>



<style>
/* 覆盖内联样式的宽高 */
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default
  .xgplayer-volume-large.xgplayer-pause.xgplayer-is-replay.xgplayer-ended,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-nostart.xgplayer-skin-default.xgplayer-inactive,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-nostart.xgplayer-skin-default,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing.xgplayer-pause,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing.xgplayer-inactive,
.volc-md-viewer .editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-playing,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-is-enter,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-is-enter.xgplayer-inactive,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-playing,
.editor-video-box.xgplayer.xgplayer-pc.xgplayer-skin-default.xgplayer-volume-large.xgplayer-isloading.xgplayer-playing {
    width: 360px !important;
    height: 180px !important;
}   
</style>


# doubao-seedream-3.0-t2i
Source: https://www.volcengine.com/docs/82379/1555133

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.17964435500037346);">

<div style="text-align: center"><code>生成质量</code></div>

<div style="text-align: center">★★★★★</div>

<div style="text-align: center">高</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.21546336439855196);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.20474416069535778);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/张）</code></div>

<div style="text-align: center">0.259 </div>

<div style="text-align: center">[输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1958789124684074);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.20426920743730936);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center"><del>Text</del>, </div>

<div style="text-align: center">Image , <del>Video</del>, <del>Audio</del> </div>

<div style="text-align: center">图片</div>




</div>
</div>


---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

Seedream 3.0 是一款支持原生高分辨率的中英双语图像生成基础模型，综合能力媲美GPT-4o，处于世界第一梯队。响应速度更快；小字生成更准确，文本排版效果增强；指令遵循能力强，美感&结构提升，保真度和细节表现较好。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

分辨率：2k



</div>
</div>


---


<span id="92d814e7"></span>
## 模型价格
图片生成模型按张计费，单价为每张0.259元。
<span id="ea0251dd"></span>
## 模型版本
doubao-seedream-3-0-t2i

* doubao-seedream-3-0-t2i-250415：根据您输入的文本提示词 生成图片。

<span id="733e6e5c"></span>
## 模型限流
模型的限流标准为每分钟生成500张图片。
<span id="787cf68c"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1548482">图片生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1541523">图片生成 API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-embedding-vision
Source: https://www.volcengine.com/docs/82379/1554712

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">0.7, 1.8</div>

<div style="text-align: center">[文本输入], [图片输入]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center">Image , Video, <del>Audio</del></div>

<div style="text-align: center">文本，图像，</div>

<div style="text-align: center">视频 *（部分模型支持）</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-embedding-vision，一款由字节跳动研发的图像向量化模型，是一种支持文本、图片及视频混合输入的向量化技术，支持中、英双语，适用于文搜图、图搜图、图文混合搜索等场景。
`doubao-embedding-vision-250615` 及后续版本支持视频输入。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：8k
最高向量维度：3072


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">0.70 [文本输入]</div>

<div style="text-align: center">1.80 [图片输入]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">0</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
</div>


> * 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。
> * 图片tokens = (width px × height px)/784，超大图封顶 1312 token，具体请参阅[图文向量化API-请求参数](https://www.volcengine.com/docs/82379/1523520#BJ5XLFqM)。
> * 视频会按照固定间隔抽取画面，具体用量请参考[用量说明](https://www.volcengine.com/docs/82379/1409291#6cf6a782)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">




</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-embedding-vision

* doubao-embedding-vision-250615
   支持 **视频、文本、图片** 输入。
   最高向量维度：2048，支持1024降维使用。
* doubao-embedding-vision-250328
   支持 **最多1张图片、1段文本** 输入。
   最高向量维度：2048
* doubao-embedding-vision-241215
   支持 **最多1张图片、1段文本** 输入。
   最高向量维度：3072

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：1,200,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：15,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1523520">图像向量化 API </a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"></div>



</div>
</div>




# doubao-embedding-large
Source: https://www.volcengine.com/docs/82379/1554711

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">0.70</div>

<div style="text-align: center">[输入]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-embedding-large，一款由字节跳动研发的语义向量化模型，主要面向向量检索的使用场景，支持中、英双语。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：4k
最高向量维度：4096


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">0.70</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">0</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">




</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-embedding-large

* doubao-embedding-large-text-250515
   * 基于Seed1.5模型训练的语义向量化模型，在通用嵌入任务中表现出色，在MTEB榜单上（包括中文和英文）均达到了最先进的效果。
   * 推理能力在复杂查询理解和推理方面展现出卓越能力，在BRIGHT榜单中取得了最先进的效果。
   * 支持多种嵌入维度 —— [2048、1024、512、256] —— 即使在较低维度下性能下降也较小。需要归一化后使用。
* doubao-embedding-large-text-240915
   * 最高向量维度 4096

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：800,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：1,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1521766">文本向量化 API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">





</div>
</div>




# doubao-1.5-vision-lite
Source: https://www.volcengine.com/docs/82379/1554516

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">1.5, 4.5</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center">Image , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本，图像</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-1.5-vision-lite，极具性价比的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：128k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：16k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">1.50</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">4.50</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">1.50</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">4.50</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1305505)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-1.5-vision-lite

* doubao-1-5-vision-lite-250315

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1362931">视觉理解</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-1.5-pro-32k
Source: https://www.volcengine.com/docs/82379/1554678

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">0.8, 2.0</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

Doubao-1.5-pro，全新一代主力模型，性能全面升级，在知识、代码、推理、等方面表现卓越。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：128k
[可配置](https://www.volcengine.com/docs/82379/1399009#%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B%E6%9C%80%E5%A4%A7%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6)最大回答长度：12k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">0.80</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">2.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">0.16</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">0.017</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">0.40</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">1.00</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
*  [工具调用 Function Calling](https://www.volcengine.com/docs/82379/1262342)
* [上下文缓存(Context API) ](https://www.volcengine.com/docs/82379/1396491)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1305505)
* [模型精调](https://www.volcengine.com/docs/82379/1099350)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-1.5-pro-32k

* doubao-1-5-pro-32k-250115
   扩展至128k上下文窗口。
   支持上下文缓存的前缀缓存和Session缓存。
* doubao-1-5-pro-32k-character-250228
   基于doubao-1.5 升级，支持故事剧情模式，优化恋爱拉扯能力，角色风格能力优化 ，增强剧情推动能力。
   支持上下文缓存的Session缓存。


<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1399009">文本生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-1.5-thinking-pro
Source: https://www.volcengine.com/docs/82379/1536428

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">高</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">较慢</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">4, 16</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center">Image , <del>Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本，图像</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> ,<del>Video, </del> <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-1.5全新深度思考模型，在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出，在AIME 2024、Codeforces、GPQA等多项权威基准上达到或接近业界第一梯队水平。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：128k
最大输入长度：96k
最大思维链内容长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B%E6%9C%80%E5%A4%A7%E8%BE%93%E5%87%BA%E9%95%BF%E5%BA%A6)最大回答长度：16k
默认最大回答长度：4k
> [附-模型输入输出长度限制说明](https://www.volcengine.com/docs/82379/1449737#4adf109b)


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">4.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">16.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">2.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">8.00</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
* [批量推理](https://www.volcengine.com/docs/82379/1399517)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

*  [工具调用 Function Calling](https://www.volcengine.com/docs/82379/1262342)
* [结构化输出](https://www.volcengine.com/docs/82379/1568221)
   * `doubao-1-5-thinking-pro-250415` 版本支持


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-1.5-thinking-pro

* doubao-1-5-thinking-pro-m-250428
   支持文本+图片输入，详细见[深度思考-视觉理解示例](https://www.volcengine.com/docs/82379/1449737#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3)。
* doubao-1-5-thinking-pro-m-250415
   支持文本+图片输入，详细见[深度思考-视觉理解示例](https://www.volcengine.com/docs/82379/1449737#%E8%A7%86%E8%A7%89%E7%90%86%E8%A7%A3)。
* doubao-1-5-thinking-pro-250415
   只支持文本输入。

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1449737">深度思考</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话（chat） API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>

<span id="d9d09587"></span>
## 使用说明
<span id="ec4f64da"></span>
### 深度思考开关（支持auto模型）
`doubao-1-5-thinking-pro-m-250428`支持使用 **thinking** 参数控制模型是否开启深度思考模式。默认为`开启`状态。
详细使用请参见 [开启关闭深度思考](https://www.volcengine.com/docs/82379/1449737#fa3f44fa)文档。



# doubao-1.5-pro-256k
Source: https://www.volcengine.com/docs/82379/1554682

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">5.0, 9.0</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-1.5-pro-256k，基于doubao-1.5-Pro全面升级版，整体效果大幅提升10%。更高性能、更大窗口、超高性价比，适用于更广泛的应用场景。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：256k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：12k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">5.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">9.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">5.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">9.00</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
*  [工具调用 Function Calling](https://www.volcengine.com/docs/82379/1262342)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1305505)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-1.5-pro-32k

* doubao-1-5-pro-256k-250115
   相比 doubao-pro-256k-241115，整体效果大幅提升10%。输出长度提升至最大 12k token。


<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：400,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：2,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1399009">文本生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-1.5-lite
Source: https://www.volcengine.com/docs/82379/1554679

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">0.3, 0.6</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

Doubao-1.5-lite，全新一代轻量版模型，极致响应速度，效果与时延均达到全球一流水平。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：12k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">0.30</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">0.60</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">0.15</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">0.30</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
*  [工具调用 Function Calling](https://www.volcengine.com/docs/82379/1262342)
* [上下文缓存(Context API) ](https://www.volcengine.com/docs/82379/1396491)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1305505)
* [前缀缓存(Context API)（已下线）](https://www.volcengine.com/docs/82379/1396490)
* [模型精调](https://www.volcengine.com/docs/82379/1099350)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-1.5-lite-32k

* doubao-1-5-lite-32k-250115

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1399009">文本生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-1.5-vision-pro
Source: https://www.volcengine.com/docs/82379/1553586

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">高</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">较慢</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">3, 9</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, Image ,Video,  <del>Audio</del></div>

<div style="text-align: center">文本，图像，视频</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text,</div>

<div style="text-align: center"><del>Image,Video</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-1.5-vision-pro，全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：128k
最大输入长度：96k
最大思维链内容长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：16k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">3.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">9.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">1.50</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">4.50</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
* [Function Calling](https://www.volcengine.com/docs/82379/1262342)
* [结构化输出](https://www.volcengine.com/docs/82379/1568221)
   * `doubao-1-5-vision-pro-250328`版本支持 `json_object`模式


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1305505)
* [深度思考](https://www.volcengine.com/docs/82379/1449737)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-1.5-vision-pro

* doubao-1-5-vision-pro-250328
   支持 文本+图片+视频 输入，可通过 [System Prompt](https://www.volcengine.com/docs/82379/1362931#%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83%E6%A8%A1%E5%BC%8F) 强制进行深度思考，输出思维链内容。
* doubao-1-5-vision-pro-32k-250115
   支持文本+图片输入，最大上下文长度为32k。

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：5,000,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1362931">视觉理解</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat) API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-vision-pro
Source: https://www.volcengine.com/docs/82379/1554677

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">3.0, 9.0</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center">Image , <del>Audio</del></div>

<div style="text-align: center">文本，图像</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

模型是豆包推出的多模态大模型，具备强大的图片理解与推理能力，以及精准的指令理解能力。模型在图像文本信息抽取、基于图像的推理任务上有展现出了强大的性能，能够应用于更复杂、更广泛的视觉问答任务。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：4k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">3.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">9.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">1.50</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">4.50</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1305505)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-vision-pro

* doubao-vision-pro-241028
   支持文本+图片输入，最大上下文长度为4k。

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：1,200,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：15,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1362931">视觉理解</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-vision-lite
Source: https://www.volcengine.com/docs/82379/1554673

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">1.5, 4.5</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center">Image , <del>Audio</del></div>

<div style="text-align: center">文本，图像</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-vision-lite 模型是豆包推出的多模态大模型，具备强大的图片理解与推理能力，以及精准的指令理解能力。模型在图像文本信息抽取、基于图像的推理任务上有展现出了强大的性能，能够应用于更复杂、更广泛的视觉问答任务。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：4k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">1.50</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">4.50</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">1.50</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">4.50</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1305505)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-vision-lite

* doubao-vision-lite-241015
   支持文本+图片输入，最大上下文长度为4k。

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：1,200,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：15,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1362931">视觉理解</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-embedding
Source: https://www.volcengine.com/docs/82379/1554710

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">0.50</div>

<div style="text-align: center">[输入]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-embedding，一款由字节跳动研发的语义向量化模型，主要面向向量检索的使用场景，支持中、英双语。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：4k
最高向量维度：2560


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">0.50</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">0</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">




</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-embedding

* doubao-embedding-text-240715 
   最高向量维度 2560
* doubao-embedding-text-240515 
   最高向量维度 2048

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：1,200,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：1,200</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1521766">文本向量化 API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">





</div>
</div>




# moonshot-v1
Source: https://www.volcengine.com/docs/82379/1554709

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">一般</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">较快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">12 <code>8K </code></div>

<div style="text-align: center">24 <code>32K</code></div>

<div style="text-align: center">60 <code>128K</code></div>

<div style="text-align: center">[输入 / 输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---


:::warning
停止售卖，只供存量用户使用
:::

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

moonshot-v1 是由 moonshot AI 推出的千亿参数的语言模型，具备优秀的语义理解、指令遵循和文本生成能力。moonshot-v1 有8K、32K、128K 三种上下文长度的模型。



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：128k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：4k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1763565891472868);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">12  <code>8K</code></div>

<div style="text-align: center">24 <code>32K</code></div>

<div style="text-align: center">60 <code>128K</code></div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.18435897435897441);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">12  <code>8K</code></div>

<div style="text-align: center">24  <code>32K</code></div>

<div style="text-align: center">60  <code>128K</code></div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15224358974358976);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14737179487179486);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.17307692307692304);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.16659212880143126);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)

<span id="6693ca28"></span>
## 模型版本
moonshot-v1

* moonshot-v1-8k 
* moonshot-v1-32k
* moonshot-v1-128k

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：</div>

<div style="text-align: center">60,000（8K）</div>

<div style="text-align: center">10,000（32K/128K）</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：</div>

<div style="text-align: center">60（8K）</div>

<div style="text-align: center">10（32K/128K）</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1399009">文本生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-lite-32k
Source: https://www.volcengine.com/docs/82379/1554660

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">0.30, 0.60</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-lite-32k，轻量级大模型，具备极致的响应速度，适用于对时延有更高要求的场景，模型配合精调使用可以获得更优质的效果。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：4k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">0.30</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">0.60</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">0.06</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">0.017</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">0.30</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">0.60</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]、缓存命中费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
* [工具调用(Function Calling)](https://www.volcengine.com/docs/82379/1262342)
* [模型精调](https://www.volcengine.com/docs/82379/1099350)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1399517)
* [上下文缓存(Context API) ](https://www.volcengine.com/docs/82379/1396491)


</div>
</div>


<span id="6693ca28"></span>
## 模型版本
doubao-lite-32k

* doubao-lite-32k-240828：通用任务
* doubao-lite-32k-character-250228：角色扮演，支持 session 缓存。
* doubao-lite-32k-character-241015：角色扮演

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">RPM：15,000 </div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：30,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1399009">文本生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-lite-4k
Source: https://www.volcengine.com/docs/82379/1554659

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">中</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">0.3, 0.6</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image </del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-lite-4k，轻量级大模型，具备极致的响应速度，适用于对时延有更高要求的场景，模型配合精调使用可以获得更优质的效果。



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：4k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：4k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">0.3</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">0.6</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">0.3</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">0.6</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1305505)


</div>
</div>


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">




</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">




</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-lite-4k

* doubao-lite-4k-character-240828
   角色扮演，支持文本输入，最大上下文长度为 4k。

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：1,200,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：15,000 </div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1399009">文本生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-lite-128k
Source: https://www.volcengine.com/docs/82379/1554661

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">0.8, 1.0</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center"><del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-lite-128k，轻量级大模型，具备极致的响应速度，适用于对时延有更高要求的场景，模型配合精调使用可以获得更优质的效果。



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：128k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：4k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">0.80</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">1.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">0.80</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">1.00</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
* [工具调用(Function Calling)](https://www.volcengine.com/docs/82379/1262342)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1305505)


</div>
</div>


<span id="6693ca28"></span>
## 模型版本
doubao-lite-128k

* doubao-lite-128k-240828


<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：1,200,000 </div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：15,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="/docs/82379/1399009">文本生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# doubao-pro-256k
Source: https://www.volcengine.com/docs/82379/1554681

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">5, 9</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, <del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, <del>Image</del> , <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-pro 是豆包推出行业领先的专业版大模型。模型在参考问答、摘要总结、创作等广泛的应用场景上能提供优质的回答，是同时具备高质量与低成本的极具性价比模型。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：256k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：4k
默认最大回答长度：4k


</div>
</div>


---



<span id="50ad88ab"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">5.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">9.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">不涉及</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="13b26b09"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
*  [工具调用 Function Calling](https://www.volcengine.com/docs/82379/1262342)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1305505)




</div>
</div>

<span id="98566d00"></span>
## 模型版本
doubao-pro-256k

* doubao-pro-256k-241115
   相比Doubao-pro-128k/240628，长文任务效果显著提升10%以上，要点提取、字数遵循、多轮对话上文记忆等能力大幅提升。

<span id="76a803e8"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：400,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：2,000</div>



</div>
</div>

<span id="287c8bd6"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1399009">文本生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>



# doubao-pro-32k
Source: https://www.volcengine.com/docs/82379/1554680

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.15156250000000002);">

<div style="text-align: center"><code>智力程度</code></div>

<div style="text-align: center">★★</div>

<div style="text-align: center">中</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1546875);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">快</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.29843749999999997);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">0.8, 2.0</div>

<div style="text-align: center">[输入], [输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.2);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, <del>Image</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1953125);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">Text, <del>Image</del>, <del>Audio</del></div>

<div style="text-align: center">文本</div>




</div>
</div>



---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

doubao-pro是豆包推出行业领先的专业版大模型。模型在参考问答、摘要总结、创作等广泛的应用场景上能提供优质的回答，是同时具备高质量与低成本的极具性价比模型。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

最大上下文长度：32k
[可配置](https://www.volcengine.com/docs/82379/1399009#0001)最大回答长度：4k
默认最大回答长度：4k


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
`元/百万 token`

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14590787119856885);">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">0.80</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15230769230769237);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center">2.00</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.15384615384615385);margin-left: 16px;">

<div style="text-align: center"><code>缓存命中</code></div>

<div style="text-align: center">0.16</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.24512820512820513);margin-left: 16px;">

<div style="text-align: center"><code>缓存存储[每小时]</code></div>

<div style="text-align: center">0.017</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.1538461538461538);margin-left: 16px;">

<div style="text-align: center"><code>输入[批量]</code></div>

<div style="text-align: center">0.80</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 80px) * 0.14896392367322614);margin-left: 16px;">

<div style="text-align: center"><code>输出[批量]</code></div>

<div style="text-align: center">2.00</div>



</div>
</div>

> 其中使用前缀缓存会产生缓存命中、缓存存储计费；批量推理产生输入[批量]、输出[批量]费用。具体请参阅[模型服务价格](https://www.volcengine.com/docs/82379/1544106)。

<span id="ea0251dd"></span>
## 能力支持

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

* [流式输出](https://www.volcengine.com/docs/82379/1399009#%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA)
*  [工具调用 Function Calling](https://www.volcengine.com/docs/82379/1262342)
* [上下文缓存(Context API) ](https://www.volcengine.com/docs/82379/1396491)


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

* [批量推理](https://www.volcengine.com/docs/82379/1305505)
* [前缀缓存(Context API)（已下线）](https://www.volcengine.com/docs/82379/1396490)
* [模型精调](https://www.volcengine.com/docs/82379/1099350)


</div>
</div>

<span id="6693ca28"></span>
## 模型版本
doubao-pro-32k

* doubao-pro-32k-241215
   全面升级，相比240828版本，整体能力显著提升，其中总结摘要、信息抽取、文本分类、复杂流程、综合任务等能力显著大幅提升。
* doubao-pro-32k-240828
   对比240615版本，模型综合能力显著提升约10%，尤其是文本分类、创作任务、总结摘要等能力上显著大幅提升。
* doubao-pro-32k-browsing-241115
   模型本身不支持联网，需要配合联网插件使用。
* doubao-pro-32k-browsing-240828
   模型本身不支持联网，需要配合联网插件使用。相较browsing-240615在信息检索问答任务效果得到全面提升，回答更准确、更少冗余内容。
* doubao-pro-32k-functioncall-241028
   相较functioncall-240815，函数调用能力显著提升18%，模型通用能力提升4.5%。
* doubao-pro-32k-functioncall-preview
   动态更新的functioncall模型，在扣子专业版中使用效果表现更好。

<span id="c34e0a1b"></span>
## 模型限流
> 速率限制通过对给定时间段内的请求或令牌使用量设置特定上限来确保公平可靠地访问 API。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center">TPM：1,200,000</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center">RPM：15,000</div>



</div>
</div>

<span id="dd1f5a32"></span>
## 使用文档

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1399009">文本生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1494384">对话(Chat)  API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>




# wan2.1-14b
Source: https://www.volcengine.com/docs/82379/1556464

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.17964435500037346);">

<div style="text-align: center"><code>生成质量</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">较高</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.21546336439855196);margin-left: 16px;">

<div style="text-align: center"><code>速度</code></div>

<div style="text-align: center">★★★</div>

<div style="text-align: center">中等</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.20474416069535778);margin-left: 16px;">

<div style="text-align: center"><code>价格（元/百万token）</code></div>

<div style="text-align: center">50.00 </div>

<div style="text-align: center">[输出]</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.1958789124684074);margin-left: 16px;">

<div style="text-align: center"><code>输入</code></div>

<div style="text-align: center">Text, </div>

<div style="text-align: center">Image, <del>Audio</del></div>

<div style="text-align: center">图片、文本</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 64px) * 0.20426920743730936);margin-left: 16px;">

<div style="text-align: center"><code>输出</code></div>

<div style="text-align: center"><del>Text</del>, </div>

<div style="text-align: center"><del>Image</del>, <del>Audio</del>, Video</div>

<div style="text-align: center">视频</div>



</div>
</div>


---



<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.6009073291050036);">

wan2.1-14b 是一个开源模型，基于DiT（Diffusion Transformer）架构，总参数量14B。生成的视频可包含中、英文文字，具备较好的运动表现、画面质量。


</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.39909267089499656);margin-left: 16px;">

分辨率：720p，480p
帧率：16 fps
时长：5 秒


</div>
</div>


---



<span id="92d814e7"></span>
## 模型价格
文生视频与图生视频同价，50 元/百万 token。支持多种视频规格，不同规格视频的单价详见 [视频生成模型](https://www.volcengine.com/docs/82379/1544106#02affcb8)。
<span id="ea0251dd"></span>
## 模型版本
wan2.1-14b

* wan2-1-14b-t2v：根据您输入的文本提示词+参数（可选）生成目标视频。
* wan2-1-14b-i2v：根据您输入的首帧图片+文本提示词+参数（可选）生成目标视频。
* wan2-1-14b-flf2v：根据您输入的首帧图片+尾帧图片+文本提示词+参数（可选）生成目标视频。

<span id="733e6e5c"></span>
## 模型限流

* RPM 限流：每个模型版本的 RPM （Request Per Minute）限流为 300。若超过该限制，创建视频生成任务时会报错。
* 并发数限制：单个主账号下，每个模型版本的最大请求并发数量为 5。若超过该限制，后续提交的请求将排队等待。

<span id="787cf68c"></span>
## 使用文档
> 视频生成为异步接口，您需要先创建视频生成任务，再通过视频生成任务的 ID 去查询视频生成结果。


<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1366799">视频生成</a></div>

<div style="text-align: center">模型调用教程</div>

<div style="text-align: center">供您了解如何调用该模型，包括参数如何配置以及一些典型使用示例代码，您可以基于此进行扩展。</div>




</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

<div style="text-align: center"><a href="https://www.volcengine.com/docs/82379/1520758">视频生成 API</a></div>

<div style="text-align: center">模型调用API参数的说明</div>

<div style="text-align: center">供您查阅API请求以及返回参数取值范围、默认值、示例等信息。</div>




</div>
</div>





# 创建模型请求
Source: https://www.volcengine.com/docs/82379/1569618
 <span style="background-color: rgb(43, 43, 43)"><code> POST https://ark.cn-beijing.volces.com/api/v3/responses</code></span><span style="background-color: rgb(43, 43, 43)"> </span>
<span style="background-color: rgb(255, 255, 255)">本文介绍 Responses API 创建模型请求时的输入输出参数，供您使用接口时查阅字段含义。</span>
:::tip
<span style="background-color: rgb(240, 244, 255)">此为邀测能力，如需使用，提交</span>[申请工单](https://console.volcengine.com/workorder/create?step=2&SubProductID=P00001166)<span style="background-color: rgb(240, 244, 255)">。 </span>

:::
```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="NxI2ZZeLhf"><RenderMd content={`<span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[模型列表](https://www.volcengine.com/docs/82379/1330310)    <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1544106)     <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[Responses API 教程](https://www.volcengine.com/docs/82379/1585128)    <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[上下文缓存教程](https://www.volcengine.com/docs/82379/1585128)    <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)
`}></RenderMd></Tabs.TabPane>
<Tabs.TabPane title="鉴权说明" key="pMCvW1OhY3"><RenderMd content={`本接口支持 API Key /Access Key 鉴权，详见[鉴权认证方式](https://www.volcengine.com/docs/82379/1298459)。
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```


---


<span id="#RxN8G2nH"></span>
## 请求参数 
<span id="#pjuiBZGA"></span>
### 请求体

---


**model** `string` %%require%%
您需要调用的模型的 ID （<span style="background-color: rgb(255, 255, 255)">Model ID</span>），[开通模型服务](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false)，并[查询 Model ID](https://www.volcengine.com/docs/82379/1330310) 。
<span style="background-color: rgb(243, 245, 247)">当您有多个应用调用模型服务或更细力度权限管理，可</span>[通过 Endpoint ID 调用模型](https://www.volcengine.com/docs/82379/1099522)<span style="background-color: rgb(243, 245, 247)">。</span>

---


<span style="background-color: rgb(32, 33, 35)"><strong>input</strong></span><span style="background-color: rgb(32, 33, 35)">  </span><span style="background-color: rgba(238, 242, 245, 0.5)"><code>string / array</code></span><span style="background-color: rgb(32, 33, 35)"> </span>%%require%%
输入的内容，模型需要处理的输入信息。

信息类型

---


**文本输入** `string`
输入给模型的文本类型信息，等同于使用 `user` 角色输入的文本信息。

---


<span style="background-color: rgb(255, 255, 255)"><strong>输入的元素列表</strong></span><span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>array</code></span>
输入给模型的信息元素，可以包括不同的信息类型。

信息类型

---


**输入的消息** `object`
发送给模型的消息，其中角色用于指示指令遵循的优先级层级。由 `developer` 或 `system` 角色给出的指令优先于 `user` 角色给出的指令。`assistant` 角色的消息通常被认为是模型在先前交互中生成的回复。

属性

---


input.**content** `string / array`  %%require%%
用于生成回复的文本、图片或视频输入，也可以包含先前助手的回复内容。

消息类型

---


**文本输入** `string`
输入给模型的文本。

---


**输入的内容列表**
包含一个或多个输入项的列表，每个输入项可包含不同类型的内容。

内容类型

---


**输入模型的文本** `object`
输入模型的文本。

属性

---


input.content.**text** `string` **** %%require%%
输入模型的文本。

---


input.content.**type** `string` **** %%require%%
输入项的类型，此处应为`input_text`。


---


**输入模型的图片** `object`
输入模型的图片。

属性

---


input.content.**type** `string` **** %%require%%
输入为图片类型，此处应为`input_image`。

---


input.content.**image_url** `string` **** %%require%%
要发送给模型的图片 URL。可以是完整的 URL，或以 data URL 形式编码的 base64 图片。

---


input.content.**detail** `string` **** 
发送给模型的图片细节级别。可选值为 `high`、`low` 或 `auto`，默认为 `auto`。


---


**输入模型的视频** `object`
输入模型的视频。

属性

---


input.content.**type** `string` **** %%require%%
输入为视频类型，此处为`input_video`。

---


input.content.**video_url** `string` **** %%require%%
要发送给模型的视频 URL。可以是完整的 URL，或以 data URL 形式编码的 base64 视频。

---


input.content.**fps** `float`
每秒钟从视频中抽取指定数量的图像，取值范围：`[0.2, 5]`。




---


input.**role** `string` %%require%%
输入消息的角色，可以是<span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>user</code></span><span style="background-color: rgb(255, 255, 255)">，</span><span style="background-color: rgb(255, 255, 255)"><code>system</code></span><span style="background-color: rgb(255, 255, 255)"> ，</span><span style="background-color: rgb(255, 255, 255)"><code>assistant</code></span><span style="background-color: rgb(255, 255, 255)">或 </span><span style="background-color: rgb(255, 255, 255)"><code>developer</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


input.**type** `string`
消息输入的类型，此处应为`message`。


---


**上下文元素** `object`
表示模型生成回复时需参考的上下文内容。该项可以包含文本、图片和视频输入，以及先前助手的回复和工具调用的输出。

属性

---


**输入的信息**`object`
历史请求中，发给模型的信息。

属性

---


input.**content** `array` %%require%%
与 **输入的信息** 中 `content` 字段的结构完全一致。

---


input.**role** `string` %%require%%
输入消息的角色，可选值：<span style="background-color: rgb(255, 255, 255)"> </span><span style="background-color: rgb(255, 255, 255)"><code>system</code></span><span style="background-color: rgb(255, 255, 255)">，</span>`user`<span style="background-color: rgb(255, 255, 255)"> 或 </span><span style="background-color: rgb(255, 255, 255)"><code>developer</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


input.**type** `string`
消息输入的类型，此处应为`message`。

---


input.**status** `string` 
项目状态，可选值：`in_progress`，`completed` 或 `incomplete`。


---


**输出的信息**`object`
历史请求中，模型输出的消息。

属性

---


input.**content** `array` %%require%%
输出消息的内容。

属性

---


**文本输出** `object`
模型的文本类型的输出。

属性

---


input.content.**text** `string` %%require%%
模型的文本输出。

---


input.content.**type** `string` %%require%%
输入给模型的内容的类型，此处应为`output_text`。表示内容是历史请求，模型输出的文本类型回答。
模型可参考历史对话，在多轮对话场景下，增强对话连续性以及语境一致性。



---


input.**role** `string` %%require%%
输出信息的角色，此处应为`assistant`。

---


input.**status** `string`%%require%%
输入消息的状态。

---


input.**type** `string` %%require%%
输出消息的类型，此处应为 `message`。


---


**输出的思维链内容**`object`
历史请求中触发了深度思考时的思维链内容。如果您在手动管理对话上下文，需将内容包含在您的 `input` 中。

属性

---


input.**summary** `array` **** %%require%%
思维链的信息。

属性

---


input.summary.**text** `string` %%require%%
历史请求的思维链内容。

---


input.summary.**type** `string` %%require%%
对象的类型，此处应为 `summary_text`。


---


input.**type** `string` **** %%require%%
对象的类型，此处应为 `reasoning`。

---


input.**status** `string`
该项的状态。


---


**工具信息** `object`
模型调用工具的信息

属性

---


input.**arguments** `string` %%require%%
要传递给函数的参数的 JSON 字符串。

---


input.**call_id** `string` %%require%%
模型生成的函数工具调用的唯一ID。

---


input.**name** `string` %%require%%
要运行的函数的名称。

---


input.**type** `string` %%require%%
工具调用的类型，始终为 `function_call`。

---


input.**status** `string`
该项的状态。


---


**工具返回的信息** `object`
调用工具后，工具返回的信息

属性

---


input.**call_id** `string` %%require%%
模型生成的函数工具调用的唯一 ID。

---


input.**output** `string` %%require%%
调用工具后，工具输出的结果。

---


input.**type** `string` %%require%%
工具调用的类型，始终为 `function_call_output`。

---


input.**status** `string`
该项的状态。





---


**instructions** `string / null` 
在模型上下文中插入系统消息或者开发者作为第一条指令。当与 `previous_response_id` 一起使用时，前一个回复中的指令不会被继承到下一个回复中。这样可以方便地在新的回复中替换系统（或开发者）消息。

---


**previous_response_id** `string / null` 
上一个模型回复的唯一标识符。使用该标识符可以实现多轮对话。
**note：**在多轮连续对话中，建议在每次请求之间加入约 100 毫秒的延迟，否则可能会导致调用失败。

---


**expire_at** `integer`
设置存储的有效期，对 `store` 和 `caching` 都生效。需传入 UTC Unix 时间戳（单位：秒）。默认值和最大值为当前时间加 3 天。

---


**max_output_tokens** `integer / null` 
模型输出最大 token 数，包含模型回答和思维链内容。

---


**thinking** `object` `默认值 {"type": "enabled"} `
控制模型是否开启深度思考模式。默认开启深度思考模式，可以手动关闭。

属性

---


thinking.**type** `string`  %%require%%
取值范围：`enabled`， `disabled`，`auto`。

* `enabled`：开启思考模式，模型一定先思考后回答。
* `disabled`：关闭思考模式，模型直接回答问题，不会进行思考。
* `auto`：自动思考模式，模型根据问题自主判断是否需要思考，简单题目直接回答。


---


**caching** `object` `默认值 {"type": "disabled"}`
是否开启缓存。

属性

---


caching.**type** `string`  %%require%%
取值范围：`enabled`， `disabled`。

* `enabled`：开启缓存。
* `disabled`：关闭缓存。


---


**store** `boolean / null` `默认值 true`
是否储存生成的模型响应，以便后续通过 API 检索。

* `false`：不储存，对话内容不能被后续的 API 检索到。
* `true`：储存当前模型响应，对话内容能被后续的 API 检索到。


---


**stream** `boolean / null` `默认值 false`
响应内容是否流式返回：

* `false`：模型生成完所有内容后一次性返回结果。
* `true`：按 SSE 协议逐块返回模型生成内容，并以一条 `data: [DONE]`消息结束。


---


**temperature** `float / null` `默认值 1`
取值范围为 [0, 2]。
采样温度。控制了生成文本时对每个候选词的概率分布进行平滑的程度。当取值为 0 时模型仅考虑对数概率最大的一个 token。
较高的值（如 0.8）会使输出更加随机，而较低的值（如 0.2）会使输出更加集中确定。
通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。

---


**top_p** `float / null` `默认值 0.7`
取值范围为 [0, 1]。
核采样概率阈值。模型会考虑概率质量在 top_p 内的 token 结果。当取值为 0 时模型仅考虑对数概率最大的一个 token。
0.1 意味着只考虑概率质量最高的前 10% 的 token，取值越大生成的随机性越高，取值越低生成的确定性越高。通常建议仅调整 temperature 或 top_p 其中之一，不建议两者都修改。

---


**text** `object`
模型文本输出的格式定义，可以是自然语言，也可以是结构化的 JSON 数据。详情请看[结构化输出](https://www.volcengine.com/docs/82379/1568221)。

属性

---


text.**format** `object` <span style="background-color: rgb(32, 33, 35)"><code>默认值 { "type": "text" }</code></span>
指定模型文本输出的格式。

属性

---


**文本格式** `object`
响应格式为自然语言。

属性
text.format.**type** `string` %%require%%
回复格式的类型，此处应为 `text`。


---


**JSON Object** `object` 
响应格式为 JSON 对象。

属性

---


text.format.**type** `string` %%require%%
回复格式的类型，此处应为 `json_object`。




---


**tools** `array`
模型可以调用的工具列表，当您需要让模型调用工具时，需要配置该结构体。

属性

---


tools.**function** `object` 
模型可以调用的类型为`function`的工具列表。

属性

---


tools.function.**name** `string` %%require%%
调用的函数的名称。

---


tools.function.**parameters** `object` %%require%%
函数请求参数，以 JSON Schema 格式描述。具体格式请参考 [JSON Schema](https://json-schema.org/understanding-json-schema) 文档，格式如下：
```JSON
{
  "type": "object",
  "properties": {
    "参数名": {
      "type": "string | number | boolean | object | array",
      "description": "参数说明"
    }
  },
  "required": ["必填参数"]
}
```

其中，

* 所有字段名大小写敏感。
* <span style="background-color: rgba(27, 31, 35, 0.05)"><strong>parameters</strong></span> 须是合规的 JSON Schema 对象。
* 建议用英文字段名，中文置于 <span style="background-color: rgba(27, 31, 35, 0.05)"><strong>description</strong></span> 字段中。


---


tools.function.**type** `string` %%require%%
工具调用的类型，固定为`function`。

---


tools.function.**description** `string` 
调用函数的描述，大模型会用它来判断是否调用这个函数。


&nbsp;
<span id="#Qu59cel0"></span>
## 响应参数
<span id="#fT1TMaZk"></span>
### 非流式调用返回

---


**created_at** `integer`
<span style="background-color: rgb(255, 255, 255)">本次请求创建时间的 Unix 时间戳（秒）。</span>

---


**error** `object / null`
模型未能生成响应时返回的错误对象。

* code：相应的错误码。
* message：错误描述。


---


**id** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求的唯一标识。</span>

---


**incomplete_details** `object / null`
响应未能完成的细节。
`reason`：响应未能完成的原因。

---


**instructions** `string / null`
在模型上下文中插入一条系统（或开发者）消息，作为首项。
当与 `previous_response_id` 一起使用时，前一响应中的指令不会延续到下一响应。

---


**max_output_tokens** `integer / null`
可生成的最大 token 数上限，不包括思考 token。

---


**model** `string`
<span style="background-color: rgb(255, 255, 255)">本次请求实际使用的模型名称和版本。</span>

---


**output** `array`
模型的输出消息列表，包含模型响应本次请求生成的回答、思维链、工具调用。

属性

---


**模型回答** `object`
模型回答，不包含思维链。

属性

---


output.**content** `array` 
输出消息的内容。

属性

---


**文本回答** `object`
模型回答的文本消息。

属性

---


output.content.**text** `string` 
模型回答的文本内容。

---


output.content.**type** `string` 
模型回答的类型，固定为`output_text`。



---


output.**role** `string` 
输出信息的角色，固定为`assistant`。

---


output.**status** `string`
输出消息的状态。

---


output.**id** `string`
<span style="background-color: rgb(255, 255, 255)">此回答的唯一标识。</span>

---


output.**type** `string` 
输出消息的类型，此处应为`message`。


---


**模型思维链**
本次请求，当触发深度思考时，模型会返回问题拆解的思维链内容。如果您在手动管理对话上下文，需在后续问答轮次中，将这些内容包含在您的 `input` 中。

属性

---


output.**summary** `array` **** 
思维链内容。

属性

---


output.summary.**text** `string` 
思维链内容的文本部分。

---


output.summary.**type** `string` 
对象的类型，此处应为 `summary_text`。


---


output.**type** `string` **** 
本输出对象的类型，此处应为 `reasoning`。

---


output.**status** `string`
本次思维链内容返回的状态。

---


output.**id** `string`
<span style="background-color: rgb(255, 255, 255)">本思维链消息的唯一标识。</span>


---


**工具调用**
本次请求，模型根据信息认为需要调用的工具信息以及对应参数。

属性

---


output.**arguments** `string` 
要传递给函数的参数，格式为 JSON 字符串。

---


output.**call_id** `string` 
本次工具调用信息的唯一 ID 。

---


output.**name** `string` 
要运行的函数的名称。

---


output.**type** `string` 
工具调用的类型，此处应为 `function_call`。

---


output.**status** `string`
此时消息返回的状态。

---


output.**id** `string`
<span style="background-color: rgb(255, 255, 255)">本次输出的唯一标识。</span>



---


**previous_response_id** `string / null`
本次请求时传入的历史响应ID。

---


**thinking** `object / null`
深度思考触发时的细节信息。

属性

---


thinking.**effort** `string / null`
触发深度思考时的思考深度。目前支持的取值有 `low`、`medium` 和 `high`。降低思考深度可以使响应更快，同时减少响应中用于深度思考的 token 数量。

---


thinking.**summary** `string / null`
模型触发深度思考时，思维链内容。


---


**caching** `object` 
是否开启缓存。

属性

---


**caching**.type **** `string` `默认值 disabled` %%require%%
取值范围：`enabled`， `disabled`。

* `enabled`：开启缓存。
* `disabled`：关闭缓存。


---


<span style="background-color: rgb(255, 255, 255)"><strong>service_tier</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">本次请求是否使用了TPM保障包。</span>

* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>scale</code></span><span style="background-color: rgb(255, 255, 255)">：本次请求使用TPM保障包额度。</span>
* <span style="background-color: rgba(27, 31, 35, 0.05)"><code>default</code></span><span style="background-color: rgb(255, 255, 255)">：本次请求未使用TPM保障包额度。</span>


---


**status** `string`
生成响应的状态。

* `completed`：响应已完成。
* `failed`：响应失败。
* `in_progress`：响应中。
* `incomplete`：响应未完成。


---


**text** `object`
用于定义输出的格式，可以是纯文本，也可以是结构化的 JSON 数据。详情请看[结构化输出](https://www.volcengine.com/docs/82379/1568221)。

属性

---


text.**format** `object`
指定模型必须输出的格式的对象。

属性

---


**自然语言输出** `object`
模型回复以自然语言输出。

text.format.**type** `string` %%require%%
回复格式的类型，固定为 `text`。


---


JSON Mode `object`
响应格式为 JSON 对象。

属性

---


text.format.**type** `string` %%require%%
回复格式的类型，固定为 `json_object`。




---


**tools** `array`
模型可以调用的工具列表。

属性

---


tools.**function** `object` 
模型可以调用的类型为`function`的工具列表。

属性

---


tools.function.**name** `string` %%require%%
调用的函数的名称。

---


tools.function.**parameters** `object` %%require%%
函数请求参数，以 JSON Schema 格式描述。具体格式请参考 [JSON Schema](https://json-schema.org/understanding-json-schema) 文档，格式如下：
```JSON
{
  "type": "object",
  "properties": {
    "参数名": {
      "type": "string | number | boolean | object | array",
      "description": "参数说明"
    }
  },
  "required": ["必填参数"]
}
```

其中，

* 所有字段名大小写敏感。
* <span style="background-color: rgba(27, 31, 35, 0.05)"><strong>parameters</strong></span> 须是合规的 JSON Schema 对象。
* 建议用英文字段名，中文置于 <span style="background-color: rgba(27, 31, 35, 0.05)"><strong>description</strong></span> 字段中。


---


tools.function.**type** `string` %%require%%
工具调用的类型，固定为`function`。

---


tools.function.**description** `string` 
调用的函数的描述，大模型会使用它来判断是否调用这个函数。



---


**top_p** `float / null`
核采样概率阈值。

---


**usage** `object`
<span style="background-color: rgb(255, 255, 255)">本次请求的 token 用量，</span>包括输入 token 数量、输入 token 的详细分解、输出 token 数量、输出 token 的详细分解，以及总共使用的 token 数。

属性

---


usage.**input_tokens** `integer`
输入的 token 量。

---


usage.**input_tokens_details** `object`
输入 token 的详细信息。

属性

---


usage.input_tokens_details.**cached_tokens** `integer`
缓存 token 的数量。


---


usage.**output_tokens** `integer`
输出的 token 量。

---


usage.**output_tokens_details** `object`
输出 token 的详细信息。

属性

---


usage.output_tokens_details.**reasoning_tokens** `integer`
思考用 token 的数量。


---


usage.**total_tokens** `integer`
消耗 token 的总量。


---


**store** `boolean` `默认值 true`
是否储存生成的模型响应，以便后续通过 API 检索。

* `false`：不储存，对话内容不能被后续的 API 检索到。
* `true`：储存当前模型响应，对话内容能被后续的 API 检索到。



# 删除模型请求
Source: https://www.volcengine.com/docs/82379/1584286
`DELETE https://ark.cn-beijing.volces.com/api/v3/responses/{response_id}`
<span style="background-color: rgb(255, 255, 255)">本文介绍如何删除指定 ID 的模型请求。</span>

```mixin-react
return (<Tabs>
<Tabs.TabPane title="快速入口" key="PuEHgP6r"><RenderMd content={` <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_2abecd05ca2779567c6d32f0ddc7874d.png =20x) </span>[模型列表](https://www.volcengine.com/docs/82379/1330310)          <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_a5fdd3028d35cc512a10bd71b982b6eb.png =20x) </span>[模型计费](https://www.volcengine.com/docs/82379/1544106)       <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_57d0bca8e0d122ab1191b40101b5df75.png =20x) </span>[模型调用教程](https://www.volcengine.com/docs/82379/1585128)    <span>![图片](https://portal.volccdn.com/obj/volcfe/cloud-universal-doc/upload_afbcf38bdec05c05089d5de5c3fd8fc8.png =20x) </span>[API Key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)
`}></RenderMd></Tabs.TabPane></Tabs>);
 ```

<span id="#rABtNeWs"></span>
## 请求参数
<span id="#vZ8meUIu"></span>
### 路径参数

---


**response_id** `string` %%require%%
<span style="background-color: rgb(255, 255, 255)">待删除请求的id。</span>
&nbsp;
<span id="#11E4X5If"></span>
## 响应参数

---


**id** `string`
<span style="background-color: rgb(255, 255, 255)">待删除请求的id。</span>

---


<span style="background-color: rgb(255, 255, 255)"><strong>object</strong></span><span style="background-color: rgb(255, 255, 255)"> </span>`string`
<span style="background-color: rgb(255, 255, 255)">固定为 </span><span style="background-color: rgb(255, 255, 255)"><code>response</code></span><span style="background-color: rgb(255, 255, 255)">。</span>

---


**deleted** `boolean`
取值范围：

* `true`：删除成功。
* `false`：未删除成功。



# 流式响应
Source: https://www.volcengine.com/docs/82379/1599499
当你创建 response 并将 `stream` 设置为 `true` 时，服务器会在生成 Response 的过程中，通过 Server\-Sent Events（SSE）实时向客户端推送事件。本节内容介绍服务器会推送的各类事件。
&nbsp;
<span id="#uJqKPOv0"></span>
## 
<span id="#uJqKPOv0"></span>
## response.created 
> 当响应被创建时触发的事件。


---


<span style="background-color: rgb(255, 255, 255)"><strong>response</strong></span> `object` 
<span style="background-color: rgb(255, 255, 255)">创建状态的响应。</span>包含参数与[创建模型请求](https://www.volcengine.com/docs/82379/1569618)时，非流式调用返回的参数一致。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.created`。

---


&nbsp;
<span id="#29Hz1H2o"></span>
## response.in_progress
> 当响应在进程中触发的事件。


---


<span style="background-color: rgb(255, 255, 255)"><strong>response</strong></span> `object` 
<span style="background-color: rgb(255, 255, 255)">进行中状态的响应。</span>包含参数与[创建模型请求](https://www.volcengine.com/docs/82379/1569618)时，非流式调用返回的参数一致。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.in_progress`。

---


&nbsp;
<span id="#8ELQhd7V"></span>
## response.completed
> 当响应已完成触发的事件。


---


<span style="background-color: rgb(255, 255, 255)"><strong>response</strong></span> `object` 
<span style="background-color: rgb(255, 255, 255)">已完成状态的响应。</span>包含参数与[创建模型请求](https://www.volcengine.com/docs/82379/1569618)时，非流式调用返回的参数一致。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.completed`。

---


&nbsp;
<span id="#JnwOkDSh"></span>
## response.failed
> 当响应失败触发的事件。

<span style="background-color: rgb(255, 255, 255)"><strong>response</strong></span> `object` 
<span style="background-color: rgb(255, 255, 255)">失败状态的响应。</span>包含参数与[创建模型请求](https://www.volcengine.com/docs/82379/1569618)时，非流式调用返回的参数一致。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.failed`。

---


&nbsp;
<span id="#AZdAWtNX"></span>
## response.incomplete
> 当响应以未完成状态结束时触发的事件 。

<span style="background-color: rgb(255, 255, 255)"><strong>response</strong></span> `object` 
<span style="background-color: rgb(255, 255, 255)">未完成状态的响应。</span>包含参数与[创建模型请求](https://www.volcengine.com/docs/82379/1569618)时，非流式调用返回的参数一致。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.incomplete`。

---


&nbsp;
&nbsp;
&nbsp;
<span id="#XxXpy5eV"></span>
## response.output_item.added
> 表示添加了新的输出项。


---


**item** `object`
模型输出内容。

属性

---


**文本输出** `object`
增加的模型回答的内容。

属性

---


item.**content** `array`
输出消息的内容。

文本信息 `object`
模型的文本输出。

属性

---


item.content.**text** `string` 
模型的文本输出。

---


item.content.**type** `string` 
输出文本的类型，总是`output_text`。



---


item.**role**  **** `string` 
输出信息的角色，总是`assistant`。 **** 

---


item.**status** `string`
输出消息的状态。

---


item.**id** `string`
<span style="background-color: rgb(255, 255, 255)">output message 请求的唯一标识。</span>

---


item.**type** `string` 
输出消息的类型。


---


**内容链** `object`
请求中触发了深度思考时的思维链内容。

属性

---


item.**summary** `array` **** 
推理文本内容。

属性

---


item.summary.**text** `string` 
模型生成答复时的推理内容。

---


item.summary.**type** `string` 
对象的类型，总是 `summary_text`。


---


item.**type** `string` **** 
对象的类型，此处应为 `reasoning`。

---


item.**status** `string`
该内容项的状态。

---


item.**id** `string`
<span style="background-color: rgb(255, 255, 255)">请求的唯一标识。</span>


---


**工具信息** `object`
模型调用工具的信息

属性

---


item.**arguments** `string` 
要传递给函数的参数的 JSON 字符串。

---


item.**call_id** `string` 
模型生成的函数工具调用的唯一ID。

---


item.**name** `string` 
要运行的函数的名称。

---


item.**type** `string` 
工具调用的类型，始终为 `function_call`。

---


item.**status** `string`
该项的状态。

---


item.**id** `string`
<span style="background-color: rgb(255, 255, 255)">工具调用请求的唯一标识。</span>



---


**output_index** `integer`
被添加的输出项的索引。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是`response.output_item.added`。

---


&nbsp;
<span id="#12MhXnUb"></span>
## response.output_item.done
> 表示输出项已完成。

**item** `object`
已完成的输出项。

属性

---


**文本输出** `object`
增加的模型回答的内容。

属性

---


item.**content** `array`
输出消息的内容。

文本信息 `object`
模型的文本输出。

属性

---


item.content.**text** `string` 
模型的文本输出。

---


item.content.**type** `string` 
输出文本的类型，总是`output_text`。


item.**role**  **** `string` 
输出信息的角色，总是`assistant`。 **** 

---


item.**status** `string`
输出消息的状态。

---


item.**id** `string`
<span style="background-color: rgb(255, 255, 255)">output message 请求的唯一标识。</span>

---


item.**type** `string` 
输出消息的类型。


---


**内容链** `object`
请求中触发了深度思考时的思维链内容。

属性

---


item.**summary** `array` **** 
推理文本内容。

属性

---


item.summary.**text** `string` 
模型生成答复时的推理内容。

---


item.summary.**type** `string` 
对象的类型，总是 `summary_text`。


---


item.**type** `string` **** 
对象的类型，此处应为 `reasoning`。

---


item.**status** `string`
该内容项的状态。

---


item.**id** `string`
<span style="background-color: rgb(255, 255, 255)">请求的唯一标识。</span>


---


**工具信息** `object`
模型调用工具的信息

属性

---


item.**arguments** `string` 
要传递给函数的参数的 JSON 字符串。

---


item.**call_id** `string` 
模型生成的函数工具调用的唯一ID。

---


item.**name** `string` 
要运行的函数的名称。

---


item.**type** `string` 
工具调用的类型，始终为 `function_call`。

---


item.**status** `string`
该项的状态。

---


item.**id** `string`
<span style="background-color: rgb(255, 255, 255)">工具调用请求的唯一标识。</span>



---


**output_index** `integer`
已完成的输出项的索引。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.output_item.done`。

---


&nbsp;
<span id="#S1Rlew1t"></span>
## response.content_part.added
> 当有新的内容部分被添加时触发。


---


**content_index** `integer`
内容部分的索引。

---


**item_id** `string`
内容部分所添加的输出项的 ID 。

---


**output_index** `integer`
内容部分所添加的输出项的索引 。

---


**part** `object`
所添加的内容部分。

属性

输出文本 **** `object`
模型输出的文本对象

part.**text**`string`
模型输出的文本内容。


part.**type** `string`
output text 的类型，此处应是`output_text`。




---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.content_part.added`。

---


&nbsp;
<span id="#XtcmlhGt"></span>
## response.content_part.done
> 当内容完成时触发。

**content_index** `integer`
内容部分的索引。

---


**item_id** `string`
内容部分所添加的输出项的 ID 。

---


**output_index** `integer`
内容部分所添加的输出项的索引 。

---


**part** `object`
所完成的内容部分。

属性

输出文本 **** `object`
模型输出的文本对象

part.**text**`string`
模型输出的文本内容。


part.**type** `string`
output text 的类型，此处应是`output_text`。




---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.content_part.done`。

---


&nbsp;
&nbsp;
<span id="#lrAYHrbh"></span>
## response.output_text.delta
> 当有新增文本片段时触发。


---


**content_index** `integer`
增量文本所属内容块的索引。

---


**delta** `string`
新增的文本片段内容。

---


**item_id** `string`
增量文本所属输出项的唯一 ID。

---


**output_index** `integer`
增量文本所属输出项的列表索引。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.output_text.delta`。

---


&nbsp;
<span id="#HXKZjqWt"></span>
## response.output_text.done
> 文本内容完成时触发。

**content_index** `integer`
文本内容所属内容块的索引。

---


**item_id** `string`
文本内容所属输出项的唯一 ID。

---


**output_index** `integer`
文本内容所属输出项的列表索引。

---


**sequence_number** `integer`
事件的序列号。

---


**text** `string`
完成的文本内容。

---


**type** `string`
事件的类型，总是 `response.output_text.done`

---


&nbsp;
<span id="#PZc03JIW"></span>
## response.function_call_arguments.delta
> 存在函数调用参数片段时触发。

**delta** `string`
本次新增的函数调用参数增量片段。

---


**item_id** `string`
所属输出项的唯一 ID。

---


**output_index** `integer`
所属输出项的列表索引。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.function_call_arguments.delta`。

---


&nbsp;
<span id="#OEfRO0nt"></span>
## response.function_call_arguments.done
> 当函数调用参数完成时触发。

**arguments** `string`
函数调用的参数。

---


**item_id** `string`
所属输出项的唯一 ID。

---


**output_index** `integer`
所属输出项的列表索引。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.function_call_arguments.done`。

---


&nbsp;
<span id="#SlWpiSbp"></span>
## response.reasoning_summary_part.added
> 当存在思维链新增部分时触发。

**item_id** `string`
所属输出项的 ID 。

---


**output_index** `integer`
所属输出项的索引 。

---


**summary_index** `integer`
输出项内，推理总结部分的子索引（若有多个总结）。

---


**part** `object`
所添加的内容部分。

属性

part.**type**`string`
part 的类型，总是`summary_text`。


part.**text**`string`
输出的思维链文本。



---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.reasoning_summary_part.added`。

---


&nbsp;
<span id="#mObConSY"></span>
## response.reasoning_summary_part.done
> 当思维链部分完成时触发。

**item_id** `string`
所属输出项的 ID 。

---


**output_index** `integer`
所属输出项的索引 。

---


**summary_index** `integer`
输出项内，推理总结部分的子索引（若有多个总结）。

---


**part** `object`
所完成的内容部分。

属性

part.**type**`string`
part 的类型，总是`summary_text`。


part.**text**`string`
输出的思维链文本。



---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.reasoning_summary_part.done`。

---


&nbsp;
<span id="#W2TBw0hz"></span>
## response.reasoning_summary_text.delta
> 当存在思维链新增文本时触发。

**item_id** `string`
所属输出项的 ID 。

---


**output_index** `integer`
所属输出项的索引 。

---


**summary_index** `integer`
输出项内，推理总结部分的子索引（若有多个总结）。

---


**delta** `string`
输出的思维链文本增量片段。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.reasoning_summary_text.delta`。

---


&nbsp;
<span id="#YoAtCl3P"></span>
## response.reasoning_summary_text.done
> 思维链文本完成时触发。


---


**item_id** `string`
所属输出项的 ID 。

---


**output_index** `integer`
所属输出项的索引 。

---


**summary_index** `integer`
输出项内，推理总结部分的子索引（若有多个总结）。

---


**text** `string`
思维链文本完整内容。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `response.reasoning_summary_text.done`。

---


&nbsp;
<span id="#511XgGmh"></span>
## error
> 发生错误时触发。


---


**code** `string/null`
错误码。

---


**message** `string`
错误原因。

---


**param** `string/null`
错误参数。

---


**sequence_number** `integer`
事件的序列号。

---


**type** `string`
事件的类型，总是 `error`。

---


&nbsp;
&nbsp;




# Agent开发指南：“显眼包”市场策略分析和报告生成
Source: https://www.volcengine.com/docs/82379/1592797
本文通过火山方舟应用实验室的 [DeepSearch](https://console.volcengine.com/ark/region:ark+cn-beijing/application/detail?id=bot-20250414112950-6x4km-procode-preset&prev=application&projectName=default) 应用，以 “撰写研究报告、生成 PPT 并自动发送邮件” 为例，展示如何集成 MCP 服务实现复杂任务的全流程自动化。
<span id="7756e153"></span>
## **任务目标**
火山方舟应用实验室 DeepSearch 应用依托 **日志服务、联网搜索、ChatPPT、浏览器控制** 等 MCP 能力，深度整合私域数据与公开信息，解决企业级场景中的高效生产力需求。

* **场景设定**：显眼包团队需分析 AI 玩具市场动态与用户行为日志（近 14 天数据），生成《2025 年 AI 玩具市场分析及显眼包迭代建议》报告、配套 PPT，并通过 163 邮箱自动发送至指定邮件组。
* **能力介绍**：
   * **日志服务**：可存储并检索私域“显眼包抽样数据”中的用户行为与访问日志；
   * **联网搜索**： 用于搜索互联网公开域信息；
   * **必优-ChatPPT**：智能 PPT 服务，本案例中用于生成《显眼包下一代迭代方案建议》PPT； 
   * **浏览器使用**：可自动执行浏览器任务，本案例中使用浏览器自动撰写并发送 163 邮件；
   * **PromptPilot**：广场 DeepSearch 内置 PromptPilot，开启后自动实现 Prompt个性化优化。
* **演示视频**：以下视频展示了使用DeepSearch撰写研究报告，生成PPT并自动发送邮件的示例

<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cd329a51d8494adfa63e31679e16edc8~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/cd329a51d8494adfa63e31679e16edc8~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer>
<span id="bc09547e"></span>
## 前置准备

* **注册账号**：[注册火山引擎账号](https://console.volcengine.com/auth/signup) 并完成企业或个人认证，详见 [账号注册流程](https://www.volcengine.com/docs/6261/64925)。

<span id="f62624d8"></span>
## 操作步骤
<span id="0edf6074"></span>
### 启动任务

1. 访问并登录 [火山方舟控制台](https://console.volcengine.com/ark)，进入 **应用广场 -** [DeepSearch](https://console.volcengine.com/ark/region:ark+cn-beijing/application/detail?id=bot-20250414112950-6x4km-procode-preset&prev=application&projectName=default)  **- 体验应用** 页面。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/2b034a6b21eb47be93b08f29e5155420~tplv-goo7wpa0wc-image.image =1392x)
2. （可选）DeepSearch支持自定义设置问题拆解层数与MCP服务，建议开启Prompt个性化优化。您也可直接使用默认配置。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/fc6984356a584ea0b55c74cb53dd1a69~tplv-goo7wpa0wc-image.image =1445x)
3. 输入研究问题，等待任务执行完成。例如，在输入框输入以下内容：
   ```Plain Text
   请撰写一份《2025年AI玩具市场分析及显眼包迭代建议》，分析日志情况（开始时间：1747123403000，结束时间：1748335823000），并结合近期AI玩具市场的最新动态和最受欢迎的新功能进行研究。在此基础上，生成一份“显眼包下一代迭代方案建议” PPT。最终将报告内容和PPT预览链接整理为一份汇报邮件通过我的163邮箱发送至XXX
   ```


> 请将上述的邮箱地址替换为自定义收件人。


   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e794a8e8e23246d0acad414edc0db275~tplv-goo7wpa0wc-image.image =833x)

<span id="a8fcc239"></span>
### 任务执行
点击“运行”按钮后，系统将开始执行任务，其大致可分为以下几个阶段：

1. **任务规划**：DeepSearch 在分析完需求后，会进行任务拆解。如果任务计划不符合预期，可以点击 **修改任务**。确认需求后点击 **开始任务**。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/90ee3481de234578bc92fb5339233581~tplv-goo7wpa0wc-image.image =717x)
   任务执行过程中，可实时展开左下角 **任务列表** 查看执行进度。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/13d73d91c7164e3cb10f637455ea85b2~tplv-goo7wpa0wc-image.image =711x)
2. **调用 日志服务 MCP**：工具将检索广场预置的示例日志 ——「显眼包抽样数据」，并分析用户行为与访问日志。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0bd7ea99a6ec47c6b6debc0f7ceb12ef~tplv-goo7wpa0wc-image.image =1601x)
3. **调用 联网搜索 MCP**：搜索互联网公开域资料，例如近期AI玩具市场的最新动态和最受欢迎的新功能。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/80390eac252d43d69711e9c2612806a3~tplv-goo7wpa0wc-image.image =1605x)
4. **调用 ChatPPT MCP**：根据分析研究内容，并生成 “显眼包下一代迭代方案建议” PPT。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b3de60ed5ee54998b56cb34451a6bbca~tplv-goo7wpa0wc-image.image =1398x)
5. **调用 浏览器使用 MCP**：将汇总内容通过163邮箱发送至用户指定邮箱地址。
   * **支持用户接管**：浏览器使用遇到登陆场景支持用户进行主动接管，用户登陆操作完成后，可退出接管模式。
      ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3a041ce95d534cb3a8b881ab0f587166~tplv-goo7wpa0wc-image.image =1619x)
   * **成功发送邮件**：等待浏览器使用MCP 依次执行填入收件人、邮件主题、邮件正文和邮件发送操作。
      ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3224431f6f47421ca983a437c5b01bb3~tplv-goo7wpa0wc-image.image =1345x)

<span id="9bf46e58"></span>
### 个性化优化 Prompt (可选)

* 通过 DeepSearch 内置的 [PromptPilot](https://www.volcengine.com/docs/82379/1399497)，用户可对任务结果点赞 / 踩、评论反馈，系统自动优化 Prompt 参数，提升后续任务的响应精准度，反馈三次即可开启个性化优化。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e773a81eeacf4097a0dc5405d329d0a0~tplv-goo7wpa0wc-image.image =1342x)
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/87a16c01a2de4ad1a4f1b43b050e97da~tplv-goo7wpa0wc-image.image =2898x)

* 进入 [控制台-Prompt 实验室](https://console.volcengine.com/ark/region:ark+cn-beijing/autope/workbench/ta-20250520131804-r5C6F) ，您可以查看实时优化结果及智能优化报告。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/8dc37762328b4d8f8b098c8a511fce79~tplv-goo7wpa0wc-image.image =1829x)

* 在 DeepSearch 中使用个性化优化后的Prompt，可以获得更佳的模型回复效果。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c19c15fba03241e39e30443dada0b89c~tplv-goo7wpa0wc-image.image =2922x)
<span id="55c06b9c"></span>
## 创建更多同款应用

* 点击应用右上角 **复制应用**，在随后弹出的 **开通及创建授权** 窗口中，确认相关服务是否一键开通，确认无误后点击 **立即创建** （注：创建同款功能即将对个人用户开放）。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3d445261a7e2419f95d50f17d3c3cc1e~tplv-goo7wpa0wc-image.image =2167x)
* 在 **创建并部署函数** 的配置页面，按需配置以下内容：
   * 若开启 **日志服务 MCP** 服务，需选择可用于检索的日志项目和主题。
   * 若开启 **知识库 MCP** 服务，需选择可用于检索的知识库，并填写知识库描述作为 MCP Server 的描述，以便模型判断是否使用。
   * 推荐开启 **日志服务-Trace** 功能，方便后续线上问题定位和排查，同时支持通过可视化的调试面板查看会话执行细节。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3cf43932167e46b080ad03fa6264d415~tplv-goo7wpa0wc-image.image =1348x)
6. 完成配置后，点击 **确定** 开始自动部署。等待部署成功后，点击 **立即体验** 即可使用该应用。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/9a056031d4d94e758efc424a703e9015~tplv-goo7wpa0wc-image.image =1873x)

<span id="ccfbd5b7"></span>
## 附录：开源应用介绍
该案例中用到的 [DeepSearch](https://console.volcengine.com/ark/region:ark+cn-beijing/application/detail?id=bot-20250414112950-6x4km-procode-preset&prev=application&projectName=default) 为火山方舟应用实验室的开源原型应用，您可在 [应用广场](https://console.volcengine.com/ark/region:ark+cn-beijing/application) 免费体验。DeepSearch 专为应对复杂问题而设计的高效工具，集成了浏览器使用、联网搜索、知识库、网页解析等丰富的 MCP 服务。无论是学术研究、企业决策，还是产品调研场景，它都能助力用户深入挖掘信息，提出切实可行的解决策略。
此外，应用实验室汇集了更多高难度、高价值的解决方案案例，并开放源代码，助力企业快速构建大模型应用。
**开源信息：**

* DeepSearch开源地址：https://github.com/volcengine/ai-app-lab/tree/main/demohouse/deep_search_mcp/backend
* 应用实验室开源地址：https://github.com/volcengine/ai-app-lab
* 开源协议：Apache License 2.0 https://github.com/volcengine/ai-app-lab/blob/main/APACHE_LICENSE


# Agent开发指南：生成“显眼包”网站
Source: https://www.volcengine.com/docs/82379/1592796
:::tip
**嗨，小伙伴们！豆包大模型一键生成的「显眼包」网页来啦！**

* 访问地址：[http://sd13cp6meq1emkiunq5hg.apigateway-cn-beijing.volceapi.com](http://sd13cp6meq1emkiunq5hg.apigateway-cn-beijing.volceapi.com/) 

<span style="color: #646a73">   （</span><span style="color: #646a73">本网页由AI生成</span><span style="color: #646a73">）</span>
:::
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/149cef8c59b846dd9fcab6e14afb558e~tplv-goo7wpa0wc-image.image =1920x)

本文通过 [火山方舟大模型体验中心](https://www.volcengine.com/experience/ark) 调用了 Doubao、DeepSeek 等先进模型，参考用户手绘设计图与自然语言指令快速生成 HTML 代码，并借助火山引擎函数服务（veFaaS）MCP，**实现了从设计稿解析、代码生成到公网可访问网页的全流程自动化部署**。
<span id="a2406e8a"></span>
## **任务目标**

* **场景设定**：基于用户设定的需求，依据手绘设计图生成风格可爱、以蓝色为主色调的火山引擎 AI 玩偶 “显眼包” 产品网页，并将网页部署到 veFaaS，获取公网可访问链接，用于产品推广。
* **能力介绍**：
   * **模型能力**：借助 Doubao、DeepSeek 等模型，解析手绘设计图视觉元素与自然语言指令，生成符合要求的 HTML 代码。
   * **Canvas 功能**：实时预览生成的 HTML 代码效果，支持多轮对话调整网页风格、配色等细节 。
   * **函数服务（veFaaS）**：事件驱动的无服务器函数托管计算平台，实现代码上传、函数创建与运行环境配置，助力网页部署。
   * **API 网关（APIG）**：为部署的网页分配公网域名，实现安全、高效的流量转发，使网页可通过公网访问。
* **演示视频**：以下视频展示了生成“显眼包”网站 demo 的能力。

<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/abadacbcc31e474a973983b39453c668~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/abadacbcc31e474a973983b39453c668~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer>
<span id="14f60a53"></span>
## 前提条件

* **账号注册**：[注册火山引擎账号](https://console.volcengine.com/auth/signup) 并完成个人或企业认证，详见 [账号注册流程](https://www.volcengine.com/docs/6261/64925)。
* **服务开通**：
   * **开通API网关**：通过函数服务部署 Web 应用前，需先在 API 网关侧创建网关实例。开通参见 [使用流程](https://www.volcengine.com/docs/6569/82995)，操作详见 [创建实例](https://www.volcengine.com/docs/6569/85693)。
   * **对象存储（可选）**：您可体验中心内一键开通。具体使用教程见[对象存储控制台快速入门](https://www.volcengine.com/docs/6349/74830)。
   * **函数服务**：您也可在体验中心内一键开通，具体参见下文使用步骤。

> 注意：**API网关、对象存储、函数服务的使用均会产生相关计费**，请您按需开通。
> 详见 [API网关计费概述](https://www.volcengine.com/docs/6569/185249)、[对象存储计费概述](https://www.volcengine.com/docs/6349/78455)、[函数服务计费概述](https://www.volcengine.com/docs/6662/107454)。

<span id="804d0ab7"></span>
## 生成网站代码
<span id="29a1ce8f"></span>
### 操作步骤

1. 访问 [火山方舟大模型体验中心](https://www.volcengine.com/experience/ark?model=doubao-1-5-thinking-vision-pro-250428)，登录火山引擎账号。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/fa03e34fcb8d40df96ae082dbd6a8eb6~tplv-goo7wpa0wc-image.image =1766x)
2. 点击模型信息旁的切换按钮，将模型切换为 Doubao-Seed-1.6模型，250615版本。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/306c99d30b6148e2b8c7a925d345776b~tplv-goo7wpa0wc-image.image =1962x)
3. 点击 **Canvas** 按钮，打开预览 html 代码功能。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/40c62aa0546544aea84d25b7f246db8c~tplv-goo7wpa0wc-image.image =1750x)
4. 点击 **+** 符号打开附件上传界面，选择**图片上传**。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/bc8dff24286346e7b78beb6816ed0b52~tplv-goo7wpa0wc-image.image =1750x)
5. 选择一个本地手绘稿设计图上传，我们以下面的图片为例。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ab683c7139e64d629288a12aa3a429b0~tplv-goo7wpa0wc-image.image =5712x)
6. 在输入框中输入想要生成网页的具体要求（可包括网页主题、风格、配色、是否需要加入额外的产品参考素材等）。例如：
   ```Plain Text
   参考给出的手绘设计图，生成一个火山引擎AI玩偶“显眼包”产品的网页，显眼包是火山引擎送给伙伴们的礼物，网页风格可爱，主题颜色为蓝色，产品素材如下：
   1、主图：
   https://force-video-data.tos-cn-beijing.volces.com/显眼包AI玩偶/显眼包全家福.jpg
   2、细节图：
   https://force-video-data.tos-cn-beijing.volces.com/显眼包AI玩偶/3034.jpg
   https://force-video-data.tos-cn-beijing.volces.com/显眼包AI玩偶/3053.jpg
   https://force-video-data.tos-cn-beijing.volces.com/显眼包AI玩偶/3056.jpg
   https://force-video-data.tos-cn-beijing.volces.com/显眼包AI玩偶/3073.jpg
   https://force-video-data.tos-cn-beijing.volces.com/显眼包AI玩偶/3075.jpg
   https://force-video-data.tos-cn-beijing.volces.com/显眼包AI玩偶/3081.jpg
   3、产品说明书：
   https://force-video-data.tos-cn-beijing.volces.com/显眼包AI玩偶/显眼包说明书.pdf
   ```

7. 点击 **发送按钮** 开始执行任务。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/7f9314432fbb48e28ed98bd749f99c43~tplv-goo7wpa0wc-image.image =1756x)
8. 等待模型完成推理。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/18d923ed83ad416fafc5e9d040b27862~tplv-goo7wpa0wc-image.image =1964x)

<span id="0efb75fd"></span>
### 效果展示
模型推理完成后，将在右侧屏幕通过Canvas快速预览生成的html网页。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/43dc65fa38bb478386d9dfc808be0445~tplv-goo7wpa0wc-image.image =2940x)
您也可以通过顶端的 **代码/预览** 切换按钮切换显示方式。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/87e560653ed84f3fa8ebf9bbae7b016b~tplv-goo7wpa0wc-image.image =2940x)
<span id="bedc89f6"></span>
### 多轮对话优化（可选）
您可以继续通过对话让模型调整生成网页的效果。
例如：把网页主题颜色改为淡粉色，重新生成。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/aaa926ad179c495db30627b8c1e1c243~tplv-goo7wpa0wc-image.image =970x)
生成效果对比如下。

<div style="display: flex;">
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);">

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/43dc65fa38bb478386d9dfc808be0445~tplv-goo7wpa0wc-image.image =2940x)
<div style="text-align: center">优化前</div>



</div>
<div style="flex-shrink: 0;width: calc((100% - 16px) * 0.5000);margin-left: 16px;">

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/23932def2d624179aa8bd61a8c96e02e~tplv-goo7wpa0wc-image.image =2940x)
<div style="text-align: center">优化后</div>



</div>
</div>

<span id="d48a10c7"></span>
## 部署网页代码
<span id="49ada60d"></span>
### 操作步骤
<span id="aaf98743"></span>
#### 开启函数服务 MCP

1. 点击 **MCP** 按钮，打开MCP服务器管理面板。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5633dd92cbad4d1fbbfa4f00b41c680e~tplv-goo7wpa0wc-image.image =974x)
2. 开通 **函数服务（veFaaS）**。在MCP服务器管理面板中，找到 **veFaaS** 功能，点击右侧开启按钮。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d45d696517d94627be5af01d183cbcd6~tplv-goo7wpa0wc-image.image =871x)
   1. 若未开通函数服务，系统可能会提示一键授权开通，请点击 **确定开通与授权** 按钮。
      ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/56e8919df905480e8448fc911d8cc011~tplv-goo7wpa0wc-image.image =1022x)
   2. 关闭 create_zip_base64 功能，其余均保持开启。
      ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/aa8195511a2e46b191405a6af3b0a78d~tplv-goo7wpa0wc-image.image =846x)
3. 配置成功后，鼠标指向 MCP 功能，会显示已启用 veFaaS 函数服务。
   ![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0c36eed889d94ae9b5b8944f2b098772~tplv-goo7wpa0wc-image.image =993x)

<span id="32f18734"></span>
#### 执行任务
在文本框中输入部署要求，点击发送按钮。 示例输入：
```Plain Text
把生成的网页部署到veFaaS，记得上传生成的代码文件，最后给我返回一个公网可以访问的地址
```

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/48684cbe8d374b1693681eb01dd6758c~tplv-goo7wpa0wc-image.image =1946x)
模型开始推理。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/45ddec7debaf46229384e4c0fa7d6c2e~tplv-goo7wpa0wc-image.image =1122x)
<span id="ea8524f8"></span>
### 效果展示
模型推理完成后，大模型会返回部署好的网页链接信息。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/56e3e17e0c1a47539067b7534928d731~tplv-goo7wpa0wc-image.image =984x)
点击链接（[http://sd13cp6meq1emkiunq5hg.apigateway-cn-beijing.volceapi.com](http://sd13cp6meq1emkiunq5hg.apigateway-cn-beijing.volceapi.com/) ），即可预览网页部署效果。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b3dad5e93e9a41349d134db982cbed19~tplv-goo7wpa0wc-image.image =2940x)




# Agent开发指南：创作“显眼包”营销视频
Source: https://www.volcengine.com/docs/82379/1592815
本文以 “多巴胺” 热点为核心，构建了完整且智能的创作闭环。首先，通过人机交互与数据挖掘锁定营销热点，生成精准的视频创作提示词；其次，运用 Seedance-1.0-lite-i2v 和 Seedance-1.0-pro 两款专业视频生成模型，打造出三段风格鲜明的显眼包商品多巴胺风格视频；最后，借助 vevod mcp 强大的视频处理能力，完成三段视频的拼接与转场特效添加，最终输出兼具创意与传播力的优质营销视频作品，实现从热点洞察到成品落地的高效转化。
<span id="8bb8dee7"></span>
# 任务目标

* **场景设定**

用户与 “显眼包” 智能交互体沟通，捕捉到当下热门的 “多巴胺” 主题，并将其作为核心创意元素。通过接入全网内容数据与企业专属知识库的系统持续挖掘契合市场需求的营销视频热点，为后续创作提供坚实的数据支撑。

* **功能介绍**


| | | \
|MCP / 服务 |功能介绍 |
|---|---|
| | | \
|DeepSearch |一款专为处理复杂问题而精心设计的高效工具，集成了联网搜索、知识库、网页解析、Python 代码执行器等丰富的 MCP 服务 |
| | | \
|联网搜索 |联网搜索工具，用于实时搜索互联网公开域内容 |
| | | \
|知识库 |在知识库内检索内容的工具 |
| | | \
|Vevod  |通过对话交互的方式，实现多视频时域拼接、长视频分段截取与拼接、添加转场动画及字幕等剪辑操作 |
| | | \
|Seedance-1.0-pro 图生视频模型服务 |通过指定提示词和首帧图的方式，生成视频 |
| | | \
|Seedance-1.0-lite-i2v 首尾帧生视频模型服务 |通过指定提示词、首帧图和尾帧图的方式，生成视频 |


* **演示视频**：

<BytedReactXgplayer config={{ url: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/8d32f2e788f34a57a30f1acab9be47b5~tplv-goo7wpa0wc-image.image', poster: 'https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/8d32f2e788f34a57a30f1acab9be47b5~tplv-goo7wpa0wc-video-poster.jpeg' }} ></BytedReactXgplayer>
<span id="1e95d1e1"></span>
# 前置准备

* **注册火山引擎账号**：如您已有火山引擎账号，可通过该步骤。如您为未注册过火山引擎账号的企业或个人，首先请 [注册火山引擎账号](https://console.volcengine.com/auth/signup) 并完成相关认证，详见 [账号注册流程](https://www.volcengine.com/docs/6261/64925)。
* **下载Trae IDE客户端**：如果您已有Trae IDE客户端，可通过该步骤。如您未下载过Trae IDE客户端，首先请前往[Trae官方网站](https://www.trae.com.cn/?utm_source=volcengine&utm_medium=mcp-marketplace)，下载客户端并完成账号注册。

<span id="b3cd85f3"></span>
# 详细操作指南
<span id="ec97eac5"></span>
## 获取关键词
<span id="c4aea95c"></span>
### 配置DeepSearch

1. 进入[火山方舟控制台](https://console.volcengine.com/ark/region:ark+cn-beijing/application)，点击火山方舟控制台右侧导航栏【应用广场】，双击打开“DeepSearch”应用，在应用界面内选择【体验应用】。
   注：我们使用的是结合了企业知识库所创建的同款配置 DeepSearch 营销洞察版。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/29eb60d4696e42b08769c2b0f030a6f3~tplv-goo7wpa0wc-image.image =3840x)

2. 用户可在页面右侧自主配置“DeepSearch”，“DeepSearch”支持自定义设置问题拆解层数与MCP服务。MCP服务默认全部开启，建议只保留上面三个MCP服务，即联网搜索、知识库、网页解析。 

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/6de063d0949547069e2802f7135338ae~tplv-goo7wpa0wc-image.image =3163x)
<span id="b937fb4e"></span>
### 应用DeepSearch
<span id="9c7587fa"></span>
#### 输入问题
在问题输入框输入以下内容：*“我想制作一个营销视频，帮我看看网上各类营销视频热点关键词吧，尤其是各类AI玩具类的营销视频热点词。”*
<span id="af17e0c8"></span>
#### **输出结果**
DeepSearch应用返回结果：AI玩偶热点词为多巴胺。注意此处需自行部署DeepSearch，并完成知识库MCP的配置 。
<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/65cbbaffdfd34103a24b800cad2eaff5~tplv-goo7wpa0wc-image.image" width="2614px" /></div>

<span id="6c1b1965"></span>
## 获取Prompt提示词
<span id="7a464a3c"></span>
### 前置条件

* Python 3.13+
* 火山引擎账号及AccessKey/SecretKey

<span id="193cf889"></span>
### 配置 Vevod MCP 

1. 进入Trae应用，点击右上角的设置按钮打开MCP服务。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/163fe7729e984ae5b28eba9fdcdbb2e1~tplv-goo7wpa0wc-image.image =2998x)

2. 点击添加新的mcp服务，在搜索栏搜索“Vevod mcp”，点击【+】添加Vevod MCP服务。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b33369dea65641b0ab2fbd7bbf119614~tplv-goo7wpa0wc-image.image =2998x)

3. 点击【获取】“VOLCENGINE_ACCESS_KEY”和“VOLCENGINE_SECRET_KEY”按钮，跳转到“[API访问密钥](https://console.volcengine.com/iam/keymanage/)”界面，获取“Access Key ID”和“Secret Access Key”后分别填入“VOLCENGINE_ACCESS_KEY”和“VOLCENGINE_SECRET_KEY”。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/94fc56828ad244c39038e9f080f3ff6c~tplv-goo7wpa0wc-image.image =1261x)
<span id="8a099229"></span>
### **配置智能体**

1. 点击右上角的设置，进入智能体界面

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/0218f98a8a1e4ed694b978787f422db4~tplv-goo7wpa0wc-image.image =2998x)

2. 创建智能体

分别按下述信息填写相对应的信息，构建爆款智造官：
- **名称**：爆款视频智造官 
- **提示词按照如下填写**：
```bash
#角色
结合获取到的热点词,生成具备传播效果的高质量视频内容
#任务
获取到热点词,生成多条高质量的视频提示词
```

- **工具**需要选择刚才配置好的VeVOD MCP
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/e199305857074b66bc4859726f81606a~tplv-goo7wpa0wc-image.image =2998x)
<span id="7aae44b3"></span>
### 获取提示词
在对话框下方智能体中选择“爆款视频智造官”，并在问题输入框输入以下内容：“请结合当前获取到的热点关键词"多巴胺",以显眼包AI玩偶为主角,生成3个视频生成所需要的提示词”。得到智能体的回答。
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/b46a0c969c484a6a857383c9d0cfd63d~tplv-goo7wpa0wc-image.image =2598x)
<span id="ee26e4f3"></span>
## 获取视频
<span id="6bb121e9"></span>
### **前置条件**

1. 在使用 Seedance 视频生成模型前，需在火山方舟大模型服务平台的[开通管理](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&OpenTokenDrawer=false&tab=ComputerVision)页面，选择「视觉大模型」下 Seedance 1.0 lite 和 pro 的开通服务，以完成相应模型的开通操作。详细说明请参考[模型开通管理](https://www.volcengine.com/docs/82379/1159200)文档。

<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/ec4c44870fe74855b1df6207bfb8d7ea~tplv-goo7wpa0wc-image.image" width="1800px" /></div>


2. 完成视频生成模型开通后，进入火山方舟大模型服务平台的[API Key 管理](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D)页面，在此页面创建并获取 API Key，该 API Key 将用于后续的视频生成调用。

![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/3a9cf38c1c7c47b2970d95bb5eac9acc~tplv-goo7wpa0wc-image.image =3840x)
<span id="7bcf2dd1"></span>
### 生成视频

1. **基于Seedance 1.0 lite i2v 模型首尾帧功能**

打开Trae IDE客户端，选择此前创建好的“**爆款视频智造官**”智能体，将内置模型选定为“**Doubao-1.5-thinking-pro**”。随后，在对话框中输入并发送以下命令以进行视频生成操作。在此过程中，需将`Bearer`之后的API Key替换为上一步所获取的API Key 。该命令运用的是**Seedance 1.0 lite首尾帧生视频**功能，用户还可依据自身实际需求，对`text`后面的提示词以及`url`后面的图片地址进行替换。 如需了解更多关于视频生成API的使用说明，请查阅[视频生成文档](https://www.volcengine.com/docs/82379/1520757)。 
- **Trae对话框的具体命令如下**：
```bash
帮我用下述命令，生成第1段视频，并打印接口真实响应信息。
curl -X POST https://ark.cn-beijing.volces.com/api/v3/contents/generations/tasks \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer 16397bb4-c488-4107-b2e6-*********" \
  -d '{
    "model": "doubao-seedance-1-0-lite-i2v-250428",
    "content": [
        {
            "type": "text",
            "text": "图1（首帧图）玩偶在空中缓缓下落，落下的瞬间极速变化成图2（尾帧图）中玩偶的样子，落地后出现图2画面，画面中的五彩棉花糖云彩大幅度晃动，保持玩偶形象始终稳定，保持玩偶大小稳定，保持画风始终一致"
        },
        {
            "type": "image_url",
            "image_url": {
                "url": "https://video-image-test2025space.tos-cn-beijing.volces.com/%E5%9C%BA%E6%99%AF1-%E9%A6%96%E5%B8%A7.png"
            },
            "role": "first_frame"
        },
        {
            "type": "image_url",
            "image_url": {
                "url": "https://video-image-test2025space.tos-cn-beijing.volces.com/%E5%9C%BA%E6%99%AF1-%E5%B0%BE%E5%B8%A7.png"
            },
            "role": "last_frame"
        }
    ]
}'

```
- **操作展示图如下**：
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/1455b400427744ffb8e7208db32ecb88~tplv-goo7wpa0wc-image.image =2880x)

2. **基于Seedance 1.0 pro 模型图生视频功能**

同样地，将内置模型选定为“**Doubao-1.5-thinking-pro**”，在对话框中输入并发送以下命令以进行视频生成操作。同样需将`Bearer`之后的API Key替换为前面所获取的API Key 。该命令运用的是**Seedance 1.0 pro图生视频**功能，用户还可依据自身实际需求，对`text`后面的提示词以及`url`后面的图片地址进行替换。 
- **Trae对话框的具体命令如下**：
```bash
帮我用下述命令，分别生成第2段视频和第3段视频，并打印接口真实响应信息。
注意将命令中的{prompt}分别替换成下述两组prompt，并将命令中的 {image_url} 替换为下述两组图片地址
第2段视频对应的prompt：
画面中云彩晃动起来，城堡的门打开，图中穿着粉色衣服戴着粉色墨镜的蓝色玩偶走出来，一直走到热气球旁边。首帧开始，保持玩偶形象始终稳定，保持玩偶大小稳定，超高清，4k画质，细节丰富
第2段视频对应的图片地址 https://video-image-test2025space.tos-cn-beijing.volces.com/%E5%9C%BA%E6%99%AF2-%E5%9B%BE%E7%89%87new.png
第3段视频对应的prompt：
图中坐着热气球的玩偶向上坐着热气球飞出图画，热气球中的黄色火焰自然燃烧，画面中的五彩棉花糖云彩大幅度晃动，保持玩偶形象始终稳定，保持玩偶大小稳定
第3段视频对应的图片地址 https://video-image-test2025space.tos-cn-beijing.volces.com/%E5%9C%BA%E6%99%AF3-%E5%9B%BE%E7%89%87.png

curl -X POST https://ark.cn-beijing.volces.com/api/v3/contents/generations/tasks \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer 16397bb4-c488-4107-b2e6-*********" \
  -d '{
    "model": "doubao-seedance-1-0-pro-250528",
    "content": [
        {
            "type": "text",
            "text": "{prompt}"
        },
        {
            "type": "image_url",
            "image_url": {
                "url": "{image_url}"
            }
        }
    ]
}'

```
- **操作图如下**：
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/c4e818ffe21b4da1b1a2668ba2880fb2~tplv-goo7wpa0wc-image.image =2880x)
<span id="29e23d81"></span>
### **查询进度**
完成视频生成任务创建后，将内置模型选定为“**Doubao-1.5-thinking-pro**”，在对话框中输入并发送以下命令以进行视频生成结果的查询操作。在此过程中，同样要将`Bearer`之后的API Key替换为之前获取到的API Key。 
- **Trae对话框的具体命令如下**：
```bash
帮我根据上述3组响应中的id字段，分别用下述命令查询视频生成的进度，并打印真实响应信息
curl -X GET https://ark.cn-beijing.volces.com/api/v3/contents/generations/tasks/{id} \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer 16397bb4-c488-4107-b2e6-*********"
```
- **效果展示图如下**：
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/f5dbfffbfa084a97a0c1791c46dfb9d1~tplv-goo7wpa0wc-image.image =2234x)
<span id="7597042e"></span>
### 视频拼接
以下将运用 VeVOD MCP 对上述视频进行拼接，并添加视频转场效果，将内置模型选定为“**Doubao-1.5-thinking-pro**”，在对话框中输入并发送以下命令以进行视频拼接和添加转场操作。在具体操作中，选用的是泛开的转场效果。若需了解和选用更多转场效果，可查阅[转场效果](https://www.volcengine.com/docs/4/102412#%E8%BD%AC%E5%9C%BA-id)说明文档。 
- **Trae对话框的具体命令如下**：
```bash
将上述三个视频下载地址对应的5s视频，依次拼接在一起合成一个新的15s视频，每两段视频之间添加泛开的转场效果，可以用mcp-test-space空间
```
- **效果展示图如下**：
![Image](https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/5f219a67ee23428db1414d342beffc5d~tplv-goo7wpa0wc-image.image =3028x)
<span id="464c15c0"></span>
### 视频查看&下载
完成上述操作后，前往火山引擎-[视频点播界面](https://console.volcengine.com/vod/region:vod+cn-north-1/overview/)，点击然后进入mcp-test-space空间。
<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/d8a9eaa5190a456195170cc7458b175e~tplv-goo7wpa0wc-image.image" width="2880px" /></div>

在此查看并可以下载最终制作完成的视频，如下图所示。
<div style="text-align: center"><img src="https://p9-arcosite.byteimg.com/tos-cn-i-goo7wpa0wc/a2bea790bc214c1a99a4780086314b59~tplv-goo7wpa0wc-image.image" width="2850px" /></div>

<span id="e515c32b"></span>
# 附录：开源应用介绍

* 该案例中用到的 [DeepSearch](https://console.volcengine.com/ark/region:ark+cn-beijing/application/detail?id=bot-20250414112950-6x4km-procode-preset&prev=application) 为火山方舟应用实验室 的 开源原型应用，您可在[应用广场](https://console.volcengine.com/ark/region:ark+cn-beijing/application)免费体验。DeepSearch 专为应对复杂问题而设计的高效工具，集成了浏览器使用、联网搜索、知识库、网页解析等丰富的 MCP 服务。无论是学术研究、企业决策，还是产品调研场景，它都能助力用户深入挖掘信息，提出切实可行的解决策略。
* 此外，应用实验室汇集了更多高难度、高价值的解决方案案例，并开放源代码，助力企业快速构建大模型应用。
* **开源信息**：
   * DeepSearch开源地址：https://github.com/volcengine/ai-app-lab/tree/main/demohouse/deep_search_mcp/backend
   * 应用实验室开源地址：https://github.com/volcengine/ai-app-lab
   * 开源协议：Apache License 2.0 https://github.com/volcengine/ai-app-lab/blob/main/APACHE_LICENSE


